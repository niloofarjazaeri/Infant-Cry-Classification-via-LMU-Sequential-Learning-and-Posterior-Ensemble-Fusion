{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07479379-0836-40cb-801d-16dc9a4dc399",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3719b62-d8d3-49b6-af63-a0847cb5274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_path = \"Chinese Babycry\"\n",
    "output_zip = \"Chinese Babycry\"\n",
    "\n",
    "# This will create myfolder.zip\n",
    "#shutil.make_archive(output_zip, 'zip', folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d50cc07-9964-442a-81d7-f5f3ac8d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_conf_wave_train_dir = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "f0_conf_wave_test_dir = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "audio_train_dir = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir = \"Chinese Babycry/Test_Split_20\"\n",
    "\n",
    "\n",
    "f0_conf_wave_train_dir = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "f0_conf_wave_test_dir = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "audio_train_dir = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir = \"Chinese Babycry/Test_Split_20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e192c-1689-42f6-b260-86e8f4d751f7",
   "metadata": {},
   "source": [
    "# Loading all F0 wave cof in big train test and labels dataset and encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9acc3d-de6b-4b83-8b93-c7ece9581915",
   "metadata": {},
   "source": [
    "It already extracted by Crepe and resized to median but even if it is not resized it is gonna be in this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cb19a-8f28-40aa-be52-3c4f3e0d13a2",
   "metadata": {},
   "source": [
    "## How I extracted F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a102a1e8-705b-4040-997e-76ddad9fd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# import os\n",
    "# import sys\n",
    "# import glob\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "# import crepe\n",
    "# from pathlib import Path\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # --------------------------\n",
    "# # CONFIG\n",
    "# # --------------------------\n",
    "# PATH_TRAIN = r\"H:\\Crynostics\\Datas\\Chinese Baby_Crying940\\Reverb_Test_Split_20\"  # root with class subfolders\n",
    "# OUT_ROOT   = r\"H:\\Crynostics\\Datas\\Chinese Baby_Crying940\\Reverb_Test_Split_20_f0_wave_conf_arrays\"            # where to save arrays\n",
    "# TARGET_SR  = 16000\n",
    "# STEP_SAMPLES = 200          # CREPE hop in samples @ 16k (200 -> 12.5 ms)\n",
    "# CREPE_CAPACITY = \"medium\"   # \"tiny\"|\"small\"|\"medium\"|\"large\"|\"full\"\n",
    "# USE_VITERBI = True\n",
    "# ALLOWED_EXT = (\".wav\", \".flac\", \".ogg\")  # extend if needed\n",
    "\n",
    "# # --------------------------\n",
    "# # HELPERS\n",
    "# # --------------------------\n",
    "# def load_mono_and_resample(path: str, target_sr: int) -> tuple[np.ndarray, int]:\n",
    "#     \"\"\"Load audio as mono float32 and resample to target_sr if needed.\"\"\"\n",
    "#     y, sr = sf.read(path, always_2d=False)\n",
    "#     if isinstance(y, np.ndarray) and y.ndim > 1:\n",
    "#         y = y.mean(axis=1)\n",
    "#     y = y.astype(np.float32, copy=False)\n",
    "#     if sr != target_sr:\n",
    "#         y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "#         sr = target_sr\n",
    "#     return y, sr\n",
    "\n",
    "# def f0_crepe(y16: np.ndarray, sr16: int, step_samples: int, capacity: str, viterbi: bool):\n",
    "#     \"\"\"Run CREPE F0; returns (time_s, f0_hz, confidence).\"\"\"\n",
    "#     time_s, f0_hz, conf, _ = crepe.predict(\n",
    "#         y16, sr16,\n",
    "#         step_size=step_samples,\n",
    "#         viterbi=viterbi,\n",
    "#         model_capacity=capacity,\n",
    "#         verbose=0\n",
    "#     )\n",
    "#     return time_s.astype(np.float32), f0_hz.astype(np.float32), conf.astype(np.float32)\n",
    "\n",
    "# def waveform_on_grid(y16: np.ndarray, sr16: int, t_grid_s: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"Sample waveform at exact CREPE frame centers (nearest-neighbor).\"\"\"\n",
    "#     idx = np.clip((t_grid_s * sr16).astype(int), 0, len(y16) - 1)\n",
    "#     return y16[idx].astype(np.float32)\n",
    "\n",
    "# def make_out_path(out_root: str, class_label: str, wav_path: str) -> str:\n",
    "#     \"\"\"Create class subdir and build .npy filename from input wav stem.\"\"\"\n",
    "#     stem = Path(wav_path).stem\n",
    "#     class_dir = Path(out_root) / class_label\n",
    "#     class_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     return str(class_dir / f\"{stem}_f0_wave_conf.npy\")\n",
    "\n",
    "# # --------------------------\n",
    "# # SCAN FILES\n",
    "# # --------------------------\n",
    "# def list_audio_files(root: str) -> list[tuple[str, str]]:\n",
    "#     \"\"\"\n",
    "#     Return a list of (wav_path, class_label), assuming structure:\n",
    "#       root/<class_label>/*.(wav/flac/ogg)\n",
    "#     \"\"\"\n",
    "#     out = []\n",
    "#     for class_dir in sorted(Path(root).glob(\"*\")):\n",
    "#         if not class_dir.is_dir():\n",
    "#             continue\n",
    "#         label = class_dir.name\n",
    "#         for ext in ALLOWED_EXT:\n",
    "#             for p in class_dir.rglob(f\"*{ext}\"):\n",
    "#                 out.append((str(p), label))\n",
    "#     return out\n",
    "\n",
    "# # --------------------------\n",
    "# # MAIN\n",
    "# # --------------------------\n",
    "# def main():\n",
    "#     files = list_audio_files(PATH_TRAIN)\n",
    "#     if not files:\n",
    "#         print(f\"No audio files found under: {PATH_TRAIN}\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     Path(OUT_ROOT).mkdir(parents=True, exist_ok=True)\n",
    "#     manifest_path = Path(OUT_ROOT) / \"manifest.csv\"\n",
    "\n",
    "#     # Write CSV header\n",
    "#     with open(manifest_path, \"w\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "#         w = csv.writer(fcsv)\n",
    "#         w.writerow([\n",
    "#             \"input_path\", \"class_label\", \"array_path\",\n",
    "#             \"n_frames\", \"duration_s\", \"sr\", \"step_samples\"\n",
    "#         ])\n",
    "\n",
    "#     with tqdm(total=len(files), desc=\"Processing files\", unit=\"file\") as pbar:\n",
    "#         for wav_path, label in files:\n",
    "#             try:\n",
    "#                 # 1) Load + resample to 16 kHz mono\n",
    "#                 y16, sr16 = load_mono_and_resample(wav_path, TARGET_SR)\n",
    "#                 duration_s = len(y16) / float(sr16)\n",
    "\n",
    "#                 # 2) CREPE F0\n",
    "#                 time_s, f0_hz, conf = f0_crepe(\n",
    "#                     y16, sr16,\n",
    "#                     step_samples=STEP_SAMPLES,\n",
    "#                     capacity=CREPE_CAPACITY,\n",
    "#                     viterbi=USE_VITERBI\n",
    "#                 )\n",
    "\n",
    "#                 # 3) Waveform sampled on the same grid\n",
    "#                 wave_grid = waveform_on_grid(y16, sr16, time_s)\n",
    "\n",
    "#                 # 4) Stack rows: [waveform; f0; confidence] -> (3, T)\n",
    "#                 arr = np.vstack([wave_grid, f0_hz, conf]).astype(np.float32)\n",
    "\n",
    "#                 # 5) Save\n",
    "#                 out_npy = make_out_path(OUT_ROOT, label, wav_path)\n",
    "#                 np.save(out_npy, arr)\n",
    "\n",
    "#                 # 6) Append manifest\n",
    "#                 with open(manifest_path, \"a\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "#                     w = csv.writer(fcsv)\n",
    "#                     w.writerow([\n",
    "#                         wav_path, label, out_npy,\n",
    "#                         arr.shape[1], f\"{duration_s:.6f}\", sr16, STEP_SAMPLES\n",
    "#                     ])\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 # Log failures but keep going\n",
    "#                 err_line = f\"[ERROR] {wav_path} ({label}): {e}\"\n",
    "#                 print(err_line)\n",
    "\n",
    "#             pbar.update(1)\n",
    "\n",
    "#     print(\"\\nDone.\")\n",
    "#     print(f\"Saved arrays under: {OUT_ROOT}\")\n",
    "#     print(f\"Manifest: {manifest_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d3e6f-3c2e-4ff6-a2b6-1744a639d775",
   "metadata": {},
   "source": [
    "# How I loaded f0 wave confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3eb262-b4b7-4739-9a05-87ecc0d9e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F0 files: 184\n",
      "Train F0 files: 734\n",
      "Median length test: 107\n",
      "Median length train: 108\n",
      "resized version test:  (3, 108) old version test:  (3, 135)\n",
      "resized version train:  (3, 108) old version train:  (3, 126)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def load_npy_data(base_dir):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    array = np.load(file_path)  # shape (3, X)\n",
    "                    feature_list.append(array)\n",
    "                    label_list.append(os.path.basename(root))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "    features_df = pd.DataFrame({'features': feature_list})\n",
    "    labels_df = pd.DataFrame({'folder': label_list})\n",
    "    return features_df, labels_df\n",
    "\n",
    "\n",
    "# Load test STFT data\n",
    "test_F0_df, test_label = load_npy_data(f0_conf_wave_test_dir)\n",
    "\n",
    "# Load train MFCC data\n",
    "train_F0_df, train_label = load_npy_data(f0_conf_wave_train_dir)\n",
    "\n",
    "train_F0_df.reset_index(drop=True, inplace=True)\n",
    "test_F0_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Optional: check number of samples loaded\n",
    "print(f\"Test F0 files: {len(test_F0_df)}\")\n",
    "print(f\"Train F0 files: {len(train_F0_df)}\")\n",
    "\n",
    "# Compute lengths of each array (X dimension)\n",
    "lengths_test = test_F0_df['features'].apply(lambda x: x.shape[1])\n",
    "lengths_train = train_F0_df['features'].apply(lambda x: x.shape[1])\n",
    "\n",
    "median_length_test = int(np.median(lengths_test))\n",
    "median_length_train = int(np.median(lengths_train))\n",
    "\n",
    "print(\"Median length test:\", median_length_test)\n",
    "print(\"Median length train:\", median_length_train)\n",
    "\n",
    "\n",
    "def resize_sequence(seq, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (3, X) sequence along the X axis to target_len.\n",
    "    \"\"\"\n",
    "    seq = np.array(seq)\n",
    "    rows, current_len = seq.shape\n",
    "\n",
    "    if current_len == target_len:\n",
    "        return seq\n",
    "    else:\n",
    "        resized = np.zeros((rows, target_len))\n",
    "        original_idx = np.linspace(0, 1, current_len)\n",
    "        target_idx = np.linspace(0, 1, target_len)\n",
    "        for i in range(rows):\n",
    "            f = interp1d(original_idx, seq[i, :], kind='linear')\n",
    "            resized[i, :] = f(target_idx)\n",
    "        return resized\n",
    "\n",
    "\n",
    "# Usage example: resize all sequences in a DataFrame column\n",
    "target_length = median_length_train  # or any fixed length\n",
    "test_F0_df['resized_features'] = test_F0_df['features'].apply(lambda x: resize_sequence(x, target_length))\n",
    "train_F0_df['resized_features'] = train_F0_df['features'].apply(lambda x: resize_sequence(x, target_length))\n",
    "\n",
    "print(\"resized version test: \", test_F0_df['resized_features'][10].shape,\n",
    "      \"old version test: \", test_F0_df['features'][10].shape)\n",
    "\n",
    "print(\"resized version train: \", train_F0_df['resized_features'][10].shape,\n",
    "      \"old version train: \", train_F0_df['features'][10].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935ea13-19b2-4ba1-a372-37856ec43b21",
   "metadata": {},
   "source": [
    "# Integrate all Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5305c-8277-49b1-955d-d9cbc9a43ad2",
   "metadata": {},
   "source": [
    "# MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7e4734-79c4-438e-92b7-6e32c119a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio files: 734\n",
      "Test  audio files: 184\n",
      "Median time frames (train): 1096 (win=480 samples, hop=240 samples @ 16000 Hz)\n",
      "Train sample shapes: (20, 1644) -> (20, 1096)\n",
      "Test  sample shapes: (20, 1201) -> (20, 1096)\n",
      "X_train: (734, 20, 1096) X_test: (184, 20, 1096)\n",
      "Classes: ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# Params\n",
    "# -----------------------------\n",
    "SR = 16000           # target sample rate\n",
    "FRAME_MS = 30.0      # window length (ms) = frame size\n",
    "HOP_MS = 15.0        # hop length (ms). Use 30.0 if you want no overlap\n",
    "N_MFCC = 20          # MFCC coefficients (common: 13 or 20)\n",
    "AUDIO_EXTS = {\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\"}\n",
    "\n",
    "WIN_LENGTH = int(round(SR * FRAME_MS / 1000.0))\n",
    "HOP_LENGTH = int(round(SR * HOP_MS   / 1000.0))\n",
    "N_FFT = 1\n",
    "while N_FFT < WIN_LENGTH:  # next power of two >= win_length (librosa-friendly)\n",
    "    N_FFT <<= 1\n",
    "\n",
    "def is_audio_file(path):\n",
    "    return os.path.splitext(path)[1].lower() in AUDIO_EXTS\n",
    "\n",
    "def compute_mfcc(file_path, sr=SR, n_mfcc=N_MFCC,\n",
    "                 n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Returns MFCC array of shape (n_mfcc, T).\n",
    "    \"\"\"\n",
    "    y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    # Use center=True (default) for better coverage at edges\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=n_mfcc,\n",
    "        n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "        center=True\n",
    "    )\n",
    "    return mfcc  # (n_mfcc, T)\n",
    "\n",
    "def load_mfcc_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Walks class-labeled subfolders under root_dir, computes MFCC for each audio.\n",
    "    Returns a DataFrame with columns: ['mfcc', 'label', 'path'].\n",
    "    \"\"\"\n",
    "    feats, labels, paths = [], [], []\n",
    "    for class_dir in sorted(os.listdir(root_dir)):\n",
    "        class_path = os.path.join(root_dir, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if not os.path.isfile(fpath) or not is_audio_file(fpath):\n",
    "                continue\n",
    "            try:\n",
    "                mfcc = compute_mfcc(fpath)\n",
    "                feats.append(mfcc)\n",
    "                labels.append(class_dir)\n",
    "                paths.append(fpath)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipped {fpath}: {e}\")\n",
    "    df = pd.DataFrame({\"mfcc\": feats, \"label\": labels, \"path\": paths})\n",
    "    return df\n",
    "\n",
    "def resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (C, T) feature matrix along time axis to target_len using linear interp.\n",
    "    C = channels/features (e.g., n_mfcc), T = time frames.\n",
    "    \"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "\n",
    "    # Build interpolation index\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (update these)\n",
    "# -----------------------------\n",
    "train_audio_root = r\".../Train\"  # each subfolder is a class\n",
    "test_audio_root  = r\".../Test\"   # each subfolder is a class\n",
    "\n",
    "# -----------------------------\n",
    "# Load MFCCs\n",
    "# -----------------------------\n",
    "train_df = load_mfcc_dataset(audio_train_dir)\n",
    "test_df  = load_mfcc_dataset(audio_test_dir)\n",
    "\n",
    "# Optional: sanity check\n",
    "print(f\"Train audio files: {len(train_df)}\")\n",
    "print(f\"Test  audio files: {len(test_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Determine target length (median frames of TRAIN)\n",
    "# -----------------------------\n",
    "train_lengths = train_df[\"mfcc\"].apply(lambda m: m.shape[1])\n",
    "test_lengths  = test_df[\"mfcc\"].apply(lambda m: m.shape[1])\n",
    "\n",
    "target_len = int(np.median(train_lengths))\n",
    "print(f\"Median time frames (train): {target_len} \"\n",
    "      f\"(win={WIN_LENGTH} samples, hop={HOP_LENGTH} samples @ {SR} Hz)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Resize MFCCs along time axis\n",
    "# -----------------------------\n",
    "train_df[\"mfcc_resized\"] = train_df[\"mfcc\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "test_df[\"mfcc_resized\"]  = test_df[\"mfcc\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "\n",
    "# Example: shapes before/after\n",
    "i = min(10, len(train_df)-1)\n",
    "j = min(10, len(test_df)-1)\n",
    "print(\"Train sample shapes:\", train_df.loc[i, \"mfcc\"].shape, \"->\", train_df.loc[i, \"mfcc_resized\"].shape)\n",
    "print(\"Test  sample shapes:\", test_df.loc[j, \"mfcc\"].shape, \"->\", test_df.loc[j, \"mfcc_resized\"].shape)\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Pack arrays for modeling\n",
    "# X_train: (N, n_mfcc, target_len), y_train: labels\n",
    "# -----------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"].values)\n",
    "y_test  = le.transform(test_df[\"label\"].values) if set(test_df[\"label\"]) <= set(le.classes_) else \\\n",
    "          le.fit_transform(test_df[\"label\"].values)  # fallback if classes differ\n",
    "\n",
    "X_train_mfcc = np.stack(train_df[\"mfcc_resized\"].values, axis=0)\n",
    "X_test_mfcc  = np.stack(test_df[\"mfcc_resized\"].values, axis=0)\n",
    "\n",
    "print(\"X_train:\", X_train_mfcc.shape, \"X_test:\", X_test_mfcc.shape)\n",
    "print(\"Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d09884-c355-4148-9438-663453c1e565",
   "metadata": {},
   "source": [
    "# STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73482e7c-bf19-422c-a0e8-f49ccfe10821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio files: 734\n",
      "Test  audio files: 184\n",
      "Median time frames (train): 1096 (win=480 samples, hop=240 samples @ 16000 Hz, n_fft=512)\n",
      "Train sample shapes: (257, 1644) -> (257, 1096)\n",
      "Test  sample shapes: (257, 1201) -> (257, 1096)\n",
      "X_train: (734, 257, 1096) X_test: (184, 257, 1096)\n",
      "Classes: ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# Params\n",
    "# -----------------------------\n",
    "SR = 16000           # target sample rate\n",
    "FRAME_MS = 30.0      # window length (ms) = frame size\n",
    "HOP_MS = 15.0        # hop length (ms). Use 30.0 if you want no overlap\n",
    "AUDIO_EXTS = {\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\"}\n",
    "\n",
    "# STFT scaling options\n",
    "POWER = 1.0          # 1.0 = magnitude, 2.0 = power\n",
    "TO_DB = True         # convert to dB (log scale) for nicer dynamics\n",
    "DB_REF = 1.0         # reference for dB conversion (librosa default is max if ref=np.max)\n",
    "\n",
    "WIN_LENGTH = int(round(SR * FRAME_MS / 1000.0))\n",
    "HOP_LENGTH = int(round(SR * HOP_MS   / 1000.0))\n",
    "N_FFT = 1\n",
    "while N_FFT < WIN_LENGTH:  # next power of two >= win_length (librosa-friendly)\n",
    "    N_FFT <<= 1\n",
    "\n",
    "def is_audio_file(path):\n",
    "    return os.path.splitext(path)[1].lower() in AUDIO_EXTS\n",
    "\n",
    "def compute_stft(file_path,\n",
    "                 sr=SR, n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH,\n",
    "                 power=POWER, to_db=TO_DB, db_ref=DB_REF):\n",
    "    \"\"\"\n",
    "    Returns STFT feature of shape (freq_bins, T).\n",
    "    By default: |STFT|^POWER, optionally converted to dB.\n",
    "    \"\"\"\n",
    "    y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    S_complex = librosa.stft(\n",
    "        y,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window='hann',\n",
    "        center=True\n",
    "    )\n",
    "    S_mag = np.abs(S_complex) ** power  # (n_fft//2+1, T)\n",
    "\n",
    "    if to_db:\n",
    "        # Avoid -inf by using a small floor; librosa handles this internally\n",
    "        S_feat = librosa.amplitude_to_db(S_mag, ref=db_ref) if power == 1.0 \\\n",
    "                 else librosa.power_to_db(S_mag, ref=db_ref)\n",
    "    else:\n",
    "        S_feat = S_mag\n",
    "\n",
    "    return S_feat.astype(np.float32)\n",
    "\n",
    "def load_stft_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Walks class-labeled subfolders under root_dir, computes STFT for each audio.\n",
    "    Returns a DataFrame with columns: ['stft', 'label', 'path'].\n",
    "    \"\"\"\n",
    "    feats, labels, paths = [], [], []\n",
    "    for class_dir in sorted(os.listdir(root_dir)):\n",
    "        class_path = os.path.join(root_dir, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if not os.path.isfile(fpath) or not is_audio_file(fpath):\n",
    "                continue\n",
    "            try:\n",
    "                stft = compute_stft(fpath)\n",
    "                feats.append(stft)           # (F, T)\n",
    "                labels.append(class_dir)\n",
    "                paths.append(fpath)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipped {fpath}: {e}\")\n",
    "    return pd.DataFrame({\"stft\": feats, \"label\": labels, \"path\": paths})\n",
    "\n",
    "def resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (C, T) feature matrix along the time axis to target_len using linear interpolation.\n",
    "    C = channels/frequency bins, T = time frames.\n",
    "    \"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (update these)\n",
    "# -----------------------------\n",
    "train_audio_root = r\".../Train\"  # each subfolder is a class\n",
    "test_audio_root  = r\".../Test\"   # each subfolder is a class\n",
    "\n",
    "# -----------------------------\n",
    "# Load STFTs\n",
    "# -----------------------------\n",
    "train_df = load_stft_dataset(audio_train_dir)\n",
    "test_df  = load_stft_dataset(audio_test_dir)\n",
    "\n",
    "print(f\"Train audio files: {len(train_df)}\")\n",
    "print(f\"Test  audio files: {len(test_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Determine target length (median frames of TRAIN)\n",
    "# -----------------------------\n",
    "train_lengths = train_df[\"stft\"].apply(lambda m: m.shape[1])\n",
    "test_lengths  = test_df[\"stft\"].apply(lambda m: m.shape[1])\n",
    "\n",
    "target_len = int(np.median(train_lengths))\n",
    "print(f\"Median time frames (train): {target_len} \"\n",
    "      f\"(win={WIN_LENGTH} samples, hop={HOP_LENGTH} samples @ {SR} Hz, n_fft={N_FFT})\")\n",
    "\n",
    "# -----------------------------\n",
    "# Resize STFTs along time axis\n",
    "# -----------------------------\n",
    "train_df[\"stft_resized\"] = train_df[\"stft\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "test_df[\"stft_resized\"]  = test_df[\"stft\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "\n",
    "# Example: shapes before/after\n",
    "i = min(10, len(train_df)-1)\n",
    "j = min(10, len(test_df)-1)\n",
    "print(\"Train sample shapes:\", train_df.loc[i, \"stft\"].shape, \"->\", train_df.loc[i, \"stft_resized\"].shape)\n",
    "print(\"Test  sample shapes:\", test_df.loc[j, \"stft\"].shape, \"->\", test_df.loc[j, \"stft_resized\"].shape)\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Pack arrays for modeling\n",
    "# X_train: (N, F, target_len), y_train: labels\n",
    "# -----------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([train_df[\"label\"], test_df[\"label\"]], axis=0))\n",
    "\n",
    "y_train_stft = le.transform(train_df[\"label\"].values)\n",
    "y_test  = le.transform(test_df[\"label\"].values)\n",
    "\n",
    "X_train_stft = np.stack(train_df[\"stft_resized\"].values, axis=0)  # (N, F, T)\n",
    "X_test_stft  = np.stack(test_df[\"stft_resized\"].values, axis=0)\n",
    "\n",
    "print(\"X_train:\", X_train_stft.shape, \"X_test:\", X_test_stft.shape)\n",
    "print(\"Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521370d-f638-4e48-94dc-668197181f77",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5ecbff-94a9-421f-a7c0-7af0cacc113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-COMBINE SUMMARY: TRAIN ===\n",
      "STFT_train: N=734, example (C,T)=(257,1096)\n",
      "  Channels (C) ~ 257 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "MFCC_train: N=734, example (C,T)=(20,1096)\n",
      "  Channels (C) ~ 20 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "F0_train: N=734, example (C,T)=(3,108)\n",
      "  Channels (C) ~ 3 (assumed constant)\n",
      "  Time frames (T): min=108, median=108, max=108\n",
      "\n",
      "=== PRE-COMBINE SUMMARY: TEST ===\n",
      "STFT_test: N=184, example (C,T)=(257,1096)\n",
      "  Channels (C) ~ 257 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "MFCC_test: N=184, example (C,T)=(20,1096)\n",
      "  Channels (C) ~ 20 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "F0_test: N=184, example (C,T)=(3,108)\n",
      "  Channels (C) ~ 3 (assumed constant)\n",
      "  Time frames (T): min=108, median=108, max=108\n",
      "\n",
      "Target time length (frames): train=1096, test=1096\n",
      "\n",
      "=== POST-COMBINE SHAPES ===\n",
      "Train_combined (N, T, F): (734, 1096, 280)\n",
      "Test_combined  (N, T, F): (184, 1096, 280)\n",
      "One train sample (T,F): (1096, 280)\n",
      "One test  sample (T,F): (1096, 280)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _pick_col(df, candidates=(\"stft_resized\",\"mfcc_resized\",\"resized_features\",\"features\",\"stft\",\"mfcc\")):\n",
    "    for c in candidates:\n",
    "        if isinstance(df, pd.DataFrame) and c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(f\"No feature column found. Tried: {candidates}\")\n",
    "\n",
    "def _len_source(source):\n",
    "    if isinstance(source, pd.DataFrame):\n",
    "        return len(source)\n",
    "    return source.shape[0]  # assume ndarray (N, ...)\n",
    "\n",
    "def _get_sample_feat(source, i):\n",
    "    \"\"\"\n",
    "    Returns a (C, T) float32 array for sample i from either:\n",
    "      - DataFrame with a feature column, or\n",
    "      - NumPy array shaped (N, C, T)\n",
    "    \"\"\"\n",
    "    if isinstance(source, pd.DataFrame):\n",
    "        col = _pick_col(source)\n",
    "        arr = source[col].iloc[i]\n",
    "    else:  # ndarray\n",
    "        arr = source[i]\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"Expected per-sample 2D (C,T); got {arr.shape}\")\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def _resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"Resize (C, T) -> (C, target_len) by linear interpolation over time axis.\"\"\"\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "    orig = np.linspace(0.0, 1.0, T, endpoint=True)\n",
    "    tgt  = np.linspace(0.0, 1.0, target_len, endpoint=True)\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt)\n",
    "    return out\n",
    "\n",
    "def _combine_three_modalities(stft_feat, mfcc_feat, f0_feat, target_len):\n",
    "    \"\"\"\n",
    "    All inputs are (C, T). They are resized to the same target_len and concatenated on C.\n",
    "    Returns (T, C_total).\n",
    "    \"\"\"\n",
    "    stft_feat = _resize_time_axis(stft_feat, target_len)\n",
    "    mfcc_feat = _resize_time_axis(mfcc_feat, target_len)\n",
    "    f0_feat   = _resize_time_axis(f0_feat,   target_len)\n",
    "    CxT = np.concatenate([stft_feat, mfcc_feat, f0_feat], axis=0)  # (C_total, T)\n",
    "    return CxT.T  # (T, C_total)\n",
    "\n",
    "def _time_lengths(source):\n",
    "    \"\"\"Return a list of T (time frames) for all samples in source.\"\"\"\n",
    "    n = _len_source(source)\n",
    "    Ts = []\n",
    "    for i in range(n):\n",
    "        C, T = _get_sample_feat(source, i).shape\n",
    "        Ts.append(T)\n",
    "    return np.array(Ts, dtype=int)\n",
    "\n",
    "def _channels_first(source):\n",
    "    \"\"\"Return channel dimension (C) of the first sample.\"\"\"\n",
    "    C, T = _get_sample_feat(source, 0).shape\n",
    "    return C\n",
    "\n",
    "def _summarize(name, source):\n",
    "    \"\"\"\n",
    "    Print N, example shape, channels, and time stats (min/median/max) for a dataset.\n",
    "    \"\"\"\n",
    "    n = _len_source(source)\n",
    "    C0 = _channels_first(source)\n",
    "    Ts = _time_lengths(source)\n",
    "    print(f\"{name}: N={n}, example (C,T)=({C0},{Ts[0]})\")\n",
    "    print(f\"  Channels (C) ~ {C0} (assumed constant)\")\n",
    "    print(f\"  Time frames (T): min={Ts.min()}, median={int(np.median(Ts))}, max={Ts.max()}\")\n",
    "\n",
    "def _stack_combined(stft_src, mfcc_src, f0_src, target_len=None):\n",
    "    \"\"\"\n",
    "    Build (N, T, F) by concatenating STFT, MFCC, F0 along features for each sample.\n",
    "    Ensures uniform T across samples by using:\n",
    "      - provided target_len, or\n",
    "      - median T of STFT set if target_len is None.\n",
    "    \"\"\"\n",
    "    n = min(_len_source(stft_src), _len_source(mfcc_src), _len_source(f0_src))\n",
    "    if n == 0:\n",
    "        raise ValueError(\"No samples to combine.\")\n",
    "\n",
    "    # Decide a uniform target length\n",
    "    if target_len is None:\n",
    "        target_len = int(np.median(_time_lengths(stft_src)))  # use STFT's median frames\n",
    "\n",
    "    combined = []\n",
    "    for i in range(n):\n",
    "        stft_i = _get_sample_feat(stft_src, i)   # (F_stft, T_s)\n",
    "        mfcc_i = _get_sample_feat(mfcc_src, i)   # (C_mfcc, T_m)\n",
    "        f0_i   = _get_sample_feat(f0_src, i)     # (3, T_f0)\n",
    "        combined_i = _combine_three_modalities(stft_i, mfcc_i, f0_i, target_len=target_len)  # (T, F_total)\n",
    "        combined.append(combined_i)\n",
    "    return np.stack(combined, axis=0)  # (N, T, F)\n",
    "\n",
    "# =========================================================\n",
    "# Your inputs (must already be in memory):\n",
    "#   train_F0_df, test_F0_df           -> DataFrames with (3, T) per sample in a feature col\n",
    "#   X_train_mfcc, X_test_mfcc         -> DataFrames or arrays with (C_mfcc, T)\n",
    "#   X_train_stft, X_test_stft         -> DataFrames or arrays with (F_stft, T)\n",
    "# =========================================================\n",
    "\n",
    "# -----------------------------\n",
    "# PRE-COMBINE SHAPE SUMMARIES\n",
    "# -----------------------------\n",
    "print(\"=== PRE-COMBINE SUMMARY: TRAIN ===\")\n",
    "_summarize(\"STFT_train\", X_train_stft)\n",
    "_summarize(\"MFCC_train\", X_train_mfcc)\n",
    "_summarize(\"F0_train\",   train_F0_df)\n",
    "\n",
    "print(\"\\n=== PRE-COMBINE SUMMARY: TEST ===\")\n",
    "_summarize(\"STFT_test\", X_test_stft)\n",
    "_summarize(\"MFCC_test\", X_test_mfcc)\n",
    "_summarize(\"F0_test\",   test_F0_df)\n",
    "\n",
    "# -----------------------------\n",
    "# CHOOSE UNIFORM TARGET LENGTH\n",
    "# Use train STFT median for both train & test (keeps shapes consistent for modeling)\n",
    "# -----------------------------\n",
    "target_len_train = int(np.median(_time_lengths(X_train_stft)))\n",
    "target_len_test  = target_len_train  # enforce same T across splits\n",
    "\n",
    "print(f\"\\nTarget time length (frames): train={target_len_train}, test={target_len_test}\")\n",
    "\n",
    "# -----------------------------\n",
    "# COMBINE (STFT + MFCC + F0) -> (N, T, F)\n",
    "# -----------------------------\n",
    "Train_combined = _stack_combined(X_train_stft, X_train_mfcc, train_F0_df, target_len=target_len_train)\n",
    "Test_combined  = _stack_combined(X_test_stft,  X_test_mfcc,  test_F0_df,  target_len=target_len_test)\n",
    "\n",
    "# -----------------------------\n",
    "# POST-COMBINE SHAPES\n",
    "# -----------------------------\n",
    "print(\"\\n=== POST-COMBINE SHAPES ===\")\n",
    "print(\"Train_combined (N, T, F):\", Train_combined.shape)\n",
    "print(\"Test_combined  (N, T, F):\", Test_combined.shape)\n",
    "\n",
    "# Optional peek at per-sample shapes\n",
    "if Train_combined.size:\n",
    "    print(\"One train sample (T,F):\", Train_combined[0].shape)\n",
    "if Test_combined.size:\n",
    "    print(\"One test  sample (T,F):\", Test_combined[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0ffcd-8116-4822-b0e6-775b7c6fff47",
   "metadata": {},
   "source": [
    "# Combined feature module for Feature extration modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b4820c-52b9-43fe-9bd0-a2f8865fddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Optional, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# General parameters (can be overridden per call)\n",
    "# -----------------------------\n",
    "AUDIO_EXTS = (\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\")\n",
    "\n",
    "def _is_audio(p: Path) -> bool:\n",
    "    return p.suffix.lower() in AUDIO_EXTS\n",
    "\n",
    "def _interp_resize_2d(feat_2d: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"Resize a (C, T) feature matrix along time axis to target_len using linear interpolation.\"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    assert feat_2d.ndim == 2, f\"Expected 2D (C,T), got {feat_2d.shape}\"\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d.astype(np.float32, copy=False)\n",
    "\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "def _choose_target_len(lengths: Iterable[int], policy: Literal[\"median\",\"max\"]=\"median\") -> int:\n",
    "    arr = np.array(list(lengths), dtype=int)\n",
    "    if len(arr) == 0:\n",
    "        raise ValueError(\"Cannot choose target length: empty lengths.\")\n",
    "    return int(np.median(arr)) if policy == \"median\" else int(arr.max())\n",
    "\n",
    "def _stft(\n",
    "    y: np.ndarray, sr: int,\n",
    "    n_fft: int, win_length: int, hop_length: int,\n",
    "    power: float = 1.0, to_db: bool = True\n",
    ") -> np.ndarray:\n",
    "    S_complex = librosa.stft(\n",
    "        y, n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "        window='hann', center=True\n",
    "    )\n",
    "    S_mag = np.abs(S_complex) ** power\n",
    "    if to_db:\n",
    "        # librosa uses 10*log10 for power and 20*log10 for amplitude internally\n",
    "        S_db = librosa.power_to_db(S_mag, ref=np.max) if power != 1.0 else librosa.amplitude_to_db(S_mag, ref=np.max)\n",
    "        return S_db.astype(np.float32)\n",
    "    return S_mag.astype(np.float32)\n",
    "\n",
    "def _mfcc(\n",
    "    y: np.ndarray, sr: int,\n",
    "    n_mfcc: int, n_fft: int, win_length: int, hop_length: int\n",
    ") -> np.ndarray:\n",
    "    M = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=n_mfcc,\n",
    "        n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
    "    )\n",
    "    return M.astype(np.float32)\n",
    "\n",
    "def _load_audio(path: Path, sr: int) -> np.ndarray:\n",
    "    y, _ = librosa.load(str(path), sr=sr, mono=True)\n",
    "    return y.astype(np.float32, copy=False)\n",
    "\n",
    "def _scan_pairs(\n",
    "    f0_dir: Path, audio_dir: Path\n",
    ") -> List[Tuple[str, str, Path, Path]]:\n",
    "    \"\"\"\n",
    "    Pair items by (class_folder, file stem). Returns list of tuples:\n",
    "      (class_label, stem, f0_npy_path, audio_path)\n",
    "\n",
    "    - f0_dir structure: f0_dir/<class>/*_f0_wave_conf.npy (or any .npy)\n",
    "    - audio_dir structure: audio_dir/<class>/*.(wav|mp3|...)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    if not f0_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing F0 dir: {f0_dir}\")\n",
    "    if not audio_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing audio dir: {audio_dir}\")\n",
    "\n",
    "    # index audio by (class, stem) -> path\n",
    "    audio_index: Dict[Tuple[str,str], Path] = {}\n",
    "    for class_dir in sorted([d for d in audio_dir.iterdir() if d.is_dir()]):\n",
    "        cls = class_dir.name\n",
    "        for ap in class_dir.rglob(\"*\"):\n",
    "            if ap.is_file() and _is_audio(ap):\n",
    "                audio_index[(cls, ap.stem)] = ap\n",
    "\n",
    "    # walk f0 npy files and find matching audio\n",
    "    for class_dir in sorted([d for d in f0_dir.iterdir() if d.is_dir()]):\n",
    "        cls = class_dir.name\n",
    "        for npy in class_dir.rglob(\"*.npy\"):\n",
    "            stem = npy.stem\n",
    "            # allow suffixes like *_f0_wave_conf; use split at first suffix\n",
    "            stem_clean = stem.replace(\"_f0_wave_conf\", \"\")\n",
    "            key = (cls, stem_clean)\n",
    "            if key not in audio_index:\n",
    "                # fallback: try exact stem\n",
    "                if (cls, stem) in audio_index:\n",
    "                    key = (cls, stem)\n",
    "                else:\n",
    "                    # couldn't match — skip silently but could warn\n",
    "                    # print(f\"[WARN] No matching audio for {npy}\")\n",
    "                    continue\n",
    "            pairs.append((cls, key[1], npy, audio_index[key]))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def _load_f0_array(npy_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expect shape (3, T): [wave_on_grid; f0_hz; confidence].\n",
    "    \"\"\"\n",
    "    arr = np.load(str(npy_path))\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2 or arr.shape[0] != 3:\n",
    "        raise ValueError(f\"Expected F0 array shape (3, T). Got {arr.shape} from {npy_path}\")\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def build_split(\n",
    "    f0_dir: str,\n",
    "    audio_dir: str,\n",
    "    *,\n",
    "    sr: int = 16000,\n",
    "    frame_ms: float = 30.0,\n",
    "    hop_ms: float = 15.0,\n",
    "    n_mfcc: int = 20,\n",
    "    stft_power: float = 1.0,\n",
    "    stft_to_db: bool = True,\n",
    "    fixed_target_len: int | None = None,   # <— NEW\n",
    "    target_len_policy: Literal[\"median\",\"max\"] = \"median\",\n",
    "    modalities: Iterable[Literal[\"stft\",\"mfcc\",\"f0\"]] = (\"stft\",\"mfcc\",\"f0\"),\n",
    "    strict_triplet: bool = True,\n",
    "    min_frames: int = 2,                         # <— NEW\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build a single split (train OR test).\n",
    "\n",
    "    Returns:\n",
    "      X  : (N, T, F) float32 — concatenated [modalities] along feature dim\n",
    "      y  : (N,) int labels (encoded by alphabetical class order)\n",
    "      df : manifest with columns [class, stem, f0_path, audio_path, T_stft, T_mfcc, T_f0, T_final]\n",
    "\n",
    "    Notes:\n",
    "      - Only items where **all requested modalities** exist are kept.\n",
    "      - Time axis is resized to a **single target length** chosen from STFT (if present),\n",
    "        else MFCC, else F0 — according to `target_len_policy`.\n",
    "    \"\"\"\n",
    "    f0_dir = Path(f0_dir)\n",
    "    audio_dir = Path(audio_dir)\n",
    "    pairs = _scan_pairs(f0_dir, audio_dir)\n",
    "\n",
    "    if len(pairs) == 0:\n",
    "        raise ValueError(f\"No (F0, audio) pairs found between {f0_dir} and {audio_dir}.\")\n",
    "\n",
    "    # window sizes\n",
    "    win_length = int(round(sr * frame_ms / 1000.0))\n",
    "    hop_length = int(round(sr * hop_ms   / 1000.0))\n",
    "    # next power of two for n_fft\n",
    "    n_fft = 1\n",
    "    while n_fft < win_length:\n",
    "        n_fft <<= 1\n",
    "\n",
    "    rows = []\n",
    "    features_list = []\n",
    "    labels = []\n",
    "\n",
    "    # first pass: compute raw modality features + their T lengths\n",
    "    stft_list, mfcc_list, f0_list = [], [], []\n",
    "    Ts_stft, Ts_mfcc, Ts_f0 = [], [], []\n",
    "\n",
    "    kept = 0\n",
    "    skipped_short = 0\n",
    "    for cls, stem, f0_path, audio_path in pairs:\n",
    "        try:\n",
    "            f0_arr = _load_f0_array(f0_path) if \"f0\" in modalities else None\n",
    "            y = _load_audio(audio_path, sr=sr)\n",
    "\n",
    "            stft_feat = _stft(y, sr, n_fft, win_length, hop_length,\n",
    "                              power=stft_power, to_db=stft_to_db) if \"stft\" in modalities else None\n",
    "            mfcc_feat = _mfcc(y, sr, n_mfcc, n_fft, win_length, hop_length) if \"mfcc\" in modalities else None\n",
    "\n",
    "            # record lengths\n",
    "            Ts_stft.append(stft_feat.shape[1] if stft_feat is not None else -1)\n",
    "            Ts_mfcc.append(mfcc_feat.shape[1] if mfcc_feat is not None else -1)\n",
    "            Ts_f0.append(f0_arr.shape[1]   if f0_arr   is not None else -1)\n",
    "\n",
    "            # skip if any requested modality has too few frames\n",
    "            if strict_triplet:\n",
    "                if (\"stft\" in modalities and (stft_feat is None or stft_feat.shape[1] < min_frames)) \\\n",
    "                or (\"mfcc\" in modalities and (mfcc_feat is None or mfcc_feat.shape[1] < min_frames)) \\\n",
    "                or (\"f0\"   in modalities and (f0_arr   is None or f0_arr.shape[1]   < min_frames)):\n",
    "                    skipped_short += 1\n",
    "                    continue\n",
    "\n",
    "            stft_list.append(stft_feat)\n",
    "            mfcc_list.append(mfcc_feat)\n",
    "            f0_list.append(f0_arr)\n",
    "            labels.append(cls)\n",
    "            rows.append({\n",
    "                \"class\": cls, \"stem\": stem,\n",
    "                \"f0_path\": str(f0_path), \"audio_path\": str(audio_path)\n",
    "            })\n",
    "            kept += 1\n",
    "        except Exception as e:\n",
    "            # Skip problematic files but keep going\n",
    "            # print(f\"[WARN] Skipped ({cls}/{stem}): {e}\")\n",
    "            continue\n",
    "            \n",
    "    if kept == 0:\n",
    "        raise ValueError(f\"After loading, no usable items remained (skipped_short={skipped_short}).\")\n",
    "\n",
    "    if len(labels) == 0:\n",
    "        raise ValueError(\"After loading, no usable items remained. Check data.\")\n",
    "\n",
    "    # choose target T from the first available modality in priority order\n",
    "    def _valid_lengths(L): return [x for x in L if x > 0]\n",
    "    if fixed_target_len is not None: \n",
    "        T_target = int(fixed_target_len)\n",
    "    elif \"stft\" in modalities and len(_valid_lengths(Ts_stft)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_stft), policy=target_len_policy)\n",
    "    elif \"mfcc\" in modalities and len(_valid_lengths(Ts_mfcc)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_mfcc), policy=target_len_policy)\n",
    "    elif \"f0\" in modalities and len(_valid_lengths(Ts_f0)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_f0), policy=target_len_policy)\n",
    "    else:\n",
    "        raise ValueError(\"Could not infer target time length from requested modalities.\")\n",
    "\n",
    "    # second pass: resize and concatenate\n",
    "    X_list = []\n",
    "    keep_mask = []\n",
    "    for stft_feat, mfcc_feat, f0_feat in zip(stft_list, mfcc_list, f0_list):\n",
    "        if strict_triplet:\n",
    "            # ensure all requested modalities exist\n",
    "            if (\"stft\" in modalities and stft_feat is None) or \\\n",
    "               (\"mfcc\" in modalities and mfcc_feat is None) or \\\n",
    "               (\"f0\"   in modalities and f0_feat   is None):\n",
    "                keep_mask.append(False)\n",
    "                X_list.append(None)\n",
    "                continue\n",
    "\n",
    "        channels = []\n",
    "        if stft_feat is not None:\n",
    "            channels.append(_interp_resize_2d(stft_feat, T_target))\n",
    "        if mfcc_feat is not None:\n",
    "            channels.append(_interp_resize_2d(mfcc_feat, T_target))\n",
    "        if f0_feat is not None:\n",
    "            channels.append(_interp_resize_2d(f0_feat, T_target))  # (3, T)\n",
    "\n",
    "        if len(channels) == 0:\n",
    "            keep_mask.append(False)\n",
    "            X_list.append(None)\n",
    "            continue\n",
    "\n",
    "        CxT = np.concatenate(channels, axis=0)     # (C_total, T)\n",
    "        X_list.append(CxT.T.astype(np.float32))    # (T, C_total)\n",
    "        keep_mask.append(True)\n",
    "\n",
    "    # filter by keep_mask\n",
    "    keep_idx = [i for i, k in enumerate(keep_mask) if k]\n",
    "    if len(keep_idx) == 0:\n",
    "        raise ValueError(\"No samples had all requested modalities (strict_triplet=True).\")\n",
    "\n",
    "    X = np.stack([X_list[i] for i in keep_idx], axis=0)   # (N, T, F)\n",
    "    y_labels = [labels[i] for i in keep_idx]\n",
    "    df = pd.DataFrame([rows[i] for i in keep_idx])\n",
    "    df[\"T_final\"] = T_target\n",
    "    if \"stft\" in modalities: df[\"T_stft\"] = [Ts_stft[i] for i in keep_idx]\n",
    "    if \"mfcc\" in modalities: df[\"T_mfcc\"] = [Ts_mfcc[i] for i in keep_idx]\n",
    "    if \"f0\"   in modalities: df[\"T_f0\"]   = [Ts_f0[i]   for i in keep_idx]\n",
    "\n",
    "    # encode labels alphabetically (stable & reproducible)\n",
    "    classes = sorted(pd.unique(df[\"class\"]))\n",
    "    cls_to_id = {c:i for i,c in enumerate(classes)}\n",
    "    y = np.array([cls_to_id[c] for c in y_labels], dtype=np.int64)\n",
    "\n",
    "    return X, y, df.assign(label_id=[cls_to_id[c] for c in y_labels])\n",
    "\n",
    "def prepare_train_test(\n",
    "    f0_conf_wave_train_dir: str,\n",
    "    f0_conf_wave_test_dir: str,\n",
    "    audio_train_dir: str,\n",
    "    audio_test_dir: str,\n",
    "    *,\n",
    "    sr: int = 16000,\n",
    "    frame_ms: float = 30.0,\n",
    "    hop_ms: float = 15.0,\n",
    "    n_mfcc: int = 20,\n",
    "    stft_power: float = 1.0,\n",
    "    stft_to_db: bool = True,\n",
    "    target_len_policy: Literal[\"median\",\"max\"] = \"median\",\n",
    "    modalities: Iterable[Literal[\"stft\",\"mfcc\",\"f0\"]] = (\"stft\",\"mfcc\",\"f0\"),\n",
    "    strict_triplet: bool = True,\n",
    "    fixed_target_len: int | None = None,   # <— NEW\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int,str], pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Convenience wrapper to build train & test with identical settings.\n",
    "\n",
    "    Returns:\n",
    "      X_train, y_train, X_test, y_test,\n",
    "      id_to_class (dict), train_manifest (df), test_manifest (df)\n",
    "    \"\"\"\n",
    "    X_train, y_train, df_train = build_split(\n",
    "        f0_conf_wave_train_dir, audio_train_dir,\n",
    "        sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "        stft_power=stft_power, stft_to_db=stft_to_db,\n",
    "        target_len_policy=target_len_policy, modalities=modalities,\n",
    "        strict_triplet=strict_triplet,\n",
    "        fixed_target_len=fixed_target_len,         # <— pass through\n",
    "        min_frames=2,                    # <— NEW\n",
    "    )\n",
    "    X_test, y_test, df_test = build_split(\n",
    "        f0_conf_wave_test_dir, audio_test_dir,\n",
    "        sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "        stft_power=stft_power, stft_to_db=stft_to_db,\n",
    "        target_len_policy=target_len_policy, modalities=modalities,\n",
    "        strict_triplet=strict_triplet,\n",
    "        fixed_target_len=fixed_target_len,         # <— pass through\n",
    "        min_frames=2,                    # <— NEW\n",
    "    )\n",
    "\n",
    "    # harmonize label ids across splits (use train mapping)\n",
    "    classes = sorted(pd.unique(df_train[\"class\"]))\n",
    "    id_to_class = {i:c for i,c in enumerate(classes)}\n",
    "    cls_to_id = {c:i for i,c in id_to_class.items()}\n",
    "\n",
    "    # remap test if classes overlap; unknown classes get new ids at the end\n",
    "    test_classes = list(pd.unique(df_test[\"class\"]))\n",
    "    for c in test_classes:\n",
    "        if c not in cls_to_id:\n",
    "            cls_to_id[c] = len(cls_to_id)\n",
    "            id_to_class[cls_to_id[c]] = c\n",
    "\n",
    "    y_train = np.array([cls_to_id[c] for c in df_train[\"class\"].tolist()], dtype=np.int64)\n",
    "    y_test  = np.array([cls_to_id[c] for c in df_test[\"class\"].tolist()], dtype=np.int64)\n",
    "\n",
    "    df_train = df_train.assign(label_id=y_train)\n",
    "    df_test  = df_test.assign(label_id=y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, id_to_class, df_train, df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4bf93-096c-43ef-868e-fba7eb4597b5",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7304a-acd4-4803-87cc-4e9fc3d99260",
   "metadata": {},
   "source": [
    "# Calling combined feature for Reverb Chinese Baby cry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3003aa-a757-4009-9b66-2a466657a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from feature_fusion import prepare_train_test\n",
    "\n",
    "# f0_conf_wave_train_dir_reverbChinese = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "# f0_conf_wave_test_dir_reverbChinese  = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "\n",
    "# audio_train_dir_reverbChinese        = \"Chinese Babycry/Reverb_Train_Split_80\"\n",
    "# audio_test_dir_reverbChinese         = \"Chinese Babycry/Reverb_Test_Split_20\"\n",
    "\n",
    "# X_train_reverbChinese, y_train_reverbChinese, X_test_reverbChinese, y_test_reverbChinese, id2cls_reverbChinese, train_manifest_reverbChinese, test_manifest_reverbChinese = prepare_train_test(\n",
    "#     f0_conf_wave_train_dir=f0_conf_wave_train_dir_reverbChinese,\n",
    "#     f0_conf_wave_test_dir=f0_conf_wave_test_dir_reverbChinese,\n",
    "#     audio_train_dir=audio_train_dir_reverbChinese,\n",
    "#     audio_test_dir=audio_test_dir_reverbChinese,\n",
    "#     sr=16000,\n",
    "#     frame_ms=30.0,\n",
    "#     hop_ms=15.0,\n",
    "#     n_mfcc=20,\n",
    "#     modalities=(\"stft\", \"mfcc\", \"f0\"),   # choose any subset e.g. (\"mfcc\",\"f0\")\n",
    "#     fixed_target_len=100, \n",
    "#     target_len_policy=\"median\",           # or \"max\"\n",
    "#     strict_triplet=True,                  # require all requested modalities per sample\n",
    "# )\n",
    "\n",
    "# print(\"X_train_reverbChinese:\", X_train_reverbChinese.shape, \"X_test_reverbChinese:\", X_test_reverbChinese.shape)\n",
    "# print(\"y_train_reverbChinese:\", y_train_reverbChinese.shape, \"y_test_reverbChinese:\", y_test_reverbChinese.shape)\n",
    "# print(\"Classes_reverbChinese:\", id2cls_reverbChinese)\n",
    "# display(train_manifest_reverbChinese.head())\n",
    "# display(test_manifest_reverbChinese.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510b72c-5c1b-407a-9a37-a717b38a1e67",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbc0fa-04ca-4408-97ab-75c4b2af28c5",
   "metadata": {},
   "source": [
    "# Also do the same  the same for chinese baby cry without reverbration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7830562-d091-4ebb-ab8e-f37fca4464e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_chinese: (734, 100, 280) X_test_cinese: (184, 100, 280)\n",
      "y_train_chinese: (734,) y_test_chinese: (184,)\n",
      "Classes_chinese: {0: 'awake', 1: 'diaper', 2: 'hug', 3: 'hungry', 4: 'sleepy', 5: 'uncomfortable'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_0</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_0.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_100</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_100...</td>\n",
       "      <td>100</td>\n",
       "      <td>1039</td>\n",
       "      <td>1039</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_101</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_101...</td>\n",
       "      <td>100</td>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_102</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_102...</td>\n",
       "      <td>100</td>\n",
       "      <td>1148</td>\n",
       "      <td>1148</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_103</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_103...</td>\n",
       "      <td>100</td>\n",
       "      <td>1048</td>\n",
       "      <td>1048</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       stem                                            f0_path  \\\n",
       "0  awake    awake_0  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "1  awake  awake_100  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "2  awake  awake_101  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "3  awake  awake_102  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "4  awake  awake_103  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "\n",
       "                                          audio_path  T_final  T_stft  T_mfcc  \\\n",
       "0   Chinese Babycry/Train_Split_80/awake/awake_0.wav      100    1051    1051   \n",
       "1  Chinese Babycry/Train_Split_80/awake/awake_100...      100    1039    1039   \n",
       "2  Chinese Babycry/Train_Split_80/awake/awake_101...      100    1713    1713   \n",
       "3  Chinese Babycry/Train_Split_80/awake/awake_102...      100    1148    1148   \n",
       "4  Chinese Babycry/Train_Split_80/awake/awake_103...      100    1048    1048   \n",
       "\n",
       "   T_f0  label_id  \n",
       "0    79         0  \n",
       "1    78         0  \n",
       "2   129         0  \n",
       "3    87         0  \n",
       "4    79         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_110</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_110.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_113</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_113.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_116</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_116.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1074</td>\n",
       "      <td>1074</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_117</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_117.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1039</td>\n",
       "      <td>1039</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_131</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_131.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1168</td>\n",
       "      <td>1168</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       stem                                            f0_path  \\\n",
       "0  awake  awake_110  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "1  awake  awake_113  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "2  awake  awake_116  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "3  awake  awake_117  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "4  awake  awake_131  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "\n",
       "                                          audio_path  T_final  T_stft  T_mfcc  \\\n",
       "0  Chinese Babycry/Test_Split_20/awake/awake_110.wav      100    1292    1292   \n",
       "1  Chinese Babycry/Test_Split_20/awake/awake_113.wav      100    1112    1112   \n",
       "2  Chinese Babycry/Test_Split_20/awake/awake_116.wav      100    1074    1074   \n",
       "3  Chinese Babycry/Test_Split_20/awake/awake_117.wav      100    1039    1039   \n",
       "4  Chinese Babycry/Test_Split_20/awake/awake_131.wav      100    1168    1168   \n",
       "\n",
       "   T_f0  label_id  \n",
       "0    97         0  \n",
       "1    84         0  \n",
       "2    81         0  \n",
       "3    78         0  \n",
       "4    88         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from feature_fusion import prepare_train_test\n",
    "\n",
    "f0_conf_wave_train_chinese_dir = \"Chinese Babycry/Chinese baby cry train_f0\"\n",
    "f0_conf_wave_test_chinese_dir  = \"Chinese Babycry/Chinese baby cry test_f0\"\n",
    "\n",
    "audio_train_dir_chinese        = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir_chinese         = \"Chinese Babycry/Test_Split_20\"\n",
    "\n",
    "X_train_chinese, y_train_chinese, X_test_chinese, y_test_chinese, id2cls_chinese, train_manifest_chinese, test_manifest_chinese = prepare_train_test(\n",
    "    f0_conf_wave_train_dir=f0_conf_wave_train_chinese_dir,\n",
    "    f0_conf_wave_test_dir=f0_conf_wave_test_chinese_dir,\n",
    "    audio_train_dir=audio_train_dir_chinese,\n",
    "    audio_test_dir=audio_test_dir_chinese,\n",
    "    sr=16000,\n",
    "    frame_ms=30.0,\n",
    "    hop_ms=15.0,\n",
    "    n_mfcc=20,\n",
    "    modalities=(\"stft\", \"mfcc\", \"f0\"),   # choose any subset e.g. (\"mfcc\",\"f0\")\n",
    "    fixed_target_len=100, \n",
    "    target_len_policy=\"median\",           # or \"max\"\n",
    "    strict_triplet=True,                  # require all requested modalities per sample\n",
    ")\n",
    "\n",
    "print(\"X_train_chinese:\", X_train_chinese.shape, \"X_test_cinese:\", X_test_chinese.shape)\n",
    "print(\"y_train_chinese:\", y_train_chinese.shape, \"y_test_chinese:\", y_test_chinese.shape)\n",
    "print(\"Classes_chinese:\", id2cls_chinese)\n",
    "display(train_manifest_chinese.head())\n",
    "display(test_manifest_chinese.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea4def-2513-4d15-9f32-591b3787bda1",
   "metadata": {},
   "source": [
    "# Filter on 3 mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378fb058-257f-4305-8c2c-45deebe9a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 'Diaper', 1: 'Sleepy', 2: 'Uncomfortable'}\n",
      "Train shape: (350, 100, 280, 1)  Val shape: (88, 100, 280, 1)\n",
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Classes of interest\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"Diaper\", 4: \"Sleepy\", 5: \"Uncomfortable\"}\n",
    "\n",
    "# --- Train filtering ---\n",
    "mask_train = np.isin(y_train_chinese, keep_classes)\n",
    "X_train_split = X_train_chinese[mask_train]\n",
    "y_train_split = y_train_chinese[mask_train]\n",
    "\n",
    "# --- Test filtering ---\n",
    "mask_test = np.isin(y_test_chinese, keep_classes)\n",
    "X_val_split = X_test_chinese[mask_test]\n",
    "y_val_split = y_test_chinese[mask_test]\n",
    "\n",
    "# --- Re-encode labels to [0,1,2] ---\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "y_train_Chinese_3mood = np.array([class2newid[y] for y in y_train_split])\n",
    "y_test_Chinese_3mood = np.array([class2newid[y] for y in y_val_split])\n",
    "\n",
    "# --- Add channel dimension ---\n",
    "X_train_Chinese_3mood = np.expand_dims(X_train_split, axis=-1)\n",
    "X_test_Chinese_3mood = np.expand_dims(X_val_split, axis=-1)\n",
    "\n",
    "print(\"Class mapping:\", id2cls_merge_3mood)\n",
    "print(\"Train shape:\", X_train_Chinese_3mood.shape, \" Val shape:\", X_test_Chinese_3mood.shape)\n",
    "print(\"Unique encoded y:\", np.unique(y_train_Chinese_3mood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c644e00-2826-4847-95b4-05924b90bf61",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e27351-31a9-467a-a580-f81c16c049e2",
   "metadata": {},
   "source": [
    "# make a merged version of chinese baby cry reverb and not reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e751b897-528a-4d82-9574-ab9e89b2519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # 0) (Fix a small print bug from your snippet)\n",
    "# print(\"Classes_chinese:\", id2cls_chinese)\n",
    "\n",
    "# # 1) Sanity checks: same (T, F)\n",
    "# assert X_train_reverbChinese.shape[1:] == X_train_chinese.shape[1:], \\\n",
    "#     f\"Train shape mismatch: {X_train_reverbChinese.shape[1:]} vs {X_train_chinese.shape[1:]}\"\n",
    "# assert X_test_reverbChinese.shape[1:] == X_test_chinese.shape[1:], \\\n",
    "#     f\"Test shape mismatch:  {X_test_reverbChinese.shape[1:]} vs {X_test_chinese.shape[1:]}\"\n",
    "\n",
    "# # 2) Build a unified label space using class NAMES (safer than reusing ints)\n",
    "# all_classes = sorted(set(id2cls_reverbChinese.values()) | set(id2cls_chinese.values()))\n",
    "# cls2new = {c: i for i, c in enumerate(all_classes)}\n",
    "# id2cls_merged = {i: c for c, i in cls2new.items()}  # inverse mapping\n",
    "\n",
    "# def remap_labels(y_old: np.ndarray, id2cls: dict, cls2new: dict) -> np.ndarray:\n",
    "#     \"\"\"Map old integer IDs -> class names -> new integer IDs.\"\"\"\n",
    "#     return np.array([cls2new[id2cls[int(k)]] for k in y_old], dtype=np.int64)\n",
    "\n",
    "# y_train_reverb_m = remap_labels(y_train_reverbChinese, id2cls_reverbChinese, cls2new)\n",
    "# y_test_reverb_m  = remap_labels(y_test_reverbChinese,  id2cls_reverbChinese, cls2new)\n",
    "# y_train_chinese_m = remap_labels(y_train_chinese, id2cls_chinese, cls2new)\n",
    "# y_test_chinese_m  = remap_labels(y_test_chinese,  id2cls_chinese, cls2new)\n",
    "\n",
    "# # 3) Concatenate per split\n",
    "# X_train_merged = np.concatenate([X_train_reverbChinese, X_train_chinese], axis=0)\n",
    "# y_train_merged = np.concatenate([y_train_reverb_m,     y_train_chinese_m], axis=0)\n",
    "\n",
    "# X_test_merged  = np.concatenate([X_test_reverbChinese, X_test_chinese], axis=0)\n",
    "# y_test_merged  = np.concatenate([y_test_reverb_m,      y_test_chinese_m], axis=0)\n",
    "\n",
    "# # 4) (Optional) shuffle train\n",
    "# X_train_merged, y_train_merged = shuffle(X_train_merged, y_train_merged, random_state=42)\n",
    "\n",
    "# # 5) Merge manifests (keep origin + new label ids)\n",
    "# train_manifest_reverbChinese = train_manifest_reverbChinese.copy()\n",
    "# train_manifest_chinese       = train_manifest_chinese.copy()\n",
    "# test_manifest_reverbChinese  = test_manifest_reverbChinese.copy()\n",
    "# test_manifest_chinese        = test_manifest_chinese.copy()\n",
    "\n",
    "# train_manifest_reverbChinese[\"dataset\"] = \"reverbChinese\"\n",
    "# train_manifest_chinese[\"dataset\"]       = \"chinese\"\n",
    "# test_manifest_reverbChinese[\"dataset\"]  = \"reverbChinese\"\n",
    "# test_manifest_chinese[\"dataset\"]        = \"chinese\"\n",
    "\n",
    "# train_manifest_reverbChinese[\"label_id_merged\"] = y_train_reverb_m\n",
    "# train_manifest_chinese[\"label_id_merged\"]       = y_train_chinese_m\n",
    "# test_manifest_reverbChinese[\"label_id_merged\"]  = y_test_reverb_m\n",
    "# test_manifest_chinese[\"label_id_merged\"]        = y_test_chinese_m\n",
    "\n",
    "# train_manifest_merged = pd.concat(\n",
    "#     [train_manifest_reverbChinese, train_manifest_chinese], ignore_index=True\n",
    "# )\n",
    "# test_manifest_merged = pd.concat(\n",
    "#     [test_manifest_reverbChinese, test_manifest_chinese], ignore_index=True\n",
    "# )\n",
    "\n",
    "# print(\"X_train_merged:\", X_train_merged.shape, \"X_test_merged:\", X_test_merged.shape)\n",
    "# print(\"y_train_merged:\", y_train_merged.shape, \"y_test_merged:\", y_test_merged.shape)\n",
    "# print(\"Classes (merged):\", id2cls_merged)\n",
    "\n",
    "# # 6) (Optional) Save to disk\n",
    "# np.savez_compressed(\"Chinese_combined_train.npz\", X=X_train_merged, y=y_train_merged)\n",
    "# np.savez_compressed(\"Chinese_combined_test.npz\",  X=X_test_merged,  y=y_test_merged)\n",
    "# train_manifest_merged.to_csv(\"Chinese_combined_train_manifest.csv\", index=False)\n",
    "# test_manifest_merged.to_csv(\"Chinese_combined_test_manifest.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e01915-60a6-4607-be0b-1b37aac49b6f",
   "metadata": {},
   "source": [
    "# Also do the same (Test & Train) for baby 2020 M0 to 3 or 9 ans merge months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e696df81-826c-46da-b713-2091d409bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _remap_labels(y_old: np.ndarray, id2cls: dict, global_cls2id: dict) -> np.ndarray:\n",
    "    return np.array([global_cls2id[id2cls[int(k)]] for k in y_old], dtype=np.int64)\n",
    "\n",
    "def _append_month_feature(X, month_idx, n_months, mode=\"onehot\"):\n",
    "    \"\"\"\n",
    "    Append month info to X along feature dim.\n",
    "    mode=\"onehot\" -> +n_months features; mode=\"index\" -> +1 feature in [0,1].\n",
    "    \"\"\"\n",
    "    N, T, F = X.shape\n",
    "    month_idx = np.asarray(month_idx, dtype=int)\n",
    "    if mode == \"onehot\":\n",
    "        X_out = np.empty((N, T, F + n_months), dtype=np.float32)\n",
    "        X_out[..., :F] = X\n",
    "        for i in range(N):\n",
    "            one = np.zeros((T, n_months), dtype=np.float32)\n",
    "            one[:, month_idx[i]] = 1.0\n",
    "            X_out[i, :, F:] = one\n",
    "        return X_out\n",
    "    elif mode == \"index\":\n",
    "        denom = max(1, n_months - 1)\n",
    "        X_out = np.empty((N, T, F + 1), dtype=np.float32)\n",
    "        X_out[..., :F] = X\n",
    "        for i in range(N):\n",
    "            X_out[i, :, F:] = float(month_idx[i]) / denom\n",
    "        return X_out\n",
    "    else:\n",
    "        return X  # no change\n",
    "\n",
    "def load_all_months_train(\n",
    "    base_path: str,\n",
    "    *,\n",
    "    months=(\"0Month\",\"1Month\",\"2Month\",\"3Month\",\"4Month\",\"5Month\",\"6Month\",\"7Month\",\"8Month\",\"9Month\"),\n",
    "    f0_root_subdir=\"Baby2020/Baby2020_f0_wave_conf_arrays\",   # sits inside base_path\n",
    "    audio_month_subdir=\"\",                           # usually empty: classes live directly under each month\n",
    "    sr=16000, frame_ms=30.0, hop_ms=15.0, n_mfcc=20,\n",
    "    modalities=(\"stft\",\"mfcc\",\"f0\"),\n",
    "    fixed_target_len=100, target_len_policy=\"median\", strict_triplet=True,\n",
    "    label_from: Literal[\"class\",\"month\"] = \"class\",\n",
    "    month_feature_mode: Literal[\"onehot\",\"index\",None] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build ONE big training set from month folders only (no test split).\n",
    "\n",
    "    Returns:\n",
    "      X_all (N, T, F[+month_feat]), y_all (N,),\n",
    "      id2cls_all (dict), df_all (manifest with month_folder), months_used (list)\n",
    "    \"\"\"\n",
    "    base = Path(base_path)\n",
    "\n",
    "    # lists to collect month-wise outputs\n",
    "    X_list, y_list = [], []\n",
    "    df_list = []\n",
    "    id2cls_per_month = []\n",
    "    class_name_set = set()\n",
    "    months_used = []\n",
    "    month_idx_list = []\n",
    "\n",
    "    # Load each month by calling your existing build_split()\n",
    "    for mi, m in enumerate(months):\n",
    "        audio_dir = base / m / audio_month_subdir\n",
    "        f0_dir    = base / f0_root_subdir / m\n",
    "\n",
    "        if not (audio_dir.exists() and f0_dir.exists()):\n",
    "            print(f\"[WARN] Skipping {m}: missing {audio_dir} or {f0_dir}\")\n",
    "            continue\n",
    "\n",
    "        # build_split expects directories with CLASS subfolders inside\n",
    "        X_m, y_m, df_m = build_split(\n",
    "            f0_dir=str(f0_dir),\n",
    "            audio_dir=str(audio_dir),\n",
    "            sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "            stft_power=1.0, stft_to_db=True,\n",
    "            fixed_target_len=fixed_target_len,\n",
    "            target_len_policy=target_len_policy,\n",
    "            modalities=modalities,\n",
    "            strict_triplet=strict_triplet,\n",
    "        )\n",
    "\n",
    "        # Add month info to manifest\n",
    "        df_m = df_m.copy()\n",
    "        df_m[\"month_folder\"] = m\n",
    "        df_list.append(df_m)\n",
    "\n",
    "        # Record id2cls for this month (class mapping from build_split)\n",
    "        # and collect class names for global map\n",
    "        # If label_from=\"month\", we'll override later anyway.\n",
    "        local_classes = sorted(pd.unique(df_m[\"class\"]))\n",
    "        id2cls_m = {i: c for i, c in enumerate(local_classes)}\n",
    "        id2cls_per_month.append(id2cls_m)\n",
    "        class_name_set.update(local_classes)\n",
    "\n",
    "        X_list.append(X_m)\n",
    "        y_list.append(y_m)\n",
    "        months_used.append(m)\n",
    "        month_idx_list.append(np.full(len(y_m), mi, dtype=int))\n",
    "\n",
    "        print(f\"[OK] {m}: {X_m.shape[0]} samples, X shape {X_m.shape}\")\n",
    "        \n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"No months loaded. Check base_path and folder names.\")\n",
    "\n",
    "    # Merge across months\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    month_idx = np.concatenate(month_idx_list, axis=0)\n",
    "\n",
    "    if label_from == \"class\":\n",
    "        # Build global class mapping and remap y from each month\n",
    "        all_classes = sorted(class_name_set)\n",
    "        cls2gid = {c:i for i,c in enumerate(all_classes)}\n",
    "        id2cls_all = {i:c for c,i in cls2gid.items()}\n",
    "        y_all = np.concatenate([\n",
    "            _remap_labels(y_m, id2cls_m, cls2gid) for y_m, id2cls_m in zip(y_list, id2cls_per_month)\n",
    "        ], axis=0)\n",
    "        df_all[\"label_id\"] = y_all\n",
    "    else:\n",
    "        # Label is the month itself (0..len(months_used)-1)\n",
    "        month2id = {m:i for i,m in enumerate(months_used)}\n",
    "        y_all = np.array([month2id[m] for m in df_all[\"month_folder\"]], dtype=np.int64)\n",
    "        id2cls_all = {i:m for m,i in month2id.items()}\n",
    "        df_all[\"label_id\"] = y_all\n",
    "\n",
    "    # Optional: append month feature to X\n",
    "    if month_feature_mode in (\"onehot\",\"index\"):\n",
    "        X_all = _append_month_feature(X_all, month_idx, n_months=len(months_used), mode=month_feature_mode)\n",
    "\n",
    "    return X_all, y_all, id2cls_all, df_all, months_used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d1aa04-7761-4d71-8951-84c26c6cab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 0Month: 500 samples, X shape (500, 100, 280)\n",
      "[OK] 1Month: 550 samples, X shape (550, 100, 280)\n",
      "[OK] 2Month: 1070 samples, X shape (1070, 100, 280)\n",
      "[OK] 3Month: 1340 samples, X shape (1340, 100, 280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=288\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 4Month: 1709 samples, X shape (1709, 100, 280)\n",
      "[OK] 5Month: 1650 samples, X shape (1650, 100, 280)\n",
      "[OK] 6Month: 1010 samples, X shape (1010, 100, 280)\n",
      "[OK] 7Month: 320 samples, X shape (320, 100, 280)\n",
      "[OK] 8Month: 399 samples, X shape (399, 100, 280)\n",
      "[OK] 9Month: 850 samples, X shape (850, 100, 280)\n",
      "Months loaded: ['0Month', '1Month', '2Month', '3Month', '4Month', '5Month', '6Month', '7Month', '8Month', '9Month']\n",
      "X_all: (9398, 100, 280) y_all: (9398,)\n",
      "Classes: {0: 'Hungry', 1: 'NeedHug', 2: 'Sleepy', 3: 'Temper', 4: 'UnComfy', 5: 'Uncomfy', 6: 'Wakeup'}\n",
      "    class month_folder  label_id\n",
      "0  Hungry       0Month         0\n",
      "1  Hungry       0Month         0\n",
      "2  Hungry       0Month         0\n",
      "3  Hungry       0Month         0\n",
      "4  Hungry       0Month         0\n"
     ]
    }
   ],
   "source": [
    "base = r\"Baby2020/\"  # <- use your real absolute path\n",
    "\n",
    "X_all, y_all, id2cls_all, df_all, months_used = load_all_months_train(\n",
    "    base_path=base,\n",
    "    months=(\"0Month\",\"1Month\",\"2Month\",\"3Month\",\"4Month\",\"5Month\",\"6Month\",\"7Month\",\"8Month\",\"9Month\"),\n",
    "    f0_root_subdir=\"Baby2020_f0_wave_conf_arrays\",  # under base, contains 0Month..6Month\n",
    "    audio_month_subdir=\"\",                          # classes live directly under each month folder\n",
    "    # features\n",
    "    modalities=(\"stft\",\"mfcc\",\"f0\"),\n",
    "    fixed_target_len=100,\n",
    "    # labels: choose \"class\" (default) or \"month\"\n",
    "    label_from=\"class\",\n",
    "    # optionally append month to X as features:\n",
    "    month_feature_mode=None,   # or \"onehot\" / \"index\"\n",
    ")\n",
    "\n",
    "print(\"Months loaded:\", months_used)\n",
    "print(\"X_all:\", X_all.shape, \"y_all:\", y_all.shape)\n",
    "print(\"Classes:\", id2cls_all)\n",
    "print(df_all[[\"class\",\"month_folder\",\"label_id\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5140281-547e-4165-9c02-346588807727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9398, 100, 280)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a14fd0c-7d04-4f26-9f99-bfb5bbb265db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.1945999e+01, -5.0404358e+01, -4.9002388e+01, ...,\n",
       "          1.4343262e-03,  4.3054242e+02,  1.0731261e-01],\n",
       "        [-5.6915745e+01, -5.4696762e+01, -5.0768116e+01, ...,\n",
       "          3.6340579e-03,  4.3080798e+02,  2.4497122e-01],\n",
       "        [-6.3433399e+01, -5.6649033e+01, -4.4152809e+01, ...,\n",
       "          5.8337897e-03,  4.3107355e+02,  3.8262981e-01],\n",
       "        ...,\n",
       "        [-6.4005219e+01, -5.1261467e+01, -4.3933140e+01, ...,\n",
       "         -7.2440715e-04,  1.9661929e+02,  7.5467360e-01],\n",
       "        [-5.4690136e+01, -5.1790001e+01, -4.3621948e+01, ...,\n",
       "         -5.1534632e-03,  1.9721800e+02,  8.0179125e-01],\n",
       "        [-5.1194679e+01, -6.1568497e+01, -4.0538029e+01, ...,\n",
       "         -9.5825195e-03,  1.9781673e+02,  8.4890890e-01]],\n",
       "\n",
       "       [[-4.2535599e+01, -4.1338474e+01, -4.0294651e+01, ...,\n",
       "         -1.7089844e-03,  4.0924353e+02,  1.4723654e-01],\n",
       "        [-5.0429012e+01, -4.8760208e+01, -4.5538258e+01, ...,\n",
       "         -1.6982570e-02,  4.1026852e+02,  2.2333166e-01],\n",
       "        [-5.0716618e+01, -4.7293198e+01, -4.0203789e+01, ...,\n",
       "         -3.2256156e-02,  4.1129355e+02,  2.9942679e-01],\n",
       "        ...,\n",
       "        [-4.8095097e+01, -4.3545494e+01, -4.2705608e+01, ...,\n",
       "         -4.6543931e-03,  3.4605145e+02,  2.2904362e-01],\n",
       "        [-5.3124561e+01, -4.8255409e+01, -5.0072117e+01, ...,\n",
       "         -5.7604238e-03,  3.4518372e+02,  2.3040044e-01],\n",
       "        [-4.7286022e+01, -3.8310947e+01, -3.7240074e+01, ...,\n",
       "         -6.8664551e-03,  3.4431598e+02,  2.3175725e-01]],\n",
       "\n",
       "       [[-5.9483597e+01, -5.4592892e+01, -5.7223381e+01, ...,\n",
       "         -1.2207031e-04,  4.2128903e+02,  1.8043664e-01],\n",
       "        [-6.0749153e+01, -4.8834267e+01, -4.6676956e+01, ...,\n",
       "          8.9678522e-03,  4.1933759e+02,  2.7388939e-01],\n",
       "        [-5.5360035e+01, -4.6987156e+01, -4.1385098e+01, ...,\n",
       "          1.8057775e-02,  4.1738614e+02,  3.6734217e-01],\n",
       "        ...,\n",
       "        [-4.1914623e+01, -4.1935040e+01, -3.3679340e+01, ...,\n",
       "          2.8174815e-03,  3.4712787e+02,  3.3297032e-01],\n",
       "        [-3.6989067e+01, -4.8239502e+01, -2.8178555e+01, ...,\n",
       "          2.3242680e-03,  3.4721725e+02,  3.1033742e-01],\n",
       "        [-4.9989952e+01, -4.3909126e+01, -3.8223278e+01, ...,\n",
       "          1.8310547e-03,  3.4730661e+02,  2.8770450e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-6.7612114e+01, -6.3780689e+01, -6.0542057e+01, ...,\n",
       "         -8.2397461e-04,  3.2438455e+02,  7.7582479e-02],\n",
       "        [-7.1608086e+01, -5.7788010e+01, -4.9506119e+01, ...,\n",
       "         -2.6710588e-03,  3.2456723e+02,  1.3812669e-01],\n",
       "        [-4.0117290e+01, -4.0121601e+01, -4.4000145e+01, ...,\n",
       "         -4.5181429e-03,  3.2474991e+02,  1.9867091e-01],\n",
       "        ...,\n",
       "        [-4.2414734e+01, -4.5422489e+01, -5.0039131e+01, ...,\n",
       "          6.3192965e-05,  3.6507034e+02,  7.4728829e-01],\n",
       "        [-4.6453438e+01, -5.4166809e+01, -4.8785198e+01, ...,\n",
       "          5.9617165e-04,  3.6608710e+02,  7.3173690e-01],\n",
       "        [-4.8127510e+01, -5.1301537e+01, -6.3256474e+01, ...,\n",
       "          1.1291504e-03,  3.6710382e+02,  7.1618557e-01]],\n",
       "\n",
       "       [[-4.3037094e+01, -3.7587318e+01, -3.5704487e+01, ...,\n",
       "         -2.4414062e-03,  4.0144809e+02,  4.7573662e-01],\n",
       "        [-4.8018078e+01, -2.9595776e+01, -3.1387712e+01, ...,\n",
       "         -4.3418189e-03,  3.9829578e+02,  4.7745413e-01],\n",
       "        [-3.1957743e+01, -3.3426685e+01, -3.9381638e+01, ...,\n",
       "         -6.2422319e-03,  3.9514343e+02,  4.7917160e-01],\n",
       "        ...,\n",
       "        [-4.7140812e+01, -4.3753643e+01, -4.5491035e+01, ...,\n",
       "         -2.6605779e-03,  3.2140167e+02,  4.2619568e-01],\n",
       "        [-5.1805714e+01, -5.4371532e+01, -4.0517601e+01, ...,\n",
       "         -2.5967686e-03,  3.2035175e+02,  3.6824143e-01],\n",
       "        [-4.0112656e+01, -4.2324120e+01, -5.5111656e+01, ...,\n",
       "         -2.5329590e-03,  3.1930179e+02,  3.1028718e-01]],\n",
       "\n",
       "       [[-5.2517704e+01, -4.7950089e+01, -4.4140038e+01, ...,\n",
       "         -3.3569336e-04,  3.3598083e+02,  1.3049002e-01],\n",
       "        [-3.9305332e+01, -4.0798157e+01, -5.7493294e+01, ...,\n",
       "         -2.1849354e-03,  3.3538977e+02,  1.5151930e-01],\n",
       "        [-5.1471291e+01, -4.7628479e+01, -4.4979080e+01, ...,\n",
       "         -4.0341774e-03,  3.3479871e+02,  1.7254856e-01],\n",
       "        ...,\n",
       "        [-3.4028316e+01, -3.7648914e+01, -3.6746033e+01, ...,\n",
       "         -1.6938489e-02,  3.0178543e+02,  8.7859148e-01],\n",
       "        [-4.3762161e+01, -3.9333748e+01, -3.8654251e+01, ...,\n",
       "         -2.0416876e-02,  3.0182806e+02,  8.7606531e-01],\n",
       "        [-3.3550289e+01, -3.4183075e+01, -3.6697456e+01, ...,\n",
       "         -2.3895264e-02,  3.0187070e+02,  8.7353915e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b909913c-9047-4732-aabb-a89a55c4edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "      <th>month_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_001</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_001.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_002</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_002.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_003</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_003.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_004</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_004.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_005</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_005.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9393</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_004</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_004.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9394</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_005</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_005.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_006</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_006.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_007</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_007.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_008</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_008.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9398 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                   stem  \\\n",
       "0     Hungry  Hungry00MB00007_2_001   \n",
       "1     Hungry  Hungry00MB00007_2_002   \n",
       "2     Hungry  Hungry00MB00007_2_003   \n",
       "3     Hungry  Hungry00MB00007_2_004   \n",
       "4     Hungry  Hungry00MB00007_2_005   \n",
       "...      ...                    ...   \n",
       "9393  Wakeup  Wakeup09MU00015_2_004   \n",
       "9394  Wakeup  Wakeup09MU00015_2_005   \n",
       "9395  Wakeup  Wakeup09MU00015_2_006   \n",
       "9396  Wakeup  Wakeup09MU00015_2_007   \n",
       "9397  Wakeup  Wakeup09MU00015_2_008   \n",
       "\n",
       "                                                f0_path  \\\n",
       "0     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "1     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "2     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "3     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "4     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "...                                                 ...   \n",
       "9393  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9394  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9395  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9396  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9397  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "\n",
       "                                            audio_path  T_final  T_stft  \\\n",
       "0     Baby2020/0Month/Hungry/Hungry00MB00007_2_001.wav      100     222   \n",
       "1     Baby2020/0Month/Hungry/Hungry00MB00007_2_002.wav      100     163   \n",
       "2     Baby2020/0Month/Hungry/Hungry00MB00007_2_003.wav      100     226   \n",
       "3     Baby2020/0Month/Hungry/Hungry00MB00007_2_004.wav      100     143   \n",
       "4     Baby2020/0Month/Hungry/Hungry00MB00007_2_005.wav      100     161   \n",
       "...                                                ...      ...     ...   \n",
       "9393  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_004.wav      100     132   \n",
       "9394  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_005.wav      100      91   \n",
       "9395  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_006.wav      100      96   \n",
       "9396  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_007.wav      100     123   \n",
       "9397  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_008.wav      100     107   \n",
       "\n",
       "      T_mfcc  T_f0  label_id month_folder  \n",
       "0        222    17         0       0Month  \n",
       "1        163    13         0       0Month  \n",
       "2        226    17         0       0Month  \n",
       "3        143    11         0       0Month  \n",
       "4        161    13         0       0Month  \n",
       "...      ...   ...       ...          ...  \n",
       "9393     132    10         6       9Month  \n",
       "9394      91     7         6       9Month  \n",
       "9395      96     8         6       9Month  \n",
       "9396     123    10         6       9Month  \n",
       "9397     107     8         6       9Month  \n",
       "\n",
       "[9398 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb1377-a28a-4b49-a85b-6bba25eb3099",
   "metadata": {},
   "source": [
    "# Make a noneleakage selection randomly test train 20 80 for baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ebddba-0665-470b-9c90-7eb90848322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def make_group_stratified_folds(\n",
    "    df_all: pd.DataFrame,\n",
    "    X_all: np.ndarray,\n",
    "    n_splits: int = 5,\n",
    "    group_from: str = \"audio_path\",\n",
    "    class_col: str = \"class\",\n",
    "    month_col: str = \"month_folder\",\n",
    "    selected_classes: list | None = None,\n",
    "    selected_months: list | None = None,\n",
    "    shuffle: bool = True,\n",
    "    random_state: int | None = None,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Leakage-safe, group-aware, stratified K-fold splits\n",
    "    with optional filtering and automatic label re-indexing.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Labels are re-indexed AFTER class/month selection\n",
    "      so they are contiguous: {0, 1, ..., K-1}\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(df_all) == len(X_all), \"df_all and X_all must be aligned\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 0. Optional filtering (NO leakage)\n",
    "    # --------------------------------------------------\n",
    "    mask = np.ones(len(df_all), dtype=bool)\n",
    "\n",
    "    if selected_classes is not None:\n",
    "        mask &= df_all[class_col].isin(selected_classes)\n",
    "\n",
    "    if selected_months is not None:\n",
    "        mask &= df_all[month_col].isin(selected_months)\n",
    "\n",
    "    df = df_all.loc[mask].copy().reset_index(drop=True)\n",
    "    X = X_all[mask]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nAfter filtering: {len(df)} samples\")\n",
    "        print(\"Class counts:\", df[class_col].value_counts().to_dict())\n",
    "        print(\"Month counts:\", df[month_col].value_counts().to_dict())\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Re-index labels AFTER selection (CRITICAL)\n",
    "    # --------------------------------------------------\n",
    "    unique_classes = sorted(df[class_col].unique())\n",
    "    class_to_label = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "    label_to_class = {i: cls for cls, i in class_to_label.items()}\n",
    "\n",
    "    df[\"label_id\"] = df[class_col].map(class_to_label)\n",
    "\n",
    "    num_classes = len(unique_classes)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nLabel re-indexing (used for training):\")\n",
    "        for cls, idx in class_to_label.items():\n",
    "            print(f\"  {cls} → {idx}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Extract group_id (leakage-safe)\n",
    "    # --------------------------------------------------\n",
    "    df[\"group_id\"] = (\n",
    "        df[group_from]\n",
    "        .str.split(\"/\")\n",
    "        .str[-1]\n",
    "        .str.split(\"_\")\n",
    "        .str[0]\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Group-level dataframe for stratification\n",
    "    # --------------------------------------------------\n",
    "    group_df = (\n",
    "        df.groupby(\"group_id\")\n",
    "        .agg({\n",
    "            class_col: \"first\",\n",
    "            month_col: \"first\"\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    group_df[\"strata\"] = (\n",
    "        group_df[class_col].astype(str) + \"_\" +\n",
    "        group_df[month_col].astype(str)\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 4. Stratified K-fold on GROUPS\n",
    "    # --------------------------------------------------\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=shuffle,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 5. Build folds\n",
    "    # --------------------------------------------------\n",
    "    for fold_idx, (train_g_idx, test_g_idx) in enumerate(\n",
    "        skf.split(group_df[\"group_id\"], group_df[\"strata\"])\n",
    "    ):\n",
    "        train_group_ids = set(group_df.iloc[train_g_idx][\"group_id\"])\n",
    "        test_group_ids  = set(group_df.iloc[test_g_idx][\"group_id\"])\n",
    "\n",
    "        train_mask = df[\"group_id\"].isin(train_group_ids)\n",
    "        test_mask  = df[\"group_id\"].isin(test_group_ids)\n",
    "\n",
    "        X_train = X[train_mask.values]\n",
    "        X_test  = X[test_mask.values]\n",
    "\n",
    "        df_train = df.loc[train_mask].reset_index(drop=True)\n",
    "        df_test  = df.loc[test_mask].reset_index(drop=True)\n",
    "\n",
    "        # Sanity checks\n",
    "        assert train_group_ids.isdisjoint(test_group_ids)\n",
    "        assert len(X_train) + len(X_test) == len(X)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nFold {fold_idx}: \"\n",
    "                f\"train={len(X_train)} ({len(X_train)/len(X):.2%}), \"\n",
    "                f\"test={len(X_test)} ({len(X_test)/len(X):.2%})\"\n",
    "            )\n",
    "\n",
    "        folds.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"df_train\": df_train,\n",
    "            \"df_test\": df_test,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"class_to_label\": class_to_label,\n",
    "            \"label_to_class\": label_to_class,\n",
    "            \"train_group_ids\": train_group_ids,\n",
    "            \"test_group_ids\": test_group_ids\n",
    "        })\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86554eee-22f6-4e32-b12e-df41e39192f7",
   "metadata": {},
   "source": [
    "# Reproduceable with random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62bc3a35-7b44-43e1-858f-4835b2519489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     shuffle=True,\n",
    "#     random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de68fa-2a96-4815-a650-4a2e05ebb152",
   "metadata": {},
   "source": [
    "## Random every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "956535f2-41e7-4b7f-ba98-ca9ece732120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     shuffle=True,\n",
    "#     random_state=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb0e6f-b371-4f11-8107-6b9e0b756cba",
   "metadata": {},
   "source": [
    "## Only selected months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c195e1-8cc9-4757-b4a2-802990909e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     selected_months=[\"0Month\", \"9Month\"],\n",
    "#     random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b58ca-8e05-4e15-8055-31b5694c7457",
   "metadata": {},
   "source": [
    "# Selected months and selected moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4177e665-5686-4114-9042-f224e2c1f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering: 2190 samples\n",
      "Class counts: {'Hungry': 1000, 'Sleepy': 600, 'Wakeup': 590}\n",
      "Month counts: {'3Month': 750, '2Month': 700, '0Month': 400, '1Month': 340}\n",
      "\n",
      "Label re-indexing (used for training):\n",
      "  Hungry → 0\n",
      "  Sleepy → 1\n",
      "  Wakeup → 2\n",
      "\n",
      "Fold 0: train=1982 (90.50%), test=208 (9.50%)\n",
      "\n",
      "Fold 1: train=1989 (90.82%), test=201 (9.18%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2: train=1996 (91.14%), test=194 (8.86%)\n",
      "\n",
      "Fold 3: train=1987 (90.73%), test=203 (9.27%)\n",
      "\n",
      "Fold 4: train=2027 (92.56%), test=163 (7.44%)\n",
      "\n",
      "Fold 5: train=1871 (85.43%), test=319 (14.57%)\n",
      "\n",
      "Fold 6: train=1925 (87.90%), test=265 (12.10%)\n",
      "\n",
      "Fold 7: train=1964 (89.68%), test=226 (10.32%)\n",
      "\n",
      "Fold 8: train=1951 (89.09%), test=239 (10.91%)\n",
      "\n",
      "Fold 9: train=2018 (92.15%), test=172 (7.85%)\n"
     ]
    }
   ],
   "source": [
    "folds = make_group_stratified_folds(\n",
    "    df_all,\n",
    "    X_all,\n",
    "    n_splits=10,\n",
    "    selected_months=[\"0Month\", \"1Month\", \"2Month\", \"3Month\"],\n",
    "    selected_classes=[\"Sleepy\", \"Hungry\", \"Wakeup\"],\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d791d-1355-4162-a5bb-eeb3dc84a2a1",
   "metadata": {},
   "source": [
    "# Folds reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5734a56-764e-4dbf-b8d9-aa92ce2893cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOLD 0\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.36\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=22, mean=7.70\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy03MB00008 Sleepy       3Month           22\n",
      "Sleepy03MB00031 Sleepy       3Month           22\n",
      "Wakeup01MB00001 Wakeup       1Month           18\n",
      "Sleepy01MB00005 Sleepy       1Month           15\n",
      "Hungry00MG00002 Hungry       0Month           12\n",
      "\n",
      "================================================================================\n",
      "FOLD 1\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.39\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=26, mean=7.44\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Hungry01MB00009 Hungry       1Month           26\n",
      "Hungry00MG00001 Hungry       0Month           20\n",
      "Hungry02MB00017 Hungry       2Month           17\n",
      "Sleepy01MB00003 Sleepy       1Month           17\n",
      "Hungry03MB00034 Hungry       3Month           13\n",
      "\n",
      "================================================================================\n",
      "FOLD 2\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.42\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=20, mean=7.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Hungry01MB00014 Hungry       1Month           20\n",
      "Hungry03MG00007 Hungry       3Month           20\n",
      "Hungry00MG00005 Hungry       0Month           18\n",
      "Hungry00MB00011 Hungry       0Month           17\n",
      "Hungry03MG00009 Hungry       3Month           15\n",
      "\n",
      "================================================================================\n",
      "FOLD 3\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.38\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=34, mean=7.52\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Hungry00MG00006 Hungry       0Month           22\n",
      "Hungry03MG00006 Hungry       3Month           19\n",
      "Hungry00MU00016 Hungry       0Month           17\n",
      "Hungry03MG00005 Hungry       3Month           16\n",
      "\n",
      "================================================================================\n",
      "FOLD 4\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.52\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=32, mean=6.27\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup03MB00004 Wakeup       3Month           32\n",
      "Sleepy00MB00001 Sleepy       0Month           21\n",
      "Hungry01MB00010 Hungry       1Month           19\n",
      "Hungry02MB00016 Hungry       2Month           15\n",
      "Hungry00MB00007 Hungry       0Month           12\n",
      "\n",
      "================================================================================\n",
      "FOLD 5\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=7.86\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup03MB00004 Wakeup       3Month           32\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=40, mean=12.27\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Hungry01MB00013 Hungry       1Month           29\n",
      "Wakeup03MG00002 Wakeup       3Month           27\n",
      "Wakeup03MB00042 Wakeup       3Month           22\n",
      "\n",
      "================================================================================\n",
      "FOLD 6\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.09\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=34, mean=10.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup00MG00004 Wakeup       0Month           29\n",
      "Sleepy00MB00002 Sleepy       0Month           26\n",
      "Hungry01MB00016 Hungry       1Month           19\n",
      "Sleepy03MB00030 Sleepy       3Month           17\n",
      "\n",
      "================================================================================\n",
      "FOLD 7\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=40, mean=8.25\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=45, mean=8.69\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup02MG00002 Wakeup       2Month           22\n",
      "Sleepy03MG00001 Sleepy       3Month           15\n",
      "Hungry00MU00003 Hungry       0Month           12\n",
      "Sleepy01MB00004 Sleepy       1Month           11\n",
      "\n",
      "================================================================================\n",
      "FOLD 8\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.20\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=36, mean=9.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Hungry01MB00002 Hungry       1Month           25\n",
      "Wakeup03MG00001 Wakeup       3Month           24\n",
      "Hungry00MB00010 Hungry       0Month           23\n",
      "Sleepy01MG00001 Sleepy       1Month           22\n",
      "\n",
      "================================================================================\n",
      "FOLD 9\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.48\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=20, mean=6.62\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy01MB00006 Sleepy       1Month           20\n",
      "Wakeup02MU00015 Wakeup       2Month           14\n",
      "Sleepy02MG00003 Sleepy       2Month           12\n",
      "Sleepy03MB00034 Sleepy       3Month           12\n",
      "Hungry00MG00004 Hungry       0Month           12\n"
     ]
    }
   ],
   "source": [
    "def print_group_statistics(folds, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Print statistics of number of samples per (group_id, class, month)\n",
    "    for each fold, separately for train and test.\n",
    "    \"\"\"\n",
    "\n",
    "    for f in folds:\n",
    "        fold_id = f[\"fold\"]\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"FOLD {fold_id}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for split_name, df_split in [\n",
    "            (\"TRAIN\", f[\"df_train\"]),\n",
    "            (\"TEST\",  f[\"df_test\"])\n",
    "        ]:\n",
    "            print(f\"\\n--- {split_name} SPLIT ---\")\n",
    "\n",
    "            # Count samples per (group_id, class, month)\n",
    "            counts = (\n",
    "                df_split\n",
    "                .groupby([\"group_id\", \"class\", \"month_folder\"])\n",
    "                .size()\n",
    "                .reset_index(name=\"num_samples\")\n",
    "            )\n",
    "\n",
    "            # Summary statistics\n",
    "            print(f\"Number of unique IDs: {counts['group_id'].nunique()}\")\n",
    "            print(\n",
    "                \"Samples per ID: \"\n",
    "                f\"min={counts['num_samples'].min()}, \"\n",
    "                f\"max={counts['num_samples'].max()}, \"\n",
    "                f\"mean={counts['num_samples'].mean():.2f}\"\n",
    "            )\n",
    "\n",
    "            # Show largest groups\n",
    "            print(f\"\\nTop {top_k} IDs with most samples:\")\n",
    "            print(\n",
    "                counts\n",
    "                .sort_values(\"num_samples\", ascending=False)\n",
    "                .head(top_k)\n",
    "                .to_string(index=False)\n",
    "            )\n",
    "\n",
    "\n",
    "print_group_statistics(folds, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48367afd-9a0d-46d8-a98d-7628456d5eb8",
   "metadata": {},
   "source": [
    "# Network Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2df4088d-e80f-4860-a335-fae695e281d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://artifacts.uottawa.ca/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: tensorflow in /usr/lib/python3/dist-packages (2.19.0)\n",
      "Collecting tensorflow\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/e5/9e/0d57922cf46b9e91de636cd5b5e0d7a424ebe98f3245380a713f1f6c2a0b/tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.4/620.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.30.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.1.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting tensorboard~=2.20.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/9c/d9/a5db55f88f258ac669a92858b70a714bbbd5acd993820b41ec4a96a4d77f/tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.5.1)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/b1/45/e1a754dc7cd465ba35e438e28557119221ac89b20aaebef48282654e3dc7/h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.6.6 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting protobuf>=5.28.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/40/01/2e730bd1c25392fc32e3268e02446f0d77cb51a2c3a8486b1798e34d5805/protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/lib/python3/dist-packages (from tensorflow) (3.10.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/fd/75/a1991dd64b331d199935e096cc9daa3415ee5ccbe9f909aa48eded7bba34/grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: pillow in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Installing collected packages: libclang, flatbuffers, tensorboard-data-server, protobuf, h5py, grpcio, gast, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/uottawa.o.univ/njaza024/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/home/uottawa.o.univ/njaza024/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed flatbuffers-25.2.10 gast-0.6.0 grpcio-1.74.0 h5py-3.14.0 libclang-18.1.1 protobuf-6.32.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff92fab-ecb7-4602-9cdc-5e526bff9444",
   "metadata": {},
   "source": [
    "## Integrate with Cross-Fold or 5 random seed\n",
    "\n",
    "### and std and avg between all MCC F1 micro and macro score precision recall and specificity and sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c25b6f0-355c-43f2-919c-0e1c5d7dc472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1468, 100, 280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee78a11b-8d42-48e8-9b42-1cd73feb3168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label_id_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_0_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1384</td>\n",
       "      <td>1384</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_100_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1373</td>\n",
       "      <td>1373</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_101_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>2047</td>\n",
       "      <td>2047</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_102_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1482</td>\n",
       "      <td>1482</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_103_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1381</td>\n",
       "      <td>1381</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_95</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1066</td>\n",
       "      <td>1066</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_96</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1136</td>\n",
       "      <td>1136</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_97</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_98</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_99</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1347</td>\n",
       "      <td>1347</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1468 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              class                stem  \\\n",
       "0             awake    awake_0_filtered   \n",
       "1             awake  awake_100_filtered   \n",
       "2             awake  awake_101_filtered   \n",
       "3             awake  awake_102_filtered   \n",
       "4             awake  awake_103_filtered   \n",
       "...             ...                 ...   \n",
       "1463  uncomfortable    uncomfortable_95   \n",
       "1464  uncomfortable    uncomfortable_96   \n",
       "1465  uncomfortable    uncomfortable_97   \n",
       "1466  uncomfortable    uncomfortable_98   \n",
       "1467  uncomfortable    uncomfortable_99   \n",
       "\n",
       "                                                f0_path  \\\n",
       "0     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "1     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "2     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "3     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "4     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "...                                                 ...   \n",
       "1463  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1464  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1465  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1466  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1467  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "\n",
       "                                             audio_path  T_final  T_stft  \\\n",
       "0     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1384   \n",
       "1     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1373   \n",
       "2     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    2047   \n",
       "3     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1482   \n",
       "4     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1381   \n",
       "...                                                 ...      ...     ...   \n",
       "1463  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1066   \n",
       "1464  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1136   \n",
       "1465  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1058   \n",
       "1466  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1033   \n",
       "1467  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1347   \n",
       "\n",
       "      T_mfcc  T_f0  label_id        dataset  label_id_merged  \n",
       "0       1384   104         0  reverbChinese                0  \n",
       "1       1373   103         0  reverbChinese                0  \n",
       "2       2047   154         0  reverbChinese                0  \n",
       "3       1482   112         0  reverbChinese                0  \n",
       "4       1381   104         0  reverbChinese                0  \n",
       "...      ...   ...       ...            ...              ...  \n",
       "1463    1066    80         5        chinese                5  \n",
       "1464    1136    86         5        chinese                5  \n",
       "1465    1058    80         5        chinese                5  \n",
       "1466    1033    78         5        chinese                5  \n",
       "1467    1347   101         5        chinese                5  \n",
       "\n",
       "[1468 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_manifest_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d2120-9135-450a-a594-7caaf936e2f7",
   "metadata": {},
   "source": [
    "# Label verification encoded if I haven't used the fold noneleakage of baby2020 or working with nother dataset than baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4b4dc8-7c22-4e62-8cca-080a2d4d07da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Every class maps to exactly one label_id_merged.\n",
      "✅ Every label_id_merged maps to exactly one class.\n",
      "Mapping looks good. Example: [('awake', 0), ('diaper', 1), ('hug', 2), ('hungry', 3), ('sleepy', 4)]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # df = train_manifest_merged.copy()\n",
    "# df = train_manifest_chinese.copy()\n",
    "\n",
    "# # If X_train_chinese is ndarray and you have y_train_chinese separately:\n",
    "# # df = pd.DataFrame({\n",
    "# #     \"class\": X_train_chinese,     # supply your class column\n",
    "# #     \"label_id_merged\": y_train_chinese  # supply your label column\n",
    "# # })\n",
    "\n",
    "\n",
    "# # Handle possible typo\n",
    "# label_col = \"label_id_merged\" if \"label_id_merged\" in df.columns else \"labe_id_merged\"\n",
    "# assert label_col in df.columns, f\"Column '{label_col}' not found.\"\n",
    "\n",
    "# # Use only unique (class, label) pairs\n",
    "# pairs = df[[\"class\", label_col]].drop_duplicates()\n",
    "\n",
    "# # 1) class -> label is unique?\n",
    "# class_to_n = pairs.groupby(\"class\")[label_col].nunique()\n",
    "# bad_classes = class_to_n[class_to_n != 1]\n",
    "\n",
    "# # 2) label -> class is unique? (optional but recommended)\n",
    "# label_to_n = pairs.groupby(label_col)[\"class\"].nunique()\n",
    "# bad_labels = label_to_n[label_to_n != 1]\n",
    "\n",
    "# if bad_classes.empty:\n",
    "#     print(\"✅ Every class maps to exactly one label_id_merged.\")\n",
    "# else:\n",
    "#     print(\"❌ Some classes map to multiple label_id_merged values:\")\n",
    "#     print(bad_classes.sort_values(ascending=False))\n",
    "\n",
    "# if bad_labels.empty:\n",
    "#     print(\"✅ Every label_id_merged maps to exactly one class.\")\n",
    "# else:\n",
    "#     print(\"❌ Some label_id_merged values are shared by multiple classes:\")\n",
    "#     print(bad_labels.sort_values(ascending=False))\n",
    "\n",
    "# # If everything is 1–1, this is the mapping dict (class -> label_id_merged):\n",
    "# if bad_classes.empty and bad_labels.empty:\n",
    "#     class_to_label = pairs.set_index(\"class\")[label_col].to_dict()\n",
    "#     print(\"Mapping looks good. Example:\", list(class_to_label.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd48279-9d46-4004-ad19-b7339d0722b7",
   "metadata": {},
   "source": [
    "# Test Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a9801-63c6-44cb-b4be-a4f516085a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chinese, y_train_chinese, X_test_chinese, y_test_chinese, id2cls_chinese, train_manifest_chinese, test_manifest_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e482b14a-461e-4fa1-8c87-acb5ba4cc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = X_train_merged\n",
    "# # y_train = y_train_merged\n",
    "# # X_test = X_test_merged\n",
    "# # y_test = y_test_merged\n",
    "\n",
    "X_train = X_train_Chinese_3mood\n",
    "y_train = y_train_Chinese_3mood\n",
    "X_test = X_test_Chinese_3mood\n",
    "y_test = y_test_Chinese_3mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90c533a-447b-46c6-a97b-4e8074251382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 100, 280, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad333270-f6a0-4ece-848c-5f70ff1d3e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f40e59-9925-4a2d-9d2b-553987d2dfe7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad961b34-fb47-4cb0-ae2b-f1aa2ca38f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"best_Chinese_baby20202_merged_blind.keras\"\n",
    "history_name = 'history_Chinese_baby20202_merged_blind.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb09a28-7eb6-43bf-bfad-681463290289",
   "metadata": {},
   "source": [
    "# IF there is no folding strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c404ad-0a65-47c4-a841-8dd1b1bf34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and validation sets (80% training, 20% validation, change as needed)  \n",
    "\n",
    "# # X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train) \n",
    "\n",
    "# X_train_split = X_train\n",
    "# X_val_split = X_test\n",
    "# y_train_split = y_train\n",
    "# y_val_split = y_test\n",
    "\n",
    "# # # # Add the channel dimension\n",
    "# X_train_split = np.expand_dims(X_train_split, axis=-1)\n",
    "# X_val_split = np.expand_dims(X_val_split, axis=-1)\n",
    "# # X_test= np.expand_dims(X_test, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272f361-007b-4bf6-8674-01a868123c1a",
   "metadata": {},
   "source": [
    "# Filter moods (for chinese baby cry or again baby2020 while no folding and filtering applied)\n",
    "\n",
    "### please comment the expand part in orevious command and run the 2 previous command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b047d4-3cc8-4468-8cbc-d3424c287bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 'diaper', 1: 'sleepy', 2: 'uncomfortable'}\n",
      "Train shape: (350, 100, 280, 1)  Val shape: (88, 100, 280, 1)\n",
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Classes of interest\n",
    "# keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "# class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# # --- Train filtering ---\n",
    "# mask_train = np.isin(y_train, keep_classes)\n",
    "# X_train_split = X_train[mask_train]\n",
    "# y_train_split = y_train[mask_train]\n",
    "\n",
    "# # --- Test filtering ---\n",
    "# mask_test = np.isin(y_test, keep_classes)\n",
    "# X_val_split = X_test[mask_test]\n",
    "# y_val_split = y_test[mask_test]\n",
    "\n",
    "# # --- Re-encode labels to [0,1,2] ---\n",
    "# unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "# class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "# id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# y_train_split = np.array([class2newid[y] for y in y_train_split])\n",
    "# y_val_split = np.array([class2newid[y] for y in y_val_split])\n",
    "\n",
    "# # --- Add channel dimension ---\n",
    "# X_train_split = np.expand_dims(X_train_split, axis=-1)\n",
    "# X_val_split = np.expand_dims(X_val_split, axis=-1)\n",
    "\n",
    "# print(\"Class mapping:\", id2cls_merge_3mood)\n",
    "# print(\"Train shape:\", X_train_split.shape, \" Val shape:\", X_val_split.shape)\n",
    "# print(\"Unique encoded y:\", np.unique(y_train_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9aa4ea-0efd-4227-93d4-7548fd590ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60e20aa-d17a-4856-bc3c-91e576575fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"diaper\", \"sleepy\", \"uncomfortable\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3bbb4f7-d476-4c49-97e3-ae298459435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique encoded y:\", np.unique(y_val_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0000c2-f943-420c-98ca-f9eb7249aa32",
   "metadata": {},
   "source": [
    "# Merging Chinese baby cry and Baby2020 3 mood 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd6b2e4-8f40-4044-9119-a220d4e6f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "global_cls2id = {c:i for i,c in enumerate(GLOBAL_CLASSES)}\n",
    "global_id2cls = {i:c for c,i in global_cls2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89c9c0f0-42a4-41ee-9e59-0a34f2b44642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def baby_fold_global_y(df_split, label_to_class, global_cls2id):\n",
    "    local_y = df_split[\"label_id\"].to_numpy()\n",
    "    class_str = np.array([label_to_class[int(i)] for i in local_y], dtype=object)\n",
    "    global_y = np.array([global_cls2id[c] for c in class_str], dtype=np.int64)\n",
    "    return global_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e44d0b4-a36f-4a6f-b127-68fe97cff73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_to_global(y_ch, id2cls_ch, global_cls2id):\n",
    "    cls_str = np.array([id2cls_ch[int(i)] for i in y_ch], dtype=object)\n",
    "    y_global = np.array([global_cls2id[c] for c in cls_str], dtype=np.int64)\n",
    "    return y_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab3c13f9-af03-4951-979a-c25782add79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_baby_folds_with_fixed_chinese(\n",
    "    baby_folds,\n",
    "    Xc_train, yc_train_global,\n",
    "    Xc_test,  yc_test_global,\n",
    "    add_channel=True,\n",
    "    keep_separate_tests=False  # False=Option A, True=Option B\n",
    "):\n",
    "    merged = []\n",
    "\n",
    "    # normalize Chinese X to (N,T,F) for concat (remove channel)\n",
    "    if Xc_train.ndim == 4 and Xc_train.shape[-1] == 1:\n",
    "        Xc_train_3d = Xc_train[..., 0]\n",
    "        Xc_test_3d  = Xc_test[..., 0]\n",
    "    else:\n",
    "        Xc_train_3d = Xc_train\n",
    "        Xc_test_3d  = Xc_test\n",
    "\n",
    "    for k, fb in enumerate(baby_folds):\n",
    "        Xb_tr, Xb_te = fb[\"X_train\"], fb[\"X_test\"]\n",
    "\n",
    "        # normalize Baby X to (N,T,F)\n",
    "        if Xb_tr.ndim == 4 and Xb_tr.shape[-1] == 1:\n",
    "            Xb_tr = Xb_tr[..., 0]\n",
    "            Xb_te = Xb_te[..., 0]\n",
    "\n",
    "        # Baby y -> global\n",
    "        yb_tr = baby_fold_global_y(fb[\"df_train\"], fb[\"label_to_class\"], global_cls2id)\n",
    "        yb_te = baby_fold_global_y(fb[\"df_test\"],  fb[\"label_to_class\"], global_cls2id)\n",
    "\n",
    "        # Merge training always\n",
    "        X_train = np.concatenate([Xb_tr, Xc_train_3d], axis=0)\n",
    "        y_train = np.concatenate([yb_tr, yc_train_global], axis=0)\n",
    "\n",
    "        # Domain labels (0=Baby, 1=Chinese) optional but useful\n",
    "        d_train = np.concatenate([\n",
    "            np.zeros(len(Xb_tr), dtype=np.int64),\n",
    "            np.ones(len(Xc_train_3d), dtype=np.int64)\n",
    "        ])\n",
    "\n",
    "        if keep_separate_tests:\n",
    "            # Option B: separate test sets\n",
    "            X_test_baby, y_test_baby = Xb_te, yb_te\n",
    "            X_test_ch,   y_test_ch   = Xc_test_3d, yc_test_global\n",
    "\n",
    "            d_test_baby = np.zeros(len(X_test_baby), dtype=np.int64)\n",
    "            d_test_ch   = np.ones(len(X_test_ch), dtype=np.int64)\n",
    "\n",
    "            if add_channel:\n",
    "                X_train = X_train[..., None]\n",
    "                X_test_baby = X_test_baby[..., None]\n",
    "                X_test_ch   = X_test_ch[..., None]\n",
    "\n",
    "            merged.append({\n",
    "                \"fold\": k,\n",
    "                \"X_train\": X_train, \"y_train\": y_train, \"d_train\": d_train,\n",
    "                \"X_test_baby\": X_test_baby, \"y_test_baby\": y_test_baby, \"d_test_baby\": d_test_baby,\n",
    "                \"X_test_chinese\": X_test_ch, \"y_test_chinese\": y_test_ch, \"d_test_chinese\": d_test_ch,\n",
    "            })\n",
    "\n",
    "            print(f\"Fold {k}: train={X_train.shape} | test_baby={X_test_baby.shape} | test_ch={X_test_ch.shape}\")\n",
    "\n",
    "        else:\n",
    "            # Option A: one mixed test set\n",
    "            X_test  = np.concatenate([Xb_te, Xc_test_3d], axis=0)\n",
    "            y_test  = np.concatenate([yb_te, yc_test_global], axis=0)\n",
    "\n",
    "            d_test = np.concatenate([\n",
    "                np.zeros(len(Xb_te), dtype=np.int64),\n",
    "                np.ones(len(Xc_test_3d), dtype=np.int64)\n",
    "            ])\n",
    "\n",
    "            if add_channel:\n",
    "                X_train = X_train[..., None]\n",
    "                X_test  = X_test[..., None]\n",
    "\n",
    "            merged.append({\n",
    "                \"fold\": k,\n",
    "                \"X_train\": X_train, \"y_train\": y_train,\n",
    "                \"X_test\": X_test, \"y_test\": y_test,\n",
    "                \"d_train\": d_train, \"d_test\": d_test\n",
    "            })\n",
    "\n",
    "            print(f\"Fold {k}: train={X_train.shape} test={X_test.shape} y_train_uniq={np.unique(y_train)}\")\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "558d77b5-45f7-4886-8c8b-24ecae23d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: train=(2332, 100, 280, 1) test=(296, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 1: train=(2339, 100, 280, 1) test=(289, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 2: train=(2346, 100, 280, 1) test=(282, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 3: train=(2337, 100, 280, 1) test=(291, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 4: train=(2377, 100, 280, 1) test=(251, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 5: train=(2221, 100, 280, 1) test=(407, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 6: train=(2275, 100, 280, 1) test=(353, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 7: train=(2314, 100, 280, 1) test=(314, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 8: train=(2301, 100, 280, 1) test=(327, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n",
      "Fold 9: train=(2368, 100, 280, 1) test=(260, 100, 280, 1) y_train_uniq=[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Chinese -> global y\n",
    "yc_train_global = chinese_to_global(y_train_Chinese_3mood, id2cls_merge_3mood, global_cls2id)\n",
    "yc_test_global  = chinese_to_global(y_test_Chinese_3mood,  id2cls_merge_3mood, global_cls2id)\n",
    "\n",
    "# Merge into Baby folds (choose Option A or B)\n",
    "merged_folds = merge_baby_folds_with_fixed_chinese(\n",
    "    baby_folds=folds,\n",
    "    Xc_train=X_train_Chinese_3mood, yc_train_global=yc_train_global,\n",
    "    Xc_test=X_test_Chinese_3mood,  yc_test_global=yc_test_global,\n",
    "    add_channel=True,\n",
    "    keep_separate_tests=False   # True = Option B, False = Option A\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934fba1-e034-43f2-8669-e5d31d39489f",
   "metadata": {},
   "source": [
    "## Cancel GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8848208a-ca72-45a8-a31f-602977fbf271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "XLA JIT?: \n"
     ]
    }
   ],
   "source": [
    "# # === MUST RUN AS FIRST CELL, BEFORE 'import tensorflow' ===\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"                 # hide all GPUs\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0 --tf_xla_enable_xla_devices=false\"\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"                  # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.config.optimizer.set_jit(False)                        # double-check\n",
    "\n",
    "# print(\"Physical devices:\", tf.config.list_physical_devices())\n",
    "# print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "# print(\"XLA JIT?:\", tf.config.optimizer.get_jit())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df9967-8f9a-4ae2-b144-7b3e7408bd54",
   "metadata": {},
   "source": [
    "## Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a32dd4f8-4c0b-4eb8-895b-27d106b4e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # 1) Make sure XLA is OFF at runtime\n",
    "# tf.config.optimizer.set_jit(False)                  # disable global XLA\n",
    "# tf.config.experimental.enable_mlir_graph_optimization(False)  # extra guard\n",
    "\n",
    "# # 2) Don't JIT-compile functions (if you use tf.function)\n",
    "# tf.config.run_functions_eagerly(False)              # keep graph mode, but no JIT\n",
    "\n",
    "# # 3) Keep GPU but avoid huge preallocs\n",
    "# for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "#     try: tf.config.experimental.set_memory_growth(g, True)\n",
    "#     except: pass\n",
    "\n",
    "# print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fadce-6908-4826-9cd4-5e517dd0a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ---- disable XLA JIT before importing TF ----\n",
    "# import os\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "# os.environ[\"TF_XLA_ENABLE_XLA_DEVICES\"] = \"0\"   # older TF env, harmless if unused\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"        # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # safety: also disable via API\n",
    "# tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# # optional: make GPU memory grow as needed (avoid big prealloc)\n",
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# for gpu in gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "# import os\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda\"  # adjust to your CUDA root\n",
    "\n",
    "# # === CPU-ONLY, no XLA ===\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"            # hide all GPUs\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"   # no XLA\n",
    "# os.environ[\"TF_XLA_ENABLE_XLA_DEVICES\"] = \"0\"\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"             # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.config.optimizer.set_jit(False)                   # double-check\n",
    "# print(\"Devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ebede6-c195-4ca9-96c0-c78d9eee9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, precision_score, recall_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K, regularizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea5438-572d-4267-950b-d7665ab6ddf5",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce58eeda-7423-4069-90fe-77c1b78a7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def bootstrap_ci(metric_fn, y_true, y_pred, class_index=None, n_boot=1000, ci=95):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for AUC, PR-AUC, etc.\n",
    "    metric_fn should accept (y_true, y_pred).\n",
    "    If multi-class, you can pass class_index to slice class column.\n",
    "    \"\"\"\n",
    "\n",
    "    boot_scores = []\n",
    "    n = len(y_true)\n",
    "\n",
    "    rng = np.random.default_rng(42)   # reproducible\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)   # sample with replacement\n",
    "        yt = y_true[idx]\n",
    "        yp = y_pred[idx]\n",
    "\n",
    "        if class_index is not None:\n",
    "            yt = yt[:, class_index]\n",
    "            yp = yp[:, class_index]\n",
    "\n",
    "        try:\n",
    "            score = metric_fn(yt, yp)\n",
    "            boot_scores.append(score)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    lower = np.percentile(boot_scores, (100-ci)/2)\n",
    "    upper = np.percentile(boot_scores, 100 - (100-ci)/2)\n",
    "    return np.mean(boot_scores), lower, upper\n",
    "\n",
    "\n",
    "class AUCPlotsCallback(Callback):\n",
    "    def __init__(self, X_val, y_val_onehot, class_names):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val_onehot = y_val_onehot\n",
    "        self.class_names = class_names\n",
    "        self.n_classes = len(class_names)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        y_prob = self.model.predict(self.X_val)\n",
    "        y_true = self.y_val_onehot\n",
    "\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"  CONFIDENCE INTERVALS (95%)\")\n",
    "        print(\"==============================\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Macro AUC with CI\n",
    "        # -------------------------\n",
    "        def auc_macro_fn(y_true, y_pred):\n",
    "            return roc_auc_score(\n",
    "                y_true, y_pred,\n",
    "                average=\"macro\",\n",
    "                multi_class=\"ovr\"\n",
    "            )\n",
    "\n",
    "        macro_mean, macro_low, macro_high = bootstrap_ci(\n",
    "            auc_macro_fn, y_true, y_prob, n_boot=1000\n",
    "        )\n",
    "\n",
    "        print(f\"\\nMacro AUC = {macro_mean:.4f}  (95% CI: {macro_low:.4f} – {macro_high:.4f})\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-Class ROC AUC\n",
    "        # -------------------------\n",
    "        print(\"\\nPer-class ROC AUC with 95% CI:\")\n",
    "        for c in range(self.n_classes):\n",
    "\n",
    "            def auc_single(y_true_c, y_pred_c):\n",
    "                fpr, tpr, _ = roc_curve(y_true_c, y_pred_c)\n",
    "                return auc(fpr, tpr)\n",
    "\n",
    "            mean_auc, low_auc, high_auc = bootstrap_ci(\n",
    "                auc_single, y_true, y_prob, class_index=c, n_boot=800\n",
    "            )\n",
    "            print(f\"  {self.class_names[c]}: {mean_auc:.4f}  (95% CI: {low_auc:.4f} – {high_auc:.4f})\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-Class PR AUC with CI\n",
    "        # -------------------------\n",
    "        print(\"\\nPer-class Precision–Recall AUC with 95% CI:\")\n",
    "        for c in range(self.n_classes):\n",
    "\n",
    "            def pr_auc_single(y_true_c, y_pred_c):\n",
    "                precision, recall, _ = precision_recall_curve(y_true_c, y_pred_c)\n",
    "                return auc(recall, precision)\n",
    "\n",
    "            mean_pr, low_pr, high_pr = bootstrap_ci(\n",
    "                pr_auc_single, y_true, y_prob, class_index=c, n_boot=800\n",
    "            )\n",
    "\n",
    "            print(f\"  {self.class_names[c]} PR-AUC: {mean_pr:.4f}  (95% CI: {low_pr:.4f} – {high_pr:.4f})\")\n",
    "\n",
    "        print(\"\\nDone computing bootstrap confidence intervals.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, num_heads=4, key_dim=32, ff_dim=64, dropout=0.1):\n",
    "    # Multi-head self-attention\n",
    "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attn = layers.Dropout(dropout)(attn)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn)\n",
    "\n",
    "    # Feed-forward\n",
    "    ffn = layers.Dense(ff_dim, activation=\"relu\")(out1)\n",
    "    ffn = layers.Dense(inputs.shape[-1])(ffn)\n",
    "    ffn = layers.Dropout(dropout)(ffn)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ffn)\n",
    "\n",
    "\n",
    "# X_train = Train_Dac_result_3d\n",
    "# X_test = Test_DaC_result_3d\n",
    "\n",
    "# X_train = X_train_reduced  #Train_Dac_result_3d\n",
    "# X_test = X_test_reduced   #Test_DaC_result_3d\n",
    "\n",
    "# y_train = y_train_reduced\n",
    "# y_test = y_test_reduced\n",
    "\n",
    "\n",
    "# checkpoint_path = \"Combined_Cinese_CNN_LSTM_3_balanced.keras\"  \n",
    "# def build_model(input_shape, num_classes):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "    \n",
    "#     # CNN Feature Extractor with only one Conv2D layer\n",
    "#     x = Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = Dropout(0.5)(x)  # Dropout added after pooling\n",
    "\n",
    "#     # Convert CNN output to time-distributed format for LSTM\n",
    "#     x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "#     # LSTM Layer\n",
    "#     x = LSTM(4, return_sequences=False)(x)\n",
    "#     x = Dropout(0.5)(x)  # Dropout added after LSTM\n",
    "\n",
    "#     # Fully Connected Layers\n",
    "#     x = Dense(4, activation=\"relu\")(x)\n",
    "#     output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.00001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    l2_reg = regularizers.l2(0.001)  # You can tune this value (e.g., 0.0001 or 0.01)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN layers with L2 regularization\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM layer with L2 regularization\n",
    "    x = LSTM(\n",
    "    32,\n",
    "    return_sequences=False,\n",
    "    kernel_regularizer=l2_reg\n",
    "    )(x)\n",
    "\n",
    "    #################################################### Transformer\n",
    "    # # Multi-head self-attention\n",
    "    # x = transformer_encoder(x)\n",
    "    # x = layers.GlobalAveragePooling1D()(x)  # like LSTM(return_sequences=False)\n",
    "\n",
    "    ####################################################  GRU\n",
    "    \n",
    "    # x = GRU(32, return_sequences=False, kernel_regularizer=l2_reg)(x)\n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Dense layers with L2\n",
    "    x = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2_reg)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    # sparse_categorical_crossentropy los\n",
    "    # model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    # Focal Loss\n",
    "    # model.compile(optimizer=Adam(learning_rate=0.000001), loss=focal_loss(alpha=0.25, gamma=2.0), metrics=['accuracy'])\n",
    "    \n",
    "    loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy']\n",
    "             ,jit_compile=False\n",
    "                 )   # <- important\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.train_f1s = []\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        train_preds = np.argmax(self.model.predict(self.X_train), axis=1)\n",
    "        val_preds = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "\n",
    "        # Use 'macro' for unweighted mean of class F1 scores\n",
    "        train_f1 = f1_score(self.y_train, train_preds, average='macro')\n",
    "        val_f1 = f1_score(self.y_val, val_preds, average='macro')\n",
    "\n",
    "        self.train_f1s.append(train_f1)\n",
    "        self.val_f1s.append(val_f1)\n",
    "\n",
    "        # NEW: expose metrics to Keras callback chain\n",
    "        logs[\"train_f1_score\"] = float(train_f1)\n",
    "        logs[\"val_f1_score\"]   = float(val_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train F1={train_f1:.4f} - Val F1={val_f1:.4f}\")\n",
    "\n",
    "class TestF1Callback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.test_f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(self.X_test), axis=1)\n",
    "        test_f1 = f1_score(self.y_test, y_pred, average='macro')  # macro mean of class F1\n",
    "        self.test_f1_scores.append(test_f1)\n",
    "        print(f\"Epoch {epoch+1}: Test F1 Score = {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "# Custom callback to monitor val F1 score\n",
    "class SaveBestModelOnF1(Callback):\n",
    "    def __init__(self, monitor='val_f1_score', save_dir='models_Kaggle/'):\n",
    "        super().__init__()\n",
    "        self.best_f1 = -np.Inf\n",
    "        self.monitor = monitor\n",
    "        self.save_dir = save_dir\n",
    "        self.best_epoch = -1\n",
    "        # Create directory if not exists\n",
    "        import os\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # Save initial best filename\n",
    "        self.best_filepath = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get current val_f1_score from logs (we'll provide it manually)\n",
    "        # Alternatively, fetch from a global variable if needed.\n",
    "        current_f1 = logs.get(self.monitor)\n",
    "        if current_f1 is None:\n",
    "            return  # Can't monitor if metric isn't in logs\n",
    "        if current_f1 > self.best_f1:\n",
    "            self.best_f1 = current_f1\n",
    "            self.best_epoch = epoch + 1\n",
    "            # Save model with timestamp and val_f1\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"model_{timestamp}_epoch{self.best_epoch}_f1{current_f1:.4f}.h5\"\n",
    "            filepath = os.path.join(self.save_dir, filename)\n",
    "            self.model.save(filepath)\n",
    "            print(f\"\\nSaved best model at epoch {self.best_epoch} with val_f1={current_f1:.4f}\")\n",
    "\n",
    "\n",
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict on validation data\n",
    "        preds = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        # Get classification report\n",
    "        report = classification_report(self.y_val, preds, output_dict=True)\n",
    "        # Print per-class precision & recall\n",
    "        print(f\"\\nEpoch {epoch+1}: Per-class metrics\")\n",
    "        for label, metrics in report.items():\n",
    "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                print(f\"  Class {label}: Precision={metrics['precision']:.3f} Recall={metrics['recall']:.3f}\")\n",
    "        # Optional: you can also print macro or weighted averages if you want:\n",
    "\n",
    "        print(f\"  Macro Avg: Precision={report['macro avg']['precision']:.3f} Recall={report['macro avg']['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a01d0-a5d2-4714-b193-5672592d3d3c",
   "metadata": {},
   "source": [
    "## Training with Folding Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecc7e8f8-4840-4662-9881-6ada30eae680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 0  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2332, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (296, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (296, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5069565217391304, 1: 0.72875, 2: 0.8685288640595903, 3: 4.358878504672897, 4: 3.64375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768195342.996347 1723792 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8092 MB memory:  -> device: 0, name: NVIDIA H100 PCIe MIG 1g.10gb, pci bus id: 0000:65:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768195346.346359 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1768195346.754087 1789478 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0438 | val_f1=0.0700 | test_f1=0.0700 | mixed_f1=0.0700\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0700\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch1_f10.0700_20260112_002239.h5\n",
      "37/37 - 15s - 400ms/step - accuracy: 0.2028 - loss: 1.9157 - val_accuracy: 0.1149 - val_loss: 1.9414 - train_f1_macro: 0.0438 - val_f1_macro: 0.0700 - test_f1_macro: 0.0700 - mixed_f1_macro: 0.0700\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0580 | val_f1=0.0944 | test_f1=0.0944 | mixed_f1=0.0944\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.0944\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch2_f10.0944_20260112_002252.h5\n",
      "37/37 - 13s - 352ms/step - accuracy: 0.2148 - loss: 1.8454 - val_accuracy: 0.1216 - val_loss: 1.9794 - train_f1_macro: 0.0580 - val_f1_macro: 0.0944 - test_f1_macro: 0.0944 - mixed_f1_macro: 0.0944\n",
      "Epoch 3/500\n",
      " — train_f1=0.0401 | val_f1=0.0642 | test_f1=0.0642 | mixed_f1=0.0642\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.2071 - loss: 1.7997 - val_accuracy: 0.0980 - val_loss: 2.1584 - train_f1_macro: 0.0401 - val_f1_macro: 0.0642 - test_f1_macro: 0.0642 - mixed_f1_macro: 0.0642\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2403 | val_f1=0.2456 | test_f1=0.2456 | mixed_f1=0.2456\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.2456\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch4_f10.2456_20260112_002302.h5\n",
      "37/37 - 6s - 157ms/step - accuracy: 0.3272 - loss: 1.6743 - val_accuracy: 0.3750 - val_loss: 1.6189 - train_f1_macro: 0.2403 - val_f1_macro: 0.2456 - test_f1_macro: 0.2456 - mixed_f1_macro: 0.2456\n",
      "Epoch 5/500\n",
      " — train_f1=0.1517 | val_f1=0.1192 | test_f1=0.1192 | mixed_f1=0.1192\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.3521 - loss: 1.5424 - val_accuracy: 0.1757 - val_loss: 1.9954 - train_f1_macro: 0.1517 - val_f1_macro: 0.1192 - test_f1_macro: 0.1192 - mixed_f1_macro: 0.1192\n",
      "Epoch 6/500\n",
      " — train_f1=0.3258 | val_f1=0.2396 | test_f1=0.2396 | mixed_f1=0.2396\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3401 - loss: 1.5212 - val_accuracy: 0.3007 - val_loss: 1.6678 - train_f1_macro: 0.3258 - val_f1_macro: 0.2396 - test_f1_macro: 0.2396 - mixed_f1_macro: 0.2396\n",
      "Epoch 7/500\n",
      " — train_f1=0.2572 | val_f1=0.1944 | test_f1=0.1944 | mixed_f1=0.1944\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.3645 - loss: 1.4836 - val_accuracy: 0.2534 - val_loss: 1.5590 - train_f1_macro: 0.2572 - val_f1_macro: 0.1944 - test_f1_macro: 0.1944 - mixed_f1_macro: 0.1944\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4421 | val_f1=0.3474 | test_f1=0.3474 | mixed_f1=0.3474\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 8 | f1=0.3474\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch8_f10.3474_20260112_002332.h5\n",
      "37/37 - 10s - 274ms/step - accuracy: 0.3718 - loss: 1.4455 - val_accuracy: 0.3311 - val_loss: 1.5067 - train_f1_macro: 0.4421 - val_f1_macro: 0.3474 - test_f1_macro: 0.3474 - mixed_f1_macro: 0.3474\n",
      "Epoch 9/500\n",
      " — train_f1=0.2844 | val_f1=0.2962 | test_f1=0.2962 | mixed_f1=0.2962\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3696 - loss: 1.4451 - val_accuracy: 0.3041 - val_loss: 1.5342 - train_f1_macro: 0.2844 - val_f1_macro: 0.2962 - test_f1_macro: 0.2962 - mixed_f1_macro: 0.2962\n",
      "Epoch 10/500\n",
      " — train_f1=0.2301 | val_f1=0.2015 | test_f1=0.2015 | mixed_f1=0.2015\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.3894 - loss: 1.4048 - val_accuracy: 0.2669 - val_loss: 1.6092 - train_f1_macro: 0.2301 - val_f1_macro: 0.2015 - test_f1_macro: 0.2015 - mixed_f1_macro: 0.2015\n",
      "Epoch 11/500\n",
      " — train_f1=0.2667 | val_f1=0.2582 | test_f1=0.2582 | mixed_f1=0.2582\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.3705 - loss: 1.3948 - val_accuracy: 0.2770 - val_loss: 1.9218 - train_f1_macro: 0.2667 - val_f1_macro: 0.2582 - test_f1_macro: 0.2582 - mixed_f1_macro: 0.2582\n",
      "Epoch 12/500\n",
      " — train_f1=0.3188 | val_f1=0.2188 | test_f1=0.2188 | mixed_f1=0.2188\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.4138 - loss: 1.3763 - val_accuracy: 0.2331 - val_loss: 1.5136 - train_f1_macro: 0.3188 - val_f1_macro: 0.2188 - test_f1_macro: 0.2188 - mixed_f1_macro: 0.2188\n",
      "Epoch 13/500\n",
      " — train_f1=0.3469 | val_f1=0.3243 | test_f1=0.3243 | mixed_f1=0.3243\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.3756 - loss: 1.3783 - val_accuracy: 0.2973 - val_loss: 1.5138 - train_f1_macro: 0.3469 - val_f1_macro: 0.3243 - test_f1_macro: 0.3243 - mixed_f1_macro: 0.3243\n",
      "Epoch 14/500\n",
      " — train_f1=0.2491 | val_f1=0.2436 | test_f1=0.2436 | mixed_f1=0.2436\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3808 - loss: 1.3767 - val_accuracy: 0.2905 - val_loss: 1.5470 - train_f1_macro: 0.2491 - val_f1_macro: 0.2436 - test_f1_macro: 0.2436 - mixed_f1_macro: 0.2436\n",
      "Epoch 15/500\n",
      " — train_f1=0.2837 | val_f1=0.2605 | test_f1=0.2605 | mixed_f1=0.2605\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4125 - loss: 1.3555 - val_accuracy: 0.2872 - val_loss: 1.5705 - train_f1_macro: 0.2837 - val_f1_macro: 0.2605 - test_f1_macro: 0.2605 - mixed_f1_macro: 0.2605\n",
      "Epoch 16/500\n",
      " — train_f1=0.2570 | val_f1=0.1927 | test_f1=0.1927 | mixed_f1=0.1927\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4117 - loss: 1.3409 - val_accuracy: 0.2601 - val_loss: 1.5485 - train_f1_macro: 0.2570 - val_f1_macro: 0.1927 - test_f1_macro: 0.1927 - mixed_f1_macro: 0.1927\n",
      "Epoch 17/500\n",
      " — train_f1=0.2695 | val_f1=0.2440 | test_f1=0.2440 | mixed_f1=0.2440\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.4292 - loss: 1.3188 - val_accuracy: 0.2669 - val_loss: 1.6220 - train_f1_macro: 0.2695 - val_f1_macro: 0.2440 - test_f1_macro: 0.2440 - mixed_f1_macro: 0.2440\n",
      "Epoch 18/500\n",
      " — train_f1=0.2980 | val_f1=0.2628 | test_f1=0.2628 | mixed_f1=0.2628\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.4340 - loss: 1.3130 - val_accuracy: 0.2736 - val_loss: 1.5823 - train_f1_macro: 0.2980 - val_f1_macro: 0.2628 - test_f1_macro: 0.2628 - mixed_f1_macro: 0.2628\n",
      "Epoch 19/500\n",
      " — train_f1=0.3536 | val_f1=0.3242 | test_f1=0.3242 | mixed_f1=0.3242\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4310 - loss: 1.3120 - val_accuracy: 0.3446 - val_loss: 1.5724 - train_f1_macro: 0.3536 - val_f1_macro: 0.3242 - test_f1_macro: 0.3242 - mixed_f1_macro: 0.3242\n",
      "Epoch 20/500\n",
      " — train_f1=0.3128 | val_f1=0.3150 | test_f1=0.3150 | mixed_f1=0.3150\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.4524 - loss: 1.3028 - val_accuracy: 0.3142 - val_loss: 1.5893 - train_f1_macro: 0.3128 - val_f1_macro: 0.3150 - test_f1_macro: 0.3150 - mixed_f1_macro: 0.3150\n",
      "Epoch 21/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4203 | val_f1=0.3680 | test_f1=0.3680 | mixed_f1=0.3680\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 21 | f1=0.3680\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch21_f10.3680_20260112_002451.h5\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.4460 - loss: 1.3000 - val_accuracy: 0.3919 - val_loss: 1.4583 - train_f1_macro: 0.4203 - val_f1_macro: 0.3680 - test_f1_macro: 0.3680 - mixed_f1_macro: 0.3680\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5186 | val_f1=0.3713 | test_f1=0.3713 | mixed_f1=0.3713\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 22 | f1=0.3713\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch22_f10.3713_20260112_002456.h5\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.4640 - loss: 1.2903 - val_accuracy: 0.3514 - val_loss: 1.4651 - train_f1_macro: 0.5186 - val_f1_macro: 0.3713 - test_f1_macro: 0.3713 - mixed_f1_macro: 0.3713\n",
      "Epoch 23/500\n",
      " — train_f1=0.2908 | val_f1=0.2655 | test_f1=0.2655 | mixed_f1=0.2655\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.4588 - loss: 1.2856 - val_accuracy: 0.2770 - val_loss: 1.6214 - train_f1_macro: 0.2908 - val_f1_macro: 0.2655 - test_f1_macro: 0.2655 - mixed_f1_macro: 0.2655\n",
      "Epoch 24/500\n",
      " — train_f1=0.1420 | val_f1=0.1623 | test_f1=0.1623 | mixed_f1=0.1623\n",
      "37/37 - 10s - 279ms/step - accuracy: 0.4550 - loss: 1.2776 - val_accuracy: 0.2095 - val_loss: 1.9436 - train_f1_macro: 0.1420 - val_f1_macro: 0.1623 - test_f1_macro: 0.1623 - mixed_f1_macro: 0.1623\n",
      "Epoch 25/500\n",
      " — train_f1=0.4820 | val_f1=0.3452 | test_f1=0.3452 | mixed_f1=0.3452\n",
      "37/37 - 10s - 257ms/step - accuracy: 0.4588 - loss: 1.2599 - val_accuracy: 0.3345 - val_loss: 1.4734 - train_f1_macro: 0.4820 - val_f1_macro: 0.3452 - test_f1_macro: 0.3452 - mixed_f1_macro: 0.3452\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4886 | val_f1=0.4167 | test_f1=0.4167 | mixed_f1=0.4167\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 26 | f1=0.4167\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch26_f10.4167_20260112_002532.h5\n",
      "37/37 - 5s - 142ms/step - accuracy: 0.4773 - loss: 1.2611 - val_accuracy: 0.4088 - val_loss: 1.4688 - train_f1_macro: 0.4886 - val_f1_macro: 0.4167 - test_f1_macro: 0.4167 - mixed_f1_macro: 0.4167\n",
      "Epoch 27/500\n",
      " — train_f1=0.2932 | val_f1=0.2467 | test_f1=0.2467 | mixed_f1=0.2467\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.4820 - loss: 1.2361 - val_accuracy: 0.3277 - val_loss: 1.5761 - train_f1_macro: 0.2932 - val_f1_macro: 0.2467 - test_f1_macro: 0.2467 - mixed_f1_macro: 0.2467\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5251 | val_f1=0.4369 | test_f1=0.4369 | mixed_f1=0.4369\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 28 | f1=0.4369\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch28_f10.4369_20260112_002547.h5\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4987 - loss: 1.2114 - val_accuracy: 0.4291 - val_loss: 1.4851 - train_f1_macro: 0.5251 - val_f1_macro: 0.4369 - test_f1_macro: 0.4369 - mixed_f1_macro: 0.4369\n",
      "Epoch 29/500\n",
      " — train_f1=0.4865 | val_f1=0.3488 | test_f1=0.3488 | mixed_f1=0.3488\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4927 - loss: 1.2303 - val_accuracy: 0.3446 - val_loss: 1.4615 - train_f1_macro: 0.4865 - val_f1_macro: 0.3488 - test_f1_macro: 0.3488 - mixed_f1_macro: 0.3488\n",
      "Epoch 30/500\n",
      " — train_f1=0.5192 | val_f1=0.3818 | test_f1=0.3818 | mixed_f1=0.3818\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4670 - loss: 1.2401 - val_accuracy: 0.3581 - val_loss: 1.4457 - train_f1_macro: 0.5192 - val_f1_macro: 0.3818 - test_f1_macro: 0.3818 - mixed_f1_macro: 0.3818\n",
      "Epoch 31/500\n",
      " — train_f1=0.2325 | val_f1=0.2302 | test_f1=0.2302 | mixed_f1=0.2302\n",
      "37/37 - 5s - 142ms/step - accuracy: 0.5043 - loss: 1.2211 - val_accuracy: 0.2939 - val_loss: 1.6771 - train_f1_macro: 0.2325 - val_f1_macro: 0.2302 - test_f1_macro: 0.2302 - mixed_f1_macro: 0.2302\n",
      "Epoch 32/500\n",
      " — train_f1=0.4246 | val_f1=0.3329 | test_f1=0.3329 | mixed_f1=0.3329\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5099 - loss: 1.2075 - val_accuracy: 0.3919 - val_loss: 1.4745 - train_f1_macro: 0.4246 - val_f1_macro: 0.3329 - test_f1_macro: 0.3329 - mixed_f1_macro: 0.3329\n",
      "Epoch 33/500\n",
      " — train_f1=0.4878 | val_f1=0.3661 | test_f1=0.3661 | mixed_f1=0.3661\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.5116 - loss: 1.2069 - val_accuracy: 0.3480 - val_loss: 1.5128 - train_f1_macro: 0.4878 - val_f1_macro: 0.3661 - test_f1_macro: 0.3661 - mixed_f1_macro: 0.3661\n",
      "Epoch 34/500\n",
      " — train_f1=0.5380 | val_f1=0.3876 | test_f1=0.3876 | mixed_f1=0.3876\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.5210 - loss: 1.1953 - val_accuracy: 0.3581 - val_loss: 1.4685 - train_f1_macro: 0.5380 - val_f1_macro: 0.3876 - test_f1_macro: 0.3876 - mixed_f1_macro: 0.3876\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6005 | val_f1=0.4591 | test_f1=0.4591 | mixed_f1=0.4591\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 35 | f1=0.4591\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch35_f10.4591_20260112_002627.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5202 - loss: 1.1733 - val_accuracy: 0.4291 - val_loss: 1.4032 - train_f1_macro: 0.6005 - val_f1_macro: 0.4591 - test_f1_macro: 0.4591 - mixed_f1_macro: 0.4591\n",
      "Epoch 36/500\n",
      " — train_f1=0.4968 | val_f1=0.4453 | test_f1=0.4453 | mixed_f1=0.4453\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5360 - loss: 1.1838 - val_accuracy: 0.4932 - val_loss: 1.4366 - train_f1_macro: 0.4968 - val_f1_macro: 0.4453 - test_f1_macro: 0.4453 - mixed_f1_macro: 0.4453\n",
      "Epoch 37/500\n",
      " — train_f1=0.5045 | val_f1=0.3756 | test_f1=0.3756 | mixed_f1=0.3756\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5592 - loss: 1.1617 - val_accuracy: 0.3446 - val_loss: 1.5012 - train_f1_macro: 0.5045 - val_f1_macro: 0.3756 - test_f1_macro: 0.3756 - mixed_f1_macro: 0.3756\n",
      "Epoch 38/500\n",
      " — train_f1=0.5492 | val_f1=0.4043 | test_f1=0.4043 | mixed_f1=0.4043\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5334 - loss: 1.1776 - val_accuracy: 0.3682 - val_loss: 1.4899 - train_f1_macro: 0.5492 - val_f1_macro: 0.4043 - test_f1_macro: 0.4043 - mixed_f1_macro: 0.4043\n",
      "Epoch 39/500\n",
      " — train_f1=0.3544 | val_f1=0.3184 | test_f1=0.3184 | mixed_f1=0.3184\n",
      "37/37 - 6s - 160ms/step - accuracy: 0.5407 - loss: 1.1654 - val_accuracy: 0.3750 - val_loss: 1.5811 - train_f1_macro: 0.3544 - val_f1_macro: 0.3184 - test_f1_macro: 0.3184 - mixed_f1_macro: 0.3184\n",
      "Epoch 40/500\n",
      " — train_f1=0.4431 | val_f1=0.3642 | test_f1=0.3642 | mixed_f1=0.3642\n",
      "37/37 - 9s - 257ms/step - accuracy: 0.5536 - loss: 1.1504 - val_accuracy: 0.3345 - val_loss: 1.5210 - train_f1_macro: 0.4431 - val_f1_macro: 0.3642 - test_f1_macro: 0.3642 - mixed_f1_macro: 0.3642\n",
      "Epoch 41/500\n",
      " — train_f1=0.3483 | val_f1=0.2527 | test_f1=0.2527 | mixed_f1=0.2527\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5549 - loss: 1.1417 - val_accuracy: 0.2939 - val_loss: 1.6974 - train_f1_macro: 0.3483 - val_f1_macro: 0.2527 - test_f1_macro: 0.2527 - mixed_f1_macro: 0.2527\n",
      "Epoch 42/500\n",
      " — train_f1=0.5697 | val_f1=0.4151 | test_f1=0.4151 | mixed_f1=0.4151\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.5506 - loss: 1.1589 - val_accuracy: 0.3953 - val_loss: 1.4552 - train_f1_macro: 0.5697 - val_f1_macro: 0.4151 - test_f1_macro: 0.4151 - mixed_f1_macro: 0.4151\n",
      "Epoch 43/500\n",
      " — train_f1=0.5918 | val_f1=0.4346 | test_f1=0.4346 | mixed_f1=0.4346\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5493 - loss: 1.1625 - val_accuracy: 0.4595 - val_loss: 1.4869 - train_f1_macro: 0.5918 - val_f1_macro: 0.4346 - test_f1_macro: 0.4346 - mixed_f1_macro: 0.4346\n",
      "Epoch 44/500\n",
      " — train_f1=0.5807 | val_f1=0.4287 | test_f1=0.4287 | mixed_f1=0.4287\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.5575 - loss: 1.1474 - val_accuracy: 0.4527 - val_loss: 1.4236 - train_f1_macro: 0.5807 - val_f1_macro: 0.4287 - test_f1_macro: 0.4287 - mixed_f1_macro: 0.4287\n",
      "Epoch 45/500\n",
      " — train_f1=0.5173 | val_f1=0.4285 | test_f1=0.4285 | mixed_f1=0.4285\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.5720 - loss: 1.1363 - val_accuracy: 0.4932 - val_loss: 1.4800 - train_f1_macro: 0.5173 - val_f1_macro: 0.4285 - test_f1_macro: 0.4285 - mixed_f1_macro: 0.4285\n",
      "Epoch 46/500\n",
      " — train_f1=0.6281 | val_f1=0.4341 | test_f1=0.4341 | mixed_f1=0.4341\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5810 - loss: 1.1037 - val_accuracy: 0.4122 - val_loss: 1.4473 - train_f1_macro: 0.6281 - val_f1_macro: 0.4341 - test_f1_macro: 0.4341 - mixed_f1_macro: 0.4341\n",
      "Epoch 47/500\n",
      " — train_f1=0.4596 | val_f1=0.3778 | test_f1=0.3778 | mixed_f1=0.3778\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5870 - loss: 1.1169 - val_accuracy: 0.4392 - val_loss: 1.5342 - train_f1_macro: 0.4596 - val_f1_macro: 0.3778 - test_f1_macro: 0.3778 - mixed_f1_macro: 0.3778\n",
      "Epoch 48/500\n",
      " — train_f1=0.5197 | val_f1=0.3786 | test_f1=0.3786 | mixed_f1=0.3786\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.5913 - loss: 1.0993 - val_accuracy: 0.3514 - val_loss: 1.5392 - train_f1_macro: 0.5197 - val_f1_macro: 0.3786 - test_f1_macro: 0.3786 - mixed_f1_macro: 0.3786\n",
      "Epoch 49/500\n",
      " — train_f1=0.5652 | val_f1=0.4052 | test_f1=0.4052 | mixed_f1=0.4052\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.5896 - loss: 1.1068 - val_accuracy: 0.3750 - val_loss: 1.4933 - train_f1_macro: 0.5652 - val_f1_macro: 0.4052 - test_f1_macro: 0.4052 - mixed_f1_macro: 0.4052\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6446 | val_f1=0.5043 | test_f1=0.5043 | mixed_f1=0.5043\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 50 | f1=0.5043\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch50_f10.5043_20260112_002754.h5\n",
      "37/37 - 5s - 143ms/step - accuracy: 0.5909 - loss: 1.0885 - val_accuracy: 0.4730 - val_loss: 1.4001 - train_f1_macro: 0.6446 - val_f1_macro: 0.5043 - test_f1_macro: 0.5043 - mixed_f1_macro: 0.5043\n",
      "Epoch 51/500\n",
      " — train_f1=0.5322 | val_f1=0.4534 | test_f1=0.4534 | mixed_f1=0.4534\n",
      "37/37 - 10s - 272ms/step - accuracy: 0.6012 - loss: 1.1018 - val_accuracy: 0.5304 - val_loss: 1.3879 - train_f1_macro: 0.5322 - val_f1_macro: 0.4534 - test_f1_macro: 0.4534 - mixed_f1_macro: 0.4534\n",
      "Epoch 52/500\n",
      " — train_f1=0.6175 | val_f1=0.4423 | test_f1=0.4423 | mixed_f1=0.4423\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6038 - loss: 1.0902 - val_accuracy: 0.4257 - val_loss: 1.4155 - train_f1_macro: 0.6175 - val_f1_macro: 0.4423 - test_f1_macro: 0.4423 - mixed_f1_macro: 0.4423\n",
      "Epoch 53/500\n",
      " — train_f1=0.6175 | val_f1=0.4124 | test_f1=0.4124 | mixed_f1=0.4124\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.6218 - loss: 1.0936 - val_accuracy: 0.4257 - val_loss: 1.4604 - train_f1_macro: 0.6175 - val_f1_macro: 0.4124 - test_f1_macro: 0.4124 - mixed_f1_macro: 0.4124\n",
      "Epoch 54/500\n",
      " — train_f1=0.6314 | val_f1=0.4689 | test_f1=0.4689 | mixed_f1=0.4689\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.6093 - loss: 1.0879 - val_accuracy: 0.5270 - val_loss: 1.3666 - train_f1_macro: 0.6314 - val_f1_macro: 0.4689 - test_f1_macro: 0.4689 - mixed_f1_macro: 0.4689\n",
      "Epoch 55/500\n",
      " — train_f1=0.6707 | val_f1=0.4590 | test_f1=0.4590 | mixed_f1=0.4590\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6128 - loss: 1.0740 - val_accuracy: 0.4392 - val_loss: 1.4116 - train_f1_macro: 0.6707 - val_f1_macro: 0.4590 - test_f1_macro: 0.4590 - mixed_f1_macro: 0.4590\n",
      "Epoch 56/500\n",
      " — train_f1=0.5497 | val_f1=0.4525 | test_f1=0.4525 | mixed_f1=0.4525\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6261 - loss: 1.0608 - val_accuracy: 0.4932 - val_loss: 1.4178 - train_f1_macro: 0.5497 - val_f1_macro: 0.4525 - test_f1_macro: 0.4525 - mixed_f1_macro: 0.4525\n",
      "Epoch 57/500\n",
      " — train_f1=0.5759 | val_f1=0.4601 | test_f1=0.4601 | mixed_f1=0.4601\n",
      "37/37 - 6s - 156ms/step - accuracy: 0.6226 - loss: 1.0711 - val_accuracy: 0.4764 - val_loss: 1.4126 - train_f1_macro: 0.5759 - val_f1_macro: 0.4601 - test_f1_macro: 0.4601 - mixed_f1_macro: 0.4601\n",
      "Epoch 58/500\n",
      " — train_f1=0.6475 | val_f1=0.4693 | test_f1=0.4693 | mixed_f1=0.4693\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.6372 - loss: 1.0586 - val_accuracy: 0.5135 - val_loss: 1.3987 - train_f1_macro: 0.6475 - val_f1_macro: 0.4693 - test_f1_macro: 0.4693 - mixed_f1_macro: 0.4693\n",
      "Epoch 59/500\n",
      " — train_f1=0.1945 | val_f1=0.2362 | test_f1=0.2362 | mixed_f1=0.2362\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6497 - loss: 1.0571 - val_accuracy: 0.3074 - val_loss: 1.8059 - train_f1_macro: 0.1945 - val_f1_macro: 0.2362 - test_f1_macro: 0.2362 - mixed_f1_macro: 0.2362\n",
      "Epoch 60/500\n",
      " — train_f1=0.6860 | val_f1=0.4846 | test_f1=0.4846 | mixed_f1=0.4846\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.6389 - loss: 1.0549 - val_accuracy: 0.4527 - val_loss: 1.4445 - train_f1_macro: 0.6860 - val_f1_macro: 0.4846 - test_f1_macro: 0.4846 - mixed_f1_macro: 0.4846\n",
      "Epoch 61/500\n",
      " — train_f1=0.6411 | val_f1=0.4542 | test_f1=0.4542 | mixed_f1=0.4542\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6385 - loss: 1.0254 - val_accuracy: 0.4223 - val_loss: 1.5154 - train_f1_macro: 0.6411 - val_f1_macro: 0.4542 - test_f1_macro: 0.4542 - mixed_f1_macro: 0.4542\n",
      "Epoch 62/500\n",
      " — train_f1=0.6634 | val_f1=0.4902 | test_f1=0.4902 | mixed_f1=0.4902\n",
      "37/37 - 5s - 147ms/step - accuracy: 0.6569 - loss: 1.0337 - val_accuracy: 0.5135 - val_loss: 1.3892 - train_f1_macro: 0.6634 - val_f1_macro: 0.4902 - test_f1_macro: 0.4902 - mixed_f1_macro: 0.4902\n",
      "Epoch 63/500\n",
      " — train_f1=0.6183 | val_f1=0.4348 | test_f1=0.4348 | mixed_f1=0.4348\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.6578 - loss: 1.0352 - val_accuracy: 0.4122 - val_loss: 1.5633 - train_f1_macro: 0.6183 - val_f1_macro: 0.4348 - test_f1_macro: 0.4348 - mixed_f1_macro: 0.4348\n",
      "Epoch 64/500\n",
      " — train_f1=0.6733 | val_f1=0.4395 | test_f1=0.4395 | mixed_f1=0.4395\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.6557 - loss: 1.0484 - val_accuracy: 0.4257 - val_loss: 1.4433 - train_f1_macro: 0.6733 - val_f1_macro: 0.4395 - test_f1_macro: 0.4395 - mixed_f1_macro: 0.4395\n",
      "Epoch 65/500\n",
      " — train_f1=0.6513 | val_f1=0.4960 | test_f1=0.4960 | mixed_f1=0.4960\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.6792 - loss: 1.0043 - val_accuracy: 0.4662 - val_loss: 1.4506 - train_f1_macro: 0.6513 - val_f1_macro: 0.4960 - test_f1_macro: 0.4960 - mixed_f1_macro: 0.4960\n",
      "Epoch 66/500\n",
      " — train_f1=0.6491 | val_f1=0.4982 | test_f1=0.4982 | mixed_f1=0.4982\n",
      "37/37 - 5s - 147ms/step - accuracy: 0.6913 - loss: 1.0056 - val_accuracy: 0.4696 - val_loss: 1.4842 - train_f1_macro: 0.6491 - val_f1_macro: 0.4982 - test_f1_macro: 0.4982 - mixed_f1_macro: 0.4982\n",
      "Epoch 67/500\n",
      " — train_f1=0.6378 | val_f1=0.4763 | test_f1=0.4763 | mixed_f1=0.4763\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6775 - loss: 0.9937 - val_accuracy: 0.5236 - val_loss: 1.4044 - train_f1_macro: 0.6378 - val_f1_macro: 0.4763 - test_f1_macro: 0.4763 - mixed_f1_macro: 0.4763\n",
      "Epoch 68/500\n",
      " — train_f1=0.5141 | val_f1=0.4471 | test_f1=0.4471 | mixed_f1=0.4471\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6814 - loss: 1.0179 - val_accuracy: 0.4865 - val_loss: 1.5289 - train_f1_macro: 0.5141 - val_f1_macro: 0.4471 - test_f1_macro: 0.4471 - mixed_f1_macro: 0.4471\n",
      "Epoch 69/500\n",
      " — train_f1=0.5911 | val_f1=0.4344 | test_f1=0.4344 | mixed_f1=0.4344\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6870 - loss: 1.0196 - val_accuracy: 0.4696 - val_loss: 1.4663 - train_f1_macro: 0.5911 - val_f1_macro: 0.4344 - test_f1_macro: 0.4344 - mixed_f1_macro: 0.4344\n",
      "Epoch 70/500\n",
      " — train_f1=0.7309 | val_f1=0.4716 | test_f1=0.4716 | mixed_f1=0.4716\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.6930 - loss: 0.9968 - val_accuracy: 0.4797 - val_loss: 1.4028 - train_f1_macro: 0.7309 - val_f1_macro: 0.4716 - test_f1_macro: 0.4716 - mixed_f1_macro: 0.4716\n",
      "Epoch 71/500\n",
      " — train_f1=0.4824 | val_f1=0.3959 | test_f1=0.3959 | mixed_f1=0.3959\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7063 - loss: 0.9826 - val_accuracy: 0.4527 - val_loss: 1.5861 - train_f1_macro: 0.4824 - val_f1_macro: 0.3959 - test_f1_macro: 0.3959 - mixed_f1_macro: 0.3959\n",
      "Epoch 72/500\n",
      " — train_f1=0.3906 | val_f1=0.4436 | test_f1=0.4436 | mixed_f1=0.4436\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6973 - loss: 0.9791 - val_accuracy: 0.5068 - val_loss: 1.5223 - train_f1_macro: 0.3906 - val_f1_macro: 0.4436 - test_f1_macro: 0.4436 - mixed_f1_macro: 0.4436\n",
      "Epoch 73/500\n",
      " — train_f1=0.6027 | val_f1=0.4775 | test_f1=0.4775 | mixed_f1=0.4775\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7058 - loss: 0.9726 - val_accuracy: 0.5405 - val_loss: 1.4026 - train_f1_macro: 0.6027 - val_f1_macro: 0.4775 - test_f1_macro: 0.4775 - mixed_f1_macro: 0.4775\n",
      "Epoch 74/500\n",
      " — train_f1=0.2022 | val_f1=0.2170 | test_f1=0.2170 | mixed_f1=0.2170\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6977 - loss: 1.0129 - val_accuracy: 0.4527 - val_loss: 1.7096 - train_f1_macro: 0.2022 - val_f1_macro: 0.2170 - test_f1_macro: 0.2170 - mixed_f1_macro: 0.2170\n",
      "Epoch 75/500\n",
      " — train_f1=0.6321 | val_f1=0.4044 | test_f1=0.4044 | mixed_f1=0.4044\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6827 - loss: 1.0322 - val_accuracy: 0.3953 - val_loss: 1.5652 - train_f1_macro: 0.6321 - val_f1_macro: 0.4044 - test_f1_macro: 0.4044 - mixed_f1_macro: 0.4044\n",
      "Epoch 76/500\n",
      " — train_f1=0.4433 | val_f1=0.3780 | test_f1=0.3780 | mixed_f1=0.3780\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.7187 - loss: 0.9828 - val_accuracy: 0.4459 - val_loss: 1.5854 - train_f1_macro: 0.4433 - val_f1_macro: 0.3780 - test_f1_macro: 0.3780 - mixed_f1_macro: 0.3780\n",
      "Epoch 77/500\n",
      " — train_f1=0.6683 | val_f1=0.4850 | test_f1=0.4850 | mixed_f1=0.4850\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7286 - loss: 0.9557 - val_accuracy: 0.4628 - val_loss: 1.5279 - train_f1_macro: 0.6683 - val_f1_macro: 0.4850 - test_f1_macro: 0.4850 - mixed_f1_macro: 0.4850\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7838 | val_f1=0.5146 | test_f1=0.5146 | mixed_f1=0.5146\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 78 | f1=0.5146\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch78_f10.5146_20260112_003049.h5\n",
      "37/37 - 6s - 156ms/step - accuracy: 0.7238 - loss: 0.9484 - val_accuracy: 0.4899 - val_loss: 1.4089 - train_f1_macro: 0.7838 - val_f1_macro: 0.5146 - test_f1_macro: 0.5146 - mixed_f1_macro: 0.5146\n",
      "Epoch 79/500\n",
      " — train_f1=0.3568 | val_f1=0.2688 | test_f1=0.2688 | mixed_f1=0.2688\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.7157 - loss: 0.9607 - val_accuracy: 0.3446 - val_loss: 1.8628 - train_f1_macro: 0.3568 - val_f1_macro: 0.2688 - test_f1_macro: 0.2688 - mixed_f1_macro: 0.2688\n",
      "Epoch 80/500\n",
      " — train_f1=0.5660 | val_f1=0.4474 | test_f1=0.4474 | mixed_f1=0.4474\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7298 - loss: 0.9715 - val_accuracy: 0.4899 - val_loss: 1.4872 - train_f1_macro: 0.5660 - val_f1_macro: 0.4474 - test_f1_macro: 0.4474 - mixed_f1_macro: 0.4474\n",
      "Epoch 81/500\n",
      " — train_f1=0.6877 | val_f1=0.4841 | test_f1=0.4841 | mixed_f1=0.4841\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.7397 - loss: 0.9279 - val_accuracy: 0.4831 - val_loss: 1.4428 - train_f1_macro: 0.6877 - val_f1_macro: 0.4841 - test_f1_macro: 0.4841 - mixed_f1_macro: 0.4841\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.8101 | val_f1=0.5589 | test_f1=0.5589 | mixed_f1=0.5589\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 82 | f1=0.5589\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch82_f10.5589_20260112_003119.h5\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.7474 - loss: 0.9358 - val_accuracy: 0.5236 - val_loss: 1.3904 - train_f1_macro: 0.8101 - val_f1_macro: 0.5589 - test_f1_macro: 0.5589 - mixed_f1_macro: 0.5589\n",
      "Epoch 83/500\n",
      " — train_f1=0.6696 | val_f1=0.4661 | test_f1=0.4661 | mixed_f1=0.4661\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7444 - loss: 0.9348 - val_accuracy: 0.4696 - val_loss: 1.4521 - train_f1_macro: 0.6696 - val_f1_macro: 0.4661 - test_f1_macro: 0.4661 - mixed_f1_macro: 0.4661\n",
      "Epoch 84/500\n",
      " — train_f1=0.5810 | val_f1=0.4773 | test_f1=0.4773 | mixed_f1=0.4773\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.7457 - loss: 0.9304 - val_accuracy: 0.5642 - val_loss: 1.4831 - train_f1_macro: 0.5810 - val_f1_macro: 0.4773 - test_f1_macro: 0.4773 - mixed_f1_macro: 0.4773\n",
      "Epoch 85/500\n",
      " — train_f1=0.8284 | val_f1=0.5147 | test_f1=0.5147 | mixed_f1=0.5147\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7440 - loss: 0.9248 - val_accuracy: 0.5304 - val_loss: 1.4113 - train_f1_macro: 0.8284 - val_f1_macro: 0.5147 - test_f1_macro: 0.5147 - mixed_f1_macro: 0.5147\n",
      "Epoch 86/500\n",
      " — train_f1=0.7247 | val_f1=0.4970 | test_f1=0.4970 | mixed_f1=0.4970\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7410 - loss: 0.9482 - val_accuracy: 0.4730 - val_loss: 1.4956 - train_f1_macro: 0.7247 - val_f1_macro: 0.4970 - test_f1_macro: 0.4970 - mixed_f1_macro: 0.4970\n",
      "Epoch 87/500\n",
      " — train_f1=0.5433 | val_f1=0.4196 | test_f1=0.4196 | mixed_f1=0.4196\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7569 - loss: 0.9156 - val_accuracy: 0.4527 - val_loss: 1.6396 - train_f1_macro: 0.5433 - val_f1_macro: 0.4196 - test_f1_macro: 0.4196 - mixed_f1_macro: 0.4196\n",
      "Epoch 88/500\n",
      " — train_f1=0.3687 | val_f1=0.3320 | test_f1=0.3320 | mixed_f1=0.3320\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7659 - loss: 0.9124 - val_accuracy: 0.4054 - val_loss: 1.7713 - train_f1_macro: 0.3687 - val_f1_macro: 0.3320 - test_f1_macro: 0.3320 - mixed_f1_macro: 0.3320\n",
      "Epoch 89/500\n",
      " — train_f1=0.7069 | val_f1=0.4548 | test_f1=0.4548 | mixed_f1=0.4548\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.7646 - loss: 0.9089 - val_accuracy: 0.4865 - val_loss: 1.5163 - train_f1_macro: 0.7069 - val_f1_macro: 0.4548 - test_f1_macro: 0.4548 - mixed_f1_macro: 0.4548\n",
      "Epoch 90/500\n",
      " — train_f1=0.8331 | val_f1=0.5490 | test_f1=0.5490 | mixed_f1=0.5490\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7702 - loss: 0.8940 - val_accuracy: 0.5236 - val_loss: 1.4059 - train_f1_macro: 0.8331 - val_f1_macro: 0.5490 - test_f1_macro: 0.5490 - mixed_f1_macro: 0.5490\n",
      "Epoch 91/500\n",
      " — train_f1=0.8414 | val_f1=0.5182 | test_f1=0.5182 | mixed_f1=0.5182\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7530 - loss: 0.9211 - val_accuracy: 0.4932 - val_loss: 1.4415 - train_f1_macro: 0.8414 - val_f1_macro: 0.5182 - test_f1_macro: 0.5182 - mixed_f1_macro: 0.5182\n",
      "Epoch 92/500\n",
      " — train_f1=0.7379 | val_f1=0.5270 | test_f1=0.5270 | mixed_f1=0.5270\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7787 - loss: 0.8833 - val_accuracy: 0.4831 - val_loss: 1.5500 - train_f1_macro: 0.7379 - val_f1_macro: 0.5270 - test_f1_macro: 0.5270 - mixed_f1_macro: 0.5270\n",
      "Epoch 93/500\n",
      " — train_f1=0.7934 | val_f1=0.5516 | test_f1=0.5516 | mixed_f1=0.5516\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7693 - loss: 0.9224 - val_accuracy: 0.5642 - val_loss: 1.4043 - train_f1_macro: 0.7934 - val_f1_macro: 0.5516 - test_f1_macro: 0.5516 - mixed_f1_macro: 0.5516\n",
      "Epoch 94/500\n",
      " — train_f1=0.8401 | val_f1=0.4799 | test_f1=0.4799 | mixed_f1=0.4799\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7509 - loss: 0.9354 - val_accuracy: 0.4831 - val_loss: 1.4137 - train_f1_macro: 0.8401 - val_f1_macro: 0.4799 - test_f1_macro: 0.4799 - mixed_f1_macro: 0.4799\n",
      "Epoch 95/500\n",
      " — train_f1=0.8146 | val_f1=0.5171 | test_f1=0.5171 | mixed_f1=0.5171\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.7710 - loss: 0.9007 - val_accuracy: 0.4932 - val_loss: 1.4737 - train_f1_macro: 0.8146 - val_f1_macro: 0.5171 - test_f1_macro: 0.5171 - mixed_f1_macro: 0.5171\n",
      "Epoch 96/500\n",
      " — train_f1=0.4780 | val_f1=0.3772 | test_f1=0.3772 | mixed_f1=0.3772\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7856 - loss: 0.8765 - val_accuracy: 0.4730 - val_loss: 1.6412 - train_f1_macro: 0.4780 - val_f1_macro: 0.3772 - test_f1_macro: 0.3772 - mixed_f1_macro: 0.3772\n",
      "Epoch 97/500\n",
      " — train_f1=0.8211 | val_f1=0.5187 | test_f1=0.5187 | mixed_f1=0.5187\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7860 - loss: 0.8722 - val_accuracy: 0.4764 - val_loss: 1.5668 - train_f1_macro: 0.8211 - val_f1_macro: 0.5187 - test_f1_macro: 0.5187 - mixed_f1_macro: 0.5187\n",
      "Epoch 98/500\n",
      " — train_f1=0.4526 | val_f1=0.3741 | test_f1=0.3741 | mixed_f1=0.3741\n",
      "37/37 - 6s - 156ms/step - accuracy: 0.7744 - loss: 0.9021 - val_accuracy: 0.4223 - val_loss: 1.7321 - train_f1_macro: 0.4526 - val_f1_macro: 0.3741 - test_f1_macro: 0.3741 - mixed_f1_macro: 0.3741\n",
      "Epoch 99/500\n",
      " — train_f1=0.8342 | val_f1=0.5406 | test_f1=0.5406 | mixed_f1=0.5406\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.7852 - loss: 0.8848 - val_accuracy: 0.5203 - val_loss: 1.4487 - train_f1_macro: 0.8342 - val_f1_macro: 0.5406 - test_f1_macro: 0.5406 - mixed_f1_macro: 0.5406\n",
      "Epoch 100/500\n",
      " — train_f1=0.8298 | val_f1=0.4933 | test_f1=0.4933 | mixed_f1=0.4933\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7864 - loss: 0.8741 - val_accuracy: 0.4966 - val_loss: 1.4534 - train_f1_macro: 0.8298 - val_f1_macro: 0.4933 - test_f1_macro: 0.4933 - mixed_f1_macro: 0.4933\n",
      "Epoch 101/500\n",
      " — train_f1=0.6990 | val_f1=0.4581 | test_f1=0.4581 | mixed_f1=0.4581\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7766 - loss: 0.8837 - val_accuracy: 0.4764 - val_loss: 1.5499 - train_f1_macro: 0.6990 - val_f1_macro: 0.4581 - test_f1_macro: 0.4581 - mixed_f1_macro: 0.4581\n",
      "Epoch 102/500\n",
      " — train_f1=0.8404 | val_f1=0.5325 | test_f1=0.5325 | mixed_f1=0.5325\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7920 - loss: 0.8708 - val_accuracy: 0.5034 - val_loss: 1.5413 - train_f1_macro: 0.8404 - val_f1_macro: 0.5325 - test_f1_macro: 0.5325 - mixed_f1_macro: 0.5325\n",
      "Epoch 103/500\n",
      " — train_f1=0.8281 | val_f1=0.5352 | test_f1=0.5352 | mixed_f1=0.5352\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.8057 - loss: 0.8545 - val_accuracy: 0.5068 - val_loss: 1.6044 - train_f1_macro: 0.8281 - val_f1_macro: 0.5352 - test_f1_macro: 0.5352 - mixed_f1_macro: 0.5352\n",
      "Epoch 104/500\n",
      " — train_f1=0.7089 | val_f1=0.5123 | test_f1=0.5123 | mixed_f1=0.5123\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7907 - loss: 0.8848 - val_accuracy: 0.5304 - val_loss: 1.5426 - train_f1_macro: 0.7089 - val_f1_macro: 0.5123 - test_f1_macro: 0.5123 - mixed_f1_macro: 0.5123\n",
      "Epoch 105/500\n",
      " — train_f1=0.8616 | val_f1=0.5549 | test_f1=0.5549 | mixed_f1=0.5549\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.8066 - loss: 0.8708 - val_accuracy: 0.5405 - val_loss: 1.4717 - train_f1_macro: 0.8616 - val_f1_macro: 0.5549 - test_f1_macro: 0.5549 - mixed_f1_macro: 0.5549\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.8793 | val_f1=0.5752 | test_f1=0.5752 | mixed_f1=0.5752\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 106 | f1=0.5752\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch106_f10.5752_20260112_003338.h5\n",
      "37/37 - 10s - 278ms/step - accuracy: 0.7980 - loss: 0.8575 - val_accuracy: 0.5574 - val_loss: 1.4601 - train_f1_macro: 0.8793 - val_f1_macro: 0.5752 - test_f1_macro: 0.5752 - mixed_f1_macro: 0.5752\n",
      "Epoch 107/500\n",
      " — train_f1=0.7203 | val_f1=0.4807 | test_f1=0.4807 | mixed_f1=0.4807\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.7942 - loss: 0.8707 - val_accuracy: 0.5135 - val_loss: 1.5022 - train_f1_macro: 0.7203 - val_f1_macro: 0.4807 - test_f1_macro: 0.4807 - mixed_f1_macro: 0.4807\n",
      "Epoch 108/500\n",
      " — train_f1=0.7903 | val_f1=0.4718 | test_f1=0.4718 | mixed_f1=0.4718\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8216 - loss: 0.8445 - val_accuracy: 0.4628 - val_loss: 1.4828 - train_f1_macro: 0.7903 - val_f1_macro: 0.4718 - test_f1_macro: 0.4718 - mixed_f1_macro: 0.4718\n",
      "Epoch 109/500\n",
      " — train_f1=0.8757 | val_f1=0.5497 | test_f1=0.5497 | mixed_f1=0.5497\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.8173 - loss: 0.8457 - val_accuracy: 0.5135 - val_loss: 1.4606 - train_f1_macro: 0.8757 - val_f1_macro: 0.5497 - test_f1_macro: 0.5497 - mixed_f1_macro: 0.5497\n",
      "Epoch 110/500\n",
      " — train_f1=0.5736 | val_f1=0.4768 | test_f1=0.4768 | mixed_f1=0.4768\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.8122 - loss: 0.8458 - val_accuracy: 0.5372 - val_loss: 1.5809 - train_f1_macro: 0.5736 - val_f1_macro: 0.4768 - test_f1_macro: 0.4768 - mixed_f1_macro: 0.4768\n",
      "Epoch 111/500\n",
      " — train_f1=0.8834 | val_f1=0.5487 | test_f1=0.5487 | mixed_f1=0.5487\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.8075 - loss: 0.8623 - val_accuracy: 0.5304 - val_loss: 1.4884 - train_f1_macro: 0.8834 - val_f1_macro: 0.5487 - test_f1_macro: 0.5487 - mixed_f1_macro: 0.5487\n",
      "Epoch 112/500\n",
      " — train_f1=0.7697 | val_f1=0.5012 | test_f1=0.5012 | mixed_f1=0.5012\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.8362 - loss: 0.8187 - val_accuracy: 0.5135 - val_loss: 1.6295 - train_f1_macro: 0.7697 - val_f1_macro: 0.5012 - test_f1_macro: 0.5012 - mixed_f1_macro: 0.5012\n",
      "Epoch 113/500\n",
      " — train_f1=0.8564 | val_f1=0.5405 | test_f1=0.5405 | mixed_f1=0.5405\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.8182 - loss: 0.8540 - val_accuracy: 0.5236 - val_loss: 1.5247 - train_f1_macro: 0.8564 - val_f1_macro: 0.5405 - test_f1_macro: 0.5405 - mixed_f1_macro: 0.5405\n",
      "Epoch 114/500\n",
      " — train_f1=0.8178 | val_f1=0.5159 | test_f1=0.5159 | mixed_f1=0.5159\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.8315 - loss: 0.8200 - val_accuracy: 0.4932 - val_loss: 1.5768 - train_f1_macro: 0.8178 - val_f1_macro: 0.5159 - test_f1_macro: 0.5159 - mixed_f1_macro: 0.5159\n",
      "Epoch 115/500\n",
      " — train_f1=0.6409 | val_f1=0.4916 | test_f1=0.4916 | mixed_f1=0.4916\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.8109 - loss: 0.8680 - val_accuracy: 0.5372 - val_loss: 1.5274 - train_f1_macro: 0.6409 - val_f1_macro: 0.4916 - test_f1_macro: 0.4916 - mixed_f1_macro: 0.4916\n",
      "Epoch 116/500\n",
      " — train_f1=0.7180 | val_f1=0.4760 | test_f1=0.4760 | mixed_f1=0.4760\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.8285 - loss: 0.8251 - val_accuracy: 0.5135 - val_loss: 1.6110 - train_f1_macro: 0.7180 - val_f1_macro: 0.4760 - test_f1_macro: 0.4760 - mixed_f1_macro: 0.4760\n",
      "Epoch 117/500\n",
      " — train_f1=0.8858 | val_f1=0.5071 | test_f1=0.5071 | mixed_f1=0.5071\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.8105 - loss: 0.8529 - val_accuracy: 0.5034 - val_loss: 1.5643 - train_f1_macro: 0.8858 - val_f1_macro: 0.5071 - test_f1_macro: 0.5071 - mixed_f1_macro: 0.5071\n",
      "Epoch 118/500\n",
      " — train_f1=0.6843 | val_f1=0.4631 | test_f1=0.4631 | mixed_f1=0.4631\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.8272 - loss: 0.8328 - val_accuracy: 0.4797 - val_loss: 1.6814 - train_f1_macro: 0.6843 - val_f1_macro: 0.4631 - test_f1_macro: 0.4631 - mixed_f1_macro: 0.4631\n",
      "Epoch 119/500\n",
      " — train_f1=0.6887 | val_f1=0.4551 | test_f1=0.4551 | mixed_f1=0.4551\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8349 - loss: 0.8396 - val_accuracy: 0.4459 - val_loss: 1.6936 - train_f1_macro: 0.6887 - val_f1_macro: 0.4551 - test_f1_macro: 0.4551 - mixed_f1_macro: 0.4551\n",
      "Epoch 120/500\n",
      " — train_f1=0.7762 | val_f1=0.5087 | test_f1=0.5087 | mixed_f1=0.5087\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8336 - loss: 0.8388 - val_accuracy: 0.5135 - val_loss: 1.5086 - train_f1_macro: 0.7762 - val_f1_macro: 0.5087 - test_f1_macro: 0.5087 - mixed_f1_macro: 0.5087\n",
      "Epoch 121/500\n",
      " — train_f1=0.7554 | val_f1=0.4903 | test_f1=0.4903 | mixed_f1=0.4903\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.8212 - loss: 0.8252 - val_accuracy: 0.5203 - val_loss: 1.6417 - train_f1_macro: 0.7554 - val_f1_macro: 0.4903 - test_f1_macro: 0.4903 - mixed_f1_macro: 0.4903\n",
      "Epoch 122/500\n",
      " — train_f1=0.7969 | val_f1=0.5494 | test_f1=0.5494 | mixed_f1=0.5494\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8405 - loss: 0.8140 - val_accuracy: 0.5135 - val_loss: 1.5895 - train_f1_macro: 0.7969 - val_f1_macro: 0.5494 - test_f1_macro: 0.5494 - mixed_f1_macro: 0.5494\n",
      "Epoch 123/500\n",
      " — train_f1=0.9170 | val_f1=0.5699 | test_f1=0.5699 | mixed_f1=0.5699\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8456 - loss: 0.8297 - val_accuracy: 0.5372 - val_loss: 1.4936 - train_f1_macro: 0.9170 - val_f1_macro: 0.5699 - test_f1_macro: 0.5699 - mixed_f1_macro: 0.5699\n",
      "Epoch 124/500\n",
      " — train_f1=0.7805 | val_f1=0.4826 | test_f1=0.4826 | mixed_f1=0.4826\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8310 - loss: 0.8057 - val_accuracy: 0.4628 - val_loss: 1.6880 - train_f1_macro: 0.7805 - val_f1_macro: 0.4826 - test_f1_macro: 0.4826 - mixed_f1_macro: 0.4826\n",
      "Epoch 125/500\n",
      " — train_f1=0.8994 | val_f1=0.5186 | test_f1=0.5186 | mixed_f1=0.5186\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.8456 - loss: 0.7933 - val_accuracy: 0.5135 - val_loss: 1.5391 - train_f1_macro: 0.8994 - val_f1_macro: 0.5186 - test_f1_macro: 0.5186 - mixed_f1_macro: 0.5186\n",
      "Epoch 126/500\n",
      " — train_f1=0.6322 | val_f1=0.4272 | test_f1=0.4272 | mixed_f1=0.4272\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8521 - loss: 0.7908 - val_accuracy: 0.4155 - val_loss: 1.8464 - train_f1_macro: 0.6322 - val_f1_macro: 0.4272 - test_f1_macro: 0.4272 - mixed_f1_macro: 0.4272\n",
      "Epoch 127/500\n",
      " — train_f1=0.7450 | val_f1=0.4894 | test_f1=0.4894 | mixed_f1=0.4894\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.8328 - loss: 0.8166 - val_accuracy: 0.4899 - val_loss: 1.6513 - train_f1_macro: 0.7450 - val_f1_macro: 0.4894 - test_f1_macro: 0.4894 - mixed_f1_macro: 0.4894\n",
      "Epoch 128/500\n",
      " — train_f1=0.9059 | val_f1=0.5125 | test_f1=0.5125 | mixed_f1=0.5125\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8379 - loss: 0.8037 - val_accuracy: 0.4966 - val_loss: 1.5791 - train_f1_macro: 0.9059 - val_f1_macro: 0.5125 - test_f1_macro: 0.5125 - mixed_f1_macro: 0.5125\n",
      "Epoch 129/500\n",
      " — train_f1=0.8927 | val_f1=0.5706 | test_f1=0.5706 | mixed_f1=0.5706\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.8486 - loss: 0.7913 - val_accuracy: 0.5405 - val_loss: 1.5248 - train_f1_macro: 0.8927 - val_f1_macro: 0.5706 - test_f1_macro: 0.5706 - mixed_f1_macro: 0.5706\n",
      "Epoch 130/500\n",
      " — train_f1=0.7279 | val_f1=0.5011 | test_f1=0.5011 | mixed_f1=0.5011\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.8370 - loss: 0.8066 - val_accuracy: 0.5203 - val_loss: 1.6272 - train_f1_macro: 0.7279 - val_f1_macro: 0.5011 - test_f1_macro: 0.5011 - mixed_f1_macro: 0.5011\n",
      "Epoch 131/500\n",
      " — train_f1=0.7770 | val_f1=0.5053 | test_f1=0.5053 | mixed_f1=0.5053\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.8375 - loss: 0.8213 - val_accuracy: 0.5068 - val_loss: 1.6312 - train_f1_macro: 0.7770 - val_f1_macro: 0.5053 - test_f1_macro: 0.5053 - mixed_f1_macro: 0.5053\n",
      "Epoch 132/500\n",
      " — train_f1=0.9114 | val_f1=0.5259 | test_f1=0.5259 | mixed_f1=0.5259\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.8435 - loss: 0.8031 - val_accuracy: 0.5236 - val_loss: 1.5462 - train_f1_macro: 0.9114 - val_f1_macro: 0.5259 - test_f1_macro: 0.5259 - mixed_f1_macro: 0.5259\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.8526 | val_f1=0.5870 | test_f1=0.5870 | mixed_f1=0.5870\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 133 | f1=0.5870\n",
      "   → saved_models/merged_fold_0/best_val_f1_macro_epoch133_f10.5870_20260112_003622.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8461 - loss: 0.8119 - val_accuracy: 0.5507 - val_loss: 1.5518 - train_f1_macro: 0.8526 - val_f1_macro: 0.5870 - test_f1_macro: 0.5870 - mixed_f1_macro: 0.5870\n",
      "Epoch 134/500\n",
      " — train_f1=0.7103 | val_f1=0.4686 | test_f1=0.4686 | mixed_f1=0.4686\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.8585 - loss: 0.7897 - val_accuracy: 0.4730 - val_loss: 1.6299 - train_f1_macro: 0.7103 - val_f1_macro: 0.4686 - test_f1_macro: 0.4686 - mixed_f1_macro: 0.4686\n",
      "Epoch 135/500\n",
      " — train_f1=0.9087 | val_f1=0.5057 | test_f1=0.5057 | mixed_f1=0.5057\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.8452 - loss: 0.7837 - val_accuracy: 0.5135 - val_loss: 1.5463 - train_f1_macro: 0.9087 - val_f1_macro: 0.5057 - test_f1_macro: 0.5057 - mixed_f1_macro: 0.5057\n",
      "Epoch 136/500\n",
      " — train_f1=0.8371 | val_f1=0.4988 | test_f1=0.4988 | mixed_f1=0.4988\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.8473 - loss: 0.8069 - val_accuracy: 0.5203 - val_loss: 1.5406 - train_f1_macro: 0.8371 - val_f1_macro: 0.4988 - test_f1_macro: 0.4988 - mixed_f1_macro: 0.4988\n",
      "Epoch 137/500\n",
      " — train_f1=0.8150 | val_f1=0.5071 | test_f1=0.5071 | mixed_f1=0.5071\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8473 - loss: 0.8137 - val_accuracy: 0.5068 - val_loss: 1.6533 - train_f1_macro: 0.8150 - val_f1_macro: 0.5071 - test_f1_macro: 0.5071 - mixed_f1_macro: 0.5071\n",
      "Epoch 138/500\n",
      " — train_f1=0.4068 | val_f1=0.3644 | test_f1=0.3644 | mixed_f1=0.3644\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.8405 - loss: 0.8104 - val_accuracy: 0.4628 - val_loss: 1.7961 - train_f1_macro: 0.4068 - val_f1_macro: 0.3644 - test_f1_macro: 0.3644 - mixed_f1_macro: 0.3644\n",
      "Epoch 139/500\n",
      " — train_f1=0.8233 | val_f1=0.5230 | test_f1=0.5230 | mixed_f1=0.5230\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.8439 - loss: 0.8079 - val_accuracy: 0.5169 - val_loss: 1.6701 - train_f1_macro: 0.8233 - val_f1_macro: 0.5230 - test_f1_macro: 0.5230 - mixed_f1_macro: 0.5230\n",
      "Epoch 140/500\n",
      " — train_f1=0.9258 | val_f1=0.5600 | test_f1=0.5600 | mixed_f1=0.5600\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8508 - loss: 0.7974 - val_accuracy: 0.5405 - val_loss: 1.4929 - train_f1_macro: 0.9258 - val_f1_macro: 0.5600 - test_f1_macro: 0.5600 - mixed_f1_macro: 0.5600\n",
      "Epoch 141/500\n",
      " — train_f1=0.5952 | val_f1=0.4410 | test_f1=0.4410 | mixed_f1=0.4410\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8628 - loss: 0.7854 - val_accuracy: 0.4831 - val_loss: 1.7367 - train_f1_macro: 0.5952 - val_f1_macro: 0.4410 - test_f1_macro: 0.4410 - mixed_f1_macro: 0.4410\n",
      "Epoch 142/500\n",
      " — train_f1=0.8296 | val_f1=0.4851 | test_f1=0.4851 | mixed_f1=0.4851\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8593 - loss: 0.7822 - val_accuracy: 0.4696 - val_loss: 1.7062 - train_f1_macro: 0.8296 - val_f1_macro: 0.4851 - test_f1_macro: 0.4851 - mixed_f1_macro: 0.4851\n",
      "Epoch 143/500\n",
      " — train_f1=0.9366 | val_f1=0.5714 | test_f1=0.5714 | mixed_f1=0.5714\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.8533 - loss: 0.8067 - val_accuracy: 0.5439 - val_loss: 1.4890 - train_f1_macro: 0.9366 - val_f1_macro: 0.5714 - test_f1_macro: 0.5714 - mixed_f1_macro: 0.5714\n",
      "Epoch 144/500\n",
      " — train_f1=0.7930 | val_f1=0.4865 | test_f1=0.4865 | mixed_f1=0.4865\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.8576 - loss: 0.7910 - val_accuracy: 0.5169 - val_loss: 1.5576 - train_f1_macro: 0.7930 - val_f1_macro: 0.4865 - test_f1_macro: 0.4865 - mixed_f1_macro: 0.4865\n",
      "Epoch 145/500\n",
      " — train_f1=0.9130 | val_f1=0.5454 | test_f1=0.5454 | mixed_f1=0.5454\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8581 - loss: 0.7733 - val_accuracy: 0.5473 - val_loss: 1.4813 - train_f1_macro: 0.9130 - val_f1_macro: 0.5454 - test_f1_macro: 0.5454 - mixed_f1_macro: 0.5454\n",
      "Epoch 146/500\n",
      " — train_f1=0.8537 | val_f1=0.4782 | test_f1=0.4782 | mixed_f1=0.4782\n",
      "37/37 - 10s - 272ms/step - accuracy: 0.8593 - loss: 0.7918 - val_accuracy: 0.4831 - val_loss: 1.7035 - train_f1_macro: 0.8537 - val_f1_macro: 0.4782 - test_f1_macro: 0.4782 - mixed_f1_macro: 0.4782\n",
      "Epoch 147/500\n",
      " — train_f1=0.9344 | val_f1=0.5571 | test_f1=0.5571 | mixed_f1=0.5571\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.8525 - loss: 0.7771 - val_accuracy: 0.5338 - val_loss: 1.4568 - train_f1_macro: 0.9344 - val_f1_macro: 0.5571 - test_f1_macro: 0.5571 - mixed_f1_macro: 0.5571\n",
      "Epoch 148/500\n",
      " — train_f1=0.7021 | val_f1=0.4859 | test_f1=0.4859 | mixed_f1=0.4859\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.8671 - loss: 0.7633 - val_accuracy: 0.4797 - val_loss: 1.6927 - train_f1_macro: 0.7021 - val_f1_macro: 0.4859 - test_f1_macro: 0.4859 - mixed_f1_macro: 0.4859\n",
      "Epoch 149/500\n",
      " — train_f1=0.6607 | val_f1=0.4123 | test_f1=0.4123 | mixed_f1=0.4123\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.8452 - loss: 0.7925 - val_accuracy: 0.4696 - val_loss: 1.7433 - train_f1_macro: 0.6607 - val_f1_macro: 0.4123 - test_f1_macro: 0.4123 - mixed_f1_macro: 0.4123\n",
      "Epoch 150/500\n",
      " — train_f1=0.8881 | val_f1=0.5111 | test_f1=0.5111 | mixed_f1=0.5111\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.8508 - loss: 0.7976 - val_accuracy: 0.5000 - val_loss: 1.6727 - train_f1_macro: 0.8881 - val_f1_macro: 0.5111 - test_f1_macro: 0.5111 - mixed_f1_macro: 0.5111\n",
      "Epoch 151/500\n",
      " — train_f1=0.6271 | val_f1=0.4488 | test_f1=0.4488 | mixed_f1=0.4488\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.8555 - loss: 0.7960 - val_accuracy: 0.4730 - val_loss: 1.7966 - train_f1_macro: 0.6271 - val_f1_macro: 0.4488 - test_f1_macro: 0.4488 - mixed_f1_macro: 0.4488\n",
      "Epoch 152/500\n",
      " — train_f1=0.9133 | val_f1=0.5461 | test_f1=0.5461 | mixed_f1=0.5461\n",
      "37/37 - 10s - 264ms/step - accuracy: 0.8619 - loss: 0.7689 - val_accuracy: 0.5135 - val_loss: 1.5136 - train_f1_macro: 0.9133 - val_f1_macro: 0.5461 - test_f1_macro: 0.5461 - mixed_f1_macro: 0.5461\n",
      "Epoch 153/500\n",
      " — train_f1=0.7316 | val_f1=0.4299 | test_f1=0.4299 | mixed_f1=0.4299\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.8752 - loss: 0.7784 - val_accuracy: 0.4662 - val_loss: 1.5933 - train_f1_macro: 0.7316 - val_f1_macro: 0.4299 - test_f1_macro: 0.4299 - mixed_f1_macro: 0.4299\n",
      "Epoch 154/500\n",
      " — train_f1=0.7390 | val_f1=0.4861 | test_f1=0.4861 | mixed_f1=0.4861\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.8546 - loss: 0.7853 - val_accuracy: 0.5101 - val_loss: 1.6044 - train_f1_macro: 0.7390 - val_f1_macro: 0.4861 - test_f1_macro: 0.4861 - mixed_f1_macro: 0.4861\n",
      "Epoch 155/500\n",
      " — train_f1=0.7959 | val_f1=0.4768 | test_f1=0.4768 | mixed_f1=0.4768\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8714 - loss: 0.7606 - val_accuracy: 0.4899 - val_loss: 1.6891 - train_f1_macro: 0.7959 - val_f1_macro: 0.4768 - test_f1_macro: 0.4768 - mixed_f1_macro: 0.4768\n",
      "Epoch 156/500\n",
      " — train_f1=0.8883 | val_f1=0.5701 | test_f1=0.5701 | mixed_f1=0.5701\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8752 - loss: 0.7775 - val_accuracy: 0.5507 - val_loss: 1.5381 - train_f1_macro: 0.8883 - val_f1_macro: 0.5701 - test_f1_macro: 0.5701 - mixed_f1_macro: 0.5701\n",
      "Epoch 157/500\n",
      " — train_f1=0.9127 | val_f1=0.5450 | test_f1=0.5450 | mixed_f1=0.5450\n",
      "37/37 - 10s - 274ms/step - accuracy: 0.8568 - loss: 0.7980 - val_accuracy: 0.5169 - val_loss: 1.4974 - train_f1_macro: 0.9127 - val_f1_macro: 0.5450 - test_f1_macro: 0.5450 - mixed_f1_macro: 0.5450\n",
      "Epoch 158/500\n",
      " — train_f1=0.8915 | val_f1=0.5580 | test_f1=0.5580 | mixed_f1=0.5580\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.8782 - loss: 0.7609 - val_accuracy: 0.5270 - val_loss: 1.5584 - train_f1_macro: 0.8915 - val_f1_macro: 0.5580 - test_f1_macro: 0.5580 - mixed_f1_macro: 0.5580\n",
      "Epoch 159/500\n",
      " — train_f1=0.7693 | val_f1=0.5079 | test_f1=0.5079 | mixed_f1=0.5079\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.8709 - loss: 0.7622 - val_accuracy: 0.5270 - val_loss: 1.6795 - train_f1_macro: 0.7693 - val_f1_macro: 0.5079 - test_f1_macro: 0.5079 - mixed_f1_macro: 0.5079\n",
      "Epoch 160/500\n",
      " — train_f1=0.9379 | val_f1=0.5627 | test_f1=0.5627 | mixed_f1=0.5627\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.8821 - loss: 0.7431 - val_accuracy: 0.5270 - val_loss: 1.6532 - train_f1_macro: 0.9379 - val_f1_macro: 0.5627 - test_f1_macro: 0.5627 - mixed_f1_macro: 0.5627\n",
      "Epoch 161/500\n",
      " — train_f1=0.8996 | val_f1=0.5087 | test_f1=0.5087 | mixed_f1=0.5087\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.8778 - loss: 0.7621 - val_accuracy: 0.5101 - val_loss: 1.5784 - train_f1_macro: 0.8996 - val_f1_macro: 0.5087 - test_f1_macro: 0.5087 - mixed_f1_macro: 0.5087\n",
      "Epoch 162/500\n",
      " — train_f1=0.8270 | val_f1=0.4795 | test_f1=0.4795 | mixed_f1=0.4795\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.8623 - loss: 0.7773 - val_accuracy: 0.5000 - val_loss: 1.6998 - train_f1_macro: 0.8270 - val_f1_macro: 0.4795 - test_f1_macro: 0.4795 - mixed_f1_macro: 0.4795\n",
      "Epoch 163/500\n",
      " — train_f1=0.6027 | val_f1=0.4649 | test_f1=0.4649 | mixed_f1=0.4649\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.8688 - loss: 0.7677 - val_accuracy: 0.5270 - val_loss: 1.6071 - train_f1_macro: 0.6027 - val_f1_macro: 0.4649 - test_f1_macro: 0.4649 - mixed_f1_macro: 0.4649\n",
      "\n",
      "Fold 0 FINAL (Mixed Test): ACC=0.5507 F1w=0.5185 MCC=0.4524\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 1  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2339, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (289, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (289, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5433217189314751, 1: 0.7024024024024024, 2: 0.8107452339688042, 3: 4.3719626168224295, 4: 3.6546875}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768196380.431396 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1_1/dropout_5_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0362 | val_f1=0.0907 | test_f1=0.0907 | mixed_f1=0.0907\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0907\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch1_f10.0907_20260112_003948.h5\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.2257 - loss: 1.9327 - val_accuracy: 0.1419 - val_loss: 1.8608 - train_f1_macro: 0.0362 - val_f1_macro: 0.0907 - test_f1_macro: 0.0907 - mixed_f1_macro: 0.0907\n",
      "Epoch 2/500\n",
      " — train_f1=0.0200 | val_f1=0.0459 | test_f1=0.0459 | mixed_f1=0.0459\n",
      "37/37 - 7s - 201ms/step - accuracy: 0.2240 - loss: 1.8482 - val_accuracy: 0.1073 - val_loss: 1.9279 - train_f1_macro: 0.0200 - val_f1_macro: 0.0459 - test_f1_macro: 0.0459 - mixed_f1_macro: 0.0459\n",
      "Epoch 3/500\n",
      " — train_f1=0.0316 | val_f1=0.0515 | test_f1=0.0515 | mixed_f1=0.0515\n",
      "37/37 - 11s - 288ms/step - accuracy: 0.2924 - loss: 1.7442 - val_accuracy: 0.1107 - val_loss: 2.1101 - train_f1_macro: 0.0316 - val_f1_macro: 0.0515 - test_f1_macro: 0.0515 - mixed_f1_macro: 0.0515\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2350 | val_f1=0.1725 | test_f1=0.1725 | mixed_f1=0.1725\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.1725\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch4_f10.1725_20260112_004011.h5\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.3322 - loss: 1.6032 - val_accuracy: 0.1834 - val_loss: 1.5860 - train_f1_macro: 0.2350 - val_f1_macro: 0.1725 - test_f1_macro: 0.1725 - mixed_f1_macro: 0.1725\n",
      "Epoch 5/500\n",
      " — train_f1=0.1959 | val_f1=0.1270 | test_f1=0.1270 | mixed_f1=0.1270\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.3454 - loss: 1.5123 - val_accuracy: 0.1107 - val_loss: 1.7206 - train_f1_macro: 0.1959 - val_f1_macro: 0.1270 - test_f1_macro: 0.1270 - mixed_f1_macro: 0.1270\n",
      "Epoch 6/500\n",
      " — train_f1=0.1878 | val_f1=0.1348 | test_f1=0.1348 | mixed_f1=0.1348\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3604 - loss: 1.4810 - val_accuracy: 0.1107 - val_loss: 1.7801 - train_f1_macro: 0.1878 - val_f1_macro: 0.1348 - test_f1_macro: 0.1348 - mixed_f1_macro: 0.1348\n",
      "Epoch 7/500\n",
      " — train_f1=0.1702 | val_f1=0.1052 | test_f1=0.1052 | mixed_f1=0.1052\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3395 - loss: 1.4695 - val_accuracy: 0.0865 - val_loss: 1.8335 - train_f1_macro: 0.1702 - val_f1_macro: 0.1052 - test_f1_macro: 0.1052 - mixed_f1_macro: 0.1052\n",
      "Epoch 8/500\n",
      " — train_f1=0.2360 | val_f1=0.1699 | test_f1=0.1699 | mixed_f1=0.1699\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.3702 - loss: 1.4464 - val_accuracy: 0.1280 - val_loss: 1.6365 - train_f1_macro: 0.2360 - val_f1_macro: 0.1699 - test_f1_macro: 0.1699 - mixed_f1_macro: 0.1699\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3013 | val_f1=0.2128 | test_f1=0.2128 | mixed_f1=0.2128\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 9 | f1=0.2128\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch9_f10.2128_20260112_004037.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.3698 - loss: 1.4277 - val_accuracy: 0.1938 - val_loss: 1.4821 - train_f1_macro: 0.3013 - val_f1_macro: 0.2128 - test_f1_macro: 0.2128 - mixed_f1_macro: 0.2128\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3476 | val_f1=0.2402 | test_f1=0.2402 | mixed_f1=0.2402\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 10 | f1=0.2402\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch10_f10.2402_20260112_004043.h5\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.3570 - loss: 1.4102 - val_accuracy: 0.3287 - val_loss: 1.4378 - train_f1_macro: 0.3476 - val_f1_macro: 0.2402 - test_f1_macro: 0.2402 - mixed_f1_macro: 0.2402\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3978 | val_f1=0.3224 | test_f1=0.3224 | mixed_f1=0.3224\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 11 | f1=0.3224\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch11_f10.3224_20260112_004048.h5\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3762 - loss: 1.3780 - val_accuracy: 0.3945 - val_loss: 1.4367 - train_f1_macro: 0.3978 - val_f1_macro: 0.3224 - test_f1_macro: 0.3224 - mixed_f1_macro: 0.3224\n",
      "Epoch 12/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4812 | val_f1=0.4314 | test_f1=0.4314 | mixed_f1=0.4314\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 12 | f1=0.4314\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch12_f10.4314_20260112_004058.h5\n",
      "37/37 - 11s - 288ms/step - accuracy: 0.3839 - loss: 1.3612 - val_accuracy: 0.5121 - val_loss: 1.3999 - train_f1_macro: 0.4812 - val_f1_macro: 0.4314 - test_f1_macro: 0.4314 - mixed_f1_macro: 0.4314\n",
      "Epoch 13/500\n",
      " — train_f1=0.0626 | val_f1=0.0667 | test_f1=0.0667 | mixed_f1=0.0667\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.3955 - loss: 1.3683 - val_accuracy: 0.1246 - val_loss: 2.5816 - train_f1_macro: 0.0626 - val_f1_macro: 0.0667 - test_f1_macro: 0.0667 - mixed_f1_macro: 0.0667\n",
      "Epoch 14/500\n",
      " — train_f1=0.3764 | val_f1=0.3299 | test_f1=0.3299 | mixed_f1=0.3299\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4023 - loss: 1.3504 - val_accuracy: 0.4256 - val_loss: 1.4012 - train_f1_macro: 0.3764 - val_f1_macro: 0.3299 - test_f1_macro: 0.3299 - mixed_f1_macro: 0.3299\n",
      "Epoch 15/500\n",
      " — train_f1=0.1646 | val_f1=0.1281 | test_f1=0.1281 | mixed_f1=0.1281\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4066 - loss: 1.3441 - val_accuracy: 0.1834 - val_loss: 2.1147 - train_f1_macro: 0.1646 - val_f1_macro: 0.1281 - test_f1_macro: 0.1281 - mixed_f1_macro: 0.1281\n",
      "Epoch 16/500\n",
      " — train_f1=0.2883 | val_f1=0.2948 | test_f1=0.2948 | mixed_f1=0.2948\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4250 - loss: 1.3265 - val_accuracy: 0.3460 - val_loss: 1.6688 - train_f1_macro: 0.2883 - val_f1_macro: 0.2948 - test_f1_macro: 0.2948 - mixed_f1_macro: 0.2948\n",
      "Epoch 17/500\n",
      " — train_f1=0.3717 | val_f1=0.2860 | test_f1=0.2860 | mixed_f1=0.2860\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4237 - loss: 1.3162 - val_accuracy: 0.2491 - val_loss: 1.4729 - train_f1_macro: 0.3717 - val_f1_macro: 0.2860 - test_f1_macro: 0.2860 - mixed_f1_macro: 0.2860\n",
      "Epoch 18/500\n",
      " — train_f1=0.4225 | val_f1=0.3677 | test_f1=0.3677 | mixed_f1=0.3677\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.4339 - loss: 1.3086 - val_accuracy: 0.3875 - val_loss: 1.3960 - train_f1_macro: 0.4225 - val_f1_macro: 0.3677 - test_f1_macro: 0.3677 - mixed_f1_macro: 0.3677\n",
      "Epoch 19/500\n",
      " — train_f1=0.3756 | val_f1=0.3225 | test_f1=0.3225 | mixed_f1=0.3225\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.4301 - loss: 1.3126 - val_accuracy: 0.3218 - val_loss: 1.4319 - train_f1_macro: 0.3756 - val_f1_macro: 0.3225 - test_f1_macro: 0.3225 - mixed_f1_macro: 0.3225\n",
      "Epoch 20/500\n",
      " — train_f1=0.3213 | val_f1=0.3718 | test_f1=0.3718 | mixed_f1=0.3718\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4613 - loss: 1.2909 - val_accuracy: 0.5260 - val_loss: 1.4373 - train_f1_macro: 0.3213 - val_f1_macro: 0.3718 - test_f1_macro: 0.3718 - mixed_f1_macro: 0.3718\n",
      "Epoch 21/500\n",
      " — train_f1=0.4209 | val_f1=0.3512 | test_f1=0.3512 | mixed_f1=0.3512\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.4365 - loss: 1.3028 - val_accuracy: 0.4983 - val_loss: 1.3038 - train_f1_macro: 0.4209 - val_f1_macro: 0.3512 - test_f1_macro: 0.3512 - mixed_f1_macro: 0.3512\n",
      "Epoch 22/500\n",
      " — train_f1=0.4635 | val_f1=0.3571 | test_f1=0.3571 | mixed_f1=0.3571\n",
      "37/37 - 11s - 287ms/step - accuracy: 0.4793 - loss: 1.2878 - val_accuracy: 0.5121 - val_loss: 1.3247 - train_f1_macro: 0.4635 - val_f1_macro: 0.3571 - test_f1_macro: 0.3571 - mixed_f1_macro: 0.3571\n",
      "Epoch 23/500\n",
      " — train_f1=0.4636 | val_f1=0.4231 | test_f1=0.4231 | mixed_f1=0.4231\n",
      "37/37 - 10s - 264ms/step - accuracy: 0.4587 - loss: 1.2806 - val_accuracy: 0.5260 - val_loss: 1.3084 - train_f1_macro: 0.4636 - val_f1_macro: 0.4231 - test_f1_macro: 0.4231 - mixed_f1_macro: 0.4231\n",
      "Epoch 24/500\n",
      " — train_f1=0.4572 | val_f1=0.3747 | test_f1=0.3747 | mixed_f1=0.3747\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4793 - loss: 1.2601 - val_accuracy: 0.5260 - val_loss: 1.2739 - train_f1_macro: 0.4572 - val_f1_macro: 0.3747 - test_f1_macro: 0.3747 - mixed_f1_macro: 0.3747\n",
      "Epoch 25/500\n",
      " — train_f1=0.3989 | val_f1=0.3704 | test_f1=0.3704 | mixed_f1=0.3704\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.4758 - loss: 1.2809 - val_accuracy: 0.4464 - val_loss: 1.4048 - train_f1_macro: 0.3989 - val_f1_macro: 0.3704 - test_f1_macro: 0.3704 - mixed_f1_macro: 0.3704\n",
      "Epoch 26/500\n",
      " — train_f1=0.4165 | val_f1=0.3439 | test_f1=0.3439 | mixed_f1=0.3439\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.4972 - loss: 1.2594 - val_accuracy: 0.4429 - val_loss: 1.4158 - train_f1_macro: 0.4165 - val_f1_macro: 0.3439 - test_f1_macro: 0.3439 - mixed_f1_macro: 0.3439\n",
      "Epoch 27/500\n",
      " — train_f1=0.4124 | val_f1=0.3221 | test_f1=0.3221 | mixed_f1=0.3221\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5036 - loss: 1.2534 - val_accuracy: 0.3426 - val_loss: 1.4976 - train_f1_macro: 0.4124 - val_f1_macro: 0.3221 - test_f1_macro: 0.3221 - mixed_f1_macro: 0.3221\n",
      "Epoch 28/500\n",
      " — train_f1=0.4849 | val_f1=0.4138 | test_f1=0.4138 | mixed_f1=0.4138\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.5229 - loss: 1.2351 - val_accuracy: 0.5502 - val_loss: 1.2622 - train_f1_macro: 0.4849 - val_f1_macro: 0.4138 - test_f1_macro: 0.4138 - mixed_f1_macro: 0.4138\n",
      "Epoch 29/500\n",
      " — train_f1=0.4885 | val_f1=0.3973 | test_f1=0.3973 | mixed_f1=0.3973\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.5118 - loss: 1.2441 - val_accuracy: 0.5156 - val_loss: 1.3175 - train_f1_macro: 0.4885 - val_f1_macro: 0.3973 - test_f1_macro: 0.3973 - mixed_f1_macro: 0.3973\n",
      "Epoch 30/500\n",
      " — train_f1=0.4547 | val_f1=0.3486 | test_f1=0.3486 | mixed_f1=0.3486\n",
      "37/37 - 10s - 267ms/step - accuracy: 0.5280 - loss: 1.2236 - val_accuracy: 0.5363 - val_loss: 1.2358 - train_f1_macro: 0.4547 - val_f1_macro: 0.3486 - test_f1_macro: 0.3486 - mixed_f1_macro: 0.3486\n",
      "Epoch 31/500\n",
      " — train_f1=0.2289 | val_f1=0.1813 | test_f1=0.1813 | mixed_f1=0.1813\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.5387 - loss: 1.2230 - val_accuracy: 0.2284 - val_loss: 1.7959 - train_f1_macro: 0.2289 - val_f1_macro: 0.1813 - test_f1_macro: 0.1813 - mixed_f1_macro: 0.1813\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5825 | val_f1=0.4496 | test_f1=0.4496 | mixed_f1=0.4496\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 32 | f1=0.4496\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch32_f10.4496_20260112_004317.h5\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.5378 - loss: 1.2127 - val_accuracy: 0.5536 - val_loss: 1.2462 - train_f1_macro: 0.5825 - val_f1_macro: 0.4496 - test_f1_macro: 0.4496 - mixed_f1_macro: 0.4496\n",
      "Epoch 33/500\n",
      " — train_f1=0.4576 | val_f1=0.4014 | test_f1=0.4014 | mixed_f1=0.4014\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5661 - loss: 1.2183 - val_accuracy: 0.4983 - val_loss: 1.2910 - train_f1_macro: 0.4576 - val_f1_macro: 0.4014 - test_f1_macro: 0.4014 - mixed_f1_macro: 0.4014\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5845 | val_f1=0.4711 | test_f1=0.4711 | mixed_f1=0.4711\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 34 | f1=0.4711\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch34_f10.4711_20260112_004332.h5\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5609 - loss: 1.1962 - val_accuracy: 0.5156 - val_loss: 1.3141 - train_f1_macro: 0.5845 - val_f1_macro: 0.4711 - test_f1_macro: 0.4711 - mixed_f1_macro: 0.4711\n",
      "Epoch 35/500\n",
      " — train_f1=0.4454 | val_f1=0.3639 | test_f1=0.3639 | mixed_f1=0.3639\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5519 - loss: 1.1959 - val_accuracy: 0.3875 - val_loss: 1.4646 - train_f1_macro: 0.4454 - val_f1_macro: 0.3639 - test_f1_macro: 0.3639 - mixed_f1_macro: 0.3639\n",
      "Epoch 36/500\n",
      " — train_f1=0.3587 | val_f1=0.2680 | test_f1=0.2680 | mixed_f1=0.2680\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.5661 - loss: 1.1898 - val_accuracy: 0.3599 - val_loss: 1.4531 - train_f1_macro: 0.3587 - val_f1_macro: 0.2680 - test_f1_macro: 0.2680 - mixed_f1_macro: 0.2680\n",
      "Epoch 37/500\n",
      " — train_f1=0.4778 | val_f1=0.3811 | test_f1=0.3811 | mixed_f1=0.3811\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5703 - loss: 1.1847 - val_accuracy: 0.4533 - val_loss: 1.3437 - train_f1_macro: 0.4778 - val_f1_macro: 0.3811 - test_f1_macro: 0.3811 - mixed_f1_macro: 0.3811\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5993 | val_f1=0.4735 | test_f1=0.4735 | mixed_f1=0.4735\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 38 | f1=0.4735\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch38_f10.4735_20260112_004352.h5\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5814 - loss: 1.1684 - val_accuracy: 0.5017 - val_loss: 1.3056 - train_f1_macro: 0.5993 - val_f1_macro: 0.4735 - test_f1_macro: 0.4735 - mixed_f1_macro: 0.4735\n",
      "Epoch 39/500\n",
      " — train_f1=0.4343 | val_f1=0.3080 | test_f1=0.3080 | mixed_f1=0.3080\n",
      "37/37 - 6s - 158ms/step - accuracy: 0.5772 - loss: 1.1748 - val_accuracy: 0.3356 - val_loss: 1.4910 - train_f1_macro: 0.4343 - val_f1_macro: 0.3080 - test_f1_macro: 0.3080 - mixed_f1_macro: 0.3080\n",
      "Epoch 40/500\n",
      " — train_f1=0.5403 | val_f1=0.3834 | test_f1=0.3834 | mixed_f1=0.3834\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.6028 - loss: 1.1370 - val_accuracy: 0.4498 - val_loss: 1.3776 - train_f1_macro: 0.5403 - val_f1_macro: 0.3834 - test_f1_macro: 0.3834 - mixed_f1_macro: 0.3834\n",
      "Epoch 41/500\n",
      " — train_f1=0.5797 | val_f1=0.3946 | test_f1=0.3946 | mixed_f1=0.3946\n",
      "37/37 - 11s - 290ms/step - accuracy: 0.5708 - loss: 1.1690 - val_accuracy: 0.4844 - val_loss: 1.3198 - train_f1_macro: 0.5797 - val_f1_macro: 0.3946 - test_f1_macro: 0.3946 - mixed_f1_macro: 0.3946\n",
      "Epoch 42/500\n",
      " — train_f1=0.3289 | val_f1=0.3031 | test_f1=0.3031 | mixed_f1=0.3031\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.6233 - loss: 1.1341 - val_accuracy: 0.2872 - val_loss: 1.5987 - train_f1_macro: 0.3289 - val_f1_macro: 0.3031 - test_f1_macro: 0.3031 - mixed_f1_macro: 0.3031\n",
      "Epoch 43/500\n",
      " — train_f1=0.6051 | val_f1=0.4674 | test_f1=0.4674 | mixed_f1=0.4674\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6178 - loss: 1.1240 - val_accuracy: 0.5017 - val_loss: 1.3010 - train_f1_macro: 0.6051 - val_f1_macro: 0.4674 - test_f1_macro: 0.4674 - mixed_f1_macro: 0.4674\n",
      "Epoch 44/500\n",
      " — train_f1=0.6201 | val_f1=0.4685 | test_f1=0.4685 | mixed_f1=0.4685\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6370 - loss: 1.1183 - val_accuracy: 0.5329 - val_loss: 1.2858 - train_f1_macro: 0.6201 - val_f1_macro: 0.4685 - test_f1_macro: 0.4685 - mixed_f1_macro: 0.4685\n",
      "Epoch 45/500\n",
      " — train_f1=0.6070 | val_f1=0.4600 | test_f1=0.4600 | mixed_f1=0.4600\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6204 - loss: 1.1287 - val_accuracy: 0.5294 - val_loss: 1.2579 - train_f1_macro: 0.6070 - val_f1_macro: 0.4600 - test_f1_macro: 0.4600 - mixed_f1_macro: 0.4600\n",
      "Epoch 46/500\n",
      " — train_f1=0.4318 | val_f1=0.4133 | test_f1=0.4133 | mixed_f1=0.4133\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6127 - loss: 1.1432 - val_accuracy: 0.5052 - val_loss: 1.4267 - train_f1_macro: 0.4318 - val_f1_macro: 0.4133 - test_f1_macro: 0.4133 - mixed_f1_macro: 0.4133\n",
      "Epoch 47/500\n",
      " — train_f1=0.4097 | val_f1=0.3268 | test_f1=0.3268 | mixed_f1=0.3268\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6178 - loss: 1.1292 - val_accuracy: 0.3253 - val_loss: 1.5732 - train_f1_macro: 0.4097 - val_f1_macro: 0.3268 - test_f1_macro: 0.3268 - mixed_f1_macro: 0.3268\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6722 | val_f1=0.4799 | test_f1=0.4799 | mixed_f1=0.4799\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 48 | f1=0.4799\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch48_f10.4799_20260112_004454.h5\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6349 - loss: 1.1022 - val_accuracy: 0.5363 - val_loss: 1.2853 - train_f1_macro: 0.6722 - val_f1_macro: 0.4799 - test_f1_macro: 0.4799 - mixed_f1_macro: 0.4799\n",
      "Epoch 49/500\n",
      " — train_f1=0.5884 | val_f1=0.4310 | test_f1=0.4310 | mixed_f1=0.4310\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6417 - loss: 1.0933 - val_accuracy: 0.4464 - val_loss: 1.4358 - train_f1_macro: 0.5884 - val_f1_macro: 0.4310 - test_f1_macro: 0.4310 - mixed_f1_macro: 0.4310\n",
      "Epoch 50/500\n",
      " — train_f1=0.5414 | val_f1=0.4006 | test_f1=0.4006 | mixed_f1=0.4006\n",
      "37/37 - 5s - 143ms/step - accuracy: 0.6439 - loss: 1.1052 - val_accuracy: 0.5398 - val_loss: 1.3126 - train_f1_macro: 0.5414 - val_f1_macro: 0.4006 - test_f1_macro: 0.4006 - mixed_f1_macro: 0.4006\n",
      "Epoch 51/500\n",
      " — train_f1=0.6430 | val_f1=0.4449 | test_f1=0.4449 | mixed_f1=0.4449\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.6396 - loss: 1.0992 - val_accuracy: 0.4602 - val_loss: 1.3740 - train_f1_macro: 0.6430 - val_f1_macro: 0.4449 - test_f1_macro: 0.4449 - mixed_f1_macro: 0.4449\n",
      "Epoch 52/500\n",
      " — train_f1=0.6919 | val_f1=0.4633 | test_f1=0.4633 | mixed_f1=0.4633\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6670 - loss: 1.0734 - val_accuracy: 0.5017 - val_loss: 1.3290 - train_f1_macro: 0.6919 - val_f1_macro: 0.4633 - test_f1_macro: 0.4633 - mixed_f1_macro: 0.4633\n",
      "Epoch 53/500\n",
      " — train_f1=0.6951 | val_f1=0.4781 | test_f1=0.4781 | mixed_f1=0.4781\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.6764 - loss: 1.0687 - val_accuracy: 0.5121 - val_loss: 1.3306 - train_f1_macro: 0.6951 - val_f1_macro: 0.4781 - test_f1_macro: 0.4781 - mixed_f1_macro: 0.4781\n",
      "Epoch 54/500\n",
      " — train_f1=0.6084 | val_f1=0.4502 | test_f1=0.4502 | mixed_f1=0.4502\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6687 - loss: 1.0636 - val_accuracy: 0.5294 - val_loss: 1.3067 - train_f1_macro: 0.6084 - val_f1_macro: 0.4502 - test_f1_macro: 0.4502 - mixed_f1_macro: 0.4502\n",
      "Epoch 55/500\n",
      " — train_f1=0.5447 | val_f1=0.4221 | test_f1=0.4221 | mixed_f1=0.4221\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.6708 - loss: 1.0699 - val_accuracy: 0.4498 - val_loss: 1.3881 - train_f1_macro: 0.5447 - val_f1_macro: 0.4221 - test_f1_macro: 0.4221 - mixed_f1_macro: 0.4221\n",
      "Epoch 56/500\n",
      " — train_f1=0.6534 | val_f1=0.4422 | test_f1=0.4422 | mixed_f1=0.4422\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6755 - loss: 1.0425 - val_accuracy: 0.5225 - val_loss: 1.2908 - train_f1_macro: 0.6534 - val_f1_macro: 0.4422 - test_f1_macro: 0.4422 - mixed_f1_macro: 0.4422\n",
      "Epoch 57/500\n",
      " — train_f1=0.6530 | val_f1=0.4457 | test_f1=0.4457 | mixed_f1=0.4457\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6858 - loss: 1.0527 - val_accuracy: 0.4602 - val_loss: 1.3953 - train_f1_macro: 0.6530 - val_f1_macro: 0.4457 - test_f1_macro: 0.4457 - mixed_f1_macro: 0.4457\n",
      "Epoch 58/500\n",
      " — train_f1=0.6459 | val_f1=0.4683 | test_f1=0.4683 | mixed_f1=0.4683\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.6836 - loss: 1.0539 - val_accuracy: 0.5744 - val_loss: 1.2711 - train_f1_macro: 0.6459 - val_f1_macro: 0.4683 - test_f1_macro: 0.4683 - mixed_f1_macro: 0.4683\n",
      "Epoch 59/500\n",
      " — train_f1=0.5830 | val_f1=0.4187 | test_f1=0.4187 | mixed_f1=0.4187\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6823 - loss: 1.0431 - val_accuracy: 0.4567 - val_loss: 1.3891 - train_f1_macro: 0.5830 - val_f1_macro: 0.4187 - test_f1_macro: 0.4187 - mixed_f1_macro: 0.4187\n",
      "Epoch 60/500\n",
      " — train_f1=0.6394 | val_f1=0.4619 | test_f1=0.4619 | mixed_f1=0.4619\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6939 - loss: 1.0511 - val_accuracy: 0.5433 - val_loss: 1.2753 - train_f1_macro: 0.6394 - val_f1_macro: 0.4619 - test_f1_macro: 0.4619 - mixed_f1_macro: 0.4619\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6900 | val_f1=0.4839 | test_f1=0.4839 | mixed_f1=0.4839\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 61 | f1=0.4839\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch61_f10.4839_20260112_004617.h5\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6965 - loss: 1.0250 - val_accuracy: 0.5536 - val_loss: 1.2835 - train_f1_macro: 0.6900 - val_f1_macro: 0.4839 - test_f1_macro: 0.4839 - mixed_f1_macro: 0.4839\n",
      "Epoch 62/500\n",
      " — train_f1=0.6472 | val_f1=0.4393 | test_f1=0.4393 | mixed_f1=0.4393\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.6926 - loss: 1.0266 - val_accuracy: 0.4671 - val_loss: 1.3967 - train_f1_macro: 0.6472 - val_f1_macro: 0.4393 - test_f1_macro: 0.4393 - mixed_f1_macro: 0.4393\n",
      "Epoch 63/500\n",
      " — train_f1=0.4626 | val_f1=0.4201 | test_f1=0.4201 | mixed_f1=0.4201\n",
      "37/37 - 11s - 290ms/step - accuracy: 0.6866 - loss: 1.0340 - val_accuracy: 0.4913 - val_loss: 1.5457 - train_f1_macro: 0.4626 - val_f1_macro: 0.4201 - test_f1_macro: 0.4201 - mixed_f1_macro: 0.4201\n",
      "Epoch 64/500\n",
      " — train_f1=0.6958 | val_f1=0.4828 | test_f1=0.4828 | mixed_f1=0.4828\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.6960 - loss: 1.0245 - val_accuracy: 0.5502 - val_loss: 1.2712 - train_f1_macro: 0.6958 - val_f1_macro: 0.4828 - test_f1_macro: 0.4828 - mixed_f1_macro: 0.4828\n",
      "Epoch 65/500\n",
      " — train_f1=0.6004 | val_f1=0.4473 | test_f1=0.4473 | mixed_f1=0.4473\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.7191 - loss: 1.0080 - val_accuracy: 0.5294 - val_loss: 1.4393 - train_f1_macro: 0.6004 - val_f1_macro: 0.4473 - test_f1_macro: 0.4473 - mixed_f1_macro: 0.4473\n",
      "Epoch 66/500\n",
      " — train_f1=0.6867 | val_f1=0.4799 | test_f1=0.4799 | mixed_f1=0.4799\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7208 - loss: 1.0176 - val_accuracy: 0.5606 - val_loss: 1.2775 - train_f1_macro: 0.6867 - val_f1_macro: 0.4799 - test_f1_macro: 0.4799 - mixed_f1_macro: 0.4799\n",
      "Epoch 67/500\n",
      " — train_f1=0.4879 | val_f1=0.3723 | test_f1=0.3723 | mixed_f1=0.3723\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7157 - loss: 1.0102 - val_accuracy: 0.3564 - val_loss: 1.6077 - train_f1_macro: 0.4879 - val_f1_macro: 0.3723 - test_f1_macro: 0.3723 - mixed_f1_macro: 0.3723\n",
      "Epoch 68/500\n",
      " — train_f1=0.3945 | val_f1=0.3484 | test_f1=0.3484 | mixed_f1=0.3484\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.7007 - loss: 0.9936 - val_accuracy: 0.4948 - val_loss: 1.5905 - train_f1_macro: 0.3945 - val_f1_macro: 0.3484 - test_f1_macro: 0.3484 - mixed_f1_macro: 0.3484\n",
      "Epoch 69/500\n",
      " — train_f1=0.6374 | val_f1=0.4485 | test_f1=0.4485 | mixed_f1=0.4485\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7191 - loss: 0.9791 - val_accuracy: 0.5052 - val_loss: 1.3476 - train_f1_macro: 0.6374 - val_f1_macro: 0.4485 - test_f1_macro: 0.4485 - mixed_f1_macro: 0.4485\n",
      "Epoch 70/500\n",
      " — train_f1=0.6894 | val_f1=0.4284 | test_f1=0.4284 | mixed_f1=0.4284\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.7148 - loss: 1.0056 - val_accuracy: 0.4706 - val_loss: 1.3961 - train_f1_macro: 0.6894 - val_f1_macro: 0.4284 - test_f1_macro: 0.4284 - mixed_f1_macro: 0.4284\n",
      "Epoch 71/500\n",
      " — train_f1=0.7378 | val_f1=0.4745 | test_f1=0.4745 | mixed_f1=0.4745\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7272 - loss: 0.9849 - val_accuracy: 0.5052 - val_loss: 1.4041 - train_f1_macro: 0.7378 - val_f1_macro: 0.4745 - test_f1_macro: 0.4745 - mixed_f1_macro: 0.4745\n",
      "Epoch 72/500\n",
      " — train_f1=0.5749 | val_f1=0.4388 | test_f1=0.4388 | mixed_f1=0.4388\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.7251 - loss: 0.9947 - val_accuracy: 0.5329 - val_loss: 1.4097 - train_f1_macro: 0.5749 - val_f1_macro: 0.4388 - test_f1_macro: 0.4388 - mixed_f1_macro: 0.4388\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6878 | val_f1=0.5473 | test_f1=0.5473 | mixed_f1=0.5473\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 73 | f1=0.5473\n",
      "   → saved_models/merged_fold_1/best_val_f1_macro_epoch73_f10.5473_20260112_004732.h5\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7542 - loss: 0.9671 - val_accuracy: 0.6228 - val_loss: 1.2079 - train_f1_macro: 0.6878 - val_f1_macro: 0.5473 - test_f1_macro: 0.5473 - mixed_f1_macro: 0.5473\n",
      "Epoch 74/500\n",
      " — train_f1=0.2908 | val_f1=0.2558 | test_f1=0.2558 | mixed_f1=0.2558\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7341 - loss: 0.9833 - val_accuracy: 0.2388 - val_loss: 1.8669 - train_f1_macro: 0.2908 - val_f1_macro: 0.2558 - test_f1_macro: 0.2558 - mixed_f1_macro: 0.2558\n",
      "Epoch 75/500\n",
      " — train_f1=0.7732 | val_f1=0.4740 | test_f1=0.4740 | mixed_f1=0.4740\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7341 - loss: 0.9729 - val_accuracy: 0.5087 - val_loss: 1.4178 - train_f1_macro: 0.7732 - val_f1_macro: 0.4740 - test_f1_macro: 0.4740 - mixed_f1_macro: 0.4740\n",
      "Epoch 76/500\n",
      " — train_f1=0.7481 | val_f1=0.4704 | test_f1=0.4704 | mixed_f1=0.4704\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7507 - loss: 0.9559 - val_accuracy: 0.5433 - val_loss: 1.3204 - train_f1_macro: 0.7481 - val_f1_macro: 0.4704 - test_f1_macro: 0.4704 - mixed_f1_macro: 0.4704\n",
      "Epoch 77/500\n",
      " — train_f1=0.7452 | val_f1=0.4093 | test_f1=0.4093 | mixed_f1=0.4093\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7345 - loss: 0.9809 - val_accuracy: 0.4187 - val_loss: 1.4951 - train_f1_macro: 0.7452 - val_f1_macro: 0.4093 - test_f1_macro: 0.4093 - mixed_f1_macro: 0.4093\n",
      "Epoch 78/500\n",
      " — train_f1=0.7642 | val_f1=0.4777 | test_f1=0.4777 | mixed_f1=0.4777\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.7456 - loss: 0.9680 - val_accuracy: 0.5294 - val_loss: 1.3603 - train_f1_macro: 0.7642 - val_f1_macro: 0.4777 - test_f1_macro: 0.4777 - mixed_f1_macro: 0.4777\n",
      "Epoch 79/500\n",
      " — train_f1=0.7112 | val_f1=0.4138 | test_f1=0.4138 | mixed_f1=0.4138\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.7422 - loss: 0.9464 - val_accuracy: 0.4152 - val_loss: 1.5276 - train_f1_macro: 0.7112 - val_f1_macro: 0.4138 - test_f1_macro: 0.4138 - mixed_f1_macro: 0.4138\n",
      "Epoch 80/500\n",
      " — train_f1=0.7434 | val_f1=0.5113 | test_f1=0.5113 | mixed_f1=0.5113\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7418 - loss: 0.9522 - val_accuracy: 0.5779 - val_loss: 1.2803 - train_f1_macro: 0.7434 - val_f1_macro: 0.5113 - test_f1_macro: 0.5113 - mixed_f1_macro: 0.5113\n",
      "Epoch 81/500\n",
      " — train_f1=0.6860 | val_f1=0.4569 | test_f1=0.4569 | mixed_f1=0.4569\n",
      "37/37 - 6s - 157ms/step - accuracy: 0.7550 - loss: 0.9442 - val_accuracy: 0.5156 - val_loss: 1.4031 - train_f1_macro: 0.6860 - val_f1_macro: 0.4569 - test_f1_macro: 0.4569 - mixed_f1_macro: 0.4569\n",
      "Epoch 82/500\n",
      " — train_f1=0.6896 | val_f1=0.4341 | test_f1=0.4341 | mixed_f1=0.4341\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.7507 - loss: 0.9657 - val_accuracy: 0.4637 - val_loss: 1.4604 - train_f1_macro: 0.6896 - val_f1_macro: 0.4341 - test_f1_macro: 0.4341 - mixed_f1_macro: 0.4341\n",
      "Epoch 83/500\n",
      " — train_f1=0.7644 | val_f1=0.4483 | test_f1=0.4483 | mixed_f1=0.4483\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7713 - loss: 0.9211 - val_accuracy: 0.5017 - val_loss: 1.4536 - train_f1_macro: 0.7644 - val_f1_macro: 0.4483 - test_f1_macro: 0.4483 - mixed_f1_macro: 0.4483\n",
      "Epoch 84/500\n",
      " — train_f1=0.5930 | val_f1=0.4172 | test_f1=0.4172 | mixed_f1=0.4172\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7529 - loss: 0.9467 - val_accuracy: 0.4256 - val_loss: 1.5136 - train_f1_macro: 0.5930 - val_f1_macro: 0.4172 - test_f1_macro: 0.4172 - mixed_f1_macro: 0.4172\n",
      "Epoch 85/500\n",
      " — train_f1=0.7895 | val_f1=0.5075 | test_f1=0.5075 | mixed_f1=0.5075\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7602 - loss: 0.9276 - val_accuracy: 0.5502 - val_loss: 1.3048 - train_f1_macro: 0.7895 - val_f1_macro: 0.5075 - test_f1_macro: 0.5075 - mixed_f1_macro: 0.5075\n",
      "Epoch 86/500\n",
      " — train_f1=0.7649 | val_f1=0.4941 | test_f1=0.4941 | mixed_f1=0.4941\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7589 - loss: 0.9421 - val_accuracy: 0.5640 - val_loss: 1.3408 - train_f1_macro: 0.7649 - val_f1_macro: 0.4941 - test_f1_macro: 0.4941 - mixed_f1_macro: 0.4941\n",
      "Epoch 87/500\n",
      " — train_f1=0.7461 | val_f1=0.4459 | test_f1=0.4459 | mixed_f1=0.4459\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7708 - loss: 0.9009 - val_accuracy: 0.4775 - val_loss: 1.4597 - train_f1_macro: 0.7461 - val_f1_macro: 0.4459 - test_f1_macro: 0.4459 - mixed_f1_macro: 0.4459\n",
      "Epoch 88/500\n",
      " — train_f1=0.6675 | val_f1=0.4344 | test_f1=0.4344 | mixed_f1=0.4344\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7738 - loss: 0.9261 - val_accuracy: 0.4567 - val_loss: 1.6686 - train_f1_macro: 0.6675 - val_f1_macro: 0.4344 - test_f1_macro: 0.4344 - mixed_f1_macro: 0.4344\n",
      "Epoch 89/500\n",
      " — train_f1=0.5505 | val_f1=0.3412 | test_f1=0.3412 | mixed_f1=0.3412\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7713 - loss: 0.9167 - val_accuracy: 0.3460 - val_loss: 1.6545 - train_f1_macro: 0.5505 - val_f1_macro: 0.3412 - test_f1_macro: 0.3412 - mixed_f1_macro: 0.3412\n",
      "Epoch 90/500\n",
      " — train_f1=0.4309 | val_f1=0.3220 | test_f1=0.3220 | mixed_f1=0.3220\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7700 - loss: 0.9312 - val_accuracy: 0.2941 - val_loss: 1.8690 - train_f1_macro: 0.4309 - val_f1_macro: 0.3220 - test_f1_macro: 0.3220 - mixed_f1_macro: 0.3220\n",
      "Epoch 91/500\n",
      " — train_f1=0.7876 | val_f1=0.4627 | test_f1=0.4627 | mixed_f1=0.4627\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7798 - loss: 0.9057 - val_accuracy: 0.5121 - val_loss: 1.3988 - train_f1_macro: 0.7876 - val_f1_macro: 0.4627 - test_f1_macro: 0.4627 - mixed_f1_macro: 0.4627\n",
      "Epoch 92/500\n",
      " — train_f1=0.6959 | val_f1=0.4221 | test_f1=0.4221 | mixed_f1=0.4221\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.7683 - loss: 0.9146 - val_accuracy: 0.4291 - val_loss: 1.4830 - train_f1_macro: 0.6959 - val_f1_macro: 0.4221 - test_f1_macro: 0.4221 - mixed_f1_macro: 0.4221\n",
      "Epoch 93/500\n",
      " — train_f1=0.5882 | val_f1=0.4050 | test_f1=0.4050 | mixed_f1=0.4050\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.7832 - loss: 0.9099 - val_accuracy: 0.3702 - val_loss: 1.6964 - train_f1_macro: 0.5882 - val_f1_macro: 0.4050 - test_f1_macro: 0.4050 - mixed_f1_macro: 0.4050\n",
      "Epoch 94/500\n",
      " — train_f1=0.7245 | val_f1=0.4346 | test_f1=0.4346 | mixed_f1=0.4346\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7623 - loss: 0.9122 - val_accuracy: 0.4291 - val_loss: 1.5771 - train_f1_macro: 0.7245 - val_f1_macro: 0.4346 - test_f1_macro: 0.4346 - mixed_f1_macro: 0.4346\n",
      "Epoch 95/500\n",
      " — train_f1=0.6747 | val_f1=0.4082 | test_f1=0.4082 | mixed_f1=0.4082\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7845 - loss: 0.8869 - val_accuracy: 0.4048 - val_loss: 1.6149 - train_f1_macro: 0.6747 - val_f1_macro: 0.4082 - test_f1_macro: 0.4082 - mixed_f1_macro: 0.4082\n",
      "Epoch 96/500\n",
      " — train_f1=0.8134 | val_f1=0.4836 | test_f1=0.4836 | mixed_f1=0.4836\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7785 - loss: 0.9036 - val_accuracy: 0.4983 - val_loss: 1.4354 - train_f1_macro: 0.8134 - val_f1_macro: 0.4836 - test_f1_macro: 0.4836 - mixed_f1_macro: 0.4836\n",
      "Epoch 97/500\n",
      " — train_f1=0.7998 | val_f1=0.5049 | test_f1=0.5049 | mixed_f1=0.5049\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7867 - loss: 0.8922 - val_accuracy: 0.5709 - val_loss: 1.3184 - train_f1_macro: 0.7998 - val_f1_macro: 0.5049 - test_f1_macro: 0.5049 - mixed_f1_macro: 0.5049\n",
      "Epoch 98/500\n",
      " — train_f1=0.7227 | val_f1=0.4362 | test_f1=0.4362 | mixed_f1=0.4362\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.7802 - loss: 0.8908 - val_accuracy: 0.4187 - val_loss: 1.5765 - train_f1_macro: 0.7227 - val_f1_macro: 0.4362 - test_f1_macro: 0.4362 - mixed_f1_macro: 0.4362\n",
      "Epoch 99/500\n",
      " — train_f1=0.6673 | val_f1=0.4533 | test_f1=0.4533 | mixed_f1=0.4533\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7811 - loss: 0.8925 - val_accuracy: 0.5606 - val_loss: 1.3686 - train_f1_macro: 0.6673 - val_f1_macro: 0.4533 - test_f1_macro: 0.4533 - mixed_f1_macro: 0.4533\n",
      "Epoch 100/500\n",
      " — train_f1=0.7369 | val_f1=0.4934 | test_f1=0.4934 | mixed_f1=0.4934\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.7867 - loss: 0.9033 - val_accuracy: 0.5709 - val_loss: 1.2442 - train_f1_macro: 0.7369 - val_f1_macro: 0.4934 - test_f1_macro: 0.4934 - mixed_f1_macro: 0.4934\n",
      "Epoch 101/500\n",
      " — train_f1=0.5665 | val_f1=0.3400 | test_f1=0.3400 | mixed_f1=0.3400\n",
      "37/37 - 10s - 274ms/step - accuracy: 0.7961 - loss: 0.8748 - val_accuracy: 0.3426 - val_loss: 1.7502 - train_f1_macro: 0.5665 - val_f1_macro: 0.3400 - test_f1_macro: 0.3400 - mixed_f1_macro: 0.3400\n",
      "Epoch 102/500\n",
      " — train_f1=0.7181 | val_f1=0.4754 | test_f1=0.4754 | mixed_f1=0.4754\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7969 - loss: 0.8677 - val_accuracy: 0.4498 - val_loss: 1.5925 - train_f1_macro: 0.7181 - val_f1_macro: 0.4754 - test_f1_macro: 0.4754 - mixed_f1_macro: 0.4754\n",
      "Epoch 103/500\n",
      " — train_f1=0.6896 | val_f1=0.4136 | test_f1=0.4136 | mixed_f1=0.4136\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7969 - loss: 0.8780 - val_accuracy: 0.3979 - val_loss: 1.5809 - train_f1_macro: 0.6896 - val_f1_macro: 0.4136 - test_f1_macro: 0.4136 - mixed_f1_macro: 0.4136\n",
      "\n",
      "Fold 1 FINAL (Mixed Test): ACC=0.6228 F1w=0.6122 MCC=0.4696\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 2  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2346, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (282, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (282, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5380733944954128, 1: 0.7023952095808383, 2: 0.8217162872154116, 3: 4.385046728971963, 4: 3.665625}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768197034.137932 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_2_1/dropout_10_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0965 | val_f1=0.1026 | test_f1=0.1026 | mixed_f1=0.1026\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.1026\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch1_f10.1026_20260112_005041.h5\n",
      "37/37 - 10s - 264ms/step - accuracy: 0.2400 - loss: 1.9365 - val_accuracy: 0.2057 - val_loss: 1.8397 - train_f1_macro: 0.0965 - val_f1_macro: 0.1026 - test_f1_macro: 0.1026 - mixed_f1_macro: 0.1026\n",
      "Epoch 2/500\n",
      " — train_f1=0.0225 | val_f1=0.0393 | test_f1=0.0393 | mixed_f1=0.0393\n",
      "37/37 - 8s - 205ms/step - accuracy: 0.2298 - loss: 1.8401 - val_accuracy: 0.0922 - val_loss: 1.8894 - train_f1_macro: 0.0225 - val_f1_macro: 0.0393 - test_f1_macro: 0.0393 - mixed_f1_macro: 0.0393\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1268 | val_f1=0.1381 | test_f1=0.1381 | mixed_f1=0.1381\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.1381\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch3_f10.1381_20260112_005054.h5\n",
      "37/37 - 5s - 142ms/step - accuracy: 0.3043 - loss: 1.7420 - val_accuracy: 0.1844 - val_loss: 1.8570 - train_f1_macro: 0.1268 - val_f1_macro: 0.1381 - test_f1_macro: 0.1381 - mixed_f1_macro: 0.1381\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2675 | val_f1=0.2806 | test_f1=0.2806 | mixed_f1=0.2806\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.2806\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch4_f10.2806_20260112_005059.h5\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.3355 - loss: 1.6019 - val_accuracy: 0.3440 - val_loss: 1.6140 - train_f1_macro: 0.2675 - val_f1_macro: 0.2806 - test_f1_macro: 0.2806 - mixed_f1_macro: 0.2806\n",
      "Epoch 5/500\n",
      " — train_f1=0.2131 | val_f1=0.1691 | test_f1=0.1691 | mixed_f1=0.1691\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3321 - loss: 1.5342 - val_accuracy: 0.1702 - val_loss: 1.9680 - train_f1_macro: 0.2131 - val_f1_macro: 0.1691 - test_f1_macro: 0.1691 - mixed_f1_macro: 0.1691\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3137 | val_f1=0.3226 | test_f1=0.3226 | mixed_f1=0.3226\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 6 | f1=0.3226\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch6_f10.3226_20260112_005110.h5\n",
      "37/37 - 6s - 158ms/step - accuracy: 0.3474 - loss: 1.5065 - val_accuracy: 0.3688 - val_loss: 1.6508 - train_f1_macro: 0.3137 - val_f1_macro: 0.3226 - test_f1_macro: 0.3226 - mixed_f1_macro: 0.3226\n",
      "Epoch 7/500\n",
      " — train_f1=0.2728 | val_f1=0.2132 | test_f1=0.2132 | mixed_f1=0.2132\n",
      "37/37 - 10s - 257ms/step - accuracy: 0.3589 - loss: 1.4700 - val_accuracy: 0.1809 - val_loss: 1.4945 - train_f1_macro: 0.2728 - val_f1_macro: 0.2132 - test_f1_macro: 0.2132 - mixed_f1_macro: 0.2132\n",
      "Epoch 8/500\n",
      " — train_f1=0.3069 | val_f1=0.2618 | test_f1=0.2618 | mixed_f1=0.2618\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3521 - loss: 1.4462 - val_accuracy: 0.3688 - val_loss: 1.4775 - train_f1_macro: 0.3069 - val_f1_macro: 0.2618 - test_f1_macro: 0.2618 - mixed_f1_macro: 0.2618\n",
      "Epoch 9/500\n",
      " — train_f1=0.2215 | val_f1=0.2579 | test_f1=0.2579 | mixed_f1=0.2579\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3713 - loss: 1.4253 - val_accuracy: 0.3298 - val_loss: 1.9132 - train_f1_macro: 0.2215 - val_f1_macro: 0.2579 - test_f1_macro: 0.2579 - mixed_f1_macro: 0.2579\n",
      "Epoch 10/500\n",
      " — train_f1=0.2765 | val_f1=0.3221 | test_f1=0.3221 | mixed_f1=0.3221\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.3640 - loss: 1.4061 - val_accuracy: 0.5319 - val_loss: 1.4806 - train_f1_macro: 0.2765 - val_f1_macro: 0.3221 - test_f1_macro: 0.3221 - mixed_f1_macro: 0.3221\n",
      "Epoch 11/500\n",
      " — train_f1=0.3155 | val_f1=0.2462 | test_f1=0.2462 | mixed_f1=0.2462\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.3576 - loss: 1.4067 - val_accuracy: 0.3404 - val_loss: 1.4534 - train_f1_macro: 0.3155 - val_f1_macro: 0.2462 - test_f1_macro: 0.2462 - mixed_f1_macro: 0.2462\n",
      "Epoch 12/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2998 | val_f1=0.3253 | test_f1=0.3253 | mixed_f1=0.3253\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 12 | f1=0.3253\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch12_f10.3253_20260112_005151.h5\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.3436 - loss: 1.3990 - val_accuracy: 0.4787 - val_loss: 1.5838 - train_f1_macro: 0.2998 - val_f1_macro: 0.3253 - test_f1_macro: 0.3253 - mixed_f1_macro: 0.3253\n",
      "Epoch 13/500\n",
      " — train_f1=0.2916 | val_f1=0.3004 | test_f1=0.3004 | mixed_f1=0.3004\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.3815 - loss: 1.3665 - val_accuracy: 0.4397 - val_loss: 1.5714 - train_f1_macro: 0.2916 - val_f1_macro: 0.3004 - test_f1_macro: 0.3004 - mixed_f1_macro: 0.3004\n",
      "Epoch 14/500\n",
      " — train_f1=0.3576 | val_f1=0.2781 | test_f1=0.2781 | mixed_f1=0.2781\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.3704 - loss: 1.3593 - val_accuracy: 0.3794 - val_loss: 1.4279 - train_f1_macro: 0.3576 - val_f1_macro: 0.2781 - test_f1_macro: 0.2781 - mixed_f1_macro: 0.2781\n",
      "Epoch 15/500\n",
      " — train_f1=0.3066 | val_f1=0.2193 | test_f1=0.2193 | mixed_f1=0.2193\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.3674 - loss: 1.3605 - val_accuracy: 0.2660 - val_loss: 1.4198 - train_f1_macro: 0.3066 - val_f1_macro: 0.2193 - test_f1_macro: 0.2193 - mixed_f1_macro: 0.2193\n",
      "Epoch 16/500\n",
      " — train_f1=0.3267 | val_f1=0.2750 | test_f1=0.2750 | mixed_f1=0.2750\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3892 - loss: 1.3345 - val_accuracy: 0.3156 - val_loss: 1.4875 - train_f1_macro: 0.3267 - val_f1_macro: 0.2750 - test_f1_macro: 0.2750 - mixed_f1_macro: 0.2750\n",
      "Epoch 17/500\n",
      " — train_f1=0.2305 | val_f1=0.1478 | test_f1=0.1478 | mixed_f1=0.1478\n",
      "37/37 - 11s - 291ms/step - accuracy: 0.3845 - loss: 1.3271 - val_accuracy: 0.1738 - val_loss: 1.5553 - train_f1_macro: 0.2305 - val_f1_macro: 0.1478 - test_f1_macro: 0.1478 - mixed_f1_macro: 0.1478\n",
      "Epoch 18/500\n",
      " — train_f1=0.3886 | val_f1=0.3157 | test_f1=0.3157 | mixed_f1=0.3157\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.4062 - loss: 1.3327 - val_accuracy: 0.2695 - val_loss: 1.4588 - train_f1_macro: 0.3886 - val_f1_macro: 0.3157 - test_f1_macro: 0.3157 - mixed_f1_macro: 0.3157\n",
      "Epoch 19/500\n",
      " — train_f1=0.4088 | val_f1=0.2940 | test_f1=0.2940 | mixed_f1=0.2940\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.4071 - loss: 1.3199 - val_accuracy: 0.3652 - val_loss: 1.4148 - train_f1_macro: 0.4088 - val_f1_macro: 0.2940 - test_f1_macro: 0.2940 - mixed_f1_macro: 0.2940\n",
      "Epoch 20/500\n",
      " — train_f1=0.3894 | val_f1=0.2370 | test_f1=0.2370 | mixed_f1=0.2370\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.4135 - loss: 1.3183 - val_accuracy: 0.2021 - val_loss: 1.4400 - train_f1_macro: 0.3894 - val_f1_macro: 0.2370 - test_f1_macro: 0.2370 - mixed_f1_macro: 0.2370\n",
      "Epoch 21/500\n",
      " — train_f1=0.3704 | val_f1=0.2236 | test_f1=0.2236 | mixed_f1=0.2236\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4105 - loss: 1.2999 - val_accuracy: 0.2589 - val_loss: 1.4003 - train_f1_macro: 0.3704 - val_f1_macro: 0.2236 - test_f1_macro: 0.2236 - mixed_f1_macro: 0.2236\n",
      "Epoch 22/500\n",
      " — train_f1=0.3722 | val_f1=0.2116 | test_f1=0.2116 | mixed_f1=0.2116\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4339 - loss: 1.2954 - val_accuracy: 0.2234 - val_loss: 1.4430 - train_f1_macro: 0.3722 - val_f1_macro: 0.2116 - test_f1_macro: 0.2116 - mixed_f1_macro: 0.2116\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4883 | val_f1=0.3325 | test_f1=0.3325 | mixed_f1=0.3325\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 23 | f1=0.3325\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch23_f10.3325_20260112_005308.h5\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.4344 - loss: 1.2834 - val_accuracy: 0.3014 - val_loss: 1.3929 - train_f1_macro: 0.4883 - val_f1_macro: 0.3325 - test_f1_macro: 0.3325 - mixed_f1_macro: 0.3325\n",
      "Epoch 24/500\n",
      " — train_f1=0.3873 | val_f1=0.2355 | test_f1=0.2355 | mixed_f1=0.2355\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.4459 - loss: 1.2799 - val_accuracy: 0.2163 - val_loss: 1.4728 - train_f1_macro: 0.3873 - val_f1_macro: 0.2355 - test_f1_macro: 0.2355 - mixed_f1_macro: 0.2355\n",
      "Epoch 25/500\n",
      " — train_f1=0.3398 | val_f1=0.2421 | test_f1=0.2421 | mixed_f1=0.2421\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.4450 - loss: 1.2814 - val_accuracy: 0.3191 - val_loss: 1.4146 - train_f1_macro: 0.3398 - val_f1_macro: 0.2421 - test_f1_macro: 0.2421 - mixed_f1_macro: 0.2421\n",
      "Epoch 26/500\n",
      " — train_f1=0.3829 | val_f1=0.2682 | test_f1=0.2682 | mixed_f1=0.2682\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.4442 - loss: 1.2790 - val_accuracy: 0.2234 - val_loss: 1.5740 - train_f1_macro: 0.3829 - val_f1_macro: 0.2682 - test_f1_macro: 0.2682 - mixed_f1_macro: 0.2682\n",
      "Epoch 27/500\n",
      " — train_f1=0.3549 | val_f1=0.2340 | test_f1=0.2340 | mixed_f1=0.2340\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4476 - loss: 1.2606 - val_accuracy: 0.2128 - val_loss: 1.4381 - train_f1_macro: 0.3549 - val_f1_macro: 0.2340 - test_f1_macro: 0.2340 - mixed_f1_macro: 0.2340\n",
      "Epoch 28/500\n",
      " — train_f1=0.4085 | val_f1=0.2774 | test_f1=0.2774 | mixed_f1=0.2774\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.4450 - loss: 1.2566 - val_accuracy: 0.3617 - val_loss: 1.4085 - train_f1_macro: 0.4085 - val_f1_macro: 0.2774 - test_f1_macro: 0.2774 - mixed_f1_macro: 0.2774\n",
      "Epoch 29/500\n",
      " — train_f1=0.3823 | val_f1=0.2861 | test_f1=0.2861 | mixed_f1=0.2861\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4599 - loss: 1.2722 - val_accuracy: 0.4007 - val_loss: 1.3852 - train_f1_macro: 0.3823 - val_f1_macro: 0.2861 - test_f1_macro: 0.2861 - mixed_f1_macro: 0.2861\n",
      "Epoch 30/500\n",
      " — train_f1=0.3529 | val_f1=0.2312 | test_f1=0.2312 | mixed_f1=0.2312\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.4655 - loss: 1.2518 - val_accuracy: 0.2092 - val_loss: 1.4875 - train_f1_macro: 0.3529 - val_f1_macro: 0.2312 - test_f1_macro: 0.2312 - mixed_f1_macro: 0.2312\n",
      "Epoch 31/500\n",
      " — train_f1=0.4208 | val_f1=0.3178 | test_f1=0.3178 | mixed_f1=0.3178\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.4847 - loss: 1.2380 - val_accuracy: 0.3475 - val_loss: 1.3736 - train_f1_macro: 0.4208 - val_f1_macro: 0.3178 - test_f1_macro: 0.3178 - mixed_f1_macro: 0.3178\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4996 | val_f1=0.3597 | test_f1=0.3597 | mixed_f1=0.3597\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 32 | f1=0.3597\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch32_f10.3597_20260112_005414.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4983 - loss: 1.2383 - val_accuracy: 0.4184 - val_loss: 1.3532 - train_f1_macro: 0.4996 - val_f1_macro: 0.3597 - test_f1_macro: 0.3597 - mixed_f1_macro: 0.3597\n",
      "Epoch 33/500\n",
      " — train_f1=0.3259 | val_f1=0.3499 | test_f1=0.3499 | mixed_f1=0.3499\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.5060 - loss: 1.2298 - val_accuracy: 0.5142 - val_loss: 1.3297 - train_f1_macro: 0.3259 - val_f1_macro: 0.3499 - test_f1_macro: 0.3499 - mixed_f1_macro: 0.3499\n",
      "Epoch 34/500\n",
      " — train_f1=0.4522 | val_f1=0.2812 | test_f1=0.2812 | mixed_f1=0.2812\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5128 - loss: 1.2149 - val_accuracy: 0.3475 - val_loss: 1.3837 - train_f1_macro: 0.4522 - val_f1_macro: 0.2812 - test_f1_macro: 0.2812 - mixed_f1_macro: 0.2812\n",
      "Epoch 35/500\n",
      " — train_f1=0.4641 | val_f1=0.2643 | test_f1=0.2643 | mixed_f1=0.2643\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.5081 - loss: 1.2111 - val_accuracy: 0.3298 - val_loss: 1.4282 - train_f1_macro: 0.4641 - val_f1_macro: 0.2643 - test_f1_macro: 0.2643 - mixed_f1_macro: 0.2643\n",
      "Epoch 36/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3707 | val_f1=0.3603 | test_f1=0.3603 | mixed_f1=0.3603\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 36 | f1=0.3603\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch36_f10.3603_20260112_005445.h5\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.5260 - loss: 1.2100 - val_accuracy: 0.4043 - val_loss: 1.3767 - train_f1_macro: 0.3707 - val_f1_macro: 0.3603 - test_f1_macro: 0.3603 - mixed_f1_macro: 0.3603\n",
      "Epoch 37/500\n",
      " — train_f1=0.4665 | val_f1=0.3038 | test_f1=0.3038 | mixed_f1=0.3038\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5247 - loss: 1.1961 - val_accuracy: 0.4397 - val_loss: 1.3279 - train_f1_macro: 0.4665 - val_f1_macro: 0.3038 - test_f1_macro: 0.3038 - mixed_f1_macro: 0.3038\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5351 | val_f1=0.3743 | test_f1=0.3743 | mixed_f1=0.3743\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 38 | f1=0.3743\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch38_f10.3743_20260112_005455.h5\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.5226 - loss: 1.2217 - val_accuracy: 0.3440 - val_loss: 1.4685 - train_f1_macro: 0.5351 - val_f1_macro: 0.3743 - test_f1_macro: 0.3743 - mixed_f1_macro: 0.3743\n",
      "Epoch 39/500\n",
      " — train_f1=0.3595 | val_f1=0.2452 | test_f1=0.2452 | mixed_f1=0.2452\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.5465 - loss: 1.1974 - val_accuracy: 0.2305 - val_loss: 1.6841 - train_f1_macro: 0.3595 - val_f1_macro: 0.2452 - test_f1_macro: 0.2452 - mixed_f1_macro: 0.2452\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4472 | val_f1=0.3887 | test_f1=0.3887 | mixed_f1=0.3887\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 40 | f1=0.3887\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch40_f10.3887_20260112_005511.h5\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.5554 - loss: 1.1886 - val_accuracy: 0.4433 - val_loss: 1.3458 - train_f1_macro: 0.4472 - val_f1_macro: 0.3887 - test_f1_macro: 0.3887 - mixed_f1_macro: 0.3887\n",
      "Epoch 41/500\n",
      " — train_f1=0.1327 | val_f1=0.1517 | test_f1=0.1517 | mixed_f1=0.1517\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.5635 - loss: 1.1846 - val_accuracy: 0.1950 - val_loss: 2.0474 - train_f1_macro: 0.1327 - val_f1_macro: 0.1517 - test_f1_macro: 0.1517 - mixed_f1_macro: 0.1517\n",
      "Epoch 42/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4905 | val_f1=0.4290 | test_f1=0.4290 | mixed_f1=0.4290\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 42 | f1=0.4290\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch42_f10.4290_20260112_005526.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5546 - loss: 1.1741 - val_accuracy: 0.5284 - val_loss: 1.2667 - train_f1_macro: 0.4905 - val_f1_macro: 0.4290 - test_f1_macro: 0.4290 - mixed_f1_macro: 0.4290\n",
      "Epoch 43/500\n",
      " — train_f1=0.4189 | val_f1=0.4288 | test_f1=0.4288 | mixed_f1=0.4288\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.5610 - loss: 1.1692 - val_accuracy: 0.5355 - val_loss: 1.3014 - train_f1_macro: 0.4189 - val_f1_macro: 0.4288 - test_f1_macro: 0.4288 - mixed_f1_macro: 0.4288\n",
      "Epoch 44/500\n",
      " — train_f1=0.6058 | val_f1=0.3905 | test_f1=0.3905 | mixed_f1=0.3905\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.5759 - loss: 1.1584 - val_accuracy: 0.3901 - val_loss: 1.3799 - train_f1_macro: 0.6058 - val_f1_macro: 0.3905 - test_f1_macro: 0.3905 - mixed_f1_macro: 0.3905\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5807 | val_f1=0.5026 | test_f1=0.5026 | mixed_f1=0.5026\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 45 | f1=0.5026\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch45_f10.5026_20260112_005547.h5\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5656 - loss: 1.1606 - val_accuracy: 0.5851 - val_loss: 1.2395 - train_f1_macro: 0.5807 - val_f1_macro: 0.5026 - test_f1_macro: 0.5026 - mixed_f1_macro: 0.5026\n",
      "Epoch 46/500\n",
      " — train_f1=0.4676 | val_f1=0.3875 | test_f1=0.3875 | mixed_f1=0.3875\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.5746 - loss: 1.1584 - val_accuracy: 0.4504 - val_loss: 1.3340 - train_f1_macro: 0.4676 - val_f1_macro: 0.3875 - test_f1_macro: 0.3875 - mixed_f1_macro: 0.3875\n",
      "Epoch 47/500\n",
      " — train_f1=0.4955 | val_f1=0.3233 | test_f1=0.3233 | mixed_f1=0.3233\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.5831 - loss: 1.1453 - val_accuracy: 0.3759 - val_loss: 1.3767 - train_f1_macro: 0.4955 - val_f1_macro: 0.3233 - test_f1_macro: 0.3233 - mixed_f1_macro: 0.3233\n",
      "Epoch 48/500\n",
      " — train_f1=0.5888 | val_f1=0.3757 | test_f1=0.3757 | mixed_f1=0.3757\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5848 - loss: 1.1478 - val_accuracy: 0.3617 - val_loss: 1.4768 - train_f1_macro: 0.5888 - val_f1_macro: 0.3757 - test_f1_macro: 0.3757 - mixed_f1_macro: 0.3757\n",
      "Epoch 49/500\n",
      " — train_f1=0.6130 | val_f1=0.3882 | test_f1=0.3882 | mixed_f1=0.3882\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.6027 - loss: 1.1214 - val_accuracy: 0.4610 - val_loss: 1.3232 - train_f1_macro: 0.6130 - val_f1_macro: 0.3882 - test_f1_macro: 0.3882 - mixed_f1_macro: 0.3882\n",
      "Epoch 50/500\n",
      " — train_f1=0.5619 | val_f1=0.4172 | test_f1=0.4172 | mixed_f1=0.4172\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6083 - loss: 1.1095 - val_accuracy: 0.4645 - val_loss: 1.3097 - train_f1_macro: 0.5619 - val_f1_macro: 0.4172 - test_f1_macro: 0.4172 - mixed_f1_macro: 0.4172\n",
      "Epoch 51/500\n",
      " — train_f1=0.6524 | val_f1=0.4519 | test_f1=0.4519 | mixed_f1=0.4519\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6061 - loss: 1.1108 - val_accuracy: 0.5177 - val_loss: 1.2789 - train_f1_macro: 0.6524 - val_f1_macro: 0.4519 - test_f1_macro: 0.4519 - mixed_f1_macro: 0.4519\n",
      "Epoch 52/500\n",
      " — train_f1=0.5867 | val_f1=0.4062 | test_f1=0.4062 | mixed_f1=0.4062\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.6091 - loss: 1.1120 - val_accuracy: 0.4468 - val_loss: 1.3450 - train_f1_macro: 0.5867 - val_f1_macro: 0.4062 - test_f1_macro: 0.4062 - mixed_f1_macro: 0.4062\n",
      "Epoch 53/500\n",
      " — train_f1=0.2069 | val_f1=0.1983 | test_f1=0.1983 | mixed_f1=0.1983\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.6292 - loss: 1.1005 - val_accuracy: 0.2553 - val_loss: 1.6855 - train_f1_macro: 0.2069 - val_f1_macro: 0.1983 - test_f1_macro: 0.1983 - mixed_f1_macro: 0.1983\n",
      "Epoch 54/500\n",
      " — train_f1=0.6608 | val_f1=0.4708 | test_f1=0.4708 | mixed_f1=0.4708\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6176 - loss: 1.0988 - val_accuracy: 0.5071 - val_loss: 1.2753 - train_f1_macro: 0.6608 - val_f1_macro: 0.4708 - test_f1_macro: 0.4708 - mixed_f1_macro: 0.4708\n",
      "Epoch 55/500\n",
      " — train_f1=0.6714 | val_f1=0.4339 | test_f1=0.4339 | mixed_f1=0.4339\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6326 - loss: 1.0753 - val_accuracy: 0.4291 - val_loss: 1.3457 - train_f1_macro: 0.6714 - val_f1_macro: 0.4339 - test_f1_macro: 0.4339 - mixed_f1_macro: 0.4339\n",
      "Epoch 56/500\n",
      " — train_f1=0.4217 | val_f1=0.3313 | test_f1=0.3313 | mixed_f1=0.3313\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6381 - loss: 1.0688 - val_accuracy: 0.4078 - val_loss: 1.3506 - train_f1_macro: 0.4217 - val_f1_macro: 0.3313 - test_f1_macro: 0.3313 - mixed_f1_macro: 0.3313\n",
      "Epoch 57/500\n",
      " — train_f1=0.5809 | val_f1=0.4116 | test_f1=0.4116 | mixed_f1=0.4116\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6321 - loss: 1.0670 - val_accuracy: 0.4433 - val_loss: 1.4362 - train_f1_macro: 0.5809 - val_f1_macro: 0.4116 - test_f1_macro: 0.4116 - mixed_f1_macro: 0.4116\n",
      "Epoch 58/500\n",
      " — train_f1=0.6142 | val_f1=0.3703 | test_f1=0.3703 | mixed_f1=0.3703\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6398 - loss: 1.0893 - val_accuracy: 0.3723 - val_loss: 1.4754 - train_f1_macro: 0.6142 - val_f1_macro: 0.3703 - test_f1_macro: 0.3703 - mixed_f1_macro: 0.3703\n",
      "Epoch 59/500\n",
      " — train_f1=0.5435 | val_f1=0.3841 | test_f1=0.3841 | mixed_f1=0.3841\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6513 - loss: 1.0558 - val_accuracy: 0.3652 - val_loss: 1.5366 - train_f1_macro: 0.5435 - val_f1_macro: 0.3841 - test_f1_macro: 0.3841 - mixed_f1_macro: 0.3841\n",
      "Epoch 60/500\n",
      " — train_f1=0.6128 | val_f1=0.4177 | test_f1=0.4177 | mixed_f1=0.4177\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6577 - loss: 1.0707 - val_accuracy: 0.5035 - val_loss: 1.3343 - train_f1_macro: 0.6128 - val_f1_macro: 0.4177 - test_f1_macro: 0.4177 - mixed_f1_macro: 0.4177\n",
      "Epoch 61/500\n",
      " — train_f1=0.4837 | val_f1=0.4471 | test_f1=0.4471 | mixed_f1=0.4471\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.6535 - loss: 1.0747 - val_accuracy: 0.5071 - val_loss: 1.2934 - train_f1_macro: 0.4837 - val_f1_macro: 0.4471 - test_f1_macro: 0.4471 - mixed_f1_macro: 0.4471\n",
      "Epoch 62/500\n",
      " — train_f1=0.4284 | val_f1=0.3910 | test_f1=0.3910 | mixed_f1=0.3910\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.6637 - loss: 1.0496 - val_accuracy: 0.4610 - val_loss: 1.3988 - train_f1_macro: 0.4284 - val_f1_macro: 0.3910 - test_f1_macro: 0.3910 - mixed_f1_macro: 0.3910\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7251 | val_f1=0.5273 | test_f1=0.5273 | mixed_f1=0.5273\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 63 | f1=0.5273\n",
      "   → saved_models/merged_fold_2/best_val_f1_macro_epoch63_f10.5273_20260112_005734.h5\n",
      "37/37 - 10s - 265ms/step - accuracy: 0.6662 - loss: 1.0509 - val_accuracy: 0.5709 - val_loss: 1.2238 - train_f1_macro: 0.7251 - val_f1_macro: 0.5273 - test_f1_macro: 0.5273 - mixed_f1_macro: 0.5273\n",
      "Epoch 64/500\n",
      " — train_f1=0.3201 | val_f1=0.3085 | test_f1=0.3085 | mixed_f1=0.3085\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6841 - loss: 1.0398 - val_accuracy: 0.3191 - val_loss: 1.6187 - train_f1_macro: 0.3201 - val_f1_macro: 0.3085 - test_f1_macro: 0.3085 - mixed_f1_macro: 0.3085\n",
      "Epoch 65/500\n",
      " — train_f1=0.6937 | val_f1=0.4674 | test_f1=0.4674 | mixed_f1=0.4674\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6807 - loss: 1.0462 - val_accuracy: 0.4894 - val_loss: 1.3451 - train_f1_macro: 0.6937 - val_f1_macro: 0.4674 - test_f1_macro: 0.4674 - mixed_f1_macro: 0.4674\n",
      "Epoch 66/500\n",
      " — train_f1=0.4647 | val_f1=0.3591 | test_f1=0.3591 | mixed_f1=0.3591\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.6965 - loss: 1.0116 - val_accuracy: 0.3440 - val_loss: 1.7764 - train_f1_macro: 0.4647 - val_f1_macro: 0.3591 - test_f1_macro: 0.3591 - mixed_f1_macro: 0.3591\n",
      "Epoch 67/500\n",
      " — train_f1=0.7064 | val_f1=0.4677 | test_f1=0.4677 | mixed_f1=0.4677\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.6922 - loss: 1.0167 - val_accuracy: 0.4929 - val_loss: 1.3161 - train_f1_macro: 0.7064 - val_f1_macro: 0.4677 - test_f1_macro: 0.4677 - mixed_f1_macro: 0.4677\n",
      "Epoch 68/500\n",
      " — train_f1=0.6681 | val_f1=0.4576 | test_f1=0.4576 | mixed_f1=0.4576\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.7042 - loss: 1.0074 - val_accuracy: 0.4645 - val_loss: 1.3808 - train_f1_macro: 0.6681 - val_f1_macro: 0.4576 - test_f1_macro: 0.4576 - mixed_f1_macro: 0.4576\n",
      "Epoch 69/500\n",
      " — train_f1=0.4571 | val_f1=0.4082 | test_f1=0.4082 | mixed_f1=0.4082\n",
      "37/37 - 10s - 280ms/step - accuracy: 0.6841 - loss: 1.0165 - val_accuracy: 0.4539 - val_loss: 1.4115 - train_f1_macro: 0.4571 - val_f1_macro: 0.4082 - test_f1_macro: 0.4082 - mixed_f1_macro: 0.4082\n",
      "Epoch 70/500\n",
      " — train_f1=0.5495 | val_f1=0.4232 | test_f1=0.4232 | mixed_f1=0.4232\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.7114 - loss: 1.0049 - val_accuracy: 0.4574 - val_loss: 1.3898 - train_f1_macro: 0.5495 - val_f1_macro: 0.4232 - test_f1_macro: 0.4232 - mixed_f1_macro: 0.4232\n",
      "Epoch 71/500\n",
      " — train_f1=0.6955 | val_f1=0.4733 | test_f1=0.4733 | mixed_f1=0.4733\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7234 - loss: 0.9836 - val_accuracy: 0.5000 - val_loss: 1.3906 - train_f1_macro: 0.6955 - val_f1_macro: 0.4733 - test_f1_macro: 0.4733 - mixed_f1_macro: 0.4733\n",
      "Epoch 72/500\n",
      " — train_f1=0.6942 | val_f1=0.5019 | test_f1=0.5019 | mixed_f1=0.5019\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.7063 - loss: 1.0129 - val_accuracy: 0.5532 - val_loss: 1.2948 - train_f1_macro: 0.6942 - val_f1_macro: 0.5019 - test_f1_macro: 0.5019 - mixed_f1_macro: 0.5019\n",
      "Epoch 73/500\n",
      " — train_f1=0.7509 | val_f1=0.4988 | test_f1=0.4988 | mixed_f1=0.4988\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.7157 - loss: 0.9958 - val_accuracy: 0.5071 - val_loss: 1.3495 - train_f1_macro: 0.7509 - val_f1_macro: 0.4988 - test_f1_macro: 0.4988 - mixed_f1_macro: 0.4988\n",
      "Epoch 74/500\n",
      " — train_f1=0.6382 | val_f1=0.4995 | test_f1=0.4995 | mixed_f1=0.4995\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7153 - loss: 0.9970 - val_accuracy: 0.5248 - val_loss: 1.3009 - train_f1_macro: 0.6382 - val_f1_macro: 0.4995 - test_f1_macro: 0.4995 - mixed_f1_macro: 0.4995\n",
      "Epoch 75/500\n",
      " — train_f1=0.5083 | val_f1=0.4421 | test_f1=0.4421 | mixed_f1=0.4421\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7042 - loss: 1.0105 - val_accuracy: 0.4965 - val_loss: 1.3505 - train_f1_macro: 0.5083 - val_f1_macro: 0.4421 - test_f1_macro: 0.4421 - mixed_f1_macro: 0.4421\n",
      "Epoch 76/500\n",
      " — train_f1=0.4570 | val_f1=0.4031 | test_f1=0.4031 | mixed_f1=0.4031\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7153 - loss: 0.9869 - val_accuracy: 0.4220 - val_loss: 1.4079 - train_f1_macro: 0.4570 - val_f1_macro: 0.4031 - test_f1_macro: 0.4031 - mixed_f1_macro: 0.4031\n",
      "Epoch 77/500\n",
      " — train_f1=0.7074 | val_f1=0.4974 | test_f1=0.4974 | mixed_f1=0.4974\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7293 - loss: 0.9795 - val_accuracy: 0.5496 - val_loss: 1.2429 - train_f1_macro: 0.7074 - val_f1_macro: 0.4974 - test_f1_macro: 0.4974 - mixed_f1_macro: 0.4974\n",
      "Epoch 78/500\n",
      " — train_f1=0.6497 | val_f1=0.4411 | test_f1=0.4411 | mixed_f1=0.4411\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7234 - loss: 0.9773 - val_accuracy: 0.4716 - val_loss: 1.3381 - train_f1_macro: 0.6497 - val_f1_macro: 0.4411 - test_f1_macro: 0.4411 - mixed_f1_macro: 0.4411\n",
      "Epoch 79/500\n",
      " — train_f1=0.7749 | val_f1=0.4911 | test_f1=0.4911 | mixed_f1=0.4911\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.7221 - loss: 0.9688 - val_accuracy: 0.4823 - val_loss: 1.4002 - train_f1_macro: 0.7749 - val_f1_macro: 0.4911 - test_f1_macro: 0.4911 - mixed_f1_macro: 0.4911\n",
      "Epoch 80/500\n",
      " — train_f1=0.5917 | val_f1=0.5010 | test_f1=0.5010 | mixed_f1=0.5010\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7357 - loss: 0.9530 - val_accuracy: 0.5426 - val_loss: 1.2747 - train_f1_macro: 0.5917 - val_f1_macro: 0.5010 - test_f1_macro: 0.5010 - mixed_f1_macro: 0.5010\n",
      "Epoch 81/500\n",
      " — train_f1=0.7060 | val_f1=0.4114 | test_f1=0.4114 | mixed_f1=0.4114\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7451 - loss: 0.9712 - val_accuracy: 0.4220 - val_loss: 1.5134 - train_f1_macro: 0.7060 - val_f1_macro: 0.4114 - test_f1_macro: 0.4114 - mixed_f1_macro: 0.4114\n",
      "Epoch 82/500\n",
      " — train_f1=0.7476 | val_f1=0.4927 | test_f1=0.4927 | mixed_f1=0.4927\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7208 - loss: 0.9764 - val_accuracy: 0.5177 - val_loss: 1.3141 - train_f1_macro: 0.7476 - val_f1_macro: 0.4927 - test_f1_macro: 0.4927 - mixed_f1_macro: 0.4927\n",
      "Epoch 83/500\n",
      " — train_f1=0.6862 | val_f1=0.4907 | test_f1=0.4907 | mixed_f1=0.4907\n",
      "37/37 - 10s - 257ms/step - accuracy: 0.7396 - loss: 0.9442 - val_accuracy: 0.5567 - val_loss: 1.3235 - train_f1_macro: 0.6862 - val_f1_macro: 0.4907 - test_f1_macro: 0.4907 - mixed_f1_macro: 0.4907\n",
      "Epoch 84/500\n",
      " — train_f1=0.5187 | val_f1=0.3754 | test_f1=0.3754 | mixed_f1=0.3754\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.7336 - loss: 0.9766 - val_accuracy: 0.4255 - val_loss: 1.5950 - train_f1_macro: 0.5187 - val_f1_macro: 0.3754 - test_f1_macro: 0.3754 - mixed_f1_macro: 0.3754\n",
      "Epoch 85/500\n",
      " — train_f1=0.7264 | val_f1=0.4345 | test_f1=0.4345 | mixed_f1=0.4345\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.7481 - loss: 0.9312 - val_accuracy: 0.4184 - val_loss: 1.5547 - train_f1_macro: 0.7264 - val_f1_macro: 0.4345 - test_f1_macro: 0.4345 - mixed_f1_macro: 0.4345\n",
      "Epoch 86/500\n",
      " — train_f1=0.6981 | val_f1=0.4119 | test_f1=0.4119 | mixed_f1=0.4119\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7383 - loss: 0.9705 - val_accuracy: 0.4468 - val_loss: 1.4722 - train_f1_macro: 0.6981 - val_f1_macro: 0.4119 - test_f1_macro: 0.4119 - mixed_f1_macro: 0.4119\n",
      "Epoch 87/500\n",
      " — train_f1=0.7179 | val_f1=0.4598 | test_f1=0.4598 | mixed_f1=0.4598\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.7447 - loss: 0.9279 - val_accuracy: 0.4787 - val_loss: 1.4615 - train_f1_macro: 0.7179 - val_f1_macro: 0.4598 - test_f1_macro: 0.4598 - mixed_f1_macro: 0.4598\n",
      "Epoch 88/500\n",
      " — train_f1=0.7797 | val_f1=0.5027 | test_f1=0.5027 | mixed_f1=0.5027\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7549 - loss: 0.9354 - val_accuracy: 0.5142 - val_loss: 1.4094 - train_f1_macro: 0.7797 - val_f1_macro: 0.5027 - test_f1_macro: 0.5027 - mixed_f1_macro: 0.5027\n",
      "Epoch 89/500\n",
      " — train_f1=0.6906 | val_f1=0.5029 | test_f1=0.5029 | mixed_f1=0.5029\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7583 - loss: 0.9409 - val_accuracy: 0.5000 - val_loss: 1.3791 - train_f1_macro: 0.6906 - val_f1_macro: 0.5029 - test_f1_macro: 0.5029 - mixed_f1_macro: 0.5029\n",
      "Epoch 90/500\n",
      " — train_f1=0.7232 | val_f1=0.4732 | test_f1=0.4732 | mixed_f1=0.4732\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.7532 - loss: 0.9473 - val_accuracy: 0.4645 - val_loss: 1.5037 - train_f1_macro: 0.7232 - val_f1_macro: 0.4732 - test_f1_macro: 0.4732 - mixed_f1_macro: 0.4732\n",
      "Epoch 91/500\n",
      " — train_f1=0.7387 | val_f1=0.4602 | test_f1=0.4602 | mixed_f1=0.4602\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.7515 - loss: 0.9349 - val_accuracy: 0.4681 - val_loss: 1.4153 - train_f1_macro: 0.7387 - val_f1_macro: 0.4602 - test_f1_macro: 0.4602 - mixed_f1_macro: 0.4602\n",
      "Epoch 92/500\n",
      " — train_f1=0.2015 | val_f1=0.1693 | test_f1=0.1693 | mixed_f1=0.1693\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7707 - loss: 0.9274 - val_accuracy: 0.2234 - val_loss: 1.9830 - train_f1_macro: 0.2015 - val_f1_macro: 0.1693 - test_f1_macro: 0.1693 - mixed_f1_macro: 0.1693\n",
      "Epoch 93/500\n",
      " — train_f1=0.6519 | val_f1=0.4946 | test_f1=0.4946 | mixed_f1=0.4946\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.7587 - loss: 0.9454 - val_accuracy: 0.5000 - val_loss: 1.3825 - train_f1_macro: 0.6519 - val_f1_macro: 0.4946 - test_f1_macro: 0.4946 - mixed_f1_macro: 0.4946\n",
      "\n",
      "Fold 2 FINAL (Mixed Test): ACC=0.5709 F1w=0.5871 MCC=0.4377\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 3  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2337, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (291, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (291, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5251685393258427, 1: 0.7179723502304147, 2: 0.8331550802139037, 3: 4.368224299065421, 4: 3.6515625}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768197656.246688 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_3_1/dropout_15_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0208 | val_f1=0.0343 | test_f1=0.0343 | mixed_f1=0.0343\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0343\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch1_f10.0343_20260112_010102.h5\n",
      "37/37 - 9s - 235ms/step - accuracy: 0.1998 - loss: 1.8893 - val_accuracy: 0.0928 - val_loss: 1.9620 - train_f1_macro: 0.0208 - val_f1_macro: 0.0343 - test_f1_macro: 0.0343 - mixed_f1_macro: 0.0343\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0191 | val_f1=0.0345 | test_f1=0.0345 | mixed_f1=0.0345\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.0345\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch2_f10.0345_20260112_010112.h5\n",
      "37/37 - 9s - 251ms/step - accuracy: 0.2199 - loss: 1.8084 - val_accuracy: 0.0928 - val_loss: 2.0018 - train_f1_macro: 0.0191 - val_f1_macro: 0.0345 - test_f1_macro: 0.0345 - mixed_f1_macro: 0.0345\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0403 | val_f1=0.0578 | test_f1=0.0578 | mixed_f1=0.0578\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.0578\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch3_f10.0578_20260112_010122.h5\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.2619 - loss: 1.6788 - val_accuracy: 0.0962 - val_loss: 2.1336 - train_f1_macro: 0.0403 - val_f1_macro: 0.0578 - test_f1_macro: 0.0578 - mixed_f1_macro: 0.0578\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2163 | val_f1=0.1898 | test_f1=0.1898 | mixed_f1=0.1898\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.1898\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch4_f10.1898_20260112_010132.h5\n",
      "37/37 - 10s - 264ms/step - accuracy: 0.3534 - loss: 1.5443 - val_accuracy: 0.1821 - val_loss: 1.8561 - train_f1_macro: 0.2163 - val_f1_macro: 0.1898 - test_f1_macro: 0.1898 - mixed_f1_macro: 0.1898\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2946 | val_f1=0.3020 | test_f1=0.3020 | mixed_f1=0.3020\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 5 | f1=0.3020\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch5_f10.3020_20260112_010142.h5\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.3380 - loss: 1.4867 - val_accuracy: 0.4777 - val_loss: 1.4713 - train_f1_macro: 0.2946 - val_f1_macro: 0.3020 - test_f1_macro: 0.3020 - mixed_f1_macro: 0.3020\n",
      "Epoch 6/500\n",
      " — train_f1=0.2404 | val_f1=0.1729 | test_f1=0.1729 | mixed_f1=0.1729\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.3406 - loss: 1.4721 - val_accuracy: 0.1821 - val_loss: 1.8629 - train_f1_macro: 0.2404 - val_f1_macro: 0.1729 - test_f1_macro: 0.1729 - mixed_f1_macro: 0.1729\n",
      "Epoch 7/500\n",
      " — train_f1=0.2914 | val_f1=0.2418 | test_f1=0.2418 | mixed_f1=0.2418\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3453 - loss: 1.4372 - val_accuracy: 0.2165 - val_loss: 1.5265 - train_f1_macro: 0.2914 - val_f1_macro: 0.2418 - test_f1_macro: 0.2418 - mixed_f1_macro: 0.2418\n",
      "Epoch 8/500\n",
      " — train_f1=0.2062 | val_f1=0.1785 | test_f1=0.1785 | mixed_f1=0.1785\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.3577 - loss: 1.4364 - val_accuracy: 0.1890 - val_loss: 1.6106 - train_f1_macro: 0.2062 - val_f1_macro: 0.1785 - test_f1_macro: 0.1785 - mixed_f1_macro: 0.1785\n",
      "Epoch 9/500\n",
      " — train_f1=0.2876 | val_f1=0.2667 | test_f1=0.2667 | mixed_f1=0.2667\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3522 - loss: 1.4080 - val_accuracy: 0.3608 - val_loss: 1.5777 - train_f1_macro: 0.2876 - val_f1_macro: 0.2667 - test_f1_macro: 0.2667 - mixed_f1_macro: 0.2667\n",
      "Epoch 10/500\n",
      " — train_f1=0.1612 | val_f1=0.0921 | test_f1=0.0921 | mixed_f1=0.0921\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3697 - loss: 1.3794 - val_accuracy: 0.1306 - val_loss: 1.7907 - train_f1_macro: 0.1612 - val_f1_macro: 0.0921 - test_f1_macro: 0.0921 - mixed_f1_macro: 0.0921\n",
      "Epoch 11/500\n",
      " — train_f1=0.1505 | val_f1=0.1280 | test_f1=0.1280 | mixed_f1=0.1280\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.3671 - loss: 1.3861 - val_accuracy: 0.1340 - val_loss: 1.7927 - train_f1_macro: 0.1505 - val_f1_macro: 0.1280 - test_f1_macro: 0.1280 - mixed_f1_macro: 0.1280\n",
      "Epoch 12/500\n",
      " — train_f1=0.2181 | val_f1=0.1551 | test_f1=0.1551 | mixed_f1=0.1551\n",
      "37/37 - 10s - 272ms/step - accuracy: 0.3731 - loss: 1.3712 - val_accuracy: 0.1959 - val_loss: 1.5213 - train_f1_macro: 0.2181 - val_f1_macro: 0.1551 - test_f1_macro: 0.1551 - mixed_f1_macro: 0.1551\n",
      "Epoch 13/500\n",
      " — train_f1=0.3033 | val_f1=0.2242 | test_f1=0.2242 | mixed_f1=0.2242\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3860 - loss: 1.3590 - val_accuracy: 0.2062 - val_loss: 1.5335 - train_f1_macro: 0.3033 - val_f1_macro: 0.2242 - test_f1_macro: 0.2242 - mixed_f1_macro: 0.2242\n",
      "Epoch 14/500\n",
      " — train_f1=0.3868 | val_f1=0.2908 | test_f1=0.2908 | mixed_f1=0.2908\n",
      "37/37 - 6s - 156ms/step - accuracy: 0.3915 - loss: 1.3447 - val_accuracy: 0.2715 - val_loss: 1.4431 - train_f1_macro: 0.3868 - val_f1_macro: 0.2908 - test_f1_macro: 0.2908 - mixed_f1_macro: 0.2908\n",
      "Epoch 15/500\n",
      " — train_f1=0.2308 | val_f1=0.2413 | test_f1=0.2413 | mixed_f1=0.2413\n",
      "37/37 - 10s - 257ms/step - accuracy: 0.4022 - loss: 1.3517 - val_accuracy: 0.2131 - val_loss: 1.5979 - train_f1_macro: 0.2308 - val_f1_macro: 0.2413 - test_f1_macro: 0.2413 - mixed_f1_macro: 0.2413\n",
      "Epoch 16/500\n",
      " — train_f1=0.3037 | val_f1=0.2591 | test_f1=0.2591 | mixed_f1=0.2591\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4168 - loss: 1.3217 - val_accuracy: 0.2337 - val_loss: 1.5087 - train_f1_macro: 0.3037 - val_f1_macro: 0.2591 - test_f1_macro: 0.2591 - mixed_f1_macro: 0.2591\n",
      "Epoch 17/500\n",
      " — train_f1=0.2921 | val_f1=0.2496 | test_f1=0.2496 | mixed_f1=0.2496\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.4399 - loss: 1.3091 - val_accuracy: 0.2302 - val_loss: 1.5470 - train_f1_macro: 0.2921 - val_f1_macro: 0.2496 - test_f1_macro: 0.2496 - mixed_f1_macro: 0.2496\n",
      "Epoch 18/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4105 | val_f1=0.3194 | test_f1=0.3194 | mixed_f1=0.3194\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 18 | f1=0.3194\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch18_f10.3194_20260112_010303.h5\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.4373 - loss: 1.3025 - val_accuracy: 0.2852 - val_loss: 1.4566 - train_f1_macro: 0.4105 - val_f1_macro: 0.3194 - test_f1_macro: 0.3194 - mixed_f1_macro: 0.3194\n",
      "Epoch 19/500\n",
      " — train_f1=0.3785 | val_f1=0.3082 | test_f1=0.3082 | mixed_f1=0.3082\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4519 - loss: 1.3058 - val_accuracy: 0.2749 - val_loss: 1.4994 - train_f1_macro: 0.3785 - val_f1_macro: 0.3082 - test_f1_macro: 0.3082 - mixed_f1_macro: 0.3082\n",
      "Epoch 20/500\n",
      " — train_f1=0.4136 | val_f1=0.3188 | test_f1=0.3188 | mixed_f1=0.3188\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.4326 - loss: 1.3050 - val_accuracy: 0.2818 - val_loss: 1.4447 - train_f1_macro: 0.4136 - val_f1_macro: 0.3188 - test_f1_macro: 0.3188 - mixed_f1_macro: 0.3188\n",
      "Epoch 21/500\n",
      " — train_f1=0.4216 | val_f1=0.3041 | test_f1=0.3041 | mixed_f1=0.3041\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4531 - loss: 1.2848 - val_accuracy: 0.2852 - val_loss: 1.4608 - train_f1_macro: 0.4216 - val_f1_macro: 0.3041 - test_f1_macro: 0.3041 - mixed_f1_macro: 0.3041\n",
      "Epoch 22/500\n",
      " — train_f1=0.3013 | val_f1=0.1831 | test_f1=0.1831 | mixed_f1=0.1831\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4596 - loss: 1.2932 - val_accuracy: 0.2234 - val_loss: 1.5547 - train_f1_macro: 0.3013 - val_f1_macro: 0.1831 - test_f1_macro: 0.1831 - mixed_f1_macro: 0.1831\n",
      "Epoch 23/500\n",
      " — train_f1=0.4002 | val_f1=0.3090 | test_f1=0.3090 | mixed_f1=0.3090\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.4630 - loss: 1.2858 - val_accuracy: 0.2887 - val_loss: 1.5534 - train_f1_macro: 0.4002 - val_f1_macro: 0.3090 - test_f1_macro: 0.3090 - mixed_f1_macro: 0.3090\n",
      "Epoch 24/500\n",
      " — train_f1=0.3474 | val_f1=0.2140 | test_f1=0.2140 | mixed_f1=0.2140\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4733 - loss: 1.2719 - val_accuracy: 0.2715 - val_loss: 1.6813 - train_f1_macro: 0.3474 - val_f1_macro: 0.2140 - test_f1_macro: 0.2140 - mixed_f1_macro: 0.2140\n",
      "Epoch 25/500\n",
      " — train_f1=0.4569 | val_f1=0.3115 | test_f1=0.3115 | mixed_f1=0.3115\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4771 - loss: 1.2663 - val_accuracy: 0.3505 - val_loss: 1.4097 - train_f1_macro: 0.4569 - val_f1_macro: 0.3115 - test_f1_macro: 0.3115 - mixed_f1_macro: 0.3115\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4947 | val_f1=0.4218 | test_f1=0.4218 | mixed_f1=0.4218\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 26 | f1=0.4218\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch26_f10.4218_20260112_010349.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.4852 - loss: 1.2602 - val_accuracy: 0.4364 - val_loss: 1.3719 - train_f1_macro: 0.4947 - val_f1_macro: 0.4218 - test_f1_macro: 0.4218 - mixed_f1_macro: 0.4218\n",
      "Epoch 27/500\n",
      " — train_f1=0.2871 | val_f1=0.2550 | test_f1=0.2550 | mixed_f1=0.2550\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4626 - loss: 1.2838 - val_accuracy: 0.3093 - val_loss: 1.5311 - train_f1_macro: 0.2871 - val_f1_macro: 0.2550 - test_f1_macro: 0.2550 - mixed_f1_macro: 0.2550\n",
      "Epoch 28/500\n",
      " — train_f1=0.3895 | val_f1=0.2778 | test_f1=0.2778 | mixed_f1=0.2778\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.4904 - loss: 1.2589 - val_accuracy: 0.3471 - val_loss: 1.4170 - train_f1_macro: 0.3895 - val_f1_macro: 0.2778 - test_f1_macro: 0.2778 - mixed_f1_macro: 0.2778\n",
      "Epoch 29/500\n",
      " — train_f1=0.3035 | val_f1=0.2229 | test_f1=0.2229 | mixed_f1=0.2229\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.4917 - loss: 1.2467 - val_accuracy: 0.2027 - val_loss: 1.7794 - train_f1_macro: 0.3035 - val_f1_macro: 0.2229 - test_f1_macro: 0.2229 - mixed_f1_macro: 0.2229\n",
      "Epoch 30/500\n",
      " — train_f1=0.4763 | val_f1=0.4157 | test_f1=0.4157 | mixed_f1=0.4157\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4887 - loss: 1.2495 - val_accuracy: 0.3986 - val_loss: 1.4203 - train_f1_macro: 0.4763 - val_f1_macro: 0.4157 - test_f1_macro: 0.4157 - mixed_f1_macro: 0.4157\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5381 | val_f1=0.4767 | test_f1=0.4767 | mixed_f1=0.4767\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 31 | f1=0.4767\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch31_f10.4767_20260112_010415.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5255 - loss: 1.2372 - val_accuracy: 0.4674 - val_loss: 1.3530 - train_f1_macro: 0.5381 - val_f1_macro: 0.4767 - test_f1_macro: 0.4767 - mixed_f1_macro: 0.4767\n",
      "Epoch 32/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5395 | val_f1=0.5280 | test_f1=0.5280 | mixed_f1=0.5280\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 32 | f1=0.5280\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch32_f10.5280_20260112_010421.h5\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.5101 - loss: 1.2299 - val_accuracy: 0.5292 - val_loss: 1.3073 - train_f1_macro: 0.5395 - val_f1_macro: 0.5280 - test_f1_macro: 0.5280 - mixed_f1_macro: 0.5280\n",
      "Epoch 33/500\n",
      " — train_f1=0.5320 | val_f1=0.5064 | test_f1=0.5064 | mixed_f1=0.5064\n",
      "37/37 - 10s - 272ms/step - accuracy: 0.5293 - loss: 1.2171 - val_accuracy: 0.5223 - val_loss: 1.3221 - train_f1_macro: 0.5320 - val_f1_macro: 0.5064 - test_f1_macro: 0.5064 - mixed_f1_macro: 0.5064\n",
      "Epoch 34/500\n",
      " — train_f1=0.5395 | val_f1=0.4204 | test_f1=0.4204 | mixed_f1=0.4204\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.5259 - loss: 1.2222 - val_accuracy: 0.4192 - val_loss: 1.3483 - train_f1_macro: 0.5394 - val_f1_macro: 0.4204 - test_f1_macro: 0.4204 - mixed_f1_macro: 0.4204\n",
      "Epoch 35/500\n",
      " — train_f1=0.3649 | val_f1=0.2888 | test_f1=0.2888 | mixed_f1=0.2888\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5400 - loss: 1.2080 - val_accuracy: 0.2887 - val_loss: 1.6374 - train_f1_macro: 0.3649 - val_f1_macro: 0.2888 - test_f1_macro: 0.2888 - mixed_f1_macro: 0.2888\n",
      "Epoch 36/500\n",
      " — train_f1=0.5547 | val_f1=0.4738 | test_f1=0.4738 | mixed_f1=0.4738\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.5516 - loss: 1.1968 - val_accuracy: 0.4777 - val_loss: 1.3267 - train_f1_macro: 0.5547 - val_f1_macro: 0.4738 - test_f1_macro: 0.4738 - mixed_f1_macro: 0.4738\n",
      "Epoch 37/500\n",
      " — train_f1=0.5724 | val_f1=0.4663 | test_f1=0.4663 | mixed_f1=0.4663\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.5516 - loss: 1.1978 - val_accuracy: 0.4467 - val_loss: 1.3624 - train_f1_macro: 0.5724 - val_f1_macro: 0.4663 - test_f1_macro: 0.4663 - mixed_f1_macro: 0.4663\n",
      "Epoch 38/500\n",
      " — train_f1=0.4787 | val_f1=0.4179 | test_f1=0.4179 | mixed_f1=0.4179\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.5661 - loss: 1.2009 - val_accuracy: 0.4021 - val_loss: 1.4268 - train_f1_macro: 0.4787 - val_f1_macro: 0.4179 - test_f1_macro: 0.4179 - mixed_f1_macro: 0.4179\n",
      "Epoch 39/500\n",
      " — train_f1=0.5447 | val_f1=0.4376 | test_f1=0.4376 | mixed_f1=0.4376\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5640 - loss: 1.1813 - val_accuracy: 0.3952 - val_loss: 1.4214 - train_f1_macro: 0.5447 - val_f1_macro: 0.4376 - test_f1_macro: 0.4376 - mixed_f1_macro: 0.4376\n",
      "Epoch 40/500\n",
      " — train_f1=0.4982 | val_f1=0.4078 | test_f1=0.4078 | mixed_f1=0.4078\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5567 - loss: 1.1782 - val_accuracy: 0.3643 - val_loss: 1.4603 - train_f1_macro: 0.4982 - val_f1_macro: 0.4078 - test_f1_macro: 0.4078 - mixed_f1_macro: 0.4078\n",
      "Epoch 41/500\n",
      " — train_f1=0.5224 | val_f1=0.3849 | test_f1=0.3849 | mixed_f1=0.3849\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5785 - loss: 1.1784 - val_accuracy: 0.3574 - val_loss: 1.4890 - train_f1_macro: 0.5224 - val_f1_macro: 0.3849 - test_f1_macro: 0.3849 - mixed_f1_macro: 0.3849\n",
      "Epoch 42/500\n",
      " — train_f1=0.4152 | val_f1=0.4259 | test_f1=0.4259 | mixed_f1=0.4259\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.5768 - loss: 1.1576 - val_accuracy: 0.4330 - val_loss: 1.4062 - train_f1_macro: 0.4152 - val_f1_macro: 0.4259 - test_f1_macro: 0.4259 - mixed_f1_macro: 0.4259\n",
      "Epoch 43/500\n",
      " — train_f1=0.4838 | val_f1=0.4490 | test_f1=0.4490 | mixed_f1=0.4490\n",
      "37/37 - 10s - 265ms/step - accuracy: 0.5687 - loss: 1.1910 - val_accuracy: 0.4811 - val_loss: 1.2955 - train_f1_macro: 0.4838 - val_f1_macro: 0.4490 - test_f1_macro: 0.4490 - mixed_f1_macro: 0.4490\n",
      "Epoch 44/500\n",
      " — train_f1=0.2448 | val_f1=0.1406 | test_f1=0.1406 | mixed_f1=0.1406\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.5798 - loss: 1.1743 - val_accuracy: 0.2509 - val_loss: 1.8972 - train_f1_macro: 0.2448 - val_f1_macro: 0.1406 - test_f1_macro: 0.1406 - mixed_f1_macro: 0.1406\n",
      "Epoch 45/500\n",
      " — train_f1=0.3795 | val_f1=0.3105 | test_f1=0.3105 | mixed_f1=0.3105\n",
      "37/37 - 5s - 149ms/step - accuracy: 0.5926 - loss: 1.1573 - val_accuracy: 0.2852 - val_loss: 1.6681 - train_f1_macro: 0.3795 - val_f1_macro: 0.3105 - test_f1_macro: 0.3105 - mixed_f1_macro: 0.3105\n",
      "Epoch 46/500\n",
      " — train_f1=0.4896 | val_f1=0.4710 | test_f1=0.4710 | mixed_f1=0.4710\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5845 - loss: 1.1510 - val_accuracy: 0.4777 - val_loss: 1.3163 - train_f1_macro: 0.4896 - val_f1_macro: 0.4710 - test_f1_macro: 0.4710 - mixed_f1_macro: 0.4710\n",
      "Epoch 47/500\n",
      " — train_f1=0.6334 | val_f1=0.5030 | test_f1=0.5030 | mixed_f1=0.5030\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5926 - loss: 1.1522 - val_accuracy: 0.4811 - val_loss: 1.3494 - train_f1_macro: 0.6334 - val_f1_macro: 0.5030 - test_f1_macro: 0.5030 - mixed_f1_macro: 0.5030\n",
      "Epoch 48/500\n",
      " — train_f1=0.5876 | val_f1=0.5210 | test_f1=0.5210 | mixed_f1=0.5210\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6033 - loss: 1.1311 - val_accuracy: 0.4914 - val_loss: 1.3113 - train_f1_macro: 0.5876 - val_f1_macro: 0.5210 - test_f1_macro: 0.5210 - mixed_f1_macro: 0.5210\n",
      "Epoch 49/500\n",
      " — train_f1=0.5573 | val_f1=0.4201 | test_f1=0.4201 | mixed_f1=0.4201\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.5896 - loss: 1.1603 - val_accuracy: 0.3952 - val_loss: 1.4855 - train_f1_macro: 0.5573 - val_f1_macro: 0.4201 - test_f1_macro: 0.4201 - mixed_f1_macro: 0.4201\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6052 | val_f1=0.5591 | test_f1=0.5591 | mixed_f1=0.5591\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 50 | f1=0.5591\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch50_f10.5591_20260112_010617.h5\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5888 - loss: 1.1497 - val_accuracy: 0.5464 - val_loss: 1.2696 - train_f1_macro: 0.6052 - val_f1_macro: 0.5591 - test_f1_macro: 0.5591 - mixed_f1_macro: 0.5591\n",
      "Epoch 51/500\n",
      " — train_f1=0.6527 | val_f1=0.5275 | test_f1=0.5275 | mixed_f1=0.5275\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6029 - loss: 1.1464 - val_accuracy: 0.5155 - val_loss: 1.2870 - train_f1_macro: 0.6527 - val_f1_macro: 0.5275 - test_f1_macro: 0.5275 - mixed_f1_macro: 0.5275\n",
      "Epoch 52/500\n",
      " — train_f1=0.6274 | val_f1=0.4896 | test_f1=0.4896 | mixed_f1=0.4896\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6115 - loss: 1.1460 - val_accuracy: 0.4605 - val_loss: 1.3738 - train_f1_macro: 0.6274 - val_f1_macro: 0.4896 - test_f1_macro: 0.4896 - mixed_f1_macro: 0.4896\n",
      "Epoch 53/500\n",
      " — train_f1=0.5872 | val_f1=0.4336 | test_f1=0.4336 | mixed_f1=0.4336\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6217 - loss: 1.1136 - val_accuracy: 0.4021 - val_loss: 1.4699 - train_f1_macro: 0.5872 - val_f1_macro: 0.4336 - test_f1_macro: 0.4336 - mixed_f1_macro: 0.4336\n",
      "Epoch 54/500\n",
      " — train_f1=0.5311 | val_f1=0.4221 | test_f1=0.4221 | mixed_f1=0.4221\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6170 - loss: 1.1198 - val_accuracy: 0.4261 - val_loss: 1.4436 - train_f1_macro: 0.5311 - val_f1_macro: 0.4221 - test_f1_macro: 0.4221 - mixed_f1_macro: 0.4221\n",
      "Epoch 55/500\n",
      " — train_f1=0.4150 | val_f1=0.2766 | test_f1=0.2766 | mixed_f1=0.2766\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.6397 - loss: 1.0997 - val_accuracy: 0.3230 - val_loss: 1.6699 - train_f1_macro: 0.4150 - val_f1_macro: 0.2766 - test_f1_macro: 0.2766 - mixed_f1_macro: 0.2766\n",
      "Epoch 56/500\n",
      " — train_f1=0.3660 | val_f1=0.2965 | test_f1=0.2965 | mixed_f1=0.2965\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.6341 - loss: 1.0971 - val_accuracy: 0.4021 - val_loss: 1.5340 - train_f1_macro: 0.3660 - val_f1_macro: 0.2965 - test_f1_macro: 0.2965 - mixed_f1_macro: 0.2965\n",
      "Epoch 57/500\n",
      " — train_f1=0.6596 | val_f1=0.5103 | test_f1=0.5103 | mixed_f1=0.5103\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.6418 - loss: 1.0941 - val_accuracy: 0.4811 - val_loss: 1.3276 - train_f1_macro: 0.6596 - val_f1_macro: 0.5103 - test_f1_macro: 0.5103 - mixed_f1_macro: 0.5103\n",
      "Epoch 58/500\n",
      " — train_f1=0.6053 | val_f1=0.5079 | test_f1=0.5079 | mixed_f1=0.5079\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.6389 - loss: 1.0990 - val_accuracy: 0.5395 - val_loss: 1.2384 - train_f1_macro: 0.6053 - val_f1_macro: 0.5079 - test_f1_macro: 0.5079 - mixed_f1_macro: 0.5079\n",
      "Epoch 59/500\n",
      " — train_f1=0.6743 | val_f1=0.5361 | test_f1=0.5361 | mixed_f1=0.5361\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.6406 - loss: 1.0783 - val_accuracy: 0.5120 - val_loss: 1.2532 - train_f1_macro: 0.6743 - val_f1_macro: 0.5361 - test_f1_macro: 0.5361 - mixed_f1_macro: 0.5361\n",
      "Epoch 60/500\n",
      " — train_f1=0.6830 | val_f1=0.5440 | test_f1=0.5440 | mixed_f1=0.5440\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6620 - loss: 1.0716 - val_accuracy: 0.5464 - val_loss: 1.2670 - train_f1_macro: 0.6830 - val_f1_macro: 0.5440 - test_f1_macro: 0.5440 - mixed_f1_macro: 0.5440\n",
      "Epoch 61/500\n",
      " — train_f1=0.6225 | val_f1=0.5112 | test_f1=0.5112 | mixed_f1=0.5112\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.6568 - loss: 1.0688 - val_accuracy: 0.5086 - val_loss: 1.3758 - train_f1_macro: 0.6225 - val_f1_macro: 0.5112 - test_f1_macro: 0.5112 - mixed_f1_macro: 0.5112\n",
      "Epoch 62/500\n",
      " — train_f1=0.6401 | val_f1=0.4747 | test_f1=0.4747 | mixed_f1=0.4747\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6650 - loss: 1.0928 - val_accuracy: 0.4674 - val_loss: 1.3458 - train_f1_macro: 0.6401 - val_f1_macro: 0.4747 - test_f1_macro: 0.4747 - mixed_f1_macro: 0.4747\n",
      "Epoch 63/500\n",
      " — train_f1=0.6382 | val_f1=0.4604 | test_f1=0.4604 | mixed_f1=0.4604\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.6517 - loss: 1.0962 - val_accuracy: 0.4605 - val_loss: 1.3800 - train_f1_macro: 0.6382 - val_f1_macro: 0.4604 - test_f1_macro: 0.4604 - mixed_f1_macro: 0.4604\n",
      "Epoch 64/500\n",
      " — train_f1=0.4627 | val_f1=0.3620 | test_f1=0.3620 | mixed_f1=0.3620\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6855 - loss: 1.0560 - val_accuracy: 0.3918 - val_loss: 1.5351 - train_f1_macro: 0.4627 - val_f1_macro: 0.3620 - test_f1_macro: 0.3620 - mixed_f1_macro: 0.3620\n",
      "Epoch 65/500\n",
      " — train_f1=0.6455 | val_f1=0.5076 | test_f1=0.5076 | mixed_f1=0.5076\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.6658 - loss: 1.0761 - val_accuracy: 0.5120 - val_loss: 1.2779 - train_f1_macro: 0.6455 - val_f1_macro: 0.5076 - test_f1_macro: 0.5076 - mixed_f1_macro: 0.5076\n",
      "Epoch 66/500\n",
      " — train_f1=0.5042 | val_f1=0.3771 | test_f1=0.3771 | mixed_f1=0.3771\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.6671 - loss: 1.0570 - val_accuracy: 0.3849 - val_loss: 1.5775 - train_f1_macro: 0.5042 - val_f1_macro: 0.3771 - test_f1_macro: 0.3771 - mixed_f1_macro: 0.3771\n",
      "Epoch 67/500\n",
      " — train_f1=0.6943 | val_f1=0.5393 | test_f1=0.5393 | mixed_f1=0.5393\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.6786 - loss: 1.0668 - val_accuracy: 0.5086 - val_loss: 1.3342 - train_f1_macro: 0.6943 - val_f1_macro: 0.5393 - test_f1_macro: 0.5393 - mixed_f1_macro: 0.5393\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7174 | val_f1=0.5724 | test_f1=0.5724 | mixed_f1=0.5724\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 68 | f1=0.5724\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch68_f10.5724_20260112_010815.h5\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.6714 - loss: 1.0468 - val_accuracy: 0.5498 - val_loss: 1.2651 - train_f1_macro: 0.7174 - val_f1_macro: 0.5724 - test_f1_macro: 0.5724 - mixed_f1_macro: 0.5724\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7194 | val_f1=0.5857 | test_f1=0.5857 | mixed_f1=0.5857\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 69 | f1=0.5857\n",
      "   → saved_models/merged_fold_3/best_val_f1_macro_epoch69_f10.5857_20260112_010820.h5\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6846 - loss: 1.0610 - val_accuracy: 0.5773 - val_loss: 1.2665 - train_f1_macro: 0.7194 - val_f1_macro: 0.5857 - test_f1_macro: 0.5857 - mixed_f1_macro: 0.5857\n",
      "Epoch 70/500\n",
      " — train_f1=0.5091 | val_f1=0.3482 | test_f1=0.3482 | mixed_f1=0.3482\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.6953 - loss: 1.0450 - val_accuracy: 0.3402 - val_loss: 1.7134 - train_f1_macro: 0.5091 - val_f1_macro: 0.3482 - test_f1_macro: 0.3482 - mixed_f1_macro: 0.3482\n",
      "Epoch 71/500\n",
      " — train_f1=0.6663 | val_f1=0.5137 | test_f1=0.5137 | mixed_f1=0.5137\n",
      "37/37 - 10s - 279ms/step - accuracy: 0.7022 - loss: 1.0253 - val_accuracy: 0.5086 - val_loss: 1.3925 - train_f1_macro: 0.6663 - val_f1_macro: 0.5137 - test_f1_macro: 0.5137 - mixed_f1_macro: 0.5137\n",
      "Epoch 72/500\n",
      " — train_f1=0.7137 | val_f1=0.5257 | test_f1=0.5257 | mixed_f1=0.5257\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.6932 - loss: 1.0599 - val_accuracy: 0.5189 - val_loss: 1.2713 - train_f1_macro: 0.7137 - val_f1_macro: 0.5257 - test_f1_macro: 0.5257 - mixed_f1_macro: 0.5257\n",
      "Epoch 73/500\n",
      " — train_f1=0.6489 | val_f1=0.4606 | test_f1=0.4606 | mixed_f1=0.4606\n",
      "37/37 - 10s - 279ms/step - accuracy: 0.6919 - loss: 1.0535 - val_accuracy: 0.4296 - val_loss: 1.4536 - train_f1_macro: 0.6489 - val_f1_macro: 0.4606 - test_f1_macro: 0.4606 - mixed_f1_macro: 0.4606\n",
      "Epoch 74/500\n",
      " — train_f1=0.6366 | val_f1=0.5281 | test_f1=0.5281 | mixed_f1=0.5281\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.7107 - loss: 1.0115 - val_accuracy: 0.4914 - val_loss: 1.3746 - train_f1_macro: 0.6366 - val_f1_macro: 0.5281 - test_f1_macro: 0.5281 - mixed_f1_macro: 0.5281\n",
      "Epoch 75/500\n",
      " — train_f1=0.7027 | val_f1=0.5453 | test_f1=0.5453 | mixed_f1=0.5453\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7013 - loss: 1.0285 - val_accuracy: 0.5223 - val_loss: 1.3053 - train_f1_macro: 0.7027 - val_f1_macro: 0.5453 - test_f1_macro: 0.5453 - mixed_f1_macro: 0.5453\n",
      "Epoch 76/500\n",
      " — train_f1=0.6049 | val_f1=0.4715 | test_f1=0.4715 | mixed_f1=0.4715\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7060 - loss: 1.0077 - val_accuracy: 0.4777 - val_loss: 1.4506 - train_f1_macro: 0.6049 - val_f1_macro: 0.4715 - test_f1_macro: 0.4715 - mixed_f1_macro: 0.4715\n",
      "Epoch 77/500\n",
      " — train_f1=0.7171 | val_f1=0.5580 | test_f1=0.5580 | mixed_f1=0.5580\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7159 - loss: 1.0117 - val_accuracy: 0.5464 - val_loss: 1.2962 - train_f1_macro: 0.7171 - val_f1_macro: 0.5580 - test_f1_macro: 0.5580 - mixed_f1_macro: 0.5580\n",
      "Epoch 78/500\n",
      " — train_f1=0.6739 | val_f1=0.5169 | test_f1=0.5169 | mixed_f1=0.5169\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7142 - loss: 1.0076 - val_accuracy: 0.4983 - val_loss: 1.3813 - train_f1_macro: 0.6739 - val_f1_macro: 0.5169 - test_f1_macro: 0.5169 - mixed_f1_macro: 0.5169\n",
      "Epoch 79/500\n",
      " — train_f1=0.3045 | val_f1=0.2528 | test_f1=0.2528 | mixed_f1=0.2528\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7249 - loss: 1.0018 - val_accuracy: 0.3918 - val_loss: 1.6664 - train_f1_macro: 0.3045 - val_f1_macro: 0.2528 - test_f1_macro: 0.2528 - mixed_f1_macro: 0.2528\n",
      "Epoch 80/500\n",
      " — train_f1=0.6077 | val_f1=0.4077 | test_f1=0.4077 | mixed_f1=0.4077\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7154 - loss: 1.0223 - val_accuracy: 0.4089 - val_loss: 1.5348 - train_f1_macro: 0.6077 - val_f1_macro: 0.4077 - test_f1_macro: 0.4077 - mixed_f1_macro: 0.4077\n",
      "Epoch 81/500\n",
      " — train_f1=0.6035 | val_f1=0.4250 | test_f1=0.4250 | mixed_f1=0.4250\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.7214 - loss: 1.0119 - val_accuracy: 0.4674 - val_loss: 1.4752 - train_f1_macro: 0.6035 - val_f1_macro: 0.4250 - test_f1_macro: 0.4250 - mixed_f1_macro: 0.4250\n",
      "Epoch 82/500\n",
      " — train_f1=0.5700 | val_f1=0.4037 | test_f1=0.4037 | mixed_f1=0.4037\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.7351 - loss: 0.9976 - val_accuracy: 0.4330 - val_loss: 1.5280 - train_f1_macro: 0.5700 - val_f1_macro: 0.4037 - test_f1_macro: 0.4037 - mixed_f1_macro: 0.4037\n",
      "Epoch 83/500\n",
      " — train_f1=0.6543 | val_f1=0.4524 | test_f1=0.4524 | mixed_f1=0.4524\n",
      "37/37 - 10s - 278ms/step - accuracy: 0.7287 - loss: 0.9896 - val_accuracy: 0.4502 - val_loss: 1.4591 - train_f1_macro: 0.6543 - val_f1_macro: 0.4524 - test_f1_macro: 0.4524 - mixed_f1_macro: 0.4524\n",
      "Epoch 84/500\n",
      " — train_f1=0.7245 | val_f1=0.5131 | test_f1=0.5131 | mixed_f1=0.5131\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.7231 - loss: 1.0135 - val_accuracy: 0.4948 - val_loss: 1.3514 - train_f1_macro: 0.7245 - val_f1_macro: 0.5131 - test_f1_macro: 0.5131 - mixed_f1_macro: 0.5131\n",
      "Epoch 85/500\n",
      " — train_f1=0.5997 | val_f1=0.4422 | test_f1=0.4422 | mixed_f1=0.4422\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.7381 - loss: 0.9677 - val_accuracy: 0.4261 - val_loss: 1.5625 - train_f1_macro: 0.5997 - val_f1_macro: 0.4422 - test_f1_macro: 0.4422 - mixed_f1_macro: 0.4422\n",
      "Epoch 86/500\n",
      " — train_f1=0.7331 | val_f1=0.5741 | test_f1=0.5741 | mixed_f1=0.5741\n",
      "37/37 - 10s - 263ms/step - accuracy: 0.7424 - loss: 0.9857 - val_accuracy: 0.5533 - val_loss: 1.2842 - train_f1_macro: 0.7331 - val_f1_macro: 0.5741 - test_f1_macro: 0.5741 - mixed_f1_macro: 0.5741\n",
      "Epoch 87/500\n",
      " — train_f1=0.6829 | val_f1=0.5037 | test_f1=0.5037 | mixed_f1=0.5037\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7420 - loss: 0.9908 - val_accuracy: 0.4880 - val_loss: 1.4194 - train_f1_macro: 0.6829 - val_f1_macro: 0.5037 - test_f1_macro: 0.5037 - mixed_f1_macro: 0.5037\n",
      "Epoch 88/500\n",
      " — train_f1=0.7357 | val_f1=0.5133 | test_f1=0.5133 | mixed_f1=0.5133\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7582 - loss: 0.9570 - val_accuracy: 0.4914 - val_loss: 1.4227 - train_f1_macro: 0.7357 - val_f1_macro: 0.5133 - test_f1_macro: 0.5133 - mixed_f1_macro: 0.5133\n",
      "Epoch 89/500\n",
      " — train_f1=0.6775 | val_f1=0.4842 | test_f1=0.4842 | mixed_f1=0.4842\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7441 - loss: 0.9569 - val_accuracy: 0.5052 - val_loss: 1.4032 - train_f1_macro: 0.6775 - val_f1_macro: 0.4842 - test_f1_macro: 0.4842 - mixed_f1_macro: 0.4842\n",
      "Epoch 90/500\n",
      " — train_f1=0.7237 | val_f1=0.5614 | test_f1=0.5614 | mixed_f1=0.5614\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.7403 - loss: 0.9581 - val_accuracy: 0.5979 - val_loss: 1.2475 - train_f1_macro: 0.7237 - val_f1_macro: 0.5614 - test_f1_macro: 0.5614 - mixed_f1_macro: 0.5614\n",
      "Epoch 91/500\n",
      " — train_f1=0.7618 | val_f1=0.5640 | test_f1=0.5640 | mixed_f1=0.5640\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7450 - loss: 0.9755 - val_accuracy: 0.5498 - val_loss: 1.2984 - train_f1_macro: 0.7618 - val_f1_macro: 0.5640 - test_f1_macro: 0.5640 - mixed_f1_macro: 0.5640\n",
      "Epoch 92/500\n",
      " — train_f1=0.6960 | val_f1=0.4399 | test_f1=0.4399 | mixed_f1=0.4399\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7612 - loss: 0.9805 - val_accuracy: 0.4467 - val_loss: 1.4136 - train_f1_macro: 0.6960 - val_f1_macro: 0.4399 - test_f1_macro: 0.4399 - mixed_f1_macro: 0.4399\n",
      "Epoch 93/500\n",
      " — train_f1=0.7606 | val_f1=0.5743 | test_f1=0.5743 | mixed_f1=0.5743\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.7608 - loss: 0.9772 - val_accuracy: 0.5739 - val_loss: 1.2529 - train_f1_macro: 0.7606 - val_f1_macro: 0.5743 - test_f1_macro: 0.5743 - mixed_f1_macro: 0.5743\n",
      "Epoch 94/500\n",
      " — train_f1=0.7365 | val_f1=0.5640 | test_f1=0.5640 | mixed_f1=0.5640\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.7386 - loss: 0.9665 - val_accuracy: 0.5704 - val_loss: 1.3141 - train_f1_macro: 0.7365 - val_f1_macro: 0.5640 - test_f1_macro: 0.5640 - mixed_f1_macro: 0.5640\n",
      "Epoch 95/500\n",
      " — train_f1=0.7706 | val_f1=0.5615 | test_f1=0.5615 | mixed_f1=0.5615\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.7582 - loss: 0.9636 - val_accuracy: 0.5464 - val_loss: 1.3330 - train_f1_macro: 0.7706 - val_f1_macro: 0.5615 - test_f1_macro: 0.5615 - mixed_f1_macro: 0.5615\n",
      "Epoch 96/500\n",
      " — train_f1=0.7670 | val_f1=0.5222 | test_f1=0.5222 | mixed_f1=0.5222\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.7647 - loss: 0.9343 - val_accuracy: 0.5086 - val_loss: 1.3976 - train_f1_macro: 0.7670 - val_f1_macro: 0.5222 - test_f1_macro: 0.5222 - mixed_f1_macro: 0.5222\n",
      "Epoch 97/500\n",
      " — train_f1=0.6438 | val_f1=0.5224 | test_f1=0.5224 | mixed_f1=0.5224\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.7587 - loss: 0.9630 - val_accuracy: 0.5155 - val_loss: 1.3785 - train_f1_macro: 0.6438 - val_f1_macro: 0.5224 - test_f1_macro: 0.5224 - mixed_f1_macro: 0.5224\n",
      "Epoch 98/500\n",
      " — train_f1=0.7283 | val_f1=0.5117 | test_f1=0.5117 | mixed_f1=0.5117\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.7745 - loss: 0.9359 - val_accuracy: 0.4845 - val_loss: 1.5355 - train_f1_macro: 0.7283 - val_f1_macro: 0.5117 - test_f1_macro: 0.5117 - mixed_f1_macro: 0.5117\n",
      "Epoch 99/500\n",
      " — train_f1=0.7232 | val_f1=0.5080 | test_f1=0.5080 | mixed_f1=0.5080\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7505 - loss: 0.9623 - val_accuracy: 0.5155 - val_loss: 1.3658 - train_f1_macro: 0.7232 - val_f1_macro: 0.5080 - test_f1_macro: 0.5080 - mixed_f1_macro: 0.5080\n",
      "\n",
      "Fold 3 FINAL (Mixed Test): ACC=0.5773 F1w=0.5812 MCC=0.4686\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 4  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2377, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (251, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (251, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5145021645021645, 1: 0.7095522388059702, 2: 0.8675182481751825, 3: 4.442990654205608, 4: 3.7140625}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768198288.058336 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_4_1/dropout_20_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0260 | val_f1=0.0502 | test_f1=0.0502 | mixed_f1=0.0502\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0502\n",
      "   → saved_models/merged_fold_4/best_val_f1_macro_epoch1_f10.0502_20260112_011135.h5\n",
      "38/38 - 10s - 250ms/step - accuracy: 0.2659 - loss: 1.8814 - val_accuracy: 0.1076 - val_loss: 1.9173 - train_f1_macro: 0.0260 - val_f1_macro: 0.0502 - test_f1_macro: 0.0502 - mixed_f1_macro: 0.0502\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0383 | val_f1=0.0753 | test_f1=0.0753 | mixed_f1=0.0753\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.0753\n",
      "   → saved_models/merged_fold_4/best_val_f1_macro_epoch2_f10.0753_20260112_011144.h5\n",
      "38/38 - 9s - 228ms/step - accuracy: 0.3012 - loss: 1.7638 - val_accuracy: 0.1195 - val_loss: 2.2643 - train_f1_macro: 0.0383 - val_f1_macro: 0.0753 - test_f1_macro: 0.0753 - mixed_f1_macro: 0.0753\n",
      "Epoch 3/500\n",
      " — train_f1=0.0173 | val_f1=0.0388 | test_f1=0.0388 | mixed_f1=0.0388\n",
      "38/38 - 10s - 267ms/step - accuracy: 0.3382 - loss: 1.6071 - val_accuracy: 0.1076 - val_loss: 2.7523 - train_f1_macro: 0.0173 - val_f1_macro: 0.0388 - test_f1_macro: 0.0388 - mixed_f1_macro: 0.0388\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4012 | val_f1=0.3613 | test_f1=0.3613 | mixed_f1=0.3613\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.3613\n",
      "   → saved_models/merged_fold_4/best_val_f1_macro_epoch4_f10.3613_20260112_011200.h5\n",
      "38/38 - 6s - 152ms/step - accuracy: 0.3286 - loss: 1.5284 - val_accuracy: 0.3944 - val_loss: 1.5849 - train_f1_macro: 0.4012 - val_f1_macro: 0.3613 - test_f1_macro: 0.3613 - mixed_f1_macro: 0.3613\n",
      "Epoch 5/500\n",
      " — train_f1=0.3938 | val_f1=0.3428 | test_f1=0.3428 | mixed_f1=0.3428\n",
      "38/38 - 10s - 253ms/step - accuracy: 0.3614 - loss: 1.4923 - val_accuracy: 0.3944 - val_loss: 1.5427 - train_f1_macro: 0.3938 - val_f1_macro: 0.3428 - test_f1_macro: 0.3428 - mixed_f1_macro: 0.3428\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4058 | val_f1=0.4023 | test_f1=0.4023 | mixed_f1=0.4023\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 6 | f1=0.4023\n",
      "   → saved_models/merged_fold_4/best_val_f1_macro_epoch6_f10.4023_20260112_011219.h5\n",
      "38/38 - 10s - 265ms/step - accuracy: 0.3475 - loss: 1.4694 - val_accuracy: 0.4064 - val_loss: 1.5268 - train_f1_macro: 0.4058 - val_f1_macro: 0.4023 - test_f1_macro: 0.4023 - mixed_f1_macro: 0.4023\n",
      "Epoch 7/500\n",
      " — train_f1=0.2760 | val_f1=0.2963 | test_f1=0.2963 | mixed_f1=0.2963\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.3496 - loss: 1.4352 - val_accuracy: 0.3028 - val_loss: 1.6057 - train_f1_macro: 0.2760 - val_f1_macro: 0.2963 - test_f1_macro: 0.2963 - mixed_f1_macro: 0.2963\n",
      "Epoch 8/500\n",
      " — train_f1=0.1707 | val_f1=0.1469 | test_f1=0.1469 | mixed_f1=0.1469\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.3660 - loss: 1.4223 - val_accuracy: 0.1753 - val_loss: 2.0716 - train_f1_macro: 0.1707 - val_f1_macro: 0.1469 - test_f1_macro: 0.1469 - mixed_f1_macro: 0.1469\n",
      "Epoch 9/500\n",
      " — train_f1=0.3830 | val_f1=0.3607 | test_f1=0.3607 | mixed_f1=0.3607\n",
      "38/38 - 11s - 283ms/step - accuracy: 0.3702 - loss: 1.3939 - val_accuracy: 0.3506 - val_loss: 1.5057 - train_f1_macro: 0.3830 - val_f1_macro: 0.3607 - test_f1_macro: 0.3607 - mixed_f1_macro: 0.3607\n",
      "Epoch 10/500\n",
      " — train_f1=0.1984 | val_f1=0.1687 | test_f1=0.1687 | mixed_f1=0.1687\n",
      "38/38 - 6s - 150ms/step - accuracy: 0.3715 - loss: 1.3906 - val_accuracy: 0.2191 - val_loss: 1.8192 - train_f1_macro: 0.1984 - val_f1_macro: 0.1687 - test_f1_macro: 0.1687 - mixed_f1_macro: 0.1687\n",
      "Epoch 11/500\n",
      " — train_f1=0.4031 | val_f1=0.3690 | test_f1=0.3690 | mixed_f1=0.3690\n",
      "38/38 - 10s - 253ms/step - accuracy: 0.3875 - loss: 1.3514 - val_accuracy: 0.3825 - val_loss: 1.4691 - train_f1_macro: 0.4031 - val_f1_macro: 0.3690 - test_f1_macro: 0.3690 - mixed_f1_macro: 0.3690\n",
      "Epoch 12/500\n",
      " — train_f1=0.3360 | val_f1=0.2741 | test_f1=0.2741 | mixed_f1=0.2741\n",
      "38/38 - 5s - 133ms/step - accuracy: 0.3790 - loss: 1.3671 - val_accuracy: 0.3147 - val_loss: 1.4964 - train_f1_macro: 0.3360 - val_f1_macro: 0.2741 - test_f1_macro: 0.2741 - mixed_f1_macro: 0.2741\n",
      "Epoch 13/500\n",
      " — train_f1=0.3637 | val_f1=0.2732 | test_f1=0.2732 | mixed_f1=0.2732\n",
      "38/38 - 6s - 153ms/step - accuracy: 0.3946 - loss: 1.3588 - val_accuracy: 0.3028 - val_loss: 1.5289 - train_f1_macro: 0.3637 - val_f1_macro: 0.2732 - test_f1_macro: 0.2732 - mixed_f1_macro: 0.2732\n",
      "Epoch 14/500\n",
      " — train_f1=0.3996 | val_f1=0.3631 | test_f1=0.3631 | mixed_f1=0.3631\n",
      "38/38 - 10s - 250ms/step - accuracy: 0.3816 - loss: 1.3464 - val_accuracy: 0.3865 - val_loss: 1.4843 - train_f1_macro: 0.3996 - val_f1_macro: 0.3631 - test_f1_macro: 0.3631 - mixed_f1_macro: 0.3631\n",
      "Epoch 15/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4790 | val_f1=0.4679 | test_f1=0.4679 | mixed_f1=0.4679\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 15 | f1=0.4679\n",
      "   → saved_models/merged_fold_4/best_val_f1_macro_epoch15_f10.4679_20260112_011321.h5\n",
      "38/38 - 5s - 137ms/step - accuracy: 0.4034 - loss: 1.3292 - val_accuracy: 0.4542 - val_loss: 1.4631 - train_f1_macro: 0.4790 - val_f1_macro: 0.4679 - test_f1_macro: 0.4679 - mixed_f1_macro: 0.4679\n",
      "Epoch 16/500\n",
      " — train_f1=0.3566 | val_f1=0.3571 | test_f1=0.3571 | mixed_f1=0.3571\n",
      "38/38 - 11s - 281ms/step - accuracy: 0.4367 - loss: 1.3181 - val_accuracy: 0.3665 - val_loss: 1.5469 - train_f1_macro: 0.3566 - val_f1_macro: 0.3571 - test_f1_macro: 0.3571 - mixed_f1_macro: 0.3571\n",
      "Epoch 17/500\n",
      " — train_f1=0.4004 | val_f1=0.3591 | test_f1=0.3591 | mixed_f1=0.3591\n",
      "38/38 - 10s - 252ms/step - accuracy: 0.4131 - loss: 1.3217 - val_accuracy: 0.3546 - val_loss: 1.5043 - train_f1_macro: 0.4004 - val_f1_macro: 0.3591 - test_f1_macro: 0.3591 - mixed_f1_macro: 0.3591\n",
      "Epoch 18/500\n",
      " — train_f1=0.4769 | val_f1=0.4341 | test_f1=0.4341 | mixed_f1=0.4341\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.4443 - loss: 1.2989 - val_accuracy: 0.4382 - val_loss: 1.4807 - train_f1_macro: 0.4769 - val_f1_macro: 0.4341 - test_f1_macro: 0.4341 - mixed_f1_macro: 0.4341\n",
      "Epoch 19/500\n",
      " — train_f1=0.4650 | val_f1=0.3976 | test_f1=0.3976 | mixed_f1=0.3976\n",
      "38/38 - 5s - 133ms/step - accuracy: 0.4434 - loss: 1.2993 - val_accuracy: 0.3745 - val_loss: 1.4918 - train_f1_macro: 0.4650 - val_f1_macro: 0.3976 - test_f1_macro: 0.3976 - mixed_f1_macro: 0.3976\n",
      "Epoch 20/500\n",
      " — train_f1=0.3988 | val_f1=0.3763 | test_f1=0.3763 | mixed_f1=0.3763\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.4434 - loss: 1.2972 - val_accuracy: 0.3825 - val_loss: 1.5182 - train_f1_macro: 0.3988 - val_f1_macro: 0.3763 - test_f1_macro: 0.3763 - mixed_f1_macro: 0.3763\n",
      "Epoch 21/500\n",
      " — train_f1=0.3657 | val_f1=0.3097 | test_f1=0.3097 | mixed_f1=0.3097\n",
      "38/38 - 6s - 148ms/step - accuracy: 0.4485 - loss: 1.2876 - val_accuracy: 0.3665 - val_loss: 1.5243 - train_f1_macro: 0.3657 - val_f1_macro: 0.3097 - test_f1_macro: 0.3097 - mixed_f1_macro: 0.3097\n",
      "Epoch 22/500\n",
      " — train_f1=0.4659 | val_f1=0.3229 | test_f1=0.3229 | mixed_f1=0.3229\n",
      "38/38 - 10s - 272ms/step - accuracy: 0.4556 - loss: 1.2736 - val_accuracy: 0.3267 - val_loss: 1.5462 - train_f1_macro: 0.4659 - val_f1_macro: 0.3229 - test_f1_macro: 0.3229 - mixed_f1_macro: 0.3229\n",
      "Epoch 23/500\n",
      " — train_f1=0.5147 | val_f1=0.3836 | test_f1=0.3836 | mixed_f1=0.3836\n",
      "38/38 - 5s - 133ms/step - accuracy: 0.4581 - loss: 1.2679 - val_accuracy: 0.3705 - val_loss: 1.5090 - train_f1_macro: 0.5147 - val_f1_macro: 0.3836 - test_f1_macro: 0.3836 - mixed_f1_macro: 0.3836\n",
      "Epoch 24/500\n",
      " — train_f1=0.5354 | val_f1=0.3797 | test_f1=0.3797 | mixed_f1=0.3797\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.4800 - loss: 1.2708 - val_accuracy: 0.3625 - val_loss: 1.4676 - train_f1_macro: 0.5354 - val_f1_macro: 0.3797 - test_f1_macro: 0.3797 - mixed_f1_macro: 0.3797\n",
      "Epoch 25/500\n",
      " — train_f1=0.4278 | val_f1=0.4021 | test_f1=0.4021 | mixed_f1=0.4021\n",
      "38/38 - 6s - 150ms/step - accuracy: 0.4792 - loss: 1.2574 - val_accuracy: 0.4303 - val_loss: 1.5186 - train_f1_macro: 0.4278 - val_f1_macro: 0.4021 - test_f1_macro: 0.4021 - mixed_f1_macro: 0.4021\n",
      "Epoch 26/500\n",
      " — train_f1=0.4605 | val_f1=0.2996 | test_f1=0.2996 | mixed_f1=0.2996\n",
      "38/38 - 10s - 255ms/step - accuracy: 0.4893 - loss: 1.2482 - val_accuracy: 0.3147 - val_loss: 1.5441 - train_f1_macro: 0.4605 - val_f1_macro: 0.2996 - test_f1_macro: 0.2996 - mixed_f1_macro: 0.2996\n",
      "Epoch 27/500\n",
      " — train_f1=0.5695 | val_f1=0.3668 | test_f1=0.3668 | mixed_f1=0.3668\n",
      "38/38 - 11s - 280ms/step - accuracy: 0.4998 - loss: 1.2455 - val_accuracy: 0.3625 - val_loss: 1.4827 - train_f1_macro: 0.5695 - val_f1_macro: 0.3668 - test_f1_macro: 0.3668 - mixed_f1_macro: 0.3668\n",
      "Epoch 28/500\n",
      " — train_f1=0.3913 | val_f1=0.3794 | test_f1=0.3794 | mixed_f1=0.3794\n",
      "38/38 - 5s - 134ms/step - accuracy: 0.5002 - loss: 1.2401 - val_accuracy: 0.4263 - val_loss: 1.5713 - train_f1_macro: 0.3913 - val_f1_macro: 0.3794 - test_f1_macro: 0.3794 - mixed_f1_macro: 0.3794\n",
      "Epoch 29/500\n",
      " — train_f1=0.2564 | val_f1=0.2654 | test_f1=0.2654 | mixed_f1=0.2654\n",
      "38/38 - 5s - 132ms/step - accuracy: 0.5124 - loss: 1.2221 - val_accuracy: 0.2908 - val_loss: 1.8037 - train_f1_macro: 0.2564 - val_f1_macro: 0.2654 - test_f1_macro: 0.2654 - mixed_f1_macro: 0.2654\n",
      "Epoch 30/500\n",
      " — train_f1=0.6111 | val_f1=0.4287 | test_f1=0.4287 | mixed_f1=0.4287\n",
      "38/38 - 6s - 151ms/step - accuracy: 0.5221 - loss: 1.2363 - val_accuracy: 0.3984 - val_loss: 1.4942 - train_f1_macro: 0.6111 - val_f1_macro: 0.4287 - test_f1_macro: 0.4287 - mixed_f1_macro: 0.4287\n",
      "Epoch 31/500\n",
      " — train_f1=0.5630 | val_f1=0.3383 | test_f1=0.3383 | mixed_f1=0.3383\n",
      "38/38 - 10s - 270ms/step - accuracy: 0.5440 - loss: 1.2075 - val_accuracy: 0.3705 - val_loss: 1.4857 - train_f1_macro: 0.5630 - val_f1_macro: 0.3383 - test_f1_macro: 0.3383 - mixed_f1_macro: 0.3383\n",
      "Epoch 32/500\n",
      " — train_f1=0.5966 | val_f1=0.3867 | test_f1=0.3867 | mixed_f1=0.3867\n",
      "38/38 - 10s - 253ms/step - accuracy: 0.5515 - loss: 1.1980 - val_accuracy: 0.3625 - val_loss: 1.5035 - train_f1_macro: 0.5966 - val_f1_macro: 0.3867 - test_f1_macro: 0.3867 - mixed_f1_macro: 0.3867\n",
      "Epoch 33/500\n",
      " — train_f1=0.5191 | val_f1=0.2584 | test_f1=0.2584 | mixed_f1=0.2584\n",
      "38/38 - 5s - 138ms/step - accuracy: 0.5633 - loss: 1.2096 - val_accuracy: 0.2869 - val_loss: 1.5361 - train_f1_macro: 0.5191 - val_f1_macro: 0.2584 - test_f1_macro: 0.2584 - mixed_f1_macro: 0.2584\n",
      "Epoch 34/500\n",
      " — train_f1=0.3300 | val_f1=0.2905 | test_f1=0.2905 | mixed_f1=0.2905\n",
      "38/38 - 11s - 280ms/step - accuracy: 0.5511 - loss: 1.2008 - val_accuracy: 0.3028 - val_loss: 1.6642 - train_f1_macro: 0.3300 - val_f1_macro: 0.2905 - test_f1_macro: 0.2905 - mixed_f1_macro: 0.2905\n",
      "Epoch 35/500\n",
      " — train_f1=0.5034 | val_f1=0.3357 | test_f1=0.3357 | mixed_f1=0.3357\n",
      "38/38 - 5s - 135ms/step - accuracy: 0.5700 - loss: 1.1852 - val_accuracy: 0.3347 - val_loss: 1.5136 - train_f1_macro: 0.5034 - val_f1_macro: 0.3357 - test_f1_macro: 0.3357 - mixed_f1_macro: 0.3357\n",
      "Epoch 36/500\n",
      " — train_f1=0.5045 | val_f1=0.3720 | test_f1=0.3720 | mixed_f1=0.3720\n",
      "38/38 - 5s - 140ms/step - accuracy: 0.5738 - loss: 1.1785 - val_accuracy: 0.3586 - val_loss: 1.4942 - train_f1_macro: 0.5045 - val_f1_macro: 0.3720 - test_f1_macro: 0.3720 - mixed_f1_macro: 0.3720\n",
      "Epoch 37/500\n",
      " — train_f1=0.2594 | val_f1=0.2520 | test_f1=0.2520 | mixed_f1=0.2520\n",
      "38/38 - 10s - 263ms/step - accuracy: 0.5772 - loss: 1.1688 - val_accuracy: 0.2789 - val_loss: 1.7029 - train_f1_macro: 0.2594 - val_f1_macro: 0.2520 - test_f1_macro: 0.2520 - mixed_f1_macro: 0.2520\n",
      "Epoch 38/500\n",
      " — train_f1=0.4682 | val_f1=0.3627 | test_f1=0.3627 | mixed_f1=0.3627\n",
      "38/38 - 6s - 147ms/step - accuracy: 0.5890 - loss: 1.1620 - val_accuracy: 0.4303 - val_loss: 1.5283 - train_f1_macro: 0.4682 - val_f1_macro: 0.3627 - test_f1_macro: 0.3627 - mixed_f1_macro: 0.3627\n",
      "Epoch 39/500\n",
      " — train_f1=0.6480 | val_f1=0.4318 | test_f1=0.4318 | mixed_f1=0.4318\n",
      "38/38 - 10s - 255ms/step - accuracy: 0.5831 - loss: 1.1563 - val_accuracy: 0.4064 - val_loss: 1.4850 - train_f1_macro: 0.6480 - val_f1_macro: 0.4318 - test_f1_macro: 0.4318 - mixed_f1_macro: 0.4318\n",
      "Epoch 40/500\n",
      " — train_f1=0.5693 | val_f1=0.3882 | test_f1=0.3882 | mixed_f1=0.3882\n",
      "38/38 - 6s - 150ms/step - accuracy: 0.6058 - loss: 1.1509 - val_accuracy: 0.3665 - val_loss: 1.5818 - train_f1_macro: 0.5693 - val_f1_macro: 0.3882 - test_f1_macro: 0.3882 - mixed_f1_macro: 0.3882\n",
      "Epoch 41/500\n",
      " — train_f1=0.6114 | val_f1=0.4003 | test_f1=0.4003 | mixed_f1=0.4003\n",
      "38/38 - 6s - 150ms/step - accuracy: 0.6277 - loss: 1.1417 - val_accuracy: 0.3904 - val_loss: 1.4645 - train_f1_macro: 0.6114 - val_f1_macro: 0.4003 - test_f1_macro: 0.4003 - mixed_f1_macro: 0.4003\n",
      "Epoch 42/500\n",
      " — train_f1=0.5553 | val_f1=0.4001 | test_f1=0.4001 | mixed_f1=0.4001\n",
      "38/38 - 10s - 253ms/step - accuracy: 0.6218 - loss: 1.1227 - val_accuracy: 0.4024 - val_loss: 1.5457 - train_f1_macro: 0.5553 - val_f1_macro: 0.4001 - test_f1_macro: 0.4001 - mixed_f1_macro: 0.4001\n",
      "Epoch 43/500\n",
      " — train_f1=0.3730 | val_f1=0.3276 | test_f1=0.3276 | mixed_f1=0.3276\n",
      "38/38 - 5s - 132ms/step - accuracy: 0.6167 - loss: 1.1232 - val_accuracy: 0.3506 - val_loss: 1.8631 - train_f1_macro: 0.3730 - val_f1_macro: 0.3276 - test_f1_macro: 0.3276 - mixed_f1_macro: 0.3276\n",
      "Epoch 44/500\n",
      " — train_f1=0.6218 | val_f1=0.4057 | test_f1=0.4057 | mixed_f1=0.4057\n",
      "38/38 - 6s - 149ms/step - accuracy: 0.6239 - loss: 1.1261 - val_accuracy: 0.3785 - val_loss: 1.4881 - train_f1_macro: 0.6218 - val_f1_macro: 0.4057 - test_f1_macro: 0.4057 - mixed_f1_macro: 0.4057\n",
      "Epoch 45/500\n",
      " — train_f1=0.6193 | val_f1=0.4499 | test_f1=0.4499 | mixed_f1=0.4499\n",
      "38/38 - 5s - 134ms/step - accuracy: 0.6066 - loss: 1.1393 - val_accuracy: 0.4462 - val_loss: 1.4923 - train_f1_macro: 0.6193 - val_f1_macro: 0.4499 - test_f1_macro: 0.4499 - mixed_f1_macro: 0.4499\n",
      "\n",
      "Fold 4 FINAL (Mixed Test): ACC=0.4542 F1w=0.4483 MCC=0.3123\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 5  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2221, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (407, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (407, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.49520624303232996, 1: 0.6720121028744327, 2: 1.0378504672897195, 3: 4.151401869158878, 4: 3.4703125}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768198616.222107 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_5_1/dropout_25_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0430 | val_f1=0.0417 | test_f1=0.0417 | mixed_f1=0.0417\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0417\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch1_f10.0417_20260112_011704.h5\n",
      "35/35 - 10s - 281ms/step - accuracy: 0.2494 - loss: 1.9258 - val_accuracy: 0.0491 - val_loss: 2.1561 - train_f1_macro: 0.0430 - val_f1_macro: 0.0417 - test_f1_macro: 0.0417 - mixed_f1_macro: 0.0417\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0311 | val_f1=0.0575 | test_f1=0.0575 | mixed_f1=0.0575\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.0575\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch2_f10.0575_20260112_011711.h5\n",
      "35/35 - 7s - 212ms/step - accuracy: 0.2598 - loss: 1.7519 - val_accuracy: 0.0590 - val_loss: 2.5956 - train_f1_macro: 0.0311 - val_f1_macro: 0.0575 - test_f1_macro: 0.0575 - mixed_f1_macro: 0.0575\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0537 | val_f1=0.0640 | test_f1=0.0640 | mixed_f1=0.0640\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.0640\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch3_f10.0640_20260112_011717.h5\n",
      "35/35 - 6s - 165ms/step - accuracy: 0.3201 - loss: 1.5952 - val_accuracy: 0.0737 - val_loss: 3.0045 - train_f1_macro: 0.0537 - val_f1_macro: 0.0640 - test_f1_macro: 0.0640 - mixed_f1_macro: 0.0640\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1205 | val_f1=0.1237 | test_f1=0.1237 | mixed_f1=0.1237\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.1237\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch4_f10.1237_20260112_011726.h5\n",
      "35/35 - 10s - 274ms/step - accuracy: 0.3368 - loss: 1.5339 - val_accuracy: 0.1523 - val_loss: 2.5136 - train_f1_macro: 0.1205 - val_f1_macro: 0.1237 - test_f1_macro: 0.1237 - mixed_f1_macro: 0.1237\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1619 | val_f1=0.1583 | test_f1=0.1583 | mixed_f1=0.1583\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 5 | f1=0.1583\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch5_f10.1583_20260112_011732.h5\n",
      "35/35 - 6s - 164ms/step - accuracy: 0.3278 - loss: 1.5358 - val_accuracy: 0.1966 - val_loss: 2.3308 - train_f1_macro: 0.1619 - val_f1_macro: 0.1583 - test_f1_macro: 0.1583 - mixed_f1_macro: 0.1583\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2910 | val_f1=0.3465 | test_f1=0.3465 | mixed_f1=0.3465\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 6 | f1=0.3465\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch6_f10.3465_20260112_011742.h5\n",
      "35/35 - 10s - 281ms/step - accuracy: 0.3350 - loss: 1.4816 - val_accuracy: 0.4816 - val_loss: 1.4652 - train_f1_macro: 0.2910 - val_f1_macro: 0.3465 - test_f1_macro: 0.3465 - mixed_f1_macro: 0.3465\n",
      "Epoch 7/500\n",
      " — train_f1=0.2876 | val_f1=0.3034 | test_f1=0.3034 | mixed_f1=0.3034\n",
      "35/35 - 10s - 286ms/step - accuracy: 0.3354 - loss: 1.4654 - val_accuracy: 0.4152 - val_loss: 1.4791 - train_f1_macro: 0.2876 - val_f1_macro: 0.3034 - test_f1_macro: 0.3034 - mixed_f1_macro: 0.3034\n",
      "Epoch 8/500\n",
      " — train_f1=0.0860 | val_f1=0.1085 | test_f1=0.1085 | mixed_f1=0.1085\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.3215 - loss: 1.4432 - val_accuracy: 0.1130 - val_loss: 2.7432 - train_f1_macro: 0.0860 - val_f1_macro: 0.1085 - test_f1_macro: 0.1085 - mixed_f1_macro: 0.1085\n",
      "Epoch 9/500\n",
      " — train_f1=0.2852 | val_f1=0.3354 | test_f1=0.3354 | mixed_f1=0.3354\n",
      "35/35 - 6s - 163ms/step - accuracy: 0.3593 - loss: 1.4350 - val_accuracy: 0.4595 - val_loss: 1.4378 - train_f1_macro: 0.2852 - val_f1_macro: 0.3354 - test_f1_macro: 0.3354 - mixed_f1_macro: 0.3354\n",
      "Epoch 10/500\n",
      " — train_f1=0.2179 | val_f1=0.2691 | test_f1=0.2691 | mixed_f1=0.2691\n",
      "35/35 - 5s - 143ms/step - accuracy: 0.3575 - loss: 1.4099 - val_accuracy: 0.4545 - val_loss: 1.4551 - train_f1_macro: 0.2179 - val_f1_macro: 0.2691 - test_f1_macro: 0.2691 - mixed_f1_macro: 0.2691\n",
      "Epoch 11/500\n",
      " — train_f1=0.2197 | val_f1=0.3014 | test_f1=0.3014 | mixed_f1=0.3014\n",
      "35/35 - 5s - 138ms/step - accuracy: 0.3381 - loss: 1.4077 - val_accuracy: 0.4595 - val_loss: 1.4727 - train_f1_macro: 0.2197 - val_f1_macro: 0.3014 - test_f1_macro: 0.3014 - mixed_f1_macro: 0.3014\n",
      "Epoch 12/500\n",
      " — train_f1=0.3029 | val_f1=0.2533 | test_f1=0.2533 | mixed_f1=0.2533\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.3449 - loss: 1.3966 - val_accuracy: 0.3342 - val_loss: 1.4490 - train_f1_macro: 0.3029 - val_f1_macro: 0.2533 - test_f1_macro: 0.2533 - mixed_f1_macro: 0.2533\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3810 | val_f1=0.3498 | test_f1=0.3498 | mixed_f1=0.3498\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 13 | f1=0.3498\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch13_f10.3498_20260112_011823.h5\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.3539 - loss: 1.3874 - val_accuracy: 0.3784 - val_loss: 1.4329 - train_f1_macro: 0.3810 - val_f1_macro: 0.3498 - test_f1_macro: 0.3498 - mixed_f1_macro: 0.3498\n",
      "Epoch 14/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4071 | val_f1=0.3609 | test_f1=0.3609 | mixed_f1=0.3609\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 14 | f1=0.3609\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch14_f10.3609_20260112_011828.h5\n",
      "35/35 - 6s - 164ms/step - accuracy: 0.3656 - loss: 1.3620 - val_accuracy: 0.3808 - val_loss: 1.4317 - train_f1_macro: 0.4071 - val_f1_macro: 0.3609 - test_f1_macro: 0.3609 - mixed_f1_macro: 0.3609\n",
      "Epoch 15/500\n",
      " — train_f1=0.3523 | val_f1=0.3064 | test_f1=0.3064 | mixed_f1=0.3064\n",
      "35/35 - 10s - 290ms/step - accuracy: 0.3728 - loss: 1.3521 - val_accuracy: 0.3317 - val_loss: 1.5368 - train_f1_macro: 0.3523 - val_f1_macro: 0.3064 - test_f1_macro: 0.3064 - mixed_f1_macro: 0.3064\n",
      "Epoch 16/500\n",
      " — train_f1=0.3390 | val_f1=0.3472 | test_f1=0.3472 | mixed_f1=0.3472\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.3602 - loss: 1.3427 - val_accuracy: 0.4521 - val_loss: 1.3780 - train_f1_macro: 0.3390 - val_f1_macro: 0.3472 - test_f1_macro: 0.3472 - mixed_f1_macro: 0.3472\n",
      "Epoch 17/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3529 | val_f1=0.3857 | test_f1=0.3857 | mixed_f1=0.3857\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 17 | f1=0.3857\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch17_f10.3857_20260112_011849.h5\n",
      "35/35 - 6s - 166ms/step - accuracy: 0.4070 - loss: 1.3474 - val_accuracy: 0.5012 - val_loss: 1.3632 - train_f1_macro: 0.3529 - val_f1_macro: 0.3857 - test_f1_macro: 0.3857 - mixed_f1_macro: 0.3857\n",
      "Epoch 18/500\n",
      " — train_f1=0.3872 | val_f1=0.3543 | test_f1=0.3543 | mixed_f1=0.3543\n",
      "35/35 - 10s - 272ms/step - accuracy: 0.3994 - loss: 1.3300 - val_accuracy: 0.4005 - val_loss: 1.3879 - train_f1_macro: 0.3872 - val_f1_macro: 0.3543 - test_f1_macro: 0.3543 - mixed_f1_macro: 0.3543\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4966 | val_f1=0.4445 | test_f1=0.4445 | mixed_f1=0.4445\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 19 | f1=0.4445\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch19_f10.4445_20260112_011904.h5\n",
      "35/35 - 6s - 159ms/step - accuracy: 0.3863 - loss: 1.3314 - val_accuracy: 0.4177 - val_loss: 1.3951 - train_f1_macro: 0.4966 - val_f1_macro: 0.4445 - test_f1_macro: 0.4445 - mixed_f1_macro: 0.4445\n",
      "Epoch 20/500\n",
      " — train_f1=0.3743 | val_f1=0.2979 | test_f1=0.2979 | mixed_f1=0.2979\n",
      "35/35 - 10s - 276ms/step - accuracy: 0.3980 - loss: 1.3182 - val_accuracy: 0.2875 - val_loss: 1.5610 - train_f1_macro: 0.3743 - val_f1_macro: 0.2979 - test_f1_macro: 0.2979 - mixed_f1_macro: 0.2979\n",
      "Epoch 21/500\n",
      " — train_f1=0.3377 | val_f1=0.4048 | test_f1=0.4048 | mixed_f1=0.4048\n",
      "35/35 - 5s - 142ms/step - accuracy: 0.4120 - loss: 1.3038 - val_accuracy: 0.5135 - val_loss: 1.3545 - train_f1_macro: 0.3377 - val_f1_macro: 0.4048 - test_f1_macro: 0.4048 - mixed_f1_macro: 0.4048\n",
      "Epoch 22/500\n",
      " — train_f1=0.3664 | val_f1=0.4173 | test_f1=0.4173 | mixed_f1=0.4173\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.4210 - loss: 1.2961 - val_accuracy: 0.5233 - val_loss: 1.3470 - train_f1_macro: 0.3664 - val_f1_macro: 0.4173 - test_f1_macro: 0.4173 - mixed_f1_macro: 0.4173\n",
      "Epoch 23/500\n",
      " — train_f1=0.4063 | val_f1=0.3999 | test_f1=0.3999 | mixed_f1=0.3999\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.4318 - loss: 1.2865 - val_accuracy: 0.4742 - val_loss: 1.3500 - train_f1_macro: 0.4063 - val_f1_macro: 0.3999 - test_f1_macro: 0.3999 - mixed_f1_macro: 0.3999\n",
      "Epoch 24/500\n",
      " — train_f1=0.2449 | val_f1=0.2980 | test_f1=0.2980 | mixed_f1=0.2980\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.4111 - loss: 1.2772 - val_accuracy: 0.4545 - val_loss: 1.5047 - train_f1_macro: 0.2449 - val_f1_macro: 0.2980 - test_f1_macro: 0.2980 - mixed_f1_macro: 0.2980\n",
      "Epoch 25/500\n",
      " — train_f1=0.3944 | val_f1=0.3145 | test_f1=0.3145 | mixed_f1=0.3145\n",
      "35/35 - 5s - 157ms/step - accuracy: 0.4327 - loss: 1.2616 - val_accuracy: 0.2752 - val_loss: 1.5333 - train_f1_macro: 0.3944 - val_f1_macro: 0.3145 - test_f1_macro: 0.3145 - mixed_f1_macro: 0.3145\n",
      "Epoch 26/500\n",
      " — train_f1=0.4869 | val_f1=0.3606 | test_f1=0.3606 | mixed_f1=0.3606\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.4358 - loss: 1.2553 - val_accuracy: 0.3047 - val_loss: 1.5090 - train_f1_macro: 0.4869 - val_f1_macro: 0.3606 - test_f1_macro: 0.3606 - mixed_f1_macro: 0.3606\n",
      "Epoch 27/500\n",
      " — train_f1=0.4407 | val_f1=0.2788 | test_f1=0.2788 | mixed_f1=0.2788\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.4777 - loss: 1.2306 - val_accuracy: 0.2776 - val_loss: 1.5149 - train_f1_macro: 0.4407 - val_f1_macro: 0.2788 - test_f1_macro: 0.2788 - mixed_f1_macro: 0.2788\n",
      "Epoch 28/500\n",
      " — train_f1=0.5230 | val_f1=0.3745 | test_f1=0.3745 | mixed_f1=0.3745\n",
      "35/35 - 6s - 160ms/step - accuracy: 0.4381 - loss: 1.2449 - val_accuracy: 0.3071 - val_loss: 1.4738 - train_f1_macro: 0.5230 - val_f1_macro: 0.3745 - test_f1_macro: 0.3745 - mixed_f1_macro: 0.3745\n",
      "Epoch 29/500\n",
      " — train_f1=0.5546 | val_f1=0.4290 | test_f1=0.4290 | mixed_f1=0.4290\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.4755 - loss: 1.2288 - val_accuracy: 0.3907 - val_loss: 1.4072 - train_f1_macro: 0.5546 - val_f1_macro: 0.4290 - test_f1_macro: 0.4290 - mixed_f1_macro: 0.4290\n",
      "Epoch 30/500\n",
      " — train_f1=0.5149 | val_f1=0.4052 | test_f1=0.4052 | mixed_f1=0.4052\n",
      "35/35 - 5s - 148ms/step - accuracy: 0.4561 - loss: 1.2217 - val_accuracy: 0.3391 - val_loss: 1.4749 - train_f1_macro: 0.5149 - val_f1_macro: 0.4052 - test_f1_macro: 0.4052 - mixed_f1_macro: 0.4052\n",
      "Epoch 31/500\n",
      " — train_f1=0.5330 | val_f1=0.3818 | test_f1=0.3818 | mixed_f1=0.3818\n",
      "35/35 - 6s - 160ms/step - accuracy: 0.4867 - loss: 1.2150 - val_accuracy: 0.3489 - val_loss: 1.4582 - train_f1_macro: 0.5330 - val_f1_macro: 0.3818 - test_f1_macro: 0.3818 - mixed_f1_macro: 0.3818\n",
      "Epoch 32/500\n",
      " — train_f1=0.3668 | val_f1=0.3741 | test_f1=0.3741 | mixed_f1=0.3741\n",
      "35/35 - 10s - 294ms/step - accuracy: 0.4782 - loss: 1.2252 - val_accuracy: 0.4889 - val_loss: 1.3547 - train_f1_macro: 0.3668 - val_f1_macro: 0.3741 - test_f1_macro: 0.3741 - mixed_f1_macro: 0.3741\n",
      "Epoch 33/500\n",
      " — train_f1=0.4924 | val_f1=0.4168 | test_f1=0.4168 | mixed_f1=0.4168\n",
      "35/35 - 10s - 290ms/step - accuracy: 0.4849 - loss: 1.1968 - val_accuracy: 0.4275 - val_loss: 1.3856 - train_f1_macro: 0.4924 - val_f1_macro: 0.4168 - test_f1_macro: 0.4168 - mixed_f1_macro: 0.4168\n",
      "Epoch 34/500\n",
      " — train_f1=0.5514 | val_f1=0.3860 | test_f1=0.3860 | mixed_f1=0.3860\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.4791 - loss: 1.2112 - val_accuracy: 0.3145 - val_loss: 1.5093 - train_f1_macro: 0.5514 - val_f1_macro: 0.3860 - test_f1_macro: 0.3860 - mixed_f1_macro: 0.3860\n",
      "Epoch 35/500\n",
      " — train_f1=0.0647 | val_f1=0.1141 | test_f1=0.1141 | mixed_f1=0.1141\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.4935 - loss: 1.2017 - val_accuracy: 0.3980 - val_loss: 1.8188 - train_f1_macro: 0.0647 - val_f1_macro: 0.1141 - test_f1_macro: 0.1141 - mixed_f1_macro: 0.1141\n",
      "Epoch 36/500\n",
      " — train_f1=0.0676 | val_f1=0.1157 | test_f1=0.1157 | mixed_f1=0.1157\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.5011 - loss: 1.1897 - val_accuracy: 0.3931 - val_loss: 1.7949 - train_f1_macro: 0.0676 - val_f1_macro: 0.1157 - test_f1_macro: 0.1157 - mixed_f1_macro: 0.1157\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5238 | val_f1=0.4631 | test_f1=0.4631 | mixed_f1=0.4631\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 37 | f1=0.4631\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch37_f10.4631_20260112_012101.h5\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.4980 - loss: 1.1773 - val_accuracy: 0.4545 - val_loss: 1.3698 - train_f1_macro: 0.5238 - val_f1_macro: 0.4631 - test_f1_macro: 0.4631 - mixed_f1_macro: 0.4631\n",
      "Epoch 38/500\n",
      " — train_f1=0.3018 | val_f1=0.3201 | test_f1=0.3201 | mixed_f1=0.3201\n",
      "35/35 - 5s - 144ms/step - accuracy: 0.5160 - loss: 1.1637 - val_accuracy: 0.2826 - val_loss: 1.6943 - train_f1_macro: 0.3018 - val_f1_macro: 0.3201 - test_f1_macro: 0.3201 - mixed_f1_macro: 0.3201\n",
      "Epoch 39/500\n",
      " — train_f1=0.5972 | val_f1=0.4392 | test_f1=0.4392 | mixed_f1=0.4392\n",
      "35/35 - 6s - 165ms/step - accuracy: 0.5070 - loss: 1.1723 - val_accuracy: 0.3710 - val_loss: 1.5063 - train_f1_macro: 0.5972 - val_f1_macro: 0.4392 - test_f1_macro: 0.4392 - mixed_f1_macro: 0.4392\n",
      "Epoch 40/500\n",
      " — train_f1=0.6026 | val_f1=0.4022 | test_f1=0.4022 | mixed_f1=0.4022\n",
      "35/35 - 10s - 273ms/step - accuracy: 0.5326 - loss: 1.1528 - val_accuracy: 0.3538 - val_loss: 1.4578 - train_f1_macro: 0.6026 - val_f1_macro: 0.4022 - test_f1_macro: 0.4022 - mixed_f1_macro: 0.4022\n",
      "Epoch 41/500\n",
      " — train_f1=0.3526 | val_f1=0.3508 | test_f1=0.3508 | mixed_f1=0.3508\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.5304 - loss: 1.1340 - val_accuracy: 0.4644 - val_loss: 1.4801 - train_f1_macro: 0.3526 - val_f1_macro: 0.3508 - test_f1_macro: 0.3508 - mixed_f1_macro: 0.3508\n",
      "Epoch 42/500\n",
      " — train_f1=0.6116 | val_f1=0.4310 | test_f1=0.4310 | mixed_f1=0.4310\n",
      "35/35 - 6s - 158ms/step - accuracy: 0.5326 - loss: 1.1745 - val_accuracy: 0.3857 - val_loss: 1.4279 - train_f1_macro: 0.6116 - val_f1_macro: 0.4310 - test_f1_macro: 0.4310 - mixed_f1_macro: 0.4310\n",
      "Epoch 43/500\n",
      " — train_f1=0.4052 | val_f1=0.3814 | test_f1=0.3814 | mixed_f1=0.3814\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.5480 - loss: 1.1266 - val_accuracy: 0.3342 - val_loss: 1.6143 - train_f1_macro: 0.4052 - val_f1_macro: 0.3814 - test_f1_macro: 0.3814 - mixed_f1_macro: 0.3814\n",
      "Epoch 44/500\n",
      " — train_f1=0.4501 | val_f1=0.3747 | test_f1=0.3747 | mixed_f1=0.3747\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.5556 - loss: 1.1310 - val_accuracy: 0.4398 - val_loss: 1.4001 - train_f1_macro: 0.4501 - val_f1_macro: 0.3747 - test_f1_macro: 0.3747 - mixed_f1_macro: 0.3747\n",
      "Epoch 45/500\n",
      " — train_f1=0.6339 | val_f1=0.3972 | test_f1=0.3972 | mixed_f1=0.3972\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.5452 - loss: 1.1226 - val_accuracy: 0.3759 - val_loss: 1.4679 - train_f1_macro: 0.6339 - val_f1_macro: 0.3972 - test_f1_macro: 0.3972 - mixed_f1_macro: 0.3972\n",
      "Epoch 46/500\n",
      " — train_f1=0.6107 | val_f1=0.4571 | test_f1=0.4571 | mixed_f1=0.4571\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.5678 - loss: 1.1102 - val_accuracy: 0.4054 - val_loss: 1.4360 - train_f1_macro: 0.6107 - val_f1_macro: 0.4571 - test_f1_macro: 0.4571 - mixed_f1_macro: 0.4571\n",
      "Epoch 47/500\n",
      " — train_f1=0.5318 | val_f1=0.4103 | test_f1=0.4103 | mixed_f1=0.4103\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.5723 - loss: 1.0935 - val_accuracy: 0.3587 - val_loss: 1.5581 - train_f1_macro: 0.5318 - val_f1_macro: 0.4103 - test_f1_macro: 0.4103 - mixed_f1_macro: 0.4103\n",
      "Epoch 48/500\n",
      " — train_f1=0.3489 | val_f1=0.3518 | test_f1=0.3518 | mixed_f1=0.3518\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.5921 - loss: 1.1077 - val_accuracy: 0.4177 - val_loss: 1.5160 - train_f1_macro: 0.3489 - val_f1_macro: 0.3518 - test_f1_macro: 0.3518 - mixed_f1_macro: 0.3518\n",
      "Epoch 49/500\n",
      " — train_f1=0.5262 | val_f1=0.3748 | test_f1=0.3748 | mixed_f1=0.3748\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.5768 - loss: 1.1074 - val_accuracy: 0.3686 - val_loss: 1.4530 - train_f1_macro: 0.5262 - val_f1_macro: 0.3748 - test_f1_macro: 0.3748 - mixed_f1_macro: 0.3748\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6302 | val_f1=0.4770 | test_f1=0.4770 | mixed_f1=0.4770\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 50 | f1=0.4770\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch50_f10.4770_20260112_012217.h5\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.5714 - loss: 1.1084 - val_accuracy: 0.4889 - val_loss: 1.3561 - train_f1_macro: 0.6302 - val_f1_macro: 0.4770 - test_f1_macro: 0.4770 - mixed_f1_macro: 0.4770\n",
      "Epoch 51/500\n",
      " — train_f1=0.6423 | val_f1=0.4195 | test_f1=0.4195 | mixed_f1=0.4195\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.5826 - loss: 1.0820 - val_accuracy: 0.3489 - val_loss: 1.6050 - train_f1_macro: 0.6423 - val_f1_macro: 0.4195 - test_f1_macro: 0.4195 - mixed_f1_macro: 0.4195\n",
      "Epoch 52/500\n",
      " — train_f1=0.6521 | val_f1=0.4406 | test_f1=0.4406 | mixed_f1=0.4406\n",
      "35/35 - 6s - 166ms/step - accuracy: 0.6114 - loss: 1.0846 - val_accuracy: 0.3636 - val_loss: 1.5656 - train_f1_macro: 0.6521 - val_f1_macro: 0.4406 - test_f1_macro: 0.4406 - mixed_f1_macro: 0.4406\n",
      "Epoch 53/500\n",
      " — train_f1=0.6237 | val_f1=0.4325 | test_f1=0.4325 | mixed_f1=0.4325\n",
      "35/35 - 10s - 288ms/step - accuracy: 0.6119 - loss: 1.0745 - val_accuracy: 0.3366 - val_loss: 1.6977 - train_f1_macro: 0.6237 - val_f1_macro: 0.4325 - test_f1_macro: 0.4325 - mixed_f1_macro: 0.4325\n",
      "Epoch 54/500\n",
      " — train_f1=0.6057 | val_f1=0.3815 | test_f1=0.3815 | mixed_f1=0.3815\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.6002 - loss: 1.0981 - val_accuracy: 0.3735 - val_loss: 1.4437 - train_f1_macro: 0.6057 - val_f1_macro: 0.3815 - test_f1_macro: 0.3815 - mixed_f1_macro: 0.3815\n",
      "Epoch 55/500\n",
      " — train_f1=0.5256 | val_f1=0.4238 | test_f1=0.4238 | mixed_f1=0.4238\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.6015 - loss: 1.0709 - val_accuracy: 0.4791 - val_loss: 1.4101 - train_f1_macro: 0.5256 - val_f1_macro: 0.4238 - test_f1_macro: 0.4238 - mixed_f1_macro: 0.4238\n",
      "Epoch 56/500\n",
      " — train_f1=0.6773 | val_f1=0.4546 | test_f1=0.4546 | mixed_f1=0.4546\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6263 - loss: 1.0649 - val_accuracy: 0.4079 - val_loss: 1.4477 - train_f1_macro: 0.6773 - val_f1_macro: 0.4546 - test_f1_macro: 0.4546 - mixed_f1_macro: 0.4546\n",
      "Epoch 57/500\n",
      " — train_f1=0.6994 | val_f1=0.4539 | test_f1=0.4539 | mixed_f1=0.4539\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6276 - loss: 1.0519 - val_accuracy: 0.3735 - val_loss: 1.5325 - train_f1_macro: 0.6994 - val_f1_macro: 0.4539 - test_f1_macro: 0.4539 - mixed_f1_macro: 0.4539\n",
      "Epoch 58/500\n",
      " — train_f1=0.7435 | val_f1=0.4309 | test_f1=0.4309 | mixed_f1=0.4309\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6376 - loss: 1.0360 - val_accuracy: 0.3587 - val_loss: 1.5059 - train_f1_macro: 0.7435 - val_f1_macro: 0.4309 - test_f1_macro: 0.4309 - mixed_f1_macro: 0.4309\n",
      "Epoch 59/500\n",
      " — train_f1=0.4533 | val_f1=0.4030 | test_f1=0.4030 | mixed_f1=0.4030\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6538 - loss: 1.0475 - val_accuracy: 0.4693 - val_loss: 1.4107 - train_f1_macro: 0.4533 - val_f1_macro: 0.4030 - test_f1_macro: 0.4030 - mixed_f1_macro: 0.4030\n",
      "Epoch 60/500\n",
      " — train_f1=0.7105 | val_f1=0.4282 | test_f1=0.4282 | mixed_f1=0.4282\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.6515 - loss: 1.0386 - val_accuracy: 0.3587 - val_loss: 1.4962 - train_f1_macro: 0.7105 - val_f1_macro: 0.4282 - test_f1_macro: 0.4282 - mixed_f1_macro: 0.4282\n",
      "Epoch 61/500\n",
      " — train_f1=0.5379 | val_f1=0.3977 | test_f1=0.3977 | mixed_f1=0.3977\n",
      "35/35 - 5s - 149ms/step - accuracy: 0.6605 - loss: 1.0387 - val_accuracy: 0.3194 - val_loss: 1.6360 - train_f1_macro: 0.5379 - val_f1_macro: 0.3977 - test_f1_macro: 0.3977 - mixed_f1_macro: 0.3977\n",
      "Epoch 62/500\n",
      " — train_f1=0.4983 | val_f1=0.4173 | test_f1=0.4173 | mixed_f1=0.4173\n",
      "35/35 - 5s - 143ms/step - accuracy: 0.6614 - loss: 1.0031 - val_accuracy: 0.4693 - val_loss: 1.4617 - train_f1_macro: 0.4983 - val_f1_macro: 0.4173 - test_f1_macro: 0.4173 - mixed_f1_macro: 0.4173\n",
      "Epoch 63/500\n",
      " — train_f1=0.6232 | val_f1=0.3377 | test_f1=0.3377 | mixed_f1=0.3377\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6808 - loss: 0.9965 - val_accuracy: 0.3464 - val_loss: 1.5866 - train_f1_macro: 0.6232 - val_f1_macro: 0.3377 - test_f1_macro: 0.3377 - mixed_f1_macro: 0.3377\n",
      "Epoch 64/500\n",
      " — train_f1=0.4715 | val_f1=0.3728 | test_f1=0.3728 | mixed_f1=0.3728\n",
      "35/35 - 5s - 138ms/step - accuracy: 0.6709 - loss: 1.0039 - val_accuracy: 0.3071 - val_loss: 1.8797 - train_f1_macro: 0.4715 - val_f1_macro: 0.3728 - test_f1_macro: 0.3728 - mixed_f1_macro: 0.3728\n",
      "Epoch 65/500\n",
      " — train_f1=0.6197 | val_f1=0.3889 | test_f1=0.3889 | mixed_f1=0.3889\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6745 - loss: 0.9852 - val_accuracy: 0.3784 - val_loss: 1.5161 - train_f1_macro: 0.6197 - val_f1_macro: 0.3889 - test_f1_macro: 0.3889 - mixed_f1_macro: 0.3889\n",
      "Epoch 66/500\n",
      " — train_f1=0.5933 | val_f1=0.4031 | test_f1=0.4031 | mixed_f1=0.4031\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.6866 - loss: 0.9952 - val_accuracy: 0.3342 - val_loss: 1.7205 - train_f1_macro: 0.5933 - val_f1_macro: 0.4031 - test_f1_macro: 0.4031 - mixed_f1_macro: 0.4031\n",
      "Epoch 67/500\n",
      " — train_f1=0.3711 | val_f1=0.3030 | test_f1=0.3030 | mixed_f1=0.3030\n",
      "35/35 - 5s - 148ms/step - accuracy: 0.6803 - loss: 0.9921 - val_accuracy: 0.2531 - val_loss: 1.8573 - train_f1_macro: 0.3711 - val_f1_macro: 0.3030 - test_f1_macro: 0.3030 - mixed_f1_macro: 0.3030\n",
      "Epoch 68/500\n",
      " — train_f1=0.7598 | val_f1=0.4603 | test_f1=0.4603 | mixed_f1=0.4603\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.6826 - loss: 0.9921 - val_accuracy: 0.3808 - val_loss: 1.5819 - train_f1_macro: 0.7598 - val_f1_macro: 0.4603 - test_f1_macro: 0.4603 - mixed_f1_macro: 0.4603\n",
      "Epoch 69/500\n",
      " — train_f1=0.6740 | val_f1=0.3999 | test_f1=0.3999 | mixed_f1=0.3999\n",
      "35/35 - 5s - 148ms/step - accuracy: 0.6862 - loss: 0.9788 - val_accuracy: 0.3759 - val_loss: 1.5653 - train_f1_macro: 0.6740 - val_f1_macro: 0.3999 - test_f1_macro: 0.3999 - mixed_f1_macro: 0.3999\n",
      "Epoch 70/500\n",
      " — train_f1=0.7209 | val_f1=0.4554 | test_f1=0.4554 | mixed_f1=0.4554\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.6799 - loss: 0.9906 - val_accuracy: 0.4177 - val_loss: 1.4866 - train_f1_macro: 0.7209 - val_f1_macro: 0.4554 - test_f1_macro: 0.4554 - mixed_f1_macro: 0.4554\n",
      "Epoch 71/500\n",
      " — train_f1=0.6965 | val_f1=0.4641 | test_f1=0.4641 | mixed_f1=0.4641\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.6911 - loss: 0.9715 - val_accuracy: 0.3710 - val_loss: 1.6258 - train_f1_macro: 0.6965 - val_f1_macro: 0.4641 - test_f1_macro: 0.4641 - mixed_f1_macro: 0.4641\n",
      "Epoch 72/500\n",
      " — train_f1=0.7285 | val_f1=0.3949 | test_f1=0.3949 | mixed_f1=0.3949\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.7213 - loss: 0.9536 - val_accuracy: 0.3563 - val_loss: 1.6061 - train_f1_macro: 0.7285 - val_f1_macro: 0.3949 - test_f1_macro: 0.3949 - mixed_f1_macro: 0.3949\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7215 | val_f1=0.5149 | test_f1=0.5149 | mixed_f1=0.5149\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 73 | f1=0.5149\n",
      "   → saved_models/merged_fold_5/best_val_f1_macro_epoch73_f10.5149_20260112_012420.h5\n",
      "35/35 - 6s - 164ms/step - accuracy: 0.7109 - loss: 0.9732 - val_accuracy: 0.4570 - val_loss: 1.4621 - train_f1_macro: 0.7215 - val_f1_macro: 0.5149 - test_f1_macro: 0.5149 - mixed_f1_macro: 0.5149\n",
      "Epoch 74/500\n",
      " — train_f1=0.7457 | val_f1=0.4168 | test_f1=0.4168 | mixed_f1=0.4168\n",
      "35/35 - 10s - 291ms/step - accuracy: 0.7006 - loss: 0.9850 - val_accuracy: 0.3907 - val_loss: 1.5150 - train_f1_macro: 0.7457 - val_f1_macro: 0.4168 - test_f1_macro: 0.4168 - mixed_f1_macro: 0.4168\n",
      "Epoch 75/500\n",
      " — train_f1=0.4094 | val_f1=0.3556 | test_f1=0.3556 | mixed_f1=0.3556\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.7159 - loss: 0.9534 - val_accuracy: 0.2875 - val_loss: 1.8806 - train_f1_macro: 0.4094 - val_f1_macro: 0.3556 - test_f1_macro: 0.3556 - mixed_f1_macro: 0.3556\n",
      "Epoch 76/500\n",
      " — train_f1=0.7890 | val_f1=0.4840 | test_f1=0.4840 | mixed_f1=0.4840\n",
      "35/35 - 5s - 147ms/step - accuracy: 0.7249 - loss: 0.9467 - val_accuracy: 0.4054 - val_loss: 1.5821 - train_f1_macro: 0.7890 - val_f1_macro: 0.4840 - test_f1_macro: 0.4840 - mixed_f1_macro: 0.4840\n",
      "Epoch 77/500\n",
      " — train_f1=0.7778 | val_f1=0.4684 | test_f1=0.4684 | mixed_f1=0.4684\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.7240 - loss: 0.9486 - val_accuracy: 0.3808 - val_loss: 1.6242 - train_f1_macro: 0.7778 - val_f1_macro: 0.4684 - test_f1_macro: 0.4684 - mixed_f1_macro: 0.4684\n",
      "Epoch 78/500\n",
      " — train_f1=0.7583 | val_f1=0.5008 | test_f1=0.5008 | mixed_f1=0.5008\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.7402 - loss: 0.9233 - val_accuracy: 0.4472 - val_loss: 1.5547 - train_f1_macro: 0.7583 - val_f1_macro: 0.5008 - test_f1_macro: 0.5008 - mixed_f1_macro: 0.5008\n",
      "Epoch 79/500\n",
      " — train_f1=0.3987 | val_f1=0.2981 | test_f1=0.2981 | mixed_f1=0.2981\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.7127 - loss: 0.9350 - val_accuracy: 0.2776 - val_loss: 1.8863 - train_f1_macro: 0.3987 - val_f1_macro: 0.2981 - test_f1_macro: 0.2981 - mixed_f1_macro: 0.2981\n",
      "Epoch 80/500\n",
      " — train_f1=0.6806 | val_f1=0.4578 | test_f1=0.4578 | mixed_f1=0.4578\n",
      "35/35 - 5s - 156ms/step - accuracy: 0.7357 - loss: 0.9401 - val_accuracy: 0.3563 - val_loss: 1.7346 - train_f1_macro: 0.6806 - val_f1_macro: 0.4578 - test_f1_macro: 0.4578 - mixed_f1_macro: 0.4578\n",
      "Epoch 81/500\n",
      " — train_f1=0.8068 | val_f1=0.4515 | test_f1=0.4515 | mixed_f1=0.4515\n",
      "35/35 - 10s - 292ms/step - accuracy: 0.7555 - loss: 0.9150 - val_accuracy: 0.3931 - val_loss: 1.6644 - train_f1_macro: 0.8068 - val_f1_macro: 0.4515 - test_f1_macro: 0.4515 - mixed_f1_macro: 0.4515\n",
      "Epoch 82/500\n",
      " — train_f1=0.8160 | val_f1=0.4373 | test_f1=0.4373 | mixed_f1=0.4373\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.7546 - loss: 0.9002 - val_accuracy: 0.3661 - val_loss: 1.6920 - train_f1_macro: 0.8160 - val_f1_macro: 0.4373 - test_f1_macro: 0.4373 - mixed_f1_macro: 0.4373\n",
      "Epoch 83/500\n",
      " — train_f1=0.6945 | val_f1=0.4154 | test_f1=0.4154 | mixed_f1=0.4154\n",
      "35/35 - 5s - 156ms/step - accuracy: 0.7578 - loss: 0.9084 - val_accuracy: 0.4177 - val_loss: 1.5945 - train_f1_macro: 0.6945 - val_f1_macro: 0.4154 - test_f1_macro: 0.4154 - mixed_f1_macro: 0.4154\n",
      "Epoch 84/500\n",
      " — train_f1=0.8092 | val_f1=0.4497 | test_f1=0.4497 | mixed_f1=0.4497\n",
      "35/35 - 10s - 275ms/step - accuracy: 0.7321 - loss: 0.9143 - val_accuracy: 0.3784 - val_loss: 1.6089 - train_f1_macro: 0.8092 - val_f1_macro: 0.4497 - test_f1_macro: 0.4497 - mixed_f1_macro: 0.4497\n",
      "Epoch 85/500\n",
      " — train_f1=0.8220 | val_f1=0.4342 | test_f1=0.4342 | mixed_f1=0.4342\n",
      "35/35 - 5s - 156ms/step - accuracy: 0.7605 - loss: 0.9052 - val_accuracy: 0.3784 - val_loss: 1.7164 - train_f1_macro: 0.8220 - val_f1_macro: 0.4342 - test_f1_macro: 0.4342 - mixed_f1_macro: 0.4342\n",
      "Epoch 86/500\n",
      " — train_f1=0.4906 | val_f1=0.3853 | test_f1=0.3853 | mixed_f1=0.3853\n",
      "35/35 - 10s - 274ms/step - accuracy: 0.7389 - loss: 0.9294 - val_accuracy: 0.3120 - val_loss: 2.0060 - train_f1_macro: 0.4906 - val_f1_macro: 0.3853 - test_f1_macro: 0.3853 - mixed_f1_macro: 0.3853\n",
      "Epoch 87/500\n",
      " — train_f1=0.4671 | val_f1=0.3523 | test_f1=0.3523 | mixed_f1=0.3523\n",
      "35/35 - 5s - 140ms/step - accuracy: 0.7375 - loss: 0.9449 - val_accuracy: 0.2973 - val_loss: 1.9738 - train_f1_macro: 0.4671 - val_f1_macro: 0.3523 - test_f1_macro: 0.3523 - mixed_f1_macro: 0.3523\n",
      "Epoch 88/500\n",
      " — train_f1=0.6026 | val_f1=0.4277 | test_f1=0.4277 | mixed_f1=0.4277\n",
      "35/35 - 5s - 144ms/step - accuracy: 0.7420 - loss: 0.9280 - val_accuracy: 0.3440 - val_loss: 1.8026 - train_f1_macro: 0.6026 - val_f1_macro: 0.4277 - test_f1_macro: 0.4277 - mixed_f1_macro: 0.4277\n",
      "Epoch 89/500\n",
      " — train_f1=0.4375 | val_f1=0.3673 | test_f1=0.3673 | mixed_f1=0.3673\n",
      "35/35 - 5s - 143ms/step - accuracy: 0.7591 - loss: 0.8885 - val_accuracy: 0.3071 - val_loss: 2.0154 - train_f1_macro: 0.4375 - val_f1_macro: 0.3673 - test_f1_macro: 0.3673 - mixed_f1_macro: 0.3673\n",
      "Epoch 90/500\n",
      " — train_f1=0.8017 | val_f1=0.4471 | test_f1=0.4471 | mixed_f1=0.4471\n",
      "35/35 - 5s - 142ms/step - accuracy: 0.7663 - loss: 0.8839 - val_accuracy: 0.3759 - val_loss: 1.7313 - train_f1_macro: 0.8017 - val_f1_macro: 0.4471 - test_f1_macro: 0.4471 - mixed_f1_macro: 0.4471\n",
      "Epoch 91/500\n",
      " — train_f1=0.8334 | val_f1=0.4857 | test_f1=0.4857 | mixed_f1=0.4857\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.7668 - loss: 0.8969 - val_accuracy: 0.4275 - val_loss: 1.6638 - train_f1_macro: 0.8334 - val_f1_macro: 0.4857 - test_f1_macro: 0.4857 - mixed_f1_macro: 0.4857\n",
      "Epoch 92/500\n",
      " — train_f1=0.7822 | val_f1=0.4575 | test_f1=0.4575 | mixed_f1=0.4575\n",
      "35/35 - 6s - 157ms/step - accuracy: 0.7807 - loss: 0.8737 - val_accuracy: 0.3735 - val_loss: 1.7457 - train_f1_macro: 0.7822 - val_f1_macro: 0.4575 - test_f1_macro: 0.4575 - mixed_f1_macro: 0.4575\n",
      "Epoch 93/500\n",
      " — train_f1=0.5996 | val_f1=0.3763 | test_f1=0.3763 | mixed_f1=0.3763\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.7731 - loss: 0.8943 - val_accuracy: 0.3292 - val_loss: 1.8519 - train_f1_macro: 0.5996 - val_f1_macro: 0.3763 - test_f1_macro: 0.3763 - mixed_f1_macro: 0.3763\n",
      "Epoch 94/500\n",
      " — train_f1=0.7974 | val_f1=0.4630 | test_f1=0.4630 | mixed_f1=0.4630\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.7807 - loss: 0.8711 - val_accuracy: 0.3931 - val_loss: 1.7125 - train_f1_macro: 0.7974 - val_f1_macro: 0.4630 - test_f1_macro: 0.4630 - mixed_f1_macro: 0.4630\n",
      "Epoch 95/500\n",
      " — train_f1=0.8464 | val_f1=0.4729 | test_f1=0.4729 | mixed_f1=0.4729\n",
      "35/35 - 5s - 151ms/step - accuracy: 0.7821 - loss: 0.8699 - val_accuracy: 0.3907 - val_loss: 1.7477 - train_f1_macro: 0.8464 - val_f1_macro: 0.4729 - test_f1_macro: 0.4729 - mixed_f1_macro: 0.4729\n",
      "Epoch 96/500\n",
      " — train_f1=0.8405 | val_f1=0.4742 | test_f1=0.4742 | mixed_f1=0.4742\n",
      "35/35 - 10s - 286ms/step - accuracy: 0.7744 - loss: 0.8840 - val_accuracy: 0.4103 - val_loss: 1.6480 - train_f1_macro: 0.8405 - val_f1_macro: 0.4742 - test_f1_macro: 0.4742 - mixed_f1_macro: 0.4742\n",
      "Epoch 97/500\n",
      " — train_f1=0.4931 | val_f1=0.3310 | test_f1=0.3310 | mixed_f1=0.3310\n",
      "35/35 - 5s - 141ms/step - accuracy: 0.7780 - loss: 0.8853 - val_accuracy: 0.2826 - val_loss: 2.0119 - train_f1_macro: 0.4931 - val_f1_macro: 0.3310 - test_f1_macro: 0.3310 - mixed_f1_macro: 0.3310\n",
      "Epoch 98/500\n",
      " — train_f1=0.8282 | val_f1=0.3844 | test_f1=0.3844 | mixed_f1=0.3844\n",
      "35/35 - 5s - 145ms/step - accuracy: 0.7803 - loss: 0.8810 - val_accuracy: 0.3464 - val_loss: 1.8219 - train_f1_macro: 0.8282 - val_f1_macro: 0.3844 - test_f1_macro: 0.3844 - mixed_f1_macro: 0.3844\n",
      "Epoch 99/500\n",
      " — train_f1=0.8135 | val_f1=0.4345 | test_f1=0.4345 | mixed_f1=0.4345\n",
      "35/35 - 5s - 146ms/step - accuracy: 0.8005 - loss: 0.8711 - val_accuracy: 0.4079 - val_loss: 1.7494 - train_f1_macro: 0.8135 - val_f1_macro: 0.4345 - test_f1_macro: 0.4345 - mixed_f1_macro: 0.4345\n",
      "Epoch 100/500\n",
      " — train_f1=0.7224 | val_f1=0.4729 | test_f1=0.4729 | mixed_f1=0.4729\n",
      "35/35 - 11s - 304ms/step - accuracy: 0.7780 - loss: 0.8734 - val_accuracy: 0.3710 - val_loss: 1.8416 - train_f1_macro: 0.7224 - val_f1_macro: 0.4729 - test_f1_macro: 0.4729 - mixed_f1_macro: 0.4729\n",
      "Epoch 101/500\n",
      " — train_f1=0.8272 | val_f1=0.4496 | test_f1=0.4496 | mixed_f1=0.4496\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.7807 - loss: 0.8738 - val_accuracy: 0.3857 - val_loss: 1.8179 - train_f1_macro: 0.8272 - val_f1_macro: 0.4496 - test_f1_macro: 0.4496 - mixed_f1_macro: 0.4496\n",
      "Epoch 102/500\n",
      " — train_f1=0.8294 | val_f1=0.4953 | test_f1=0.4953 | mixed_f1=0.4953\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.7951 - loss: 0.8596 - val_accuracy: 0.3931 - val_loss: 1.7974 - train_f1_macro: 0.8294 - val_f1_macro: 0.4953 - test_f1_macro: 0.4953 - mixed_f1_macro: 0.4953\n",
      "Epoch 103/500\n",
      " — train_f1=0.8056 | val_f1=0.4552 | test_f1=0.4552 | mixed_f1=0.4552\n",
      "35/35 - 5s - 139ms/step - accuracy: 0.8113 - loss: 0.8442 - val_accuracy: 0.3882 - val_loss: 1.8994 - train_f1_macro: 0.8056 - val_f1_macro: 0.4552 - test_f1_macro: 0.4552 - mixed_f1_macro: 0.4552\n",
      "\n",
      "Fold 5 FINAL (Mixed Test): ACC=0.4570 F1w=0.4587 MCC=0.2844\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 6  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2275, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (353, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (353, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5083798882681564, 1: 0.7165354330708661, 2: 0.8921568627450981, 3: 4.252336448598131, 4: 3.5546875}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768199254.148961 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_6_1/dropout_30_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0561 | val_f1=0.1044 | test_f1=0.1044 | mixed_f1=0.1044\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.1044\n",
      "   → saved_models/merged_fold_6/best_val_f1_macro_epoch1_f10.1044_20260112_012740.h5\n",
      "36/36 - 8s - 221ms/step - accuracy: 0.2492 - loss: 1.8757 - val_accuracy: 0.1275 - val_loss: 2.0057 - train_f1_macro: 0.0561 - val_f1_macro: 0.1044 - test_f1_macro: 0.1044 - mixed_f1_macro: 0.1044\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3389 | val_f1=0.3648 | test_f1=0.3648 | mixed_f1=0.3648\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.3648\n",
      "   → saved_models/merged_fold_6/best_val_f1_macro_epoch2_f10.3648_20260112_012745.h5\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.3015 - loss: 1.7011 - val_accuracy: 0.4249 - val_loss: 1.6211 - train_f1_macro: 0.3389 - val_f1_macro: 0.3648 - test_f1_macro: 0.3648 - mixed_f1_macro: 0.3648\n",
      "Epoch 3/500\n",
      " — train_f1=0.2365 | val_f1=0.2432 | test_f1=0.2432 | mixed_f1=0.2432\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.3125 - loss: 1.6024 - val_accuracy: 0.3059 - val_loss: 1.6822 - train_f1_macro: 0.2365 - val_f1_macro: 0.2432 - test_f1_macro: 0.2432 - mixed_f1_macro: 0.2432\n",
      "Epoch 4/500\n",
      " — train_f1=0.1093 | val_f1=0.1375 | test_f1=0.1375 | mixed_f1=0.1375\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3389 - loss: 1.5402 - val_accuracy: 0.1445 - val_loss: 2.2335 - train_f1_macro: 0.1093 - val_f1_macro: 0.1375 - test_f1_macro: 0.1375 - mixed_f1_macro: 0.1375\n",
      "Epoch 5/500\n",
      " — train_f1=0.2770 | val_f1=0.3645 | test_f1=0.3645 | mixed_f1=0.3645\n",
      "36/36 - 10s - 280ms/step - accuracy: 0.3503 - loss: 1.4937 - val_accuracy: 0.4561 - val_loss: 1.5508 - train_f1_macro: 0.2770 - val_f1_macro: 0.3645 - test_f1_macro: 0.3645 - mixed_f1_macro: 0.3645\n",
      "Epoch 6/500\n",
      " — train_f1=0.1995 | val_f1=0.2570 | test_f1=0.2570 | mixed_f1=0.2570\n",
      "36/36 - 6s - 155ms/step - accuracy: 0.3376 - loss: 1.4654 - val_accuracy: 0.3258 - val_loss: 1.5989 - train_f1_macro: 0.1995 - val_f1_macro: 0.2570 - test_f1_macro: 0.2570 - mixed_f1_macro: 0.2570\n",
      "Epoch 7/500\n",
      " — train_f1=0.2403 | val_f1=0.2935 | test_f1=0.2935 | mixed_f1=0.2935\n",
      "36/36 - 10s - 285ms/step - accuracy: 0.3789 - loss: 1.4414 - val_accuracy: 0.3314 - val_loss: 1.5675 - train_f1_macro: 0.2403 - val_f1_macro: 0.2935 - test_f1_macro: 0.2935 - mixed_f1_macro: 0.2935\n",
      "Epoch 8/500\n",
      " — train_f1=0.2644 | val_f1=0.2348 | test_f1=0.2348 | mixed_f1=0.2348\n",
      "36/36 - 5s - 138ms/step - accuracy: 0.3710 - loss: 1.4412 - val_accuracy: 0.3371 - val_loss: 1.5397 - train_f1_macro: 0.2644 - val_f1_macro: 0.2348 - test_f1_macro: 0.2348 - mixed_f1_macro: 0.2348\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3690 | val_f1=0.4249 | test_f1=0.4249 | mixed_f1=0.4249\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 9 | f1=0.4249\n",
      "   → saved_models/merged_fold_6/best_val_f1_macro_epoch9_f10.4249_20260112_012831.h5\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.3710 - loss: 1.4182 - val_accuracy: 0.4929 - val_loss: 1.4648 - train_f1_macro: 0.3690 - val_f1_macro: 0.4249 - test_f1_macro: 0.4249 - mixed_f1_macro: 0.4249\n",
      "Epoch 10/500\n",
      " — train_f1=0.3185 | val_f1=0.3185 | test_f1=0.3185 | mixed_f1=0.3185\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.3538 - loss: 1.4076 - val_accuracy: 0.4221 - val_loss: 1.4561 - train_f1_macro: 0.3185 - val_f1_macro: 0.3185 - test_f1_macro: 0.3185 - mixed_f1_macro: 0.3185\n",
      "Epoch 11/500\n",
      " — train_f1=0.2968 | val_f1=0.2707 | test_f1=0.2707 | mixed_f1=0.2707\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3692 - loss: 1.3998 - val_accuracy: 0.3966 - val_loss: 1.4491 - train_f1_macro: 0.2968 - val_f1_macro: 0.2707 - test_f1_macro: 0.2707 - mixed_f1_macro: 0.2707\n",
      "Epoch 12/500\n",
      " — train_f1=0.3109 | val_f1=0.3400 | test_f1=0.3400 | mixed_f1=0.3400\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.3903 - loss: 1.3906 - val_accuracy: 0.4079 - val_loss: 1.5445 - train_f1_macro: 0.3109 - val_f1_macro: 0.3400 - test_f1_macro: 0.3400 - mixed_f1_macro: 0.3400\n",
      "Epoch 13/500\n",
      " — train_f1=0.3609 | val_f1=0.4206 | test_f1=0.4206 | mixed_f1=0.4206\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3666 - loss: 1.3721 - val_accuracy: 0.4929 - val_loss: 1.3964 - train_f1_macro: 0.3609 - val_f1_macro: 0.4206 - test_f1_macro: 0.4206 - mixed_f1_macro: 0.4206\n",
      "Epoch 14/500\n",
      " — train_f1=0.2359 | val_f1=0.2635 | test_f1=0.2635 | mixed_f1=0.2635\n",
      "36/36 - 5s - 144ms/step - accuracy: 0.3895 - loss: 1.3645 - val_accuracy: 0.3343 - val_loss: 1.5794 - train_f1_macro: 0.2359 - val_f1_macro: 0.2635 - test_f1_macro: 0.2635 - mixed_f1_macro: 0.2635\n",
      "Epoch 15/500\n",
      " — train_f1=0.3241 | val_f1=0.3890 | test_f1=0.3890 | mixed_f1=0.3890\n",
      "36/36 - 11s - 298ms/step - accuracy: 0.3763 - loss: 1.3638 - val_accuracy: 0.4618 - val_loss: 1.4708 - train_f1_macro: 0.3241 - val_f1_macro: 0.3890 - test_f1_macro: 0.3890 - mixed_f1_macro: 0.3890\n",
      "Epoch 16/500\n",
      " — train_f1=0.3069 | val_f1=0.3540 | test_f1=0.3540 | mixed_f1=0.3540\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3789 - loss: 1.3506 - val_accuracy: 0.4391 - val_loss: 1.3821 - train_f1_macro: 0.3069 - val_f1_macro: 0.3540 - test_f1_macro: 0.3540 - mixed_f1_macro: 0.3540\n",
      "Epoch 17/500\n",
      " — train_f1=0.3019 | val_f1=0.3625 | test_f1=0.3625 | mixed_f1=0.3625\n",
      "36/36 - 5s - 138ms/step - accuracy: 0.3556 - loss: 1.3329 - val_accuracy: 0.3909 - val_loss: 1.4293 - train_f1_macro: 0.3019 - val_f1_macro: 0.3625 - test_f1_macro: 0.3625 - mixed_f1_macro: 0.3625\n",
      "Epoch 18/500\n",
      " — train_f1=0.2720 | val_f1=0.3123 | test_f1=0.3123 | mixed_f1=0.3123\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3657 - loss: 1.3283 - val_accuracy: 0.3484 - val_loss: 1.4514 - train_f1_macro: 0.2720 - val_f1_macro: 0.3123 - test_f1_macro: 0.3123 - mixed_f1_macro: 0.3123\n",
      "Epoch 19/500\n",
      " — train_f1=0.3292 | val_f1=0.3920 | test_f1=0.3920 | mixed_f1=0.3920\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.3793 - loss: 1.3226 - val_accuracy: 0.4589 - val_loss: 1.3624 - train_f1_macro: 0.3292 - val_f1_macro: 0.3920 - test_f1_macro: 0.3920 - mixed_f1_macro: 0.3920\n",
      "Epoch 20/500\n",
      " — train_f1=0.2835 | val_f1=0.3141 | test_f1=0.3141 | mixed_f1=0.3141\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.3714 - loss: 1.3197 - val_accuracy: 0.3683 - val_loss: 1.4350 - train_f1_macro: 0.2835 - val_f1_macro: 0.3141 - test_f1_macro: 0.3141 - mixed_f1_macro: 0.3141\n",
      "Epoch 21/500\n",
      " — train_f1=0.3524 | val_f1=0.3884 | test_f1=0.3884 | mixed_f1=0.3884\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.3912 - loss: 1.3076 - val_accuracy: 0.4533 - val_loss: 1.3377 - train_f1_macro: 0.3524 - val_f1_macro: 0.3884 - test_f1_macro: 0.3884 - mixed_f1_macro: 0.3884\n",
      "Epoch 22/500\n",
      " — train_f1=0.3199 | val_f1=0.3988 | test_f1=0.3988 | mixed_f1=0.3988\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.4110 - loss: 1.3021 - val_accuracy: 0.4164 - val_loss: 1.3794 - train_f1_macro: 0.3199 - val_f1_macro: 0.3988 - test_f1_macro: 0.3988 - mixed_f1_macro: 0.3988\n",
      "Epoch 23/500\n",
      " — train_f1=0.2496 | val_f1=0.2690 | test_f1=0.2690 | mixed_f1=0.2690\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.4040 - loss: 1.2909 - val_accuracy: 0.3314 - val_loss: 1.4350 - train_f1_macro: 0.2496 - val_f1_macro: 0.2690 - test_f1_macro: 0.2690 - mixed_f1_macro: 0.2690\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3786 | val_f1=0.4599 | test_f1=0.4599 | mixed_f1=0.4599\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 24 | f1=0.4599\n",
      "   → saved_models/merged_fold_6/best_val_f1_macro_epoch24_f10.4599_20260112_012958.h5\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.3956 - loss: 1.2992 - val_accuracy: 0.4873 - val_loss: 1.3320 - train_f1_macro: 0.3786 - val_f1_macro: 0.4599 - test_f1_macro: 0.4599 - mixed_f1_macro: 0.4599\n",
      "Epoch 25/500\n",
      " — train_f1=0.2027 | val_f1=0.2506 | test_f1=0.2506 | mixed_f1=0.2506\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.4123 - loss: 1.2871 - val_accuracy: 0.2918 - val_loss: 1.6900 - train_f1_macro: 0.2027 - val_f1_macro: 0.2506 - test_f1_macro: 0.2506 - mixed_f1_macro: 0.2506\n",
      "Epoch 26/500\n",
      " — train_f1=0.3358 | val_f1=0.4082 | test_f1=0.4082 | mixed_f1=0.4082\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.3921 - loss: 1.2863 - val_accuracy: 0.5071 - val_loss: 1.3071 - train_f1_macro: 0.3358 - val_f1_macro: 0.4082 - test_f1_macro: 0.4082 - mixed_f1_macro: 0.4082\n",
      "Epoch 27/500\n",
      " — train_f1=0.3844 | val_f1=0.4545 | test_f1=0.4545 | mixed_f1=0.4545\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.4418 - loss: 1.2793 - val_accuracy: 0.5269 - val_loss: 1.2955 - train_f1_macro: 0.3844 - val_f1_macro: 0.4545 - test_f1_macro: 0.4545 - mixed_f1_macro: 0.4545\n",
      "Epoch 28/500\n",
      " — train_f1=0.1960 | val_f1=0.2030 | test_f1=0.2030 | mixed_f1=0.2030\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.4308 - loss: 1.2744 - val_accuracy: 0.2833 - val_loss: 1.4885 - train_f1_macro: 0.1960 - val_f1_macro: 0.2030 - test_f1_macro: 0.2030 - mixed_f1_macro: 0.2030\n",
      "Epoch 29/500\n",
      " — train_f1=0.3788 | val_f1=0.4290 | test_f1=0.4290 | mixed_f1=0.4290\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.4084 - loss: 1.2752 - val_accuracy: 0.4193 - val_loss: 1.3494 - train_f1_macro: 0.3788 - val_f1_macro: 0.4290 - test_f1_macro: 0.4290 - mixed_f1_macro: 0.4290\n",
      "Epoch 30/500\n",
      " — train_f1=0.2904 | val_f1=0.2696 | test_f1=0.2696 | mixed_f1=0.2696\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.4290 - loss: 1.2651 - val_accuracy: 0.3201 - val_loss: 1.4980 - train_f1_macro: 0.2904 - val_f1_macro: 0.2696 - test_f1_macro: 0.2696 - mixed_f1_macro: 0.2696\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5108 | val_f1=0.6229 | test_f1=0.6229 | mixed_f1=0.6229\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 31 | f1=0.6229\n",
      "   → saved_models/merged_fold_6/best_val_f1_macro_epoch31_f10.6229_20260112_013040.h5\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.4374 - loss: 1.2558 - val_accuracy: 0.6232 - val_loss: 1.2601 - train_f1_macro: 0.5108 - val_f1_macro: 0.6229 - test_f1_macro: 0.6229 - mixed_f1_macro: 0.6229\n",
      "Epoch 32/500\n",
      " — train_f1=0.1842 | val_f1=0.1924 | test_f1=0.1924 | mixed_f1=0.1924\n",
      "36/36 - 10s - 283ms/step - accuracy: 0.4492 - loss: 1.2492 - val_accuracy: 0.2606 - val_loss: 1.7751 - train_f1_macro: 0.1842 - val_f1_macro: 0.1924 - test_f1_macro: 0.1924 - mixed_f1_macro: 0.1924\n",
      "Epoch 33/500\n",
      " — train_f1=0.2185 | val_f1=0.2762 | test_f1=0.2762 | mixed_f1=0.2762\n",
      "36/36 - 10s - 285ms/step - accuracy: 0.4409 - loss: 1.2549 - val_accuracy: 0.2975 - val_loss: 1.7565 - train_f1_macro: 0.2185 - val_f1_macro: 0.2762 - test_f1_macro: 0.2762 - mixed_f1_macro: 0.2762\n",
      "Epoch 34/500\n",
      " — train_f1=0.5088 | val_f1=0.6181 | test_f1=0.6181 | mixed_f1=0.6181\n",
      "36/36 - 10s - 283ms/step - accuracy: 0.4462 - loss: 1.2448 - val_accuracy: 0.6346 - val_loss: 1.2294 - train_f1_macro: 0.5088 - val_f1_macro: 0.6181 - test_f1_macro: 0.6181 - mixed_f1_macro: 0.6181\n",
      "Epoch 35/500\n",
      " — train_f1=0.4584 | val_f1=0.5363 | test_f1=0.5363 | mixed_f1=0.5363\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.4677 - loss: 1.2386 - val_accuracy: 0.5524 - val_loss: 1.3063 - train_f1_macro: 0.4584 - val_f1_macro: 0.5363 - test_f1_macro: 0.5363 - mixed_f1_macro: 0.5363\n",
      "Epoch 36/500\n",
      " — train_f1=0.5081 | val_f1=0.5804 | test_f1=0.5804 | mixed_f1=0.5804\n",
      "36/36 - 10s - 264ms/step - accuracy: 0.4668 - loss: 1.2303 - val_accuracy: 0.6034 - val_loss: 1.2576 - train_f1_macro: 0.5081 - val_f1_macro: 0.5804 - test_f1_macro: 0.5804 - mixed_f1_macro: 0.5804\n",
      "Epoch 37/500\n",
      " — train_f1=0.4424 | val_f1=0.5211 | test_f1=0.5211 | mixed_f1=0.5211\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.4765 - loss: 1.2280 - val_accuracy: 0.5382 - val_loss: 1.3384 - train_f1_macro: 0.4424 - val_f1_macro: 0.5211 - test_f1_macro: 0.5211 - mixed_f1_macro: 0.5211\n",
      "Epoch 38/500\n",
      " — train_f1=0.5018 | val_f1=0.6051 | test_f1=0.6051 | mixed_f1=0.6051\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.4725 - loss: 1.2210 - val_accuracy: 0.5892 - val_loss: 1.2335 - train_f1_macro: 0.5018 - val_f1_macro: 0.6051 - test_f1_macro: 0.6051 - mixed_f1_macro: 0.6051\n",
      "Epoch 39/500\n",
      " — train_f1=0.5111 | val_f1=0.5564 | test_f1=0.5564 | mixed_f1=0.5564\n",
      "36/36 - 5s - 138ms/step - accuracy: 0.5064 - loss: 1.2083 - val_accuracy: 0.5694 - val_loss: 1.2545 - train_f1_macro: 0.5111 - val_f1_macro: 0.5564 - test_f1_macro: 0.5564 - mixed_f1_macro: 0.5564\n",
      "Epoch 40/500\n",
      " — train_f1=0.3976 | val_f1=0.4349 | test_f1=0.4349 | mixed_f1=0.4349\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.4774 - loss: 1.2172 - val_accuracy: 0.4646 - val_loss: 1.4030 - train_f1_macro: 0.3976 - val_f1_macro: 0.4349 - test_f1_macro: 0.4349 - mixed_f1_macro: 0.4349\n",
      "Epoch 41/500\n",
      " — train_f1=0.3763 | val_f1=0.4153 | test_f1=0.4153 | mixed_f1=0.4153\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.4927 - loss: 1.2077 - val_accuracy: 0.4079 - val_loss: 1.3640 - train_f1_macro: 0.3763 - val_f1_macro: 0.4153 - test_f1_macro: 0.4153 - mixed_f1_macro: 0.4153\n",
      "Epoch 42/500\n",
      " — train_f1=0.1930 | val_f1=0.1923 | test_f1=0.1923 | mixed_f1=0.1923\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.4976 - loss: 1.2369 - val_accuracy: 0.2975 - val_loss: 1.7357 - train_f1_macro: 0.1930 - val_f1_macro: 0.1923 - test_f1_macro: 0.1923 - mixed_f1_macro: 0.1923\n",
      "Epoch 43/500\n",
      " — train_f1=0.4248 | val_f1=0.4586 | test_f1=0.4586 | mixed_f1=0.4586\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.4971 - loss: 1.2217 - val_accuracy: 0.4731 - val_loss: 1.4033 - train_f1_macro: 0.4248 - val_f1_macro: 0.4586 - test_f1_macro: 0.4586 - mixed_f1_macro: 0.4586\n",
      "Epoch 44/500\n",
      " — train_f1=0.4309 | val_f1=0.4567 | test_f1=0.4567 | mixed_f1=0.4567\n",
      "36/36 - 6s - 154ms/step - accuracy: 0.5002 - loss: 1.1998 - val_accuracy: 0.4901 - val_loss: 1.3753 - train_f1_macro: 0.4309 - val_f1_macro: 0.4567 - test_f1_macro: 0.4567 - mixed_f1_macro: 0.4567\n",
      "Epoch 45/500\n",
      " — train_f1=0.4564 | val_f1=0.5106 | test_f1=0.5106 | mixed_f1=0.5106\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.5468 - loss: 1.1895 - val_accuracy: 0.5382 - val_loss: 1.3174 - train_f1_macro: 0.4564 - val_f1_macro: 0.5106 - test_f1_macro: 0.5106 - mixed_f1_macro: 0.5106\n",
      "Epoch 46/500\n",
      " — train_f1=0.5146 | val_f1=0.5407 | test_f1=0.5407 | mixed_f1=0.5407\n",
      "36/36 - 5s - 137ms/step - accuracy: 0.5420 - loss: 1.1922 - val_accuracy: 0.5836 - val_loss: 1.2203 - train_f1_macro: 0.5146 - val_f1_macro: 0.5407 - test_f1_macro: 0.5407 - mixed_f1_macro: 0.5407\n",
      "Epoch 47/500\n",
      " — train_f1=0.4632 | val_f1=0.5267 | test_f1=0.5267 | mixed_f1=0.5267\n",
      "36/36 - 5s - 138ms/step - accuracy: 0.5543 - loss: 1.1703 - val_accuracy: 0.5439 - val_loss: 1.3447 - train_f1_macro: 0.4632 - val_f1_macro: 0.5267 - test_f1_macro: 0.5267 - mixed_f1_macro: 0.5267\n",
      "Epoch 48/500\n",
      " — train_f1=0.5785 | val_f1=0.6023 | test_f1=0.6023 | mixed_f1=0.6023\n",
      "36/36 - 6s - 154ms/step - accuracy: 0.5604 - loss: 1.1731 - val_accuracy: 0.6091 - val_loss: 1.1939 - train_f1_macro: 0.5785 - val_f1_macro: 0.6023 - test_f1_macro: 0.6023 - mixed_f1_macro: 0.6023\n",
      "Epoch 49/500\n",
      " — train_f1=0.5409 | val_f1=0.5236 | test_f1=0.5236 | mixed_f1=0.5236\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.5516 - loss: 1.1560 - val_accuracy: 0.5326 - val_loss: 1.3042 - train_f1_macro: 0.5409 - val_f1_macro: 0.5236 - test_f1_macro: 0.5236 - mixed_f1_macro: 0.5236\n",
      "Epoch 50/500\n",
      " — train_f1=0.5492 | val_f1=0.5274 | test_f1=0.5274 | mixed_f1=0.5274\n",
      "36/36 - 5s - 137ms/step - accuracy: 0.5829 - loss: 1.1607 - val_accuracy: 0.5439 - val_loss: 1.3320 - train_f1_macro: 0.5492 - val_f1_macro: 0.5274 - test_f1_macro: 0.5274 - mixed_f1_macro: 0.5274\n",
      "Epoch 51/500\n",
      " — train_f1=0.5418 | val_f1=0.5152 | test_f1=0.5152 | mixed_f1=0.5152\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.5877 - loss: 1.1410 - val_accuracy: 0.5326 - val_loss: 1.3445 - train_f1_macro: 0.5418 - val_f1_macro: 0.5152 - test_f1_macro: 0.5152 - mixed_f1_macro: 0.5152\n",
      "Epoch 52/500\n",
      " — train_f1=0.6047 | val_f1=0.5626 | test_f1=0.5626 | mixed_f1=0.5626\n",
      "36/36 - 5s - 137ms/step - accuracy: 0.5820 - loss: 1.1464 - val_accuracy: 0.5921 - val_loss: 1.2337 - train_f1_macro: 0.6047 - val_f1_macro: 0.5626 - test_f1_macro: 0.5626 - mixed_f1_macro: 0.5626\n",
      "Epoch 53/500\n",
      " — train_f1=0.3514 | val_f1=0.3473 | test_f1=0.3473 | mixed_f1=0.3473\n",
      "36/36 - 5s - 144ms/step - accuracy: 0.6018 - loss: 1.1460 - val_accuracy: 0.3456 - val_loss: 1.7220 - train_f1_macro: 0.3514 - val_f1_macro: 0.3473 - test_f1_macro: 0.3473 - mixed_f1_macro: 0.3473\n",
      "Epoch 54/500\n",
      " — train_f1=0.5915 | val_f1=0.5670 | test_f1=0.5670 | mixed_f1=0.5670\n",
      "36/36 - 5s - 152ms/step - accuracy: 0.6031 - loss: 1.1352 - val_accuracy: 0.5722 - val_loss: 1.2204 - train_f1_macro: 0.5915 - val_f1_macro: 0.5670 - test_f1_macro: 0.5670 - mixed_f1_macro: 0.5670\n",
      "Epoch 55/500\n",
      " — train_f1=0.4129 | val_f1=0.4318 | test_f1=0.4318 | mixed_f1=0.4318\n",
      "36/36 - 10s - 287ms/step - accuracy: 0.5969 - loss: 1.1311 - val_accuracy: 0.4221 - val_loss: 1.3833 - train_f1_macro: 0.4129 - val_f1_macro: 0.4318 - test_f1_macro: 0.4318 - mixed_f1_macro: 0.4318\n",
      "Epoch 56/500\n",
      " — train_f1=0.5967 | val_f1=0.5328 | test_f1=0.5328 | mixed_f1=0.5328\n",
      "36/36 - 10s - 265ms/step - accuracy: 0.6040 - loss: 1.1421 - val_accuracy: 0.5694 - val_loss: 1.1954 - train_f1_macro: 0.5967 - val_f1_macro: 0.5328 - test_f1_macro: 0.5328 - mixed_f1_macro: 0.5328\n",
      "Epoch 57/500\n",
      " — train_f1=0.5760 | val_f1=0.5292 | test_f1=0.5292 | mixed_f1=0.5292\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.6114 - loss: 1.1250 - val_accuracy: 0.5241 - val_loss: 1.3324 - train_f1_macro: 0.5760 - val_f1_macro: 0.5292 - test_f1_macro: 0.5292 - mixed_f1_macro: 0.5292\n",
      "Epoch 58/500\n",
      " — train_f1=0.3777 | val_f1=0.3582 | test_f1=0.3582 | mixed_f1=0.3582\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.6312 - loss: 1.1002 - val_accuracy: 0.3881 - val_loss: 1.6550 - train_f1_macro: 0.3777 - val_f1_macro: 0.3582 - test_f1_macro: 0.3582 - mixed_f1_macro: 0.3582\n",
      "Epoch 59/500\n",
      " — train_f1=0.4845 | val_f1=0.4743 | test_f1=0.4743 | mixed_f1=0.4743\n",
      "36/36 - 10s - 266ms/step - accuracy: 0.6136 - loss: 1.1168 - val_accuracy: 0.4646 - val_loss: 1.4314 - train_f1_macro: 0.4845 - val_f1_macro: 0.4743 - test_f1_macro: 0.4743 - mixed_f1_macro: 0.4743\n",
      "Epoch 60/500\n",
      " — train_f1=0.5703 | val_f1=0.5093 | test_f1=0.5093 | mixed_f1=0.5093\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.6277 - loss: 1.1068 - val_accuracy: 0.5467 - val_loss: 1.2482 - train_f1_macro: 0.5703 - val_f1_macro: 0.5093 - test_f1_macro: 0.5093 - mixed_f1_macro: 0.5093\n",
      "Epoch 61/500\n",
      " — train_f1=0.4418 | val_f1=0.4595 | test_f1=0.4595 | mixed_f1=0.4595\n",
      "36/36 - 5s - 136ms/step - accuracy: 0.6334 - loss: 1.0972 - val_accuracy: 0.4533 - val_loss: 1.4643 - train_f1_macro: 0.4418 - val_f1_macro: 0.4595 - test_f1_macro: 0.4595 - mixed_f1_macro: 0.4595\n",
      "\n",
      "Fold 6 FINAL (Mixed Test): ACC=0.6232 F1w=0.6199 MCC=0.5173\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 7  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2314, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (314, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (314, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5046892039258452, 1: 0.7054878048780487, 2: 0.9146245059288538, 3: 4.325233644859813, 4: 3.615625}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768199636.154537 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_7_1/dropout_35_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0282 | val_f1=0.0431 | test_f1=0.0431 | mixed_f1=0.0431\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0431\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch1_f10.0431_20260112_013402.h5\n",
      "37/37 - 9s - 235ms/step - accuracy: 0.2502 - loss: 1.8979 - val_accuracy: 0.0828 - val_loss: 1.9014 - train_f1_macro: 0.0282 - val_f1_macro: 0.0431 - test_f1_macro: 0.0431 - mixed_f1_macro: 0.0431\n",
      "Epoch 2/500\n",
      " — train_f1=0.0563 | val_f1=0.0419 | test_f1=0.0419 | mixed_f1=0.0419\n",
      "37/37 - 9s - 251ms/step - accuracy: 0.2990 - loss: 1.7193 - val_accuracy: 0.0924 - val_loss: 2.0164 - train_f1_macro: 0.0563 - val_f1_macro: 0.0419 - test_f1_macro: 0.0419 - mixed_f1_macro: 0.0419\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1432 | val_f1=0.2158 | test_f1=0.2158 | mixed_f1=0.2158\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.2158\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch3_f10.2158_20260112_013422.h5\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.3388 - loss: 1.5860 - val_accuracy: 0.2293 - val_loss: 1.8948 - train_f1_macro: 0.1432 - val_f1_macro: 0.2158 - test_f1_macro: 0.2158 - mixed_f1_macro: 0.2158\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1573 | val_f1=0.2236 | test_f1=0.2236 | mixed_f1=0.2236\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.2236\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch4_f10.2236_20260112_013431.h5\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.3475 - loss: 1.5205 - val_accuracy: 0.2675 - val_loss: 1.8261 - train_f1_macro: 0.1573 - val_f1_macro: 0.2236 - test_f1_macro: 0.2236 - mixed_f1_macro: 0.2236\n",
      "Epoch 5/500\n",
      " — train_f1=0.0563 | val_f1=0.1013 | test_f1=0.1013 | mixed_f1=0.1013\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.3621 - loss: 1.4854 - val_accuracy: 0.1465 - val_loss: 2.2699 - train_f1_macro: 0.0563 - val_f1_macro: 0.1013 - test_f1_macro: 0.1013 - mixed_f1_macro: 0.1013\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3052 | val_f1=0.2682 | test_f1=0.2682 | mixed_f1=0.2682\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 6 | f1=0.2682\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch6_f10.2682_20260112_013442.h5\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.3621 - loss: 1.4772 - val_accuracy: 0.3567 - val_loss: 1.4987 - train_f1_macro: 0.3052 - val_f1_macro: 0.2682 - test_f1_macro: 0.2682 - mixed_f1_macro: 0.2682\n",
      "Epoch 7/500\n",
      " — train_f1=0.3218 | val_f1=0.2606 | test_f1=0.2606 | mixed_f1=0.2606\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.3500 - loss: 1.4415 - val_accuracy: 0.3248 - val_loss: 1.4700 - train_f1_macro: 0.3218 - val_f1_macro: 0.2606 - test_f1_macro: 0.2606 - mixed_f1_macro: 0.2606\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3332 | val_f1=0.3482 | test_f1=0.3482 | mixed_f1=0.3482\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 8 | f1=0.3482\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch8_f10.3482_20260112_013457.h5\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3708 - loss: 1.4254 - val_accuracy: 0.3790 - val_loss: 1.5327 - train_f1_macro: 0.3332 - val_f1_macro: 0.3482 - test_f1_macro: 0.3482 - mixed_f1_macro: 0.3482\n",
      "Epoch 9/500\n",
      " — train_f1=0.3024 | val_f1=0.2751 | test_f1=0.2751 | mixed_f1=0.2751\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.3773 - loss: 1.4031 - val_accuracy: 0.3599 - val_loss: 1.4441 - train_f1_macro: 0.3024 - val_f1_macro: 0.2751 - test_f1_macro: 0.2751 - mixed_f1_macro: 0.2751\n",
      "Epoch 10/500\n",
      " — train_f1=0.3579 | val_f1=0.2989 | test_f1=0.2989 | mixed_f1=0.2989\n",
      "37/37 - 10s - 276ms/step - accuracy: 0.3721 - loss: 1.4035 - val_accuracy: 0.3694 - val_loss: 1.4275 - train_f1_macro: 0.3579 - val_f1_macro: 0.2989 - test_f1_macro: 0.2989 - mixed_f1_macro: 0.2989\n",
      "Epoch 11/500\n",
      " — train_f1=0.3233 | val_f1=0.2823 | test_f1=0.2823 | mixed_f1=0.2823\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.3738 - loss: 1.3807 - val_accuracy: 0.3662 - val_loss: 1.4210 - train_f1_macro: 0.3233 - val_f1_macro: 0.2823 - test_f1_macro: 0.2823 - mixed_f1_macro: 0.2823\n",
      "Epoch 12/500\n",
      " — train_f1=0.3412 | val_f1=0.3081 | test_f1=0.3081 | mixed_f1=0.3081\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.3686 - loss: 1.3741 - val_accuracy: 0.3790 - val_loss: 1.4346 - train_f1_macro: 0.3412 - val_f1_macro: 0.3081 - test_f1_macro: 0.3081 - mixed_f1_macro: 0.3081\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3198 | val_f1=0.3703 | test_f1=0.3703 | mixed_f1=0.3703\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 13 | f1=0.3703\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch13_f10.3703_20260112_013533.h5\n",
      "37/37 - 5s - 142ms/step - accuracy: 0.3721 - loss: 1.3624 - val_accuracy: 0.4172 - val_loss: 1.5687 - train_f1_macro: 0.3198 - val_f1_macro: 0.3703 - test_f1_macro: 0.3703 - mixed_f1_macro: 0.3703\n",
      "Epoch 14/500\n",
      " — train_f1=0.2606 | val_f1=0.3018 | test_f1=0.3018 | mixed_f1=0.3018\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.3790 - loss: 1.3703 - val_accuracy: 0.3599 - val_loss: 1.5528 - train_f1_macro: 0.2606 - val_f1_macro: 0.3018 - test_f1_macro: 0.3018 - mixed_f1_macro: 0.3018\n",
      "Epoch 15/500\n",
      " — train_f1=0.2253 | val_f1=0.2618 | test_f1=0.2618 | mixed_f1=0.2618\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.3881 - loss: 1.3464 - val_accuracy: 0.3280 - val_loss: 1.6122 - train_f1_macro: 0.2253 - val_f1_macro: 0.2618 - test_f1_macro: 0.2618 - mixed_f1_macro: 0.2618\n",
      "Epoch 16/500\n",
      " — train_f1=0.2899 | val_f1=0.3013 | test_f1=0.3013 | mixed_f1=0.3013\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3868 - loss: 1.3423 - val_accuracy: 0.3631 - val_loss: 1.4768 - train_f1_macro: 0.2899 - val_f1_macro: 0.3013 - test_f1_macro: 0.3013 - mixed_f1_macro: 0.3013\n",
      "Epoch 17/500\n",
      " — train_f1=0.3298 | val_f1=0.3398 | test_f1=0.3398 | mixed_f1=0.3398\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.4136 - loss: 1.3245 - val_accuracy: 0.3917 - val_loss: 1.4101 - train_f1_macro: 0.3298 - val_f1_macro: 0.3398 - test_f1_macro: 0.3398 - mixed_f1_macro: 0.3398\n",
      "Epoch 18/500\n",
      " — train_f1=0.3140 | val_f1=0.3305 | test_f1=0.3305 | mixed_f1=0.3305\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.3933 - loss: 1.3288 - val_accuracy: 0.4013 - val_loss: 1.4399 - train_f1_macro: 0.3140 - val_f1_macro: 0.3305 - test_f1_macro: 0.3305 - mixed_f1_macro: 0.3305\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3573 | val_f1=0.3863 | test_f1=0.3863 | mixed_f1=0.3863\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 19 | f1=0.3863\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch19_f10.3863_20260112_013604.h5\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3980 - loss: 1.3289 - val_accuracy: 0.4172 - val_loss: 1.5054 - train_f1_macro: 0.3573 - val_f1_macro: 0.3863 - test_f1_macro: 0.3863 - mixed_f1_macro: 0.3863\n",
      "Epoch 20/500\n",
      " — train_f1=0.3155 | val_f1=0.3188 | test_f1=0.3188 | mixed_f1=0.3188\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.3889 - loss: 1.3153 - val_accuracy: 0.3694 - val_loss: 1.4814 - train_f1_macro: 0.3155 - val_f1_macro: 0.3188 - test_f1_macro: 0.3188 - mixed_f1_macro: 0.3188\n",
      "Epoch 21/500\n",
      " — train_f1=0.3769 | val_f1=0.3482 | test_f1=0.3482 | mixed_f1=0.3482\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.4045 - loss: 1.3006 - val_accuracy: 0.3854 - val_loss: 1.3990 - train_f1_macro: 0.3769 - val_f1_macro: 0.3482 - test_f1_macro: 0.3482 - mixed_f1_macro: 0.3482\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4083 | val_f1=0.3882 | test_f1=0.3882 | mixed_f1=0.3882\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 22 | f1=0.3882\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch22_f10.3882_20260112_013624.h5\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.4196 - loss: 1.2950 - val_accuracy: 0.4490 - val_loss: 1.3375 - train_f1_macro: 0.4083 - val_f1_macro: 0.3882 - test_f1_macro: 0.3882 - mixed_f1_macro: 0.3882\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4479 | val_f1=0.4355 | test_f1=0.4355 | mixed_f1=0.4355\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 23 | f1=0.4355\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch23_f10.4355_20260112_013629.h5\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4529 - loss: 1.2848 - val_accuracy: 0.4268 - val_loss: 1.3681 - train_f1_macro: 0.4479 - val_f1_macro: 0.4355 - test_f1_macro: 0.4355 - mixed_f1_macro: 0.4355\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4295 | val_f1=0.4761 | test_f1=0.4761 | mixed_f1=0.4761\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 24 | f1=0.4761\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch24_f10.4761_20260112_013634.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.4300 - loss: 1.2737 - val_accuracy: 0.4618 - val_loss: 1.4015 - train_f1_macro: 0.4295 - val_f1_macro: 0.4761 - test_f1_macro: 0.4761 - mixed_f1_macro: 0.4761\n",
      "Epoch 25/500\n",
      " — train_f1=0.3774 | val_f1=0.3228 | test_f1=0.3228 | mixed_f1=0.3228\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.4028 - loss: 1.3120 - val_accuracy: 0.4013 - val_loss: 1.3859 - train_f1_macro: 0.3774 - val_f1_macro: 0.3228 - test_f1_macro: 0.3228 - mixed_f1_macro: 0.3228\n",
      "Epoch 26/500\n",
      " — train_f1=0.4527 | val_f1=0.4192 | test_f1=0.4192 | mixed_f1=0.4192\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.4196 - loss: 1.2887 - val_accuracy: 0.4586 - val_loss: 1.3513 - train_f1_macro: 0.4527 - val_f1_macro: 0.4192 - test_f1_macro: 0.4192 - mixed_f1_macro: 0.4192\n",
      "Epoch 27/500\n",
      " — train_f1=0.4667 | val_f1=0.4636 | test_f1=0.4636 | mixed_f1=0.4636\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.4451 - loss: 1.2777 - val_accuracy: 0.5032 - val_loss: 1.3259 - train_f1_macro: 0.4667 - val_f1_macro: 0.4636 - test_f1_macro: 0.4636 - mixed_f1_macro: 0.4636\n",
      "Epoch 28/500\n",
      " — train_f1=0.4720 | val_f1=0.4244 | test_f1=0.4244 | mixed_f1=0.4244\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4417 - loss: 1.2756 - val_accuracy: 0.4395 - val_loss: 1.3220 - train_f1_macro: 0.4720 - val_f1_macro: 0.4244 - test_f1_macro: 0.4244 - mixed_f1_macro: 0.4244\n",
      "Epoch 29/500\n",
      " — train_f1=0.3449 | val_f1=0.3629 | test_f1=0.3629 | mixed_f1=0.3629\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4706 - loss: 1.2544 - val_accuracy: 0.4395 - val_loss: 1.4475 - train_f1_macro: 0.3449 - val_f1_macro: 0.3629 - test_f1_macro: 0.3629 - mixed_f1_macro: 0.3629\n",
      "Epoch 30/500\n",
      " — train_f1=0.4664 | val_f1=0.4144 | test_f1=0.4144 | mixed_f1=0.4144\n",
      "37/37 - 6s - 157ms/step - accuracy: 0.4827 - loss: 1.2496 - val_accuracy: 0.4204 - val_loss: 1.3566 - train_f1_macro: 0.4664 - val_f1_macro: 0.4144 - test_f1_macro: 0.4144 - mixed_f1_macro: 0.4144\n",
      "Epoch 31/500\n",
      " — train_f1=0.4647 | val_f1=0.4287 | test_f1=0.4287 | mixed_f1=0.4287\n",
      "37/37 - 5s - 148ms/step - accuracy: 0.4814 - loss: 1.2435 - val_accuracy: 0.4713 - val_loss: 1.3159 - train_f1_macro: 0.4647 - val_f1_macro: 0.4287 - test_f1_macro: 0.4287 - mixed_f1_macro: 0.4287\n",
      "Epoch 32/500\n",
      " — train_f1=0.4205 | val_f1=0.3643 | test_f1=0.3643 | mixed_f1=0.3643\n",
      "37/37 - 10s - 264ms/step - accuracy: 0.4823 - loss: 1.2413 - val_accuracy: 0.4618 - val_loss: 1.3486 - train_f1_macro: 0.4205 - val_f1_macro: 0.3643 - test_f1_macro: 0.3643 - mixed_f1_macro: 0.3643\n",
      "Epoch 33/500\n",
      " — train_f1=0.4308 | val_f1=0.3957 | test_f1=0.3957 | mixed_f1=0.3957\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.4818 - loss: 1.2424 - val_accuracy: 0.4586 - val_loss: 1.3579 - train_f1_macro: 0.4308 - val_f1_macro: 0.3957 - test_f1_macro: 0.3957 - mixed_f1_macro: 0.3957\n",
      "Epoch 34/500\n",
      " — train_f1=0.4374 | val_f1=0.4151 | test_f1=0.4151 | mixed_f1=0.4151\n",
      "37/37 - 5s - 149ms/step - accuracy: 0.5039 - loss: 1.2252 - val_accuracy: 0.4268 - val_loss: 1.3712 - train_f1_macro: 0.4374 - val_f1_macro: 0.4151 - test_f1_macro: 0.4151 - mixed_f1_macro: 0.4151\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4782 | val_f1=0.4795 | test_f1=0.4795 | mixed_f1=0.4795\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 35 | f1=0.4795\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch35_f10.4795_20260112_013747.h5\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4922 - loss: 1.2340 - val_accuracy: 0.5032 - val_loss: 1.2946 - train_f1_macro: 0.4782 - val_f1_macro: 0.4795 - test_f1_macro: 0.4795 - mixed_f1_macro: 0.4795\n",
      "Epoch 36/500\n",
      " — train_f1=0.5177 | val_f1=0.4553 | test_f1=0.4553 | mixed_f1=0.4553\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.5030 - loss: 1.2303 - val_accuracy: 0.4618 - val_loss: 1.3066 - train_f1_macro: 0.5177 - val_f1_macro: 0.4553 - test_f1_macro: 0.4553 - mixed_f1_macro: 0.4553\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5312 | val_f1=0.5078 | test_f1=0.5078 | mixed_f1=0.5078\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 37 | f1=0.5078\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch37_f10.5078_20260112_013757.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5052 - loss: 1.2133 - val_accuracy: 0.5096 - val_loss: 1.3027 - train_f1_macro: 0.5312 - val_f1_macro: 0.5078 - test_f1_macro: 0.5078 - mixed_f1_macro: 0.5078\n",
      "Epoch 38/500\n",
      " — train_f1=0.4697 | val_f1=0.4024 | test_f1=0.4024 | mixed_f1=0.4024\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.5194 - loss: 1.2034 - val_accuracy: 0.4586 - val_loss: 1.3240 - train_f1_macro: 0.4697 - val_f1_macro: 0.4024 - test_f1_macro: 0.4024 - mixed_f1_macro: 0.4024\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5540 | val_f1=0.5253 | test_f1=0.5253 | mixed_f1=0.5253\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 39 | f1=0.5253\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch39_f10.5253_20260112_013813.h5\n",
      "37/37 - 10s - 280ms/step - accuracy: 0.5251 - loss: 1.2030 - val_accuracy: 0.5287 - val_loss: 1.2983 - train_f1_macro: 0.5540 - val_f1_macro: 0.5253 - test_f1_macro: 0.5253 - mixed_f1_macro: 0.5253\n",
      "Epoch 40/500\n",
      " — train_f1=0.4880 | val_f1=0.4048 | test_f1=0.4048 | mixed_f1=0.4048\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.5177 - loss: 1.1932 - val_accuracy: 0.3917 - val_loss: 1.3847 - train_f1_macro: 0.4880 - val_f1_macro: 0.4048 - test_f1_macro: 0.4048 - mixed_f1_macro: 0.4048\n",
      "Epoch 41/500\n",
      " — train_f1=0.5478 | val_f1=0.4587 | test_f1=0.4587 | mixed_f1=0.4587\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.5307 - loss: 1.1923 - val_accuracy: 0.4777 - val_loss: 1.3073 - train_f1_macro: 0.5478 - val_f1_macro: 0.4587 - test_f1_macro: 0.4587 - mixed_f1_macro: 0.4587\n",
      "Epoch 42/500\n",
      " — train_f1=0.3945 | val_f1=0.2816 | test_f1=0.2816 | mixed_f1=0.2816\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.5601 - loss: 1.1863 - val_accuracy: 0.2994 - val_loss: 1.5916 - train_f1_macro: 0.3945 - val_f1_macro: 0.2816 - test_f1_macro: 0.2816 - mixed_f1_macro: 0.2816\n",
      "Epoch 43/500\n",
      " — train_f1=0.4566 | val_f1=0.3258 | test_f1=0.3258 | mixed_f1=0.3258\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.5389 - loss: 1.1854 - val_accuracy: 0.3726 - val_loss: 1.4205 - train_f1_macro: 0.4566 - val_f1_macro: 0.3258 - test_f1_macro: 0.3258 - mixed_f1_macro: 0.3258\n",
      "Epoch 44/500\n",
      " — train_f1=0.4390 | val_f1=0.3296 | test_f1=0.3296 | mixed_f1=0.3296\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5514 - loss: 1.1885 - val_accuracy: 0.3599 - val_loss: 1.4825 - train_f1_macro: 0.4390 - val_f1_macro: 0.3296 - test_f1_macro: 0.3296 - mixed_f1_macro: 0.3296\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6065 | val_f1=0.5417 | test_f1=0.5417 | mixed_f1=0.5417\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 45 | f1=0.5417\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch45_f10.5417_20260112_013848.h5\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.5501 - loss: 1.1716 - val_accuracy: 0.5478 - val_loss: 1.2308 - train_f1_macro: 0.6065 - val_f1_macro: 0.5417 - test_f1_macro: 0.5417 - mixed_f1_macro: 0.5417\n",
      "Epoch 46/500\n",
      " — train_f1=0.5726 | val_f1=0.5121 | test_f1=0.5121 | mixed_f1=0.5121\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5566 - loss: 1.1846 - val_accuracy: 0.4936 - val_loss: 1.3101 - train_f1_macro: 0.5726 - val_f1_macro: 0.5121 - test_f1_macro: 0.5121 - mixed_f1_macro: 0.5121\n",
      "Epoch 47/500\n",
      " — train_f1=0.5775 | val_f1=0.5164 | test_f1=0.5164 | mixed_f1=0.5164\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.5320 - loss: 1.1809 - val_accuracy: 0.4904 - val_loss: 1.2812 - train_f1_macro: 0.5775 - val_f1_macro: 0.5164 - test_f1_macro: 0.5164 - mixed_f1_macro: 0.5164\n",
      "Epoch 48/500\n",
      " — train_f1=0.5290 | val_f1=0.4423 | test_f1=0.4423 | mixed_f1=0.4423\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.5579 - loss: 1.1560 - val_accuracy: 0.4395 - val_loss: 1.3661 - train_f1_macro: 0.5290 - val_f1_macro: 0.4423 - test_f1_macro: 0.4423 - mixed_f1_macro: 0.4423\n",
      "Epoch 49/500\n",
      " — train_f1=0.5916 | val_f1=0.5193 | test_f1=0.5193 | mixed_f1=0.5193\n",
      "37/37 - 10s - 277ms/step - accuracy: 0.5696 - loss: 1.1649 - val_accuracy: 0.5287 - val_loss: 1.2854 - train_f1_macro: 0.5916 - val_f1_macro: 0.5193 - test_f1_macro: 0.5193 - mixed_f1_macro: 0.5193\n",
      "Epoch 50/500\n",
      " — train_f1=0.5915 | val_f1=0.4767 | test_f1=0.4767 | mixed_f1=0.4767\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.5830 - loss: 1.1426 - val_accuracy: 0.4936 - val_loss: 1.3085 - train_f1_macro: 0.5915 - val_f1_macro: 0.4767 - test_f1_macro: 0.4767 - mixed_f1_macro: 0.4767\n",
      "Epoch 51/500\n",
      " — train_f1=0.5648 | val_f1=0.4868 | test_f1=0.4868 | mixed_f1=0.4868\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.5791 - loss: 1.1313 - val_accuracy: 0.5096 - val_loss: 1.3302 - train_f1_macro: 0.5648 - val_f1_macro: 0.4868 - test_f1_macro: 0.4868 - mixed_f1_macro: 0.4868\n",
      "Epoch 52/500\n",
      " — train_f1=0.2630 | val_f1=0.2496 | test_f1=0.2496 | mixed_f1=0.2496\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5726 - loss: 1.1685 - val_accuracy: 0.2548 - val_loss: 1.7976 - train_f1_macro: 0.2630 - val_f1_macro: 0.2496 - test_f1_macro: 0.2496 - mixed_f1_macro: 0.2496\n",
      "Epoch 53/500\n",
      " — train_f1=0.4599 | val_f1=0.3564 | test_f1=0.3564 | mixed_f1=0.3564\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5756 - loss: 1.1384 - val_accuracy: 0.3949 - val_loss: 1.4989 - train_f1_macro: 0.4599 - val_f1_macro: 0.3564 - test_f1_macro: 0.3564 - mixed_f1_macro: 0.3564\n",
      "Epoch 54/500\n",
      " — train_f1=0.5287 | val_f1=0.4574 | test_f1=0.4574 | mixed_f1=0.4574\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5990 - loss: 1.1341 - val_accuracy: 0.4777 - val_loss: 1.3622 - train_f1_macro: 0.5287 - val_f1_macro: 0.4574 - test_f1_macro: 0.4574 - mixed_f1_macro: 0.4574\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6304 | val_f1=0.5901 | test_f1=0.5901 | mixed_f1=0.5901\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 55 | f1=0.5901\n",
      "   → saved_models/merged_fold_7/best_val_f1_macro_epoch55_f10.5901_20260112_013950.h5\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5856 - loss: 1.1358 - val_accuracy: 0.5860 - val_loss: 1.2080 - train_f1_macro: 0.6304 - val_f1_macro: 0.5901 - test_f1_macro: 0.5901 - mixed_f1_macro: 0.5901\n",
      "Epoch 56/500\n",
      " — train_f1=0.5896 | val_f1=0.5686 | test_f1=0.5686 | mixed_f1=0.5686\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5799 - loss: 1.1382 - val_accuracy: 0.5669 - val_loss: 1.2552 - train_f1_macro: 0.5896 - val_f1_macro: 0.5686 - test_f1_macro: 0.5686 - mixed_f1_macro: 0.5686\n",
      "Epoch 57/500\n",
      " — train_f1=0.6440 | val_f1=0.5191 | test_f1=0.5191 | mixed_f1=0.5191\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5873 - loss: 1.1237 - val_accuracy: 0.5032 - val_loss: 1.3088 - train_f1_macro: 0.6440 - val_f1_macro: 0.5191 - test_f1_macro: 0.5191 - mixed_f1_macro: 0.5191\n",
      "Epoch 58/500\n",
      " — train_f1=0.3693 | val_f1=0.3559 | test_f1=0.3559 | mixed_f1=0.3559\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6037 - loss: 1.0990 - val_accuracy: 0.3599 - val_loss: 1.6706 - train_f1_macro: 0.3693 - val_f1_macro: 0.3559 - test_f1_macro: 0.3559 - mixed_f1_macro: 0.3559\n",
      "Epoch 59/500\n",
      " — train_f1=0.6384 | val_f1=0.5064 | test_f1=0.5064 | mixed_f1=0.5064\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6132 - loss: 1.0902 - val_accuracy: 0.5159 - val_loss: 1.2998 - train_f1_macro: 0.6384 - val_f1_macro: 0.5064 - test_f1_macro: 0.5064 - mixed_f1_macro: 0.5064\n",
      "Epoch 60/500\n",
      " — train_f1=0.6299 | val_f1=0.4860 | test_f1=0.4860 | mixed_f1=0.4860\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6054 - loss: 1.0865 - val_accuracy: 0.4713 - val_loss: 1.3212 - train_f1_macro: 0.6299 - val_f1_macro: 0.4860 - test_f1_macro: 0.4860 - mixed_f1_macro: 0.4860\n",
      "Epoch 61/500\n",
      " — train_f1=0.6486 | val_f1=0.5786 | test_f1=0.5786 | mixed_f1=0.5786\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6029 - loss: 1.1013 - val_accuracy: 0.5637 - val_loss: 1.2379 - train_f1_macro: 0.6486 - val_f1_macro: 0.5786 - test_f1_macro: 0.5786 - mixed_f1_macro: 0.5786\n",
      "Epoch 62/500\n",
      " — train_f1=0.6446 | val_f1=0.5056 | test_f1=0.5056 | mixed_f1=0.5056\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.6067 - loss: 1.0864 - val_accuracy: 0.5096 - val_loss: 1.2816 - train_f1_macro: 0.6446 - val_f1_macro: 0.5056 - test_f1_macro: 0.5056 - mixed_f1_macro: 0.5056\n",
      "Epoch 63/500\n",
      " — train_f1=0.6427 | val_f1=0.5645 | test_f1=0.5645 | mixed_f1=0.5645\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6119 - loss: 1.1215 - val_accuracy: 0.5478 - val_loss: 1.2764 - train_f1_macro: 0.6427 - val_f1_macro: 0.5645 - test_f1_macro: 0.5645 - mixed_f1_macro: 0.5645\n",
      "Epoch 64/500\n",
      " — train_f1=0.5775 | val_f1=0.5249 | test_f1=0.5249 | mixed_f1=0.5249\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.6162 - loss: 1.0952 - val_accuracy: 0.5191 - val_loss: 1.2917 - train_f1_macro: 0.5775 - val_f1_macro: 0.5249 - test_f1_macro: 0.5249 - mixed_f1_macro: 0.5249\n",
      "Epoch 65/500\n",
      " — train_f1=0.6290 | val_f1=0.5552 | test_f1=0.5552 | mixed_f1=0.5552\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.6266 - loss: 1.0897 - val_accuracy: 0.5255 - val_loss: 1.2980 - train_f1_macro: 0.6290 - val_f1_macro: 0.5552 - test_f1_macro: 0.5552 - mixed_f1_macro: 0.5552\n",
      "Epoch 66/500\n",
      " — train_f1=0.5613 | val_f1=0.4240 | test_f1=0.4240 | mixed_f1=0.4240\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.6413 - loss: 1.0629 - val_accuracy: 0.4459 - val_loss: 1.3660 - train_f1_macro: 0.5613 - val_f1_macro: 0.4240 - test_f1_macro: 0.4240 - mixed_f1_macro: 0.4240\n",
      "Epoch 67/500\n",
      " — train_f1=0.4640 | val_f1=0.4111 | test_f1=0.4111 | mixed_f1=0.4111\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.6335 - loss: 1.0796 - val_accuracy: 0.4459 - val_loss: 1.5089 - train_f1_macro: 0.4640 - val_f1_macro: 0.4111 - test_f1_macro: 0.4111 - mixed_f1_macro: 0.4111\n",
      "Epoch 68/500\n",
      " — train_f1=0.5606 | val_f1=0.5125 | test_f1=0.5125 | mixed_f1=0.5125\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.6560 - loss: 1.0726 - val_accuracy: 0.5000 - val_loss: 1.3831 - train_f1_macro: 0.5606 - val_f1_macro: 0.5125 - test_f1_macro: 0.5125 - mixed_f1_macro: 0.5125\n",
      "Epoch 69/500\n",
      " — train_f1=0.5334 | val_f1=0.4991 | test_f1=0.4991 | mixed_f1=0.4991\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6577 - loss: 1.0695 - val_accuracy: 0.5064 - val_loss: 1.3220 - train_f1_macro: 0.5334 - val_f1_macro: 0.4991 - test_f1_macro: 0.4991 - mixed_f1_macro: 0.4991\n",
      "Epoch 70/500\n",
      " — train_f1=0.5175 | val_f1=0.4650 | test_f1=0.4650 | mixed_f1=0.4650\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.6616 - loss: 1.0546 - val_accuracy: 0.4936 - val_loss: 1.4270 - train_f1_macro: 0.5175 - val_f1_macro: 0.4650 - test_f1_macro: 0.4650 - mixed_f1_macro: 0.4650\n",
      "Epoch 71/500\n",
      " — train_f1=0.4516 | val_f1=0.4270 | test_f1=0.4270 | mixed_f1=0.4270\n",
      "37/37 - 10s - 278ms/step - accuracy: 0.6638 - loss: 1.0361 - val_accuracy: 0.4554 - val_loss: 1.5308 - train_f1_macro: 0.4516 - val_f1_macro: 0.4270 - test_f1_macro: 0.4270 - mixed_f1_macro: 0.4270\n",
      "Epoch 72/500\n",
      " — train_f1=0.6659 | val_f1=0.5305 | test_f1=0.5305 | mixed_f1=0.5305\n",
      "37/37 - 10s - 274ms/step - accuracy: 0.6560 - loss: 1.0463 - val_accuracy: 0.5350 - val_loss: 1.2662 - train_f1_macro: 0.6659 - val_f1_macro: 0.5305 - test_f1_macro: 0.5305 - mixed_f1_macro: 0.5305\n",
      "Epoch 73/500\n",
      " — train_f1=0.6372 | val_f1=0.5186 | test_f1=0.5186 | mixed_f1=0.5186\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6750 - loss: 1.0361 - val_accuracy: 0.4841 - val_loss: 1.3467 - train_f1_macro: 0.6372 - val_f1_macro: 0.5186 - test_f1_macro: 0.5186 - mixed_f1_macro: 0.5186\n",
      "Epoch 74/500\n",
      " — train_f1=0.6620 | val_f1=0.5307 | test_f1=0.5307 | mixed_f1=0.5307\n",
      "37/37 - 6s - 150ms/step - accuracy: 0.6595 - loss: 1.0480 - val_accuracy: 0.5159 - val_loss: 1.3005 - train_f1_macro: 0.6620 - val_f1_macro: 0.5307 - test_f1_macro: 0.5307 - mixed_f1_macro: 0.5307\n",
      "Epoch 75/500\n",
      " — train_f1=0.6599 | val_f1=0.5372 | test_f1=0.5372 | mixed_f1=0.5372\n",
      "37/37 - 6s - 149ms/step - accuracy: 0.6893 - loss: 1.0161 - val_accuracy: 0.5064 - val_loss: 1.3260 - train_f1_macro: 0.6599 - val_f1_macro: 0.5372 - test_f1_macro: 0.5372 - mixed_f1_macro: 0.5372\n",
      "Epoch 76/500\n",
      " — train_f1=0.7025 | val_f1=0.5623 | test_f1=0.5623 | mixed_f1=0.5623\n",
      "37/37 - 5s - 132ms/step - accuracy: 0.6768 - loss: 1.0096 - val_accuracy: 0.5510 - val_loss: 1.2790 - train_f1_macro: 0.7025 - val_f1_macro: 0.5623 - test_f1_macro: 0.5623 - mixed_f1_macro: 0.5623\n",
      "Epoch 77/500\n",
      " — train_f1=0.5515 | val_f1=0.4048 | test_f1=0.4048 | mixed_f1=0.4048\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6897 - loss: 1.0075 - val_accuracy: 0.4459 - val_loss: 1.5137 - train_f1_macro: 0.5515 - val_f1_macro: 0.4048 - test_f1_macro: 0.4048 - mixed_f1_macro: 0.4048\n",
      "Epoch 78/500\n",
      " — train_f1=0.6577 | val_f1=0.5592 | test_f1=0.5592 | mixed_f1=0.5592\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.6655 - loss: 1.0555 - val_accuracy: 0.5510 - val_loss: 1.2836 - train_f1_macro: 0.6577 - val_f1_macro: 0.5592 - test_f1_macro: 0.5592 - mixed_f1_macro: 0.5592\n",
      "Epoch 79/500\n",
      " — train_f1=0.6481 | val_f1=0.5351 | test_f1=0.5351 | mixed_f1=0.5351\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6768 - loss: 1.0066 - val_accuracy: 0.5223 - val_loss: 1.3764 - train_f1_macro: 0.6481 - val_f1_macro: 0.5351 - test_f1_macro: 0.5351 - mixed_f1_macro: 0.5351\n",
      "Epoch 80/500\n",
      " — train_f1=0.6220 | val_f1=0.5114 | test_f1=0.5114 | mixed_f1=0.5114\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.6819 - loss: 1.0230 - val_accuracy: 0.4745 - val_loss: 1.4047 - train_f1_macro: 0.6220 - val_f1_macro: 0.5114 - test_f1_macro: 0.5114 - mixed_f1_macro: 0.5114\n",
      "Epoch 81/500\n",
      " — train_f1=0.5725 | val_f1=0.4883 | test_f1=0.4883 | mixed_f1=0.4883\n",
      "37/37 - 10s - 280ms/step - accuracy: 0.6927 - loss: 0.9957 - val_accuracy: 0.4745 - val_loss: 1.4975 - train_f1_macro: 0.5725 - val_f1_macro: 0.4883 - test_f1_macro: 0.4883 - mixed_f1_macro: 0.4883\n",
      "Epoch 82/500\n",
      " — train_f1=0.6596 | val_f1=0.5664 | test_f1=0.5664 | mixed_f1=0.5664\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.7053 - loss: 1.0133 - val_accuracy: 0.5382 - val_loss: 1.2964 - train_f1_macro: 0.6596 - val_f1_macro: 0.5664 - test_f1_macro: 0.5664 - mixed_f1_macro: 0.5664\n",
      "Epoch 83/500\n",
      " — train_f1=0.7304 | val_f1=0.5857 | test_f1=0.5857 | mixed_f1=0.5857\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.6962 - loss: 1.0072 - val_accuracy: 0.5732 - val_loss: 1.2372 - train_f1_macro: 0.7304 - val_f1_macro: 0.5857 - test_f1_macro: 0.5857 - mixed_f1_macro: 0.5857\n",
      "Epoch 84/500\n",
      " — train_f1=0.5464 | val_f1=0.4739 | test_f1=0.4739 | mixed_f1=0.4739\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.6932 - loss: 1.0052 - val_accuracy: 0.4904 - val_loss: 1.5211 - train_f1_macro: 0.5464 - val_f1_macro: 0.4739 - test_f1_macro: 0.4739 - mixed_f1_macro: 0.4739\n",
      "Epoch 85/500\n",
      " — train_f1=0.6953 | val_f1=0.5590 | test_f1=0.5590 | mixed_f1=0.5590\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7079 - loss: 0.9983 - val_accuracy: 0.5573 - val_loss: 1.2970 - train_f1_macro: 0.6953 - val_f1_macro: 0.5590 - test_f1_macro: 0.5590 - mixed_f1_macro: 0.5590\n",
      "\n",
      "Fold 7 FINAL (Mixed Test): ACC=0.5860 F1w=0.5573 MCC=0.4833\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 8  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2301, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (327, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (327, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5159192825112108, 1: 0.7036697247706422, 2: 0.885, 3: 4.300934579439252, 4: 3.5953125}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768200173.221236 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_8_1/dropout_40_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0314 | val_f1=0.0523 | test_f1=0.0523 | mixed_f1=0.0523\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0523\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch1_f10.0523_20260112_014301.h5\n",
      "36/36 - 11s - 306ms/step - accuracy: 0.2477 - loss: 1.9080 - val_accuracy: 0.1070 - val_loss: 1.9312 - train_f1_macro: 0.0314 - val_f1_macro: 0.0523 - test_f1_macro: 0.0523 - mixed_f1_macro: 0.0523\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0558 | val_f1=0.0804 | test_f1=0.0804 | mixed_f1=0.0804\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 2 | f1=0.0804\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch2_f10.0804_20260112_014306.h5\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.2807 - loss: 1.7979 - val_accuracy: 0.1070 - val_loss: 2.0085 - train_f1_macro: 0.0558 - val_f1_macro: 0.0804 - test_f1_macro: 0.0804 - mixed_f1_macro: 0.0804\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.1138 | val_f1=0.1355 | test_f1=0.1355 | mixed_f1=0.1355\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.1355\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch3_f10.1355_20260112_014312.h5\n",
      "36/36 - 6s - 163ms/step - accuracy: 0.3099 - loss: 1.6690 - val_accuracy: 0.1621 - val_loss: 2.0791 - train_f1_macro: 0.1138 - val_f1_macro: 0.1355 - test_f1_macro: 0.1355 - mixed_f1_macro: 0.1355\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3004 | val_f1=0.3687 | test_f1=0.3687 | mixed_f1=0.3687\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.3687\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch4_f10.3687_20260112_014318.h5\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.3325 - loss: 1.5544 - val_accuracy: 0.4067 - val_loss: 1.6523 - train_f1_macro: 0.3004 - val_f1_macro: 0.3687 - test_f1_macro: 0.3687 - mixed_f1_macro: 0.3687\n",
      "Epoch 5/500\n",
      " — train_f1=0.2508 | val_f1=0.2739 | test_f1=0.2739 | mixed_f1=0.2739\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.3381 - loss: 1.5079 - val_accuracy: 0.3517 - val_loss: 1.5191 - train_f1_macro: 0.2508 - val_f1_macro: 0.2739 - test_f1_macro: 0.2739 - mixed_f1_macro: 0.2739\n",
      "Epoch 6/500\n",
      " — train_f1=0.3119 | val_f1=0.3141 | test_f1=0.3141 | mixed_f1=0.3141\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3459 - loss: 1.4649 - val_accuracy: 0.3578 - val_loss: 1.5774 - train_f1_macro: 0.3119 - val_f1_macro: 0.3141 - test_f1_macro: 0.3141 - mixed_f1_macro: 0.3141\n",
      "Epoch 7/500\n",
      " — train_f1=0.2662 | val_f1=0.3083 | test_f1=0.3083 | mixed_f1=0.3083\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.3364 - loss: 1.4589 - val_accuracy: 0.3333 - val_loss: 1.5073 - train_f1_macro: 0.2662 - val_f1_macro: 0.3083 - test_f1_macro: 0.3083 - mixed_f1_macro: 0.3083\n",
      "Epoch 8/500\n",
      " — train_f1=0.2862 | val_f1=0.2929 | test_f1=0.2929 | mixed_f1=0.2929\n",
      "36/36 - 10s - 268ms/step - accuracy: 0.3442 - loss: 1.4142 - val_accuracy: 0.3517 - val_loss: 1.4642 - train_f1_macro: 0.2862 - val_f1_macro: 0.2929 - test_f1_macro: 0.2929 - mixed_f1_macro: 0.2929\n",
      "Epoch 9/500\n",
      " — train_f1=0.0199 | val_f1=0.0368 | test_f1=0.0368 | mixed_f1=0.0368\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3629 - loss: 1.4335 - val_accuracy: 0.0856 - val_loss: 2.8237 - train_f1_macro: 0.0199 - val_f1_macro: 0.0368 - test_f1_macro: 0.0368 - mixed_f1_macro: 0.0368\n",
      "Epoch 10/500\n",
      " — train_f1=0.3642 | val_f1=0.3495 | test_f1=0.3495 | mixed_f1=0.3495\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.3677 - loss: 1.4209 - val_accuracy: 0.3333 - val_loss: 1.5973 - train_f1_macro: 0.3642 - val_f1_macro: 0.3495 - test_f1_macro: 0.3495 - mixed_f1_macro: 0.3495\n",
      "Epoch 11/500\n",
      " — train_f1=0.3749 | val_f1=0.3219 | test_f1=0.3219 | mixed_f1=0.3219\n",
      "36/36 - 6s - 156ms/step - accuracy: 0.3946 - loss: 1.3750 - val_accuracy: 0.3639 - val_loss: 1.4325 - train_f1_macro: 0.3749 - val_f1_macro: 0.3219 - test_f1_macro: 0.3219 - mixed_f1_macro: 0.3219\n",
      "Epoch 12/500\n",
      " — train_f1=0.2868 | val_f1=0.2883 | test_f1=0.2883 | mixed_f1=0.2883\n",
      "36/36 - 10s - 270ms/step - accuracy: 0.4072 - loss: 1.3556 - val_accuracy: 0.3456 - val_loss: 1.4506 - train_f1_macro: 0.2868 - val_f1_macro: 0.2883 - test_f1_macro: 0.2883 - mixed_f1_macro: 0.2883\n",
      "Epoch 13/500\n",
      " — train_f1=0.3063 | val_f1=0.2957 | test_f1=0.2957 | mixed_f1=0.2957\n",
      "36/36 - 11s - 299ms/step - accuracy: 0.3890 - loss: 1.3691 - val_accuracy: 0.3364 - val_loss: 1.4406 - train_f1_macro: 0.3063 - val_f1_macro: 0.2957 - test_f1_macro: 0.2957 - mixed_f1_macro: 0.2957\n",
      "Epoch 14/500\n",
      " — train_f1=0.3846 | val_f1=0.2948 | test_f1=0.2948 | mixed_f1=0.2948\n",
      "36/36 - 10s - 269ms/step - accuracy: 0.3837 - loss: 1.3591 - val_accuracy: 0.3333 - val_loss: 1.5209 - train_f1_macro: 0.3846 - val_f1_macro: 0.2948 - test_f1_macro: 0.2948 - mixed_f1_macro: 0.2948\n",
      "Epoch 15/500\n",
      " — train_f1=0.3164 | val_f1=0.3176 | test_f1=0.3176 | mixed_f1=0.3176\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.4268 - loss: 1.3318 - val_accuracy: 0.3486 - val_loss: 1.5247 - train_f1_macro: 0.3164 - val_f1_macro: 0.3176 - test_f1_macro: 0.3176 - mixed_f1_macro: 0.3176\n",
      "Epoch 16/500\n",
      " — train_f1=0.3952 | val_f1=0.3280 | test_f1=0.3280 | mixed_f1=0.3280\n",
      "36/36 - 10s - 268ms/step - accuracy: 0.4311 - loss: 1.3160 - val_accuracy: 0.3609 - val_loss: 1.4061 - train_f1_macro: 0.3952 - val_f1_macro: 0.3280 - test_f1_macro: 0.3280 - mixed_f1_macro: 0.3280\n",
      "Epoch 17/500\n",
      " — train_f1=0.2866 | val_f1=0.2458 | test_f1=0.2458 | mixed_f1=0.2458\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.4281 - loss: 1.3234 - val_accuracy: 0.3394 - val_loss: 1.4618 - train_f1_macro: 0.2866 - val_f1_macro: 0.2458 - test_f1_macro: 0.2458 - mixed_f1_macro: 0.2458\n",
      "Epoch 18/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4912 | val_f1=0.4346 | test_f1=0.4346 | mixed_f1=0.4346\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 18 | f1=0.4346\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch18_f10.4346_20260112_014500.h5\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.4415 - loss: 1.3055 - val_accuracy: 0.4159 - val_loss: 1.3983 - train_f1_macro: 0.4912 - val_f1_macro: 0.4346 - test_f1_macro: 0.4346 - mixed_f1_macro: 0.4346\n",
      "Epoch 19/500\n",
      " — train_f1=0.4013 | val_f1=0.3360 | test_f1=0.3360 | mixed_f1=0.3360\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.4272 - loss: 1.3102 - val_accuracy: 0.3303 - val_loss: 1.5106 - train_f1_macro: 0.4013 - val_f1_macro: 0.3360 - test_f1_macro: 0.3360 - mixed_f1_macro: 0.3360\n",
      "Epoch 20/500\n",
      " — train_f1=0.4013 | val_f1=0.3371 | test_f1=0.3371 | mixed_f1=0.3371\n",
      "36/36 - 6s - 156ms/step - accuracy: 0.4442 - loss: 1.2874 - val_accuracy: 0.3609 - val_loss: 1.4897 - train_f1_macro: 0.4013 - val_f1_macro: 0.3371 - test_f1_macro: 0.3371 - mixed_f1_macro: 0.3371\n",
      "Epoch 21/500\n",
      " — train_f1=0.4820 | val_f1=0.3172 | test_f1=0.3172 | mixed_f1=0.3172\n",
      "36/36 - 10s - 269ms/step - accuracy: 0.4807 - loss: 1.2816 - val_accuracy: 0.3180 - val_loss: 1.3885 - train_f1_macro: 0.4820 - val_f1_macro: 0.3172 - test_f1_macro: 0.3172 - mixed_f1_macro: 0.3172\n",
      "Epoch 22/500\n",
      " — train_f1=0.4256 | val_f1=0.3788 | test_f1=0.3788 | mixed_f1=0.3788\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.4668 - loss: 1.2841 - val_accuracy: 0.3884 - val_loss: 1.4401 - train_f1_macro: 0.4256 - val_f1_macro: 0.3788 - test_f1_macro: 0.3788 - mixed_f1_macro: 0.3788\n",
      "Epoch 23/500\n",
      " — train_f1=0.2864 | val_f1=0.2313 | test_f1=0.2313 | mixed_f1=0.2313\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.4802 - loss: 1.2724 - val_accuracy: 0.2294 - val_loss: 1.7707 - train_f1_macro: 0.2864 - val_f1_macro: 0.2313 - test_f1_macro: 0.2313 - mixed_f1_macro: 0.2313\n",
      "Epoch 24/500\n",
      " — train_f1=0.5509 | val_f1=0.4088 | test_f1=0.4088 | mixed_f1=0.4088\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.4885 - loss: 1.2535 - val_accuracy: 0.3761 - val_loss: 1.3951 - train_f1_macro: 0.5509 - val_f1_macro: 0.4088 - test_f1_macro: 0.4088 - mixed_f1_macro: 0.4088\n",
      "Epoch 25/500\n",
      " — train_f1=0.4543 | val_f1=0.3574 | test_f1=0.3574 | mixed_f1=0.3574\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.4894 - loss: 1.2590 - val_accuracy: 0.3823 - val_loss: 1.4262 - train_f1_macro: 0.4543 - val_f1_macro: 0.3574 - test_f1_macro: 0.3574 - mixed_f1_macro: 0.3574\n",
      "Epoch 26/500\n",
      " — train_f1=0.4340 | val_f1=0.3709 | test_f1=0.3709 | mixed_f1=0.3709\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.5007 - loss: 1.2430 - val_accuracy: 0.3486 - val_loss: 1.4186 - train_f1_macro: 0.4340 - val_f1_macro: 0.3709 - test_f1_macro: 0.3709 - mixed_f1_macro: 0.3709\n",
      "Epoch 27/500\n",
      " — train_f1=0.4116 | val_f1=0.2995 | test_f1=0.2995 | mixed_f1=0.2995\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.5093 - loss: 1.2468 - val_accuracy: 0.2936 - val_loss: 1.5420 - train_f1_macro: 0.4116 - val_f1_macro: 0.2995 - test_f1_macro: 0.2995 - mixed_f1_macro: 0.2995\n",
      "Epoch 28/500\n",
      " — train_f1=0.5325 | val_f1=0.4104 | test_f1=0.4104 | mixed_f1=0.4104\n",
      "36/36 - 10s - 270ms/step - accuracy: 0.5106 - loss: 1.2419 - val_accuracy: 0.3578 - val_loss: 1.4070 - train_f1_macro: 0.5325 - val_f1_macro: 0.4104 - test_f1_macro: 0.4104 - mixed_f1_macro: 0.4104\n",
      "Epoch 29/500\n",
      " — train_f1=0.1279 | val_f1=0.1108 | test_f1=0.1108 | mixed_f1=0.1108\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.5211 - loss: 1.2189 - val_accuracy: 0.1437 - val_loss: 2.0447 - train_f1_macro: 0.1279 - val_f1_macro: 0.1108 - test_f1_macro: 0.1108 - mixed_f1_macro: 0.1108\n",
      "Epoch 30/500\n",
      " — train_f1=0.3261 | val_f1=0.2405 | test_f1=0.2405 | mixed_f1=0.2405\n",
      "36/36 - 10s - 268ms/step - accuracy: 0.5241 - loss: 1.2247 - val_accuracy: 0.2661 - val_loss: 1.6005 - train_f1_macro: 0.3261 - val_f1_macro: 0.2405 - test_f1_macro: 0.2405 - mixed_f1_macro: 0.2405\n",
      "Epoch 31/500\n",
      " — train_f1=0.0867 | val_f1=0.1050 | test_f1=0.1050 | mixed_f1=0.1050\n",
      "36/36 - 11s - 299ms/step - accuracy: 0.5537 - loss: 1.1975 - val_accuracy: 0.1284 - val_loss: 2.1749 - train_f1_macro: 0.0867 - val_f1_macro: 0.1050 - test_f1_macro: 0.1050 - mixed_f1_macro: 0.1050\n",
      "Epoch 32/500\n",
      " — train_f1=0.1742 | val_f1=0.1231 | test_f1=0.1231 | mixed_f1=0.1231\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.5411 - loss: 1.2076 - val_accuracy: 0.1743 - val_loss: 1.8803 - train_f1_macro: 0.1742 - val_f1_macro: 0.1231 - test_f1_macro: 0.1231 - mixed_f1_macro: 0.1231\n",
      "Epoch 33/500\n",
      " — train_f1=0.5962 | val_f1=0.4275 | test_f1=0.4275 | mixed_f1=0.4275\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.5424 - loss: 1.1949 - val_accuracy: 0.4220 - val_loss: 1.3614 - train_f1_macro: 0.5962 - val_f1_macro: 0.4275 - test_f1_macro: 0.4275 - mixed_f1_macro: 0.4275\n",
      "Epoch 34/500\n",
      " — train_f1=0.5512 | val_f1=0.4120 | test_f1=0.4120 | mixed_f1=0.4120\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.5558 - loss: 1.1929 - val_accuracy: 0.4373 - val_loss: 1.3814 - train_f1_macro: 0.5512 - val_f1_macro: 0.4120 - test_f1_macro: 0.4120 - mixed_f1_macro: 0.4120\n",
      "Epoch 35/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5673 | val_f1=0.4535 | test_f1=0.4535 | mixed_f1=0.4535\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 35 | f1=0.4535\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch35_f10.4535_20260112_014709.h5\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.5493 - loss: 1.1780 - val_accuracy: 0.4465 - val_loss: 1.3712 - train_f1_macro: 0.5673 - val_f1_macro: 0.4535 - test_f1_macro: 0.4535 - mixed_f1_macro: 0.4535\n",
      "Epoch 36/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5644 | val_f1=0.4643 | test_f1=0.4643 | mixed_f1=0.4643\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 36 | f1=0.4643\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch36_f10.4643_20260112_014714.h5\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.5797 - loss: 1.1487 - val_accuracy: 0.4251 - val_loss: 1.3973 - train_f1_macro: 0.5644 - val_f1_macro: 0.4643 - test_f1_macro: 0.4643 - mixed_f1_macro: 0.4643\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5953 | val_f1=0.4970 | test_f1=0.4970 | mixed_f1=0.4970\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 37 | f1=0.4970\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch37_f10.4970_20260112_014719.h5\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.5754 - loss: 1.1610 - val_accuracy: 0.4648 - val_loss: 1.3287 - train_f1_macro: 0.5953 - val_f1_macro: 0.4970 - test_f1_macro: 0.4970 - mixed_f1_macro: 0.4970\n",
      "Epoch 38/500\n",
      " — train_f1=0.4805 | val_f1=0.4147 | test_f1=0.4147 | mixed_f1=0.4147\n",
      "36/36 - 10s - 282ms/step - accuracy: 0.5915 - loss: 1.1500 - val_accuracy: 0.4587 - val_loss: 1.3625 - train_f1_macro: 0.4805 - val_f1_macro: 0.4147 - test_f1_macro: 0.4147 - mixed_f1_macro: 0.4147\n",
      "Epoch 39/500\n",
      " — train_f1=0.3534 | val_f1=0.3142 | test_f1=0.3142 | mixed_f1=0.3142\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.5841 - loss: 1.1387 - val_accuracy: 0.3180 - val_loss: 1.6611 - train_f1_macro: 0.3534 - val_f1_macro: 0.3142 - test_f1_macro: 0.3142 - mixed_f1_macro: 0.3142\n",
      "Epoch 40/500\n",
      " — train_f1=0.6355 | val_f1=0.4615 | test_f1=0.4615 | mixed_f1=0.4615\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.5811 - loss: 1.1445 - val_accuracy: 0.4434 - val_loss: 1.3510 - train_f1_macro: 0.6355 - val_f1_macro: 0.4615 - test_f1_macro: 0.4615 - mixed_f1_macro: 0.4615\n",
      "Epoch 41/500\n",
      " — train_f1=0.4371 | val_f1=0.3567 | test_f1=0.3567 | mixed_f1=0.3567\n",
      "36/36 - 10s - 266ms/step - accuracy: 0.5924 - loss: 1.1451 - val_accuracy: 0.3425 - val_loss: 1.4966 - train_f1_macro: 0.4371 - val_f1_macro: 0.3567 - test_f1_macro: 0.3567 - mixed_f1_macro: 0.3567\n",
      "Epoch 42/500\n",
      " — train_f1=0.5191 | val_f1=0.3926 | test_f1=0.3926 | mixed_f1=0.3926\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.5919 - loss: 1.1463 - val_accuracy: 0.3731 - val_loss: 1.4868 - train_f1_macro: 0.5191 - val_f1_macro: 0.3926 - test_f1_macro: 0.3926 - mixed_f1_macro: 0.3926\n",
      "Epoch 43/500\n",
      " — train_f1=0.5685 | val_f1=0.4498 | test_f1=0.4498 | mixed_f1=0.4498\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.5993 - loss: 1.1169 - val_accuracy: 0.4312 - val_loss: 1.4136 - train_f1_macro: 0.5685 - val_f1_macro: 0.4498 - test_f1_macro: 0.4498 - mixed_f1_macro: 0.4498\n",
      "Epoch 44/500\n",
      " — train_f1=0.5753 | val_f1=0.4271 | test_f1=0.4271 | mixed_f1=0.4271\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.5967 - loss: 1.1194 - val_accuracy: 0.4312 - val_loss: 1.4475 - train_f1_macro: 0.5753 - val_f1_macro: 0.4271 - test_f1_macro: 0.4271 - mixed_f1_macro: 0.4271\n",
      "Epoch 45/500\n",
      " — train_f1=0.4169 | val_f1=0.3495 | test_f1=0.3495 | mixed_f1=0.3495\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.5976 - loss: 1.1224 - val_accuracy: 0.3486 - val_loss: 1.5700 - train_f1_macro: 0.4169 - val_f1_macro: 0.3495 - test_f1_macro: 0.3495 - mixed_f1_macro: 0.3495\n",
      "Epoch 46/500\n",
      " — train_f1=0.5279 | val_f1=0.4226 | test_f1=0.4226 | mixed_f1=0.4226\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.6371 - loss: 1.0935 - val_accuracy: 0.4128 - val_loss: 1.4577 - train_f1_macro: 0.5279 - val_f1_macro: 0.4226 - test_f1_macro: 0.4226 - mixed_f1_macro: 0.4226\n",
      "Epoch 47/500\n",
      " — train_f1=0.2051 | val_f1=0.1537 | test_f1=0.1537 | mixed_f1=0.1537\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.6158 - loss: 1.1213 - val_accuracy: 0.3211 - val_loss: 2.0080 - train_f1_macro: 0.2051 - val_f1_macro: 0.1537 - test_f1_macro: 0.1537 - mixed_f1_macro: 0.1537\n",
      "Epoch 48/500\n",
      " — train_f1=0.4374 | val_f1=0.3556 | test_f1=0.3556 | mixed_f1=0.3556\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.6315 - loss: 1.1036 - val_accuracy: 0.4098 - val_loss: 1.5722 - train_f1_macro: 0.4374 - val_f1_macro: 0.3556 - test_f1_macro: 0.3556 - mixed_f1_macro: 0.3556\n",
      "Epoch 49/500\n",
      " — train_f1=0.5562 | val_f1=0.3901 | test_f1=0.3901 | mixed_f1=0.3901\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.6293 - loss: 1.0901 - val_accuracy: 0.3731 - val_loss: 1.4936 - train_f1_macro: 0.5562 - val_f1_macro: 0.3901 - test_f1_macro: 0.3901 - mixed_f1_macro: 0.3901\n",
      "Epoch 50/500\n",
      " — train_f1=0.6602 | val_f1=0.4720 | test_f1=0.4720 | mixed_f1=0.4720\n",
      "36/36 - 10s - 270ms/step - accuracy: 0.6436 - loss: 1.0817 - val_accuracy: 0.4709 - val_loss: 1.3976 - train_f1_macro: 0.6602 - val_f1_macro: 0.4720 - test_f1_macro: 0.4720 - mixed_f1_macro: 0.4720\n",
      "Epoch 51/500\n",
      " — train_f1=0.3223 | val_f1=0.2326 | test_f1=0.2326 | mixed_f1=0.2326\n",
      "36/36 - 10s - 281ms/step - accuracy: 0.6410 - loss: 1.0960 - val_accuracy: 0.2446 - val_loss: 1.8300 - train_f1_macro: 0.3223 - val_f1_macro: 0.2326 - test_f1_macro: 0.2326 - mixed_f1_macro: 0.2326\n",
      "Epoch 52/500\n",
      " — train_f1=0.6407 | val_f1=0.4651 | test_f1=0.4651 | mixed_f1=0.4651\n",
      "36/36 - 5s - 145ms/step - accuracy: 0.6649 - loss: 1.0696 - val_accuracy: 0.4526 - val_loss: 1.3696 - train_f1_macro: 0.6407 - val_f1_macro: 0.4651 - test_f1_macro: 0.4651 - mixed_f1_macro: 0.4651\n",
      "Epoch 53/500\n",
      " — train_f1=0.5942 | val_f1=0.4120 | test_f1=0.4120 | mixed_f1=0.4120\n",
      "36/36 - 11s - 299ms/step - accuracy: 0.6675 - loss: 1.0518 - val_accuracy: 0.3945 - val_loss: 1.5347 - train_f1_macro: 0.5942 - val_f1_macro: 0.4120 - test_f1_macro: 0.4120 - mixed_f1_macro: 0.4120\n",
      "Epoch 54/500\n",
      " — train_f1=0.5780 | val_f1=0.4590 | test_f1=0.4590 | mixed_f1=0.4590\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.6658 - loss: 1.0396 - val_accuracy: 0.4465 - val_loss: 1.4181 - train_f1_macro: 0.5780 - val_f1_macro: 0.4590 - test_f1_macro: 0.4590 - mixed_f1_macro: 0.4590\n",
      "Epoch 55/500\n",
      " — train_f1=0.5202 | val_f1=0.4622 | test_f1=0.4622 | mixed_f1=0.4622\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.6641 - loss: 1.0395 - val_accuracy: 0.4434 - val_loss: 1.4155 - train_f1_macro: 0.5202 - val_f1_macro: 0.4622 - test_f1_macro: 0.4622 - mixed_f1_macro: 0.4622\n",
      "Epoch 56/500\n",
      " — train_f1=0.5332 | val_f1=0.4021 | test_f1=0.4021 | mixed_f1=0.4021\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.6784 - loss: 1.0376 - val_accuracy: 0.4037 - val_loss: 1.6291 - train_f1_macro: 0.5332 - val_f1_macro: 0.4021 - test_f1_macro: 0.4021 - mixed_f1_macro: 0.4021\n",
      "Epoch 57/500\n",
      " — train_f1=0.5527 | val_f1=0.4343 | test_f1=0.4343 | mixed_f1=0.4343\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.6688 - loss: 1.0531 - val_accuracy: 0.4190 - val_loss: 1.5043 - train_f1_macro: 0.5527 - val_f1_macro: 0.4343 - test_f1_macro: 0.4343 - mixed_f1_macro: 0.4343\n",
      "Epoch 58/500\n",
      " — train_f1=0.5705 | val_f1=0.4171 | test_f1=0.4171 | mixed_f1=0.4171\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.6927 - loss: 1.0322 - val_accuracy: 0.4190 - val_loss: 1.5758 - train_f1_macro: 0.5705 - val_f1_macro: 0.4171 - test_f1_macro: 0.4171 - mixed_f1_macro: 0.4171\n",
      "Epoch 59/500\n",
      " — train_f1=0.5490 | val_f1=0.4337 | test_f1=0.4337 | mixed_f1=0.4337\n",
      "36/36 - 6s - 158ms/step - accuracy: 0.6823 - loss: 1.0201 - val_accuracy: 0.4281 - val_loss: 1.5752 - train_f1_macro: 0.5490 - val_f1_macro: 0.4337 - test_f1_macro: 0.4337 - mixed_f1_macro: 0.4337\n",
      "Epoch 60/500\n",
      " — train_f1=0.5843 | val_f1=0.4020 | test_f1=0.4020 | mixed_f1=0.4020\n",
      "36/36 - 10s - 285ms/step - accuracy: 0.6923 - loss: 1.0147 - val_accuracy: 0.4251 - val_loss: 1.5390 - train_f1_macro: 0.5843 - val_f1_macro: 0.4020 - test_f1_macro: 0.4020 - mixed_f1_macro: 0.4020\n",
      "Epoch 61/500\n",
      " — train_f1=0.4481 | val_f1=0.3833 | test_f1=0.3833 | mixed_f1=0.3833\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.6858 - loss: 1.0351 - val_accuracy: 0.3853 - val_loss: 1.6340 - train_f1_macro: 0.4481 - val_f1_macro: 0.3833 - test_f1_macro: 0.3833 - mixed_f1_macro: 0.3833\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7203 | val_f1=0.5111 | test_f1=0.5111 | mixed_f1=0.5111\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 62 | f1=0.5111\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch62_f10.5111_20260112_014958.h5\n",
      "36/36 - 5s - 145ms/step - accuracy: 0.6971 - loss: 1.0330 - val_accuracy: 0.4740 - val_loss: 1.3909 - train_f1_macro: 0.7203 - val_f1_macro: 0.5111 - test_f1_macro: 0.5111 - mixed_f1_macro: 0.5111\n",
      "Epoch 63/500\n",
      " — train_f1=0.4935 | val_f1=0.3960 | test_f1=0.3960 | mixed_f1=0.3960\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.6980 - loss: 1.0186 - val_accuracy: 0.4434 - val_loss: 1.5107 - train_f1_macro: 0.4935 - val_f1_macro: 0.3960 - test_f1_macro: 0.3960 - mixed_f1_macro: 0.3960\n",
      "Epoch 64/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6436 | val_f1=0.5218 | test_f1=0.5218 | mixed_f1=0.5218\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 64 | f1=0.5218\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch64_f10.5218_20260112_015014.h5\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.6923 - loss: 1.0343 - val_accuracy: 0.5076 - val_loss: 1.3922 - train_f1_macro: 0.6436 - val_f1_macro: 0.5218 - test_f1_macro: 0.5218 - mixed_f1_macro: 0.5218\n",
      "Epoch 65/500\n",
      " — train_f1=0.5625 | val_f1=0.4360 | test_f1=0.4360 | mixed_f1=0.4360\n",
      "36/36 - 10s - 282ms/step - accuracy: 0.7049 - loss: 1.0046 - val_accuracy: 0.4587 - val_loss: 1.6043 - train_f1_macro: 0.5625 - val_f1_macro: 0.4360 - test_f1_macro: 0.4360 - mixed_f1_macro: 0.4360\n",
      "Epoch 66/500\n",
      " — train_f1=0.6274 | val_f1=0.4848 | test_f1=0.4848 | mixed_f1=0.4848\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.7106 - loss: 0.9993 - val_accuracy: 0.4587 - val_loss: 1.4374 - train_f1_macro: 0.6274 - val_f1_macro: 0.4848 - test_f1_macro: 0.4848 - mixed_f1_macro: 0.4848\n",
      "Epoch 67/500\n",
      " — train_f1=0.3278 | val_f1=0.2659 | test_f1=0.2659 | mixed_f1=0.2659\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.7193 - loss: 0.9953 - val_accuracy: 0.2661 - val_loss: 2.0379 - train_f1_macro: 0.3278 - val_f1_macro: 0.2659 - test_f1_macro: 0.2659 - mixed_f1_macro: 0.2659\n",
      "Epoch 68/500\n",
      " — train_f1=0.5717 | val_f1=0.5121 | test_f1=0.5121 | mixed_f1=0.5121\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.7136 - loss: 0.9835 - val_accuracy: 0.4985 - val_loss: 1.4385 - train_f1_macro: 0.5717 - val_f1_macro: 0.5121 - test_f1_macro: 0.5121 - mixed_f1_macro: 0.5121\n",
      "Epoch 69/500\n",
      " — train_f1=0.3797 | val_f1=0.3382 | test_f1=0.3382 | mixed_f1=0.3382\n",
      "36/36 - 6s - 155ms/step - accuracy: 0.7071 - loss: 0.9878 - val_accuracy: 0.4220 - val_loss: 1.6185 - train_f1_macro: 0.3797 - val_f1_macro: 0.3382 - test_f1_macro: 0.3382 - mixed_f1_macro: 0.3382\n",
      "Epoch 70/500\n",
      " — train_f1=0.4654 | val_f1=0.3991 | test_f1=0.3991 | mixed_f1=0.3991\n",
      "36/36 - 10s - 269ms/step - accuracy: 0.7158 - loss: 0.9878 - val_accuracy: 0.4373 - val_loss: 1.6151 - train_f1_macro: 0.4654 - val_f1_macro: 0.3991 - test_f1_macro: 0.3991 - mixed_f1_macro: 0.3991\n",
      "Epoch 71/500\n",
      " — train_f1=0.6776 | val_f1=0.4812 | test_f1=0.4812 | mixed_f1=0.4812\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.7136 - loss: 0.9777 - val_accuracy: 0.4709 - val_loss: 1.4825 - train_f1_macro: 0.6776 - val_f1_macro: 0.4812 - test_f1_macro: 0.4812 - mixed_f1_macro: 0.4812\n",
      "Epoch 72/500\n",
      " — train_f1=0.6728 | val_f1=0.4799 | test_f1=0.4799 | mixed_f1=0.4799\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.7258 - loss: 0.9874 - val_accuracy: 0.4557 - val_loss: 1.5179 - train_f1_macro: 0.6728 - val_f1_macro: 0.4799 - test_f1_macro: 0.4799 - mixed_f1_macro: 0.4799\n",
      "Epoch 73/500\n",
      " — train_f1=0.7765 | val_f1=0.4821 | test_f1=0.4821 | mixed_f1=0.4821\n",
      "36/36 - 6s - 162ms/step - accuracy: 0.7423 - loss: 0.9566 - val_accuracy: 0.4618 - val_loss: 1.4961 - train_f1_macro: 0.7765 - val_f1_macro: 0.4821 - test_f1_macro: 0.4821 - mixed_f1_macro: 0.4821\n",
      "Epoch 74/500\n",
      " — train_f1=0.7161 | val_f1=0.4662 | test_f1=0.4662 | mixed_f1=0.4662\n",
      "36/36 - 10s - 283ms/step - accuracy: 0.7310 - loss: 0.9638 - val_accuracy: 0.4648 - val_loss: 1.5123 - train_f1_macro: 0.7161 - val_f1_macro: 0.4662 - test_f1_macro: 0.4662 - mixed_f1_macro: 0.4662\n",
      "Epoch 75/500\n",
      " — train_f1=0.5079 | val_f1=0.4106 | test_f1=0.4106 | mixed_f1=0.4106\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.7458 - loss: 0.9503 - val_accuracy: 0.4098 - val_loss: 1.6547 - train_f1_macro: 0.5079 - val_f1_macro: 0.4106 - test_f1_macro: 0.4106 - mixed_f1_macro: 0.4106\n",
      "Epoch 76/500\n",
      " — train_f1=0.6278 | val_f1=0.4192 | test_f1=0.4192 | mixed_f1=0.4192\n",
      "36/36 - 10s - 283ms/step - accuracy: 0.7471 - loss: 0.9370 - val_accuracy: 0.4251 - val_loss: 1.6292 - train_f1_macro: 0.6278 - val_f1_macro: 0.4192 - test_f1_macro: 0.4192 - mixed_f1_macro: 0.4192\n",
      "Epoch 77/500\n",
      " — train_f1=0.6771 | val_f1=0.4743 | test_f1=0.4743 | mixed_f1=0.4743\n",
      "36/36 - 10s - 285ms/step - accuracy: 0.7471 - loss: 0.9424 - val_accuracy: 0.4526 - val_loss: 1.6011 - train_f1_macro: 0.6771 - val_f1_macro: 0.4743 - test_f1_macro: 0.4743 - mixed_f1_macro: 0.4743\n",
      "Epoch 78/500\n",
      " — train_f1=0.2311 | val_f1=0.1878 | test_f1=0.1878 | mixed_f1=0.1878\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.7549 - loss: 0.9415 - val_accuracy: 0.3517 - val_loss: 2.0545 - train_f1_macro: 0.2311 - val_f1_macro: 0.1878 - test_f1_macro: 0.1878 - mixed_f1_macro: 0.1878\n",
      "Epoch 79/500\n",
      " — train_f1=0.6925 | val_f1=0.4972 | test_f1=0.4972 | mixed_f1=0.4972\n",
      "36/36 - 11s - 299ms/step - accuracy: 0.7323 - loss: 0.9487 - val_accuracy: 0.4985 - val_loss: 1.5312 - train_f1_macro: 0.6925 - val_f1_macro: 0.4972 - test_f1_macro: 0.4972 - mixed_f1_macro: 0.4972\n",
      "Epoch 80/500\n",
      " — train_f1=0.5449 | val_f1=0.3695 | test_f1=0.3695 | mixed_f1=0.3695\n",
      "36/36 - 10s - 286ms/step - accuracy: 0.7523 - loss: 0.9616 - val_accuracy: 0.3609 - val_loss: 1.7035 - train_f1_macro: 0.5449 - val_f1_macro: 0.3695 - test_f1_macro: 0.3695 - mixed_f1_macro: 0.3695\n",
      "Epoch 81/500\n",
      " — train_f1=0.5962 | val_f1=0.4348 | test_f1=0.4348 | mixed_f1=0.4348\n",
      "36/36 - 10s - 282ms/step - accuracy: 0.7558 - loss: 0.9330 - val_accuracy: 0.4343 - val_loss: 1.6373 - train_f1_macro: 0.5962 - val_f1_macro: 0.4348 - test_f1_macro: 0.4348 - mixed_f1_macro: 0.4348\n",
      "Epoch 82/500\n",
      " — train_f1=0.7534 | val_f1=0.4716 | test_f1=0.4716 | mixed_f1=0.4716\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7540 - loss: 0.9464 - val_accuracy: 0.4709 - val_loss: 1.5235 - train_f1_macro: 0.7534 - val_f1_macro: 0.4716 - test_f1_macro: 0.4716 - mixed_f1_macro: 0.4716\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.7357 | val_f1=0.5423 | test_f1=0.5423 | mixed_f1=0.5423\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 83 | f1=0.5423\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch83_f10.5423_20260112_015239.h5\n",
      "36/36 - 11s - 301ms/step - accuracy: 0.7510 - loss: 0.9216 - val_accuracy: 0.5168 - val_loss: 1.4269 - train_f1_macro: 0.7357 - val_f1_macro: 0.5423 - test_f1_macro: 0.5423 - mixed_f1_macro: 0.5423\n",
      "Epoch 84/500\n",
      " — train_f1=0.5834 | val_f1=0.4380 | test_f1=0.4380 | mixed_f1=0.4380\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7618 - loss: 0.9329 - val_accuracy: 0.4343 - val_loss: 1.6474 - train_f1_macro: 0.5834 - val_f1_macro: 0.4380 - test_f1_macro: 0.4380 - mixed_f1_macro: 0.4380\n",
      "Epoch 85/500\n",
      " — train_f1=0.7995 | val_f1=0.5199 | test_f1=0.5199 | mixed_f1=0.5199\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.7605 - loss: 0.9290 - val_accuracy: 0.5015 - val_loss: 1.5073 - train_f1_macro: 0.7995 - val_f1_macro: 0.5199 - test_f1_macro: 0.5199 - mixed_f1_macro: 0.5199\n",
      "Epoch 86/500\n",
      " — train_f1=0.4196 | val_f1=0.3660 | test_f1=0.3660 | mixed_f1=0.3660\n",
      "36/36 - 6s - 157ms/step - accuracy: 0.7623 - loss: 0.9060 - val_accuracy: 0.3639 - val_loss: 1.7778 - train_f1_macro: 0.4196 - val_f1_macro: 0.3660 - test_f1_macro: 0.3660 - mixed_f1_macro: 0.3660\n",
      "Epoch 87/500\n",
      " — train_f1=0.7013 | val_f1=0.4747 | test_f1=0.4747 | mixed_f1=0.4747\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.7675 - loss: 0.9199 - val_accuracy: 0.4587 - val_loss: 1.5744 - train_f1_macro: 0.7013 - val_f1_macro: 0.4747 - test_f1_macro: 0.4747 - mixed_f1_macro: 0.4747\n",
      "Epoch 88/500\n",
      " — train_f1=0.7645 | val_f1=0.5382 | test_f1=0.5382 | mixed_f1=0.5382\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7727 - loss: 0.9095 - val_accuracy: 0.5138 - val_loss: 1.4543 - train_f1_macro: 0.7645 - val_f1_macro: 0.5382 - test_f1_macro: 0.5382 - mixed_f1_macro: 0.5382\n",
      "Epoch 89/500\n",
      " — train_f1=0.7598 | val_f1=0.4941 | test_f1=0.4941 | mixed_f1=0.4941\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.7918 - loss: 0.8970 - val_accuracy: 0.4801 - val_loss: 1.5697 - train_f1_macro: 0.7598 - val_f1_macro: 0.4941 - test_f1_macro: 0.4941 - mixed_f1_macro: 0.4941\n",
      "Epoch 90/500\n",
      " — train_f1=0.7426 | val_f1=0.5390 | test_f1=0.5390 | mixed_f1=0.5390\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.7827 - loss: 0.8829 - val_accuracy: 0.5107 - val_loss: 1.4993 - train_f1_macro: 0.7426 - val_f1_macro: 0.5390 - test_f1_macro: 0.5390 - mixed_f1_macro: 0.5390\n",
      "Epoch 91/500\n",
      " — train_f1=0.8031 | val_f1=0.4869 | test_f1=0.4869 | mixed_f1=0.4869\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.7810 - loss: 0.8779 - val_accuracy: 0.4771 - val_loss: 1.5851 - train_f1_macro: 0.8031 - val_f1_macro: 0.4869 - test_f1_macro: 0.4869 - mixed_f1_macro: 0.4869\n",
      "Epoch 92/500\n",
      " — train_f1=0.7272 | val_f1=0.4890 | test_f1=0.4890 | mixed_f1=0.4890\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7888 - loss: 0.8888 - val_accuracy: 0.4679 - val_loss: 1.5863 - train_f1_macro: 0.7272 - val_f1_macro: 0.4890 - test_f1_macro: 0.4890 - mixed_f1_macro: 0.4890\n",
      "Epoch 93/500\n",
      " — train_f1=0.7462 | val_f1=0.5256 | test_f1=0.5256 | mixed_f1=0.5256\n",
      "36/36 - 5s - 146ms/step - accuracy: 0.7897 - loss: 0.8875 - val_accuracy: 0.5076 - val_loss: 1.5123 - train_f1_macro: 0.7462 - val_f1_macro: 0.5256 - test_f1_macro: 0.5256 - mixed_f1_macro: 0.5256\n",
      "Epoch 94/500\n",
      " — train_f1=0.6205 | val_f1=0.4738 | test_f1=0.4738 | mixed_f1=0.4738\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7784 - loss: 0.8927 - val_accuracy: 0.4648 - val_loss: 1.6486 - train_f1_macro: 0.6205 - val_f1_macro: 0.4738 - test_f1_macro: 0.4738 - mixed_f1_macro: 0.4738\n",
      "Epoch 95/500\n",
      " — train_f1=0.6043 | val_f1=0.4909 | test_f1=0.4909 | mixed_f1=0.4909\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.7801 - loss: 0.9051 - val_accuracy: 0.4832 - val_loss: 1.5628 - train_f1_macro: 0.6043 - val_f1_macro: 0.4909 - test_f1_macro: 0.4909 - mixed_f1_macro: 0.4909\n",
      "Epoch 96/500\n",
      " — train_f1=0.7613 | val_f1=0.4626 | test_f1=0.4626 | mixed_f1=0.4626\n",
      "36/36 - 6s - 155ms/step - accuracy: 0.7753 - loss: 0.9012 - val_accuracy: 0.4618 - val_loss: 1.5995 - train_f1_macro: 0.7613 - val_f1_macro: 0.4626 - test_f1_macro: 0.4626 - mixed_f1_macro: 0.4626\n",
      "Epoch 97/500\n",
      " — train_f1=0.5821 | val_f1=0.4513 | test_f1=0.4513 | mixed_f1=0.4513\n",
      "36/36 - 10s - 273ms/step - accuracy: 0.7744 - loss: 0.9288 - val_accuracy: 0.4434 - val_loss: 1.6642 - train_f1_macro: 0.5821 - val_f1_macro: 0.4513 - test_f1_macro: 0.4513 - mixed_f1_macro: 0.4513\n",
      "Epoch 98/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.8066 | val_f1=0.5616 | test_f1=0.5616 | mixed_f1=0.5616\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 98 | f1=0.5616\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch98_f10.5616_20260112_015401.h5\n",
      "36/36 - 5s - 146ms/step - accuracy: 0.7814 - loss: 0.9098 - val_accuracy: 0.5443 - val_loss: 1.4214 - train_f1_macro: 0.8066 - val_f1_macro: 0.5616 - test_f1_macro: 0.5616 - mixed_f1_macro: 0.5616\n",
      "Epoch 99/500\n",
      " — train_f1=0.7308 | val_f1=0.4606 | test_f1=0.4606 | mixed_f1=0.4606\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7957 - loss: 0.8706 - val_accuracy: 0.4404 - val_loss: 1.6532 - train_f1_macro: 0.7308 - val_f1_macro: 0.4606 - test_f1_macro: 0.4606 - mixed_f1_macro: 0.4606\n",
      "Epoch 100/500\n",
      " — train_f1=0.4711 | val_f1=0.3427 | test_f1=0.3427 | mixed_f1=0.3427\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7975 - loss: 0.8664 - val_accuracy: 0.3547 - val_loss: 1.9038 - train_f1_macro: 0.4711 - val_f1_macro: 0.3427 - test_f1_macro: 0.3427 - mixed_f1_macro: 0.3427\n",
      "Epoch 101/500\n",
      " — train_f1=0.7834 | val_f1=0.5001 | test_f1=0.5001 | mixed_f1=0.5001\n",
      "36/36 - 6s - 160ms/step - accuracy: 0.7627 - loss: 0.9083 - val_accuracy: 0.4954 - val_loss: 1.5714 - train_f1_macro: 0.7834 - val_f1_macro: 0.5001 - test_f1_macro: 0.5001 - mixed_f1_macro: 0.5001\n",
      "Epoch 102/500\n",
      " — train_f1=0.6088 | val_f1=0.4140 | test_f1=0.4140 | mixed_f1=0.4140\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7836 - loss: 0.9149 - val_accuracy: 0.4128 - val_loss: 1.7702 - train_f1_macro: 0.6088 - val_f1_macro: 0.4140 - test_f1_macro: 0.4140 - mixed_f1_macro: 0.4140\n",
      "Epoch 103/500\n",
      " — train_f1=0.8102 | val_f1=0.5000 | test_f1=0.5000 | mixed_f1=0.5000\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.7983 - loss: 0.8604 - val_accuracy: 0.4740 - val_loss: 1.6016 - train_f1_macro: 0.8102 - val_f1_macro: 0.5000 - test_f1_macro: 0.5000 - mixed_f1_macro: 0.5000\n",
      "Epoch 104/500\n",
      " — train_f1=0.8010 | val_f1=0.5438 | test_f1=0.5438 | mixed_f1=0.5438\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.7962 - loss: 0.8668 - val_accuracy: 0.5229 - val_loss: 1.5192 - train_f1_macro: 0.8010 - val_f1_macro: 0.5438 - test_f1_macro: 0.5438 - mixed_f1_macro: 0.5438\n",
      "Epoch 105/500\n",
      " — train_f1=0.8355 | val_f1=0.4863 | test_f1=0.4863 | mixed_f1=0.4863\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.8166 - loss: 0.8609 - val_accuracy: 0.4648 - val_loss: 1.6585 - train_f1_macro: 0.8355 - val_f1_macro: 0.4863 - test_f1_macro: 0.4863 - mixed_f1_macro: 0.4863\n",
      "Epoch 106/500\n",
      " — train_f1=0.7320 | val_f1=0.4820 | test_f1=0.4820 | mixed_f1=0.4820\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.7953 - loss: 0.8850 - val_accuracy: 0.4587 - val_loss: 1.6078 - train_f1_macro: 0.7320 - val_f1_macro: 0.4820 - test_f1_macro: 0.4820 - mixed_f1_macro: 0.4820\n",
      "Epoch 107/500\n",
      " — train_f1=0.8209 | val_f1=0.5417 | test_f1=0.5417 | mixed_f1=0.5417\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7997 - loss: 0.8727 - val_accuracy: 0.5199 - val_loss: 1.4885 - train_f1_macro: 0.8209 - val_f1_macro: 0.5417 - test_f1_macro: 0.5417 - mixed_f1_macro: 0.5417\n",
      "Epoch 108/500\n",
      " — train_f1=0.7414 | val_f1=0.4439 | test_f1=0.4439 | mixed_f1=0.4439\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.7992 - loss: 0.8567 - val_accuracy: 0.4404 - val_loss: 1.7450 - train_f1_macro: 0.7414 - val_f1_macro: 0.4439 - test_f1_macro: 0.4439 - mixed_f1_macro: 0.4439\n",
      "Epoch 109/500\n",
      " — train_f1=0.6361 | val_f1=0.4541 | test_f1=0.4541 | mixed_f1=0.4541\n",
      "36/36 - 6s - 156ms/step - accuracy: 0.8036 - loss: 0.8683 - val_accuracy: 0.4404 - val_loss: 1.7027 - train_f1_macro: 0.6361 - val_f1_macro: 0.4541 - test_f1_macro: 0.4541 - mixed_f1_macro: 0.4541\n",
      "Epoch 110/500\n",
      " — train_f1=0.7549 | val_f1=0.5176 | test_f1=0.5176 | mixed_f1=0.5176\n",
      "36/36 - 10s - 271ms/step - accuracy: 0.8227 - loss: 0.8624 - val_accuracy: 0.4954 - val_loss: 1.5654 - train_f1_macro: 0.7549 - val_f1_macro: 0.5176 - test_f1_macro: 0.5176 - mixed_f1_macro: 0.5176\n",
      "Epoch 111/500\n",
      " — train_f1=0.7926 | val_f1=0.5340 | test_f1=0.5340 | mixed_f1=0.5340\n",
      "36/36 - 6s - 156ms/step - accuracy: 0.8192 - loss: 0.8499 - val_accuracy: 0.5046 - val_loss: 1.5876 - train_f1_macro: 0.7926 - val_f1_macro: 0.5340 - test_f1_macro: 0.5340 - mixed_f1_macro: 0.5340\n",
      "Epoch 112/500\n",
      " — train_f1=0.7346 | val_f1=0.4566 | test_f1=0.4566 | mixed_f1=0.4566\n",
      "36/36 - 10s - 272ms/step - accuracy: 0.8175 - loss: 0.8481 - val_accuracy: 0.4618 - val_loss: 1.6852 - train_f1_macro: 0.7346 - val_f1_macro: 0.4566 - test_f1_macro: 0.4566 - mixed_f1_macro: 0.4566\n",
      "Epoch 113/500\n",
      " — train_f1=0.6568 | val_f1=0.4513 | test_f1=0.4513 | mixed_f1=0.4513\n",
      "36/36 - 10s - 281ms/step - accuracy: 0.8266 - loss: 0.8329 - val_accuracy: 0.4618 - val_loss: 1.6805 - train_f1_macro: 0.6568 - val_f1_macro: 0.4513 - test_f1_macro: 0.4513 - mixed_f1_macro: 0.4513\n",
      "Epoch 114/500\n",
      " — train_f1=0.6001 | val_f1=0.4092 | test_f1=0.4092 | mixed_f1=0.4092\n",
      "36/36 - 6s - 156ms/step - accuracy: 0.8131 - loss: 0.8456 - val_accuracy: 0.3731 - val_loss: 2.0269 - train_f1_macro: 0.6001 - val_f1_macro: 0.4092 - test_f1_macro: 0.4092 - mixed_f1_macro: 0.4092\n",
      "Epoch 115/500\n",
      " — train_f1=0.8063 | val_f1=0.5318 | test_f1=0.5318 | mixed_f1=0.5318\n",
      "36/36 - 10s - 270ms/step - accuracy: 0.8179 - loss: 0.8226 - val_accuracy: 0.5076 - val_loss: 1.5733 - train_f1_macro: 0.8063 - val_f1_macro: 0.5318 - test_f1_macro: 0.5318 - mixed_f1_macro: 0.5318\n",
      "Epoch 116/500\n",
      " — train_f1=0.8269 | val_f1=0.5267 | test_f1=0.5267 | mixed_f1=0.5267\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.8236 - loss: 0.8363 - val_accuracy: 0.5046 - val_loss: 1.6031 - train_f1_macro: 0.8269 - val_f1_macro: 0.5267 - test_f1_macro: 0.5267 - mixed_f1_macro: 0.5267\n",
      "Epoch 117/500\n",
      " — train_f1=0.6787 | val_f1=0.5129 | test_f1=0.5129 | mixed_f1=0.5129\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.8244 - loss: 0.8228 - val_accuracy: 0.5107 - val_loss: 1.5883 - train_f1_macro: 0.6787 - val_f1_macro: 0.5129 - test_f1_macro: 0.5129 - mixed_f1_macro: 0.5129\n",
      "Epoch 118/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.8486 | val_f1=0.5689 | test_f1=0.5689 | mixed_f1=0.5689\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 118 | f1=0.5689\n",
      "   → saved_models/merged_fold_8/best_val_f1_macro_epoch118_f10.5689_20260112_015610.h5\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.8283 - loss: 0.8296 - val_accuracy: 0.5352 - val_loss: 1.4657 - train_f1_macro: 0.8486 - val_f1_macro: 0.5689 - test_f1_macro: 0.5689 - mixed_f1_macro: 0.5689\n",
      "Epoch 119/500\n",
      " — train_f1=0.6841 | val_f1=0.4759 | test_f1=0.4759 | mixed_f1=0.4759\n",
      "36/36 - 6s - 159ms/step - accuracy: 0.8305 - loss: 0.8256 - val_accuracy: 0.4648 - val_loss: 1.7331 - train_f1_macro: 0.6841 - val_f1_macro: 0.4759 - test_f1_macro: 0.4759 - mixed_f1_macro: 0.4759\n",
      "Epoch 120/500\n",
      " — train_f1=0.7708 | val_f1=0.4762 | test_f1=0.4762 | mixed_f1=0.4762\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8227 - loss: 0.8268 - val_accuracy: 0.4526 - val_loss: 1.7155 - train_f1_macro: 0.7708 - val_f1_macro: 0.4762 - test_f1_macro: 0.4762 - mixed_f1_macro: 0.4762\n",
      "Epoch 121/500\n",
      " — train_f1=0.6667 | val_f1=0.4207 | test_f1=0.4207 | mixed_f1=0.4207\n",
      "36/36 - 10s - 280ms/step - accuracy: 0.8244 - loss: 0.8271 - val_accuracy: 0.4495 - val_loss: 1.7791 - train_f1_macro: 0.6667 - val_f1_macro: 0.4207 - test_f1_macro: 0.4207 - mixed_f1_macro: 0.4207\n",
      "Epoch 122/500\n",
      " — train_f1=0.8760 | val_f1=0.5364 | test_f1=0.5364 | mixed_f1=0.5364\n",
      "36/36 - 5s - 144ms/step - accuracy: 0.8336 - loss: 0.8350 - val_accuracy: 0.5199 - val_loss: 1.6064 - train_f1_macro: 0.8760 - val_f1_macro: 0.5364 - test_f1_macro: 0.5364 - mixed_f1_macro: 0.5364\n",
      "Epoch 123/500\n",
      " — train_f1=0.8247 | val_f1=0.4995 | test_f1=0.4995 | mixed_f1=0.4995\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8496 - loss: 0.8054 - val_accuracy: 0.4832 - val_loss: 1.6874 - train_f1_macro: 0.8247 - val_f1_macro: 0.4995 - test_f1_macro: 0.4995 - mixed_f1_macro: 0.4995\n",
      "Epoch 124/500\n",
      " — train_f1=0.4813 | val_f1=0.3255 | test_f1=0.3255 | mixed_f1=0.3255\n",
      "36/36 - 11s - 297ms/step - accuracy: 0.8249 - loss: 0.8244 - val_accuracy: 0.3303 - val_loss: 1.9567 - train_f1_macro: 0.4813 - val_f1_macro: 0.3255 - test_f1_macro: 0.3255 - mixed_f1_macro: 0.3255\n",
      "Epoch 125/500\n",
      " — train_f1=0.8182 | val_f1=0.4907 | test_f1=0.4907 | mixed_f1=0.4907\n",
      "36/36 - 10s - 285ms/step - accuracy: 0.8375 - loss: 0.8270 - val_accuracy: 0.4801 - val_loss: 1.7190 - train_f1_macro: 0.8182 - val_f1_macro: 0.4907 - test_f1_macro: 0.4907 - mixed_f1_macro: 0.4907\n",
      "Epoch 126/500\n",
      " — train_f1=0.8492 | val_f1=0.4924 | test_f1=0.4924 | mixed_f1=0.4924\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.8509 - loss: 0.8013 - val_accuracy: 0.4862 - val_loss: 1.6758 - train_f1_macro: 0.8492 - val_f1_macro: 0.4924 - test_f1_macro: 0.4924 - mixed_f1_macro: 0.4924\n",
      "Epoch 127/500\n",
      " — train_f1=0.7922 | val_f1=0.5392 | test_f1=0.5392 | mixed_f1=0.5392\n",
      "36/36 - 10s - 267ms/step - accuracy: 0.8475 - loss: 0.8003 - val_accuracy: 0.5168 - val_loss: 1.5680 - train_f1_macro: 0.7922 - val_f1_macro: 0.5392 - test_f1_macro: 0.5392 - mixed_f1_macro: 0.5392\n",
      "Epoch 128/500\n",
      " — train_f1=0.7357 | val_f1=0.4982 | test_f1=0.4982 | mixed_f1=0.4982\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.8449 - loss: 0.8288 - val_accuracy: 0.4893 - val_loss: 1.5867 - train_f1_macro: 0.7357 - val_f1_macro: 0.4982 - test_f1_macro: 0.4982 - mixed_f1_macro: 0.4982\n",
      "Epoch 129/500\n",
      " — train_f1=0.8393 | val_f1=0.5531 | test_f1=0.5531 | mixed_f1=0.5531\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8396 - loss: 0.8080 - val_accuracy: 0.5260 - val_loss: 1.6337 - train_f1_macro: 0.8393 - val_f1_macro: 0.5531 - test_f1_macro: 0.5531 - mixed_f1_macro: 0.5531\n",
      "Epoch 130/500\n",
      " — train_f1=0.8430 | val_f1=0.4938 | test_f1=0.4938 | mixed_f1=0.4938\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8548 - loss: 0.7843 - val_accuracy: 0.4893 - val_loss: 1.6375 - train_f1_macro: 0.8430 - val_f1_macro: 0.4938 - test_f1_macro: 0.4938 - mixed_f1_macro: 0.4938\n",
      "Epoch 131/500\n",
      " — train_f1=0.7209 | val_f1=0.5027 | test_f1=0.5027 | mixed_f1=0.5027\n",
      "36/36 - 5s - 140ms/step - accuracy: 0.8414 - loss: 0.8154 - val_accuracy: 0.4893 - val_loss: 1.5893 - train_f1_macro: 0.7209 - val_f1_macro: 0.5027 - test_f1_macro: 0.5027 - mixed_f1_macro: 0.5027\n",
      "Epoch 132/500\n",
      " — train_f1=0.6203 | val_f1=0.4112 | test_f1=0.4112 | mixed_f1=0.4112\n",
      "36/36 - 5s - 144ms/step - accuracy: 0.8396 - loss: 0.8222 - val_accuracy: 0.4098 - val_loss: 1.8881 - train_f1_macro: 0.6203 - val_f1_macro: 0.4112 - test_f1_macro: 0.4112 - mixed_f1_macro: 0.4112\n",
      "Epoch 133/500\n",
      " — train_f1=0.7860 | val_f1=0.4982 | test_f1=0.4982 | mixed_f1=0.4982\n",
      "36/36 - 10s - 280ms/step - accuracy: 0.8240 - loss: 0.8495 - val_accuracy: 0.4648 - val_loss: 1.7092 - train_f1_macro: 0.7860 - val_f1_macro: 0.4982 - test_f1_macro: 0.4982 - mixed_f1_macro: 0.4982\n",
      "Epoch 134/500\n",
      " — train_f1=0.6194 | val_f1=0.4539 | test_f1=0.4539 | mixed_f1=0.4539\n",
      "36/36 - 6s - 155ms/step - accuracy: 0.8218 - loss: 0.8590 - val_accuracy: 0.4495 - val_loss: 1.7396 - train_f1_macro: 0.6194 - val_f1_macro: 0.4539 - test_f1_macro: 0.4539 - mixed_f1_macro: 0.4539\n",
      "Epoch 135/500\n",
      " — train_f1=0.8903 | val_f1=0.5469 | test_f1=0.5469 | mixed_f1=0.5469\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.8444 - loss: 0.7913 - val_accuracy: 0.5260 - val_loss: 1.6412 - train_f1_macro: 0.8903 - val_f1_macro: 0.5469 - test_f1_macro: 0.5469 - mixed_f1_macro: 0.5469\n",
      "Epoch 136/500\n",
      " — train_f1=0.8834 | val_f1=0.5263 | test_f1=0.5263 | mixed_f1=0.5263\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.8457 - loss: 0.7948 - val_accuracy: 0.5107 - val_loss: 1.6068 - train_f1_macro: 0.8834 - val_f1_macro: 0.5263 - test_f1_macro: 0.5263 - mixed_f1_macro: 0.5263\n",
      "Epoch 137/500\n",
      " — train_f1=0.8173 | val_f1=0.5059 | test_f1=0.5059 | mixed_f1=0.5059\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.8666 - loss: 0.7702 - val_accuracy: 0.4985 - val_loss: 1.7305 - train_f1_macro: 0.8173 - val_f1_macro: 0.5059 - test_f1_macro: 0.5059 - mixed_f1_macro: 0.5059\n",
      "Epoch 138/500\n",
      " — train_f1=0.6166 | val_f1=0.4615 | test_f1=0.4615 | mixed_f1=0.4615\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.8396 - loss: 0.8138 - val_accuracy: 0.4434 - val_loss: 1.8142 - train_f1_macro: 0.6166 - val_f1_macro: 0.4615 - test_f1_macro: 0.4615 - mixed_f1_macro: 0.4615\n",
      "Epoch 139/500\n",
      " — train_f1=0.7756 | val_f1=0.5098 | test_f1=0.5098 | mixed_f1=0.5098\n",
      "36/36 - 5s - 139ms/step - accuracy: 0.8592 - loss: 0.8026 - val_accuracy: 0.5015 - val_loss: 1.6937 - train_f1_macro: 0.7756 - val_f1_macro: 0.5098 - test_f1_macro: 0.5098 - mixed_f1_macro: 0.5098\n",
      "Epoch 140/500\n",
      " — train_f1=0.8788 | val_f1=0.4936 | test_f1=0.4936 | mixed_f1=0.4936\n",
      "36/36 - 5s - 145ms/step - accuracy: 0.8588 - loss: 0.7690 - val_accuracy: 0.4740 - val_loss: 1.7405 - train_f1_macro: 0.8788 - val_f1_macro: 0.4936 - test_f1_macro: 0.4936 - mixed_f1_macro: 0.4936\n",
      "Epoch 141/500\n",
      " — train_f1=0.6331 | val_f1=0.4239 | test_f1=0.4239 | mixed_f1=0.4239\n",
      "36/36 - 5s - 141ms/step - accuracy: 0.8561 - loss: 0.7893 - val_accuracy: 0.4251 - val_loss: 1.8901 - train_f1_macro: 0.6331 - val_f1_macro: 0.4239 - test_f1_macro: 0.4239 - mixed_f1_macro: 0.4239\n",
      "Epoch 142/500\n",
      " — train_f1=0.6903 | val_f1=0.4622 | test_f1=0.4622 | mixed_f1=0.4622\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8583 - loss: 0.7916 - val_accuracy: 0.4557 - val_loss: 1.7595 - train_f1_macro: 0.6903 - val_f1_macro: 0.4622 - test_f1_macro: 0.4622 - mixed_f1_macro: 0.4622\n",
      "Epoch 143/500\n",
      " — train_f1=0.8408 | val_f1=0.4800 | test_f1=0.4800 | mixed_f1=0.4800\n",
      "36/36 - 10s - 284ms/step - accuracy: 0.8518 - loss: 0.7959 - val_accuracy: 0.4709 - val_loss: 1.7465 - train_f1_macro: 0.8408 - val_f1_macro: 0.4800 - test_f1_macro: 0.4800 - mixed_f1_macro: 0.4800\n",
      "Epoch 144/500\n",
      " — train_f1=0.7460 | val_f1=0.4666 | test_f1=0.4666 | mixed_f1=0.4666\n",
      "36/36 - 11s - 297ms/step - accuracy: 0.8670 - loss: 0.7743 - val_accuracy: 0.4679 - val_loss: 1.7956 - train_f1_macro: 0.7460 - val_f1_macro: 0.4666 - test_f1_macro: 0.4666 - mixed_f1_macro: 0.4666\n",
      "Epoch 145/500\n",
      " — train_f1=0.7653 | val_f1=0.4594 | test_f1=0.4594 | mixed_f1=0.4594\n",
      "36/36 - 10s - 283ms/step - accuracy: 0.8696 - loss: 0.7625 - val_accuracy: 0.4587 - val_loss: 1.8734 - train_f1_macro: 0.7653 - val_f1_macro: 0.4594 - test_f1_macro: 0.4594 - mixed_f1_macro: 0.4594\n",
      "Epoch 146/500\n",
      " — train_f1=0.8624 | val_f1=0.5351 | test_f1=0.5351 | mixed_f1=0.5351\n",
      "36/36 - 10s - 268ms/step - accuracy: 0.8648 - loss: 0.7649 - val_accuracy: 0.5015 - val_loss: 1.6520 - train_f1_macro: 0.8624 - val_f1_macro: 0.5351 - test_f1_macro: 0.5351 - mixed_f1_macro: 0.5351\n",
      "Epoch 147/500\n",
      " — train_f1=0.7899 | val_f1=0.4477 | test_f1=0.4477 | mixed_f1=0.4477\n",
      "36/36 - 5s - 142ms/step - accuracy: 0.8705 - loss: 0.7891 - val_accuracy: 0.4557 - val_loss: 1.8555 - train_f1_macro: 0.7899 - val_f1_macro: 0.4477 - test_f1_macro: 0.4477 - mixed_f1_macro: 0.4477\n",
      "Epoch 148/500\n",
      " — train_f1=0.8965 | val_f1=0.5248 | test_f1=0.5248 | mixed_f1=0.5248\n",
      "36/36 - 5s - 143ms/step - accuracy: 0.8596 - loss: 0.7850 - val_accuracy: 0.5015 - val_loss: 1.7042 - train_f1_macro: 0.8965 - val_f1_macro: 0.5248 - test_f1_macro: 0.5248 - mixed_f1_macro: 0.5248\n",
      "\n",
      "Fold 8 FINAL (Mixed Test): ACC=0.5352 F1w=0.5227 MCC=0.4075\n",
      "\n",
      "==========================================================================================\n",
      "TRAINING MERGED FOLD 9  (robust to keep_separate_tests True/False)\n",
      "==========================================================================================\n",
      "X_train: (2368, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_test: (260, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "X_mix: (260, 100, 280, 1) uniq y: [0 1 2 3 4]\n",
      "Class weights (present only): {0: 0.5081545064377683, 1: 0.7297380585516179, 2: 0.8579710144927536, 3: 4.426168224299065, 4: 3.7}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1768201182.945321 1723792 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_9_1/dropout_45_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.0253 | val_f1=0.0448 | test_f1=0.0448 | mixed_f1=0.0448\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 1 | f1=0.0448\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch1_f10.0448_20260112_015949.h5\n",
      "37/37 - 8s - 216ms/step - accuracy: 0.2555 - loss: 1.8585 - val_accuracy: 0.1231 - val_loss: 2.0245 - train_f1_macro: 0.0253 - val_f1_macro: 0.0448 - test_f1_macro: 0.0448 - mixed_f1_macro: 0.0448\n",
      "Epoch 2/500\n",
      " — train_f1=0.0198 | val_f1=0.0436 | test_f1=0.0436 | mixed_f1=0.0436\n",
      "37/37 - 9s - 255ms/step - accuracy: 0.3112 - loss: 1.7208 - val_accuracy: 0.1077 - val_loss: 2.1252 - train_f1_macro: 0.0198 - val_f1_macro: 0.0436 - test_f1_macro: 0.0436 - mixed_f1_macro: 0.0436\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.2939 | val_f1=0.2967 | test_f1=0.2967 | mixed_f1=0.2967\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 3 | f1=0.2967\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch3_f10.2967_20260112_020004.h5\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.3370 - loss: 1.6022 - val_accuracy: 0.2923 - val_loss: 1.6060 - train_f1_macro: 0.2939 - val_f1_macro: 0.2967 - test_f1_macro: 0.2967 - mixed_f1_macro: 0.2967\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3273 | val_f1=0.3213 | test_f1=0.3213 | mixed_f1=0.3213\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 4 | f1=0.3213\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch4_f10.3213_20260112_020014.h5\n",
      "37/37 - 10s - 281ms/step - accuracy: 0.3353 - loss: 1.5509 - val_accuracy: 0.3231 - val_loss: 1.6327 - train_f1_macro: 0.3273 - val_f1_macro: 0.3213 - test_f1_macro: 0.3213 - mixed_f1_macro: 0.3213\n",
      "Epoch 5/500\n",
      " — train_f1=0.3409 | val_f1=0.2569 | test_f1=0.2569 | mixed_f1=0.2569\n",
      "37/37 - 9s - 255ms/step - accuracy: 0.3758 - loss: 1.5041 - val_accuracy: 0.3346 - val_loss: 1.5833 - train_f1_macro: 0.3409 - val_f1_macro: 0.2569 - test_f1_macro: 0.2569 - mixed_f1_macro: 0.2569\n",
      "Epoch 6/500\n",
      " — train_f1=0.2186 | val_f1=0.2015 | test_f1=0.2015 | mixed_f1=0.2015\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.3526 - loss: 1.4734 - val_accuracy: 0.2385 - val_loss: 1.6257 - train_f1_macro: 0.2186 - val_f1_macro: 0.2015 - test_f1_macro: 0.2015 - mixed_f1_macro: 0.2015\n",
      "Epoch 7/500\n",
      " — train_f1=0.3618 | val_f1=0.3125 | test_f1=0.3125 | mixed_f1=0.3125\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.3530 - loss: 1.4597 - val_accuracy: 0.3038 - val_loss: 1.4759 - train_f1_macro: 0.3618 - val_f1_macro: 0.3125 - test_f1_macro: 0.3125 - mixed_f1_macro: 0.3125\n",
      "Epoch 8/500\n",
      " — train_f1=0.3269 | val_f1=0.2541 | test_f1=0.2541 | mixed_f1=0.2541\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3775 - loss: 1.4259 - val_accuracy: 0.3038 - val_loss: 1.5983 - train_f1_macro: 0.3269 - val_f1_macro: 0.2541 - test_f1_macro: 0.2541 - mixed_f1_macro: 0.2541\n",
      "Epoch 9/500\n",
      " — train_f1=0.2340 | val_f1=0.2183 | test_f1=0.2183 | mixed_f1=0.2183\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.3818 - loss: 1.4034 - val_accuracy: 0.2654 - val_loss: 1.5679 - train_f1_macro: 0.2340 - val_f1_macro: 0.2183 - test_f1_macro: 0.2183 - mixed_f1_macro: 0.2183\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4143 | val_f1=0.3338 | test_f1=0.3338 | mixed_f1=0.3338\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 10 | f1=0.3338\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch10_f10.3338_20260112_020054.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.3691 - loss: 1.4002 - val_accuracy: 0.3577 - val_loss: 1.4786 - train_f1_macro: 0.4143 - val_f1_macro: 0.3338 - test_f1_macro: 0.3338 - mixed_f1_macro: 0.3338\n",
      "Epoch 11/500\n",
      " — train_f1=0.3594 | val_f1=0.2454 | test_f1=0.2454 | mixed_f1=0.2454\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3746 - loss: 1.3954 - val_accuracy: 0.2962 - val_loss: 1.5305 - train_f1_macro: 0.3594 - val_f1_macro: 0.2454 - test_f1_macro: 0.2454 - mixed_f1_macro: 0.2454\n",
      "Epoch 12/500\n",
      " — train_f1=0.2901 | val_f1=0.2324 | test_f1=0.2324 | mixed_f1=0.2324\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.3868 - loss: 1.3803 - val_accuracy: 0.2923 - val_loss: 1.4697 - train_f1_macro: 0.2901 - val_f1_macro: 0.2324 - test_f1_macro: 0.2324 - mixed_f1_macro: 0.2324\n",
      "Epoch 13/500\n",
      " — train_f1=0.3370 | val_f1=0.2720 | test_f1=0.2720 | mixed_f1=0.2720\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.3948 - loss: 1.3631 - val_accuracy: 0.3269 - val_loss: 1.4575 - train_f1_macro: 0.3370 - val_f1_macro: 0.2720 - test_f1_macro: 0.2720 - mixed_f1_macro: 0.2720\n",
      "Epoch 14/500\n",
      " — train_f1=0.2186 | val_f1=0.2066 | test_f1=0.2066 | mixed_f1=0.2066\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.3801 - loss: 1.3539 - val_accuracy: 0.2731 - val_loss: 1.6057 - train_f1_macro: 0.2186 - val_f1_macro: 0.2066 - test_f1_macro: 0.2066 - mixed_f1_macro: 0.2066\n",
      "Epoch 15/500\n",
      " — train_f1=0.2619 | val_f1=0.2549 | test_f1=0.2549 | mixed_f1=0.2549\n",
      "37/37 - 10s - 273ms/step - accuracy: 0.3906 - loss: 1.3492 - val_accuracy: 0.2654 - val_loss: 1.6641 - train_f1_macro: 0.2619 - val_f1_macro: 0.2549 - test_f1_macro: 0.2549 - mixed_f1_macro: 0.2549\n",
      "Epoch 16/500\n",
      " — train_f1=0.3517 | val_f1=0.2988 | test_f1=0.2988 | mixed_f1=0.2988\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.4071 - loss: 1.3364 - val_accuracy: 0.3769 - val_loss: 1.5146 - train_f1_macro: 0.3517 - val_f1_macro: 0.2988 - test_f1_macro: 0.2988 - mixed_f1_macro: 0.2988\n",
      "Epoch 17/500\n",
      " — train_f1=0.1851 | val_f1=0.1530 | test_f1=0.1530 | mixed_f1=0.1530\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.4134 - loss: 1.3221 - val_accuracy: 0.2077 - val_loss: 1.9711 - train_f1_macro: 0.1851 - val_f1_macro: 0.1530 - test_f1_macro: 0.1530 - mixed_f1_macro: 0.1530\n",
      "Epoch 18/500\n",
      " — train_f1=0.1783 | val_f1=0.1550 | test_f1=0.1550 | mixed_f1=0.1550\n",
      "37/37 - 5s - 141ms/step - accuracy: 0.3948 - loss: 1.3151 - val_accuracy: 0.2154 - val_loss: 1.8457 - train_f1_macro: 0.1783 - val_f1_macro: 0.1550 - test_f1_macro: 0.1550 - mixed_f1_macro: 0.1550\n",
      "Epoch 19/500\n",
      " — train_f1=0.1912 | val_f1=0.1804 | test_f1=0.1804 | mixed_f1=0.1804\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4181 - loss: 1.3075 - val_accuracy: 0.2462 - val_loss: 1.7378 - train_f1_macro: 0.1912 - val_f1_macro: 0.1804 - test_f1_macro: 0.1804 - mixed_f1_macro: 0.1804\n",
      "Epoch 20/500\n",
      " — train_f1=0.3684 | val_f1=0.2843 | test_f1=0.2843 | mixed_f1=0.2843\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4337 - loss: 1.2901 - val_accuracy: 0.3462 - val_loss: 1.4326 - train_f1_macro: 0.3684 - val_f1_macro: 0.2843 - test_f1_macro: 0.2843 - mixed_f1_macro: 0.2843\n",
      "Epoch 21/500\n",
      " — train_f1=0.3365 | val_f1=0.2756 | test_f1=0.2756 | mixed_f1=0.2756\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.4143 - loss: 1.2983 - val_accuracy: 0.3308 - val_loss: 1.4900 - train_f1_macro: 0.3365 - val_f1_macro: 0.2756 - test_f1_macro: 0.2756 - mixed_f1_macro: 0.2756\n",
      "Epoch 22/500\n",
      " — train_f1=0.2839 | val_f1=0.2711 | test_f1=0.2711 | mixed_f1=0.2711\n",
      "37/37 - 5s - 133ms/step - accuracy: 0.4468 - loss: 1.2819 - val_accuracy: 0.2962 - val_loss: 1.7162 - train_f1_macro: 0.2839 - val_f1_macro: 0.2711 - test_f1_macro: 0.2711 - mixed_f1_macro: 0.2711\n",
      "Epoch 23/500\n",
      " — train_f1=0.1688 | val_f1=0.1929 | test_f1=0.1929 | mixed_f1=0.1929\n",
      "37/37 - 6s - 156ms/step - accuracy: 0.4548 - loss: 1.2737 - val_accuracy: 0.2231 - val_loss: 2.0376 - train_f1_macro: 0.1688 - val_f1_macro: 0.1929 - test_f1_macro: 0.1929 - mixed_f1_macro: 0.1929\n",
      "Epoch 24/500\n",
      " — train_f1=0.4450 | val_f1=0.3326 | test_f1=0.3326 | mixed_f1=0.3326\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.4578 - loss: 1.2624 - val_accuracy: 0.4462 - val_loss: 1.3937 - train_f1_macro: 0.4450 - val_f1_macro: 0.3326 - test_f1_macro: 0.3326 - mixed_f1_macro: 0.3326\n",
      "Epoch 25/500\n",
      " — train_f1=0.2375 | val_f1=0.3100 | test_f1=0.3100 | mixed_f1=0.3100\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.4481 - loss: 1.2606 - val_accuracy: 0.3423 - val_loss: 1.7700 - train_f1_macro: 0.2375 - val_f1_macro: 0.3100 - test_f1_macro: 0.3100 - mixed_f1_macro: 0.3100\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3300 | val_f1=0.3614 | test_f1=0.3614 | mixed_f1=0.3614\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 26 | f1=0.3614\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch26_f10.3614_20260112_020226.h5\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.4772 - loss: 1.2548 - val_accuracy: 0.4269 - val_loss: 1.4948 - train_f1_macro: 0.3300 - val_f1_macro: 0.3614 - test_f1_macro: 0.3614 - mixed_f1_macro: 0.3614\n",
      "Epoch 27/500\n",
      " — train_f1=0.4263 | val_f1=0.3067 | test_f1=0.3067 | mixed_f1=0.3067\n",
      "37/37 - 10s - 260ms/step - accuracy: 0.4865 - loss: 1.2495 - val_accuracy: 0.4115 - val_loss: 1.4002 - train_f1_macro: 0.4263 - val_f1_macro: 0.3067 - test_f1_macro: 0.3067 - mixed_f1_macro: 0.3067\n",
      "Epoch 28/500\n",
      " — train_f1=0.3079 | val_f1=0.3492 | test_f1=0.3492 | mixed_f1=0.3492\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.4620 - loss: 1.2587 - val_accuracy: 0.4077 - val_loss: 1.5046 - train_f1_macro: 0.3079 - val_f1_macro: 0.3492 - test_f1_macro: 0.3492 - mixed_f1_macro: 0.3492\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3890 | val_f1=0.3643 | test_f1=0.3643 | mixed_f1=0.3643\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 29 | f1=0.3643\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch29_f10.3643_20260112_020246.h5\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.4924 - loss: 1.2304 - val_accuracy: 0.4500 - val_loss: 1.3735 - train_f1_macro: 0.3890 - val_f1_macro: 0.3643 - test_f1_macro: 0.3643 - mixed_f1_macro: 0.3643\n",
      "Epoch 30/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.4268 | val_f1=0.3676 | test_f1=0.3676 | mixed_f1=0.3676\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 30 | f1=0.3676\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch30_f10.3676_20260112_020256.h5\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.4924 - loss: 1.2316 - val_accuracy: 0.4231 - val_loss: 1.3820 - train_f1_macro: 0.4268 - val_f1_macro: 0.3676 - test_f1_macro: 0.3676 - mixed_f1_macro: 0.3676\n",
      "Epoch 31/500\n",
      " — train_f1=0.3345 | val_f1=0.2458 | test_f1=0.2458 | mixed_f1=0.2458\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5000 - loss: 1.2260 - val_accuracy: 0.2731 - val_loss: 1.6901 - train_f1_macro: 0.3345 - val_f1_macro: 0.2458 - test_f1_macro: 0.2458 - mixed_f1_macro: 0.2458\n",
      "Epoch 32/500\n",
      " — train_f1=0.3087 | val_f1=0.2793 | test_f1=0.2793 | mixed_f1=0.2793\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5101 - loss: 1.2179 - val_accuracy: 0.4038 - val_loss: 1.4743 - train_f1_macro: 0.3087 - val_f1_macro: 0.2793 - test_f1_macro: 0.2793 - mixed_f1_macro: 0.2793\n",
      "Epoch 33/500\n",
      " — train_f1=0.3747 | val_f1=0.3328 | test_f1=0.3328 | mixed_f1=0.3328\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5025 - loss: 1.2157 - val_accuracy: 0.4577 - val_loss: 1.3902 - train_f1_macro: 0.3747 - val_f1_macro: 0.3328 - test_f1_macro: 0.3328 - mixed_f1_macro: 0.3328\n",
      "Epoch 34/500\n",
      " — train_f1=0.2824 | val_f1=0.3085 | test_f1=0.3085 | mixed_f1=0.3085\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5376 - loss: 1.1966 - val_accuracy: 0.4462 - val_loss: 1.4515 - train_f1_macro: 0.2824 - val_f1_macro: 0.3085 - test_f1_macro: 0.3085 - mixed_f1_macro: 0.3085\n",
      "Epoch 35/500\n",
      " — train_f1=0.4269 | val_f1=0.2821 | test_f1=0.2821 | mixed_f1=0.2821\n",
      "37/37 - 5s - 135ms/step - accuracy: 0.5380 - loss: 1.2055 - val_accuracy: 0.3077 - val_loss: 1.6394 - train_f1_macro: 0.4269 - val_f1_macro: 0.2821 - test_f1_macro: 0.2821 - mixed_f1_macro: 0.2821\n",
      "Epoch 36/500\n",
      " — train_f1=0.5186 | val_f1=0.3595 | test_f1=0.3595 | mixed_f1=0.3595\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.5431 - loss: 1.1776 - val_accuracy: 0.3885 - val_loss: 1.4520 - train_f1_macro: 0.5186 - val_f1_macro: 0.3595 - test_f1_macro: 0.3595 - mixed_f1_macro: 0.3595\n",
      "Epoch 37/500\n",
      " — train_f1=0.5300 | val_f1=0.3395 | test_f1=0.3395 | mixed_f1=0.3395\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.5384 - loss: 1.1705 - val_accuracy: 0.3577 - val_loss: 1.4287 - train_f1_macro: 0.5300 - val_f1_macro: 0.3395 - test_f1_macro: 0.3395 - mixed_f1_macro: 0.3395\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.3788 | val_f1=0.3907 | test_f1=0.3907 | mixed_f1=0.3907\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 38 | f1=0.3907\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch38_f10.3907_20260112_020337.h5\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.5676 - loss: 1.1635 - val_accuracy: 0.4885 - val_loss: 1.3663 - train_f1_macro: 0.3788 - val_f1_macro: 0.3907 - test_f1_macro: 0.3907 - mixed_f1_macro: 0.3907\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.5888 | val_f1=0.4511 | test_f1=0.4511 | mixed_f1=0.4511\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 39 | f1=0.4511\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch39_f10.4511_20260112_020342.h5\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.5503 - loss: 1.1844 - val_accuracy: 0.5000 - val_loss: 1.3247 - train_f1_macro: 0.5888 - val_f1_macro: 0.4511 - test_f1_macro: 0.4511 - mixed_f1_macro: 0.4511\n",
      "Epoch 40/500\n",
      " — train_f1=0.5376 | val_f1=0.3640 | test_f1=0.3640 | mixed_f1=0.3640\n",
      "37/37 - 6s - 153ms/step - accuracy: 0.5693 - loss: 1.1636 - val_accuracy: 0.4269 - val_loss: 1.4361 - train_f1_macro: 0.5376 - val_f1_macro: 0.3640 - test_f1_macro: 0.3640 - mixed_f1_macro: 0.3640\n",
      "Epoch 41/500\n",
      " — train_f1=0.4409 | val_f1=0.4250 | test_f1=0.4250 | mixed_f1=0.4250\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.5663 - loss: 1.1601 - val_accuracy: 0.4923 - val_loss: 1.3857 - train_f1_macro: 0.4409 - val_f1_macro: 0.4250 - test_f1_macro: 0.4250 - mixed_f1_macro: 0.4250\n",
      "Epoch 42/500\n",
      " — train_f1=0.5002 | val_f1=0.3025 | test_f1=0.3025 | mixed_f1=0.3025\n",
      "37/37 - 10s - 262ms/step - accuracy: 0.5976 - loss: 1.1359 - val_accuracy: 0.3654 - val_loss: 1.5307 - train_f1_macro: 0.5002 - val_f1_macro: 0.3025 - test_f1_macro: 0.3025 - mixed_f1_macro: 0.3025\n",
      "Epoch 43/500\n",
      " — train_f1=0.4766 | val_f1=0.3866 | test_f1=0.3866 | mixed_f1=0.3866\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.6018 - loss: 1.1395 - val_accuracy: 0.4654 - val_loss: 1.3791 - train_f1_macro: 0.4766 - val_f1_macro: 0.3866 - test_f1_macro: 0.3866 - mixed_f1_macro: 0.3866\n",
      "Epoch 44/500\n",
      " — train_f1=0.5317 | val_f1=0.4144 | test_f1=0.4144 | mixed_f1=0.4144\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.5861 - loss: 1.1486 - val_accuracy: 0.3962 - val_loss: 1.5329 - train_f1_macro: 0.5317 - val_f1_macro: 0.4144 - test_f1_macro: 0.4144 - mixed_f1_macro: 0.4144\n",
      "Epoch 45/500\n",
      " — train_f1=0.6019 | val_f1=0.4291 | test_f1=0.4291 | mixed_f1=0.4291\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.5992 - loss: 1.1304 - val_accuracy: 0.4962 - val_loss: 1.3170 - train_f1_macro: 0.6019 - val_f1_macro: 0.4291 - test_f1_macro: 0.4291 - mixed_f1_macro: 0.4291\n",
      "Epoch 46/500\n",
      " — train_f1=0.1742 | val_f1=0.2504 | test_f1=0.2504 | mixed_f1=0.2504\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.5921 - loss: 1.1281 - val_accuracy: 0.3385 - val_loss: 1.7765 - train_f1_macro: 0.1742 - val_f1_macro: 0.2504 - test_f1_macro: 0.2504 - mixed_f1_macro: 0.2504\n",
      "Epoch 47/500\n",
      " — train_f1=0.5499 | val_f1=0.3683 | test_f1=0.3683 | mixed_f1=0.3683\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6085 - loss: 1.1283 - val_accuracy: 0.3923 - val_loss: 1.5133 - train_f1_macro: 0.5499 - val_f1_macro: 0.3683 - test_f1_macro: 0.3683 - mixed_f1_macro: 0.3683\n",
      "Epoch 48/500\n",
      " — train_f1=0.6162 | val_f1=0.4202 | test_f1=0.4202 | mixed_f1=0.4202\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.6191 - loss: 1.1029 - val_accuracy: 0.4846 - val_loss: 1.3349 - train_f1_macro: 0.6162 - val_f1_macro: 0.4202 - test_f1_macro: 0.4202 - mixed_f1_macro: 0.4202\n",
      "Epoch 49/500\n",
      " — train_f1=0.6034 | val_f1=0.4471 | test_f1=0.4471 | mixed_f1=0.4471\n",
      "37/37 - 5s - 138ms/step - accuracy: 0.6389 - loss: 1.0906 - val_accuracy: 0.4692 - val_loss: 1.4276 - train_f1_macro: 0.6034 - val_f1_macro: 0.4471 - test_f1_macro: 0.4471 - mixed_f1_macro: 0.4471\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6331 | val_f1=0.4998 | test_f1=0.4998 | mixed_f1=0.4998\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 50 | f1=0.4998\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch50_f10.4998_20260112_020458.h5\n",
      "37/37 - 5s - 142ms/step - accuracy: 0.6406 - loss: 1.0933 - val_accuracy: 0.5654 - val_loss: 1.2653 - train_f1_macro: 0.6331 - val_f1_macro: 0.4998 - test_f1_macro: 0.4998 - mixed_f1_macro: 0.4998\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — train_f1=0.6581 | val_f1=0.5508 | test_f1=0.5508 | mixed_f1=0.5508\n",
      "\n",
      "✅ Saved BEST model (val_f1_macro) at epoch 51 | f1=0.5508\n",
      "   → saved_models/merged_fold_9/best_val_f1_macro_epoch51_f10.5508_20260112_020504.h5\n",
      "37/37 - 6s - 152ms/step - accuracy: 0.6406 - loss: 1.0926 - val_accuracy: 0.5808 - val_loss: 1.2608 - train_f1_macro: 0.6581 - val_f1_macro: 0.5508 - test_f1_macro: 0.5508 - mixed_f1_macro: 0.5508\n",
      "Epoch 52/500\n",
      " — train_f1=0.6189 | val_f1=0.4869 | test_f1=0.4869 | mixed_f1=0.4869\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.6326 - loss: 1.0917 - val_accuracy: 0.5654 - val_loss: 1.2716 - train_f1_macro: 0.6189 - val_f1_macro: 0.4869 - test_f1_macro: 0.4869 - mixed_f1_macro: 0.4869\n",
      "Epoch 53/500\n",
      " — train_f1=0.5260 | val_f1=0.3372 | test_f1=0.3372 | mixed_f1=0.3372\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6432 - loss: 1.0840 - val_accuracy: 0.3538 - val_loss: 1.6703 - train_f1_macro: 0.5260 - val_f1_macro: 0.3372 - test_f1_macro: 0.3372 - mixed_f1_macro: 0.3372\n",
      "Epoch 54/500\n",
      " — train_f1=0.5406 | val_f1=0.4682 | test_f1=0.4682 | mixed_f1=0.4682\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.6423 - loss: 1.0842 - val_accuracy: 0.5462 - val_loss: 1.2835 - train_f1_macro: 0.5406 - val_f1_macro: 0.4682 - test_f1_macro: 0.4682 - mixed_f1_macro: 0.4682\n",
      "Epoch 55/500\n",
      " — train_f1=0.6393 | val_f1=0.4231 | test_f1=0.4231 | mixed_f1=0.4231\n",
      "37/37 - 6s - 154ms/step - accuracy: 0.6436 - loss: 1.0568 - val_accuracy: 0.4808 - val_loss: 1.4483 - train_f1_macro: 0.6393 - val_f1_macro: 0.4231 - test_f1_macro: 0.4231 - mixed_f1_macro: 0.4231\n",
      "Epoch 56/500\n",
      " — train_f1=0.5087 | val_f1=0.4542 | test_f1=0.4542 | mixed_f1=0.4542\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.6757 - loss: 1.0567 - val_accuracy: 0.5308 - val_loss: 1.3161 - train_f1_macro: 0.5087 - val_f1_macro: 0.4542 - test_f1_macro: 0.4542 - mixed_f1_macro: 0.4542\n",
      "Epoch 57/500\n",
      " — train_f1=0.5798 | val_f1=0.3806 | test_f1=0.3806 | mixed_f1=0.3806\n",
      "37/37 - 5s - 147ms/step - accuracy: 0.6651 - loss: 1.0452 - val_accuracy: 0.3885 - val_loss: 1.6238 - train_f1_macro: 0.5798 - val_f1_macro: 0.3806 - test_f1_macro: 0.3806 - mixed_f1_macro: 0.3806\n",
      "Epoch 58/500\n",
      " — train_f1=0.7005 | val_f1=0.4903 | test_f1=0.4903 | mixed_f1=0.4903\n",
      "37/37 - 10s - 279ms/step - accuracy: 0.6913 - loss: 1.0440 - val_accuracy: 0.4923 - val_loss: 1.3861 - train_f1_macro: 0.7005 - val_f1_macro: 0.4903 - test_f1_macro: 0.4903 - mixed_f1_macro: 0.4903\n",
      "Epoch 59/500\n",
      " — train_f1=0.7242 | val_f1=0.5223 | test_f1=0.5223 | mixed_f1=0.5223\n",
      "37/37 - 10s - 259ms/step - accuracy: 0.6486 - loss: 1.0642 - val_accuracy: 0.5269 - val_loss: 1.3097 - train_f1_macro: 0.7242 - val_f1_macro: 0.5223 - test_f1_macro: 0.5223 - mixed_f1_macro: 0.5223\n",
      "Epoch 60/500\n",
      " — train_f1=0.6236 | val_f1=0.3626 | test_f1=0.3626 | mixed_f1=0.3626\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6829 - loss: 1.0393 - val_accuracy: 0.4308 - val_loss: 1.5096 - train_f1_macro: 0.6236 - val_f1_macro: 0.3626 - test_f1_macro: 0.3626 - mixed_f1_macro: 0.3626\n",
      "Epoch 61/500\n",
      " — train_f1=0.6905 | val_f1=0.4822 | test_f1=0.4822 | mixed_f1=0.4822\n",
      "37/37 - 10s - 275ms/step - accuracy: 0.6858 - loss: 1.0235 - val_accuracy: 0.5077 - val_loss: 1.3665 - train_f1_macro: 0.6905 - val_f1_macro: 0.4822 - test_f1_macro: 0.4822 - mixed_f1_macro: 0.4822\n",
      "Epoch 62/500\n",
      " — train_f1=0.6163 | val_f1=0.4146 | test_f1=0.4146 | mixed_f1=0.4146\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6782 - loss: 1.0366 - val_accuracy: 0.4038 - val_loss: 1.5433 - train_f1_macro: 0.6163 - val_f1_macro: 0.4146 - test_f1_macro: 0.4146 - mixed_f1_macro: 0.4146\n",
      "Epoch 63/500\n",
      " — train_f1=0.6344 | val_f1=0.4559 | test_f1=0.4559 | mixed_f1=0.4559\n",
      "37/37 - 6s - 155ms/step - accuracy: 0.6921 - loss: 1.0020 - val_accuracy: 0.4846 - val_loss: 1.4636 - train_f1_macro: 0.6344 - val_f1_macro: 0.4559 - test_f1_macro: 0.4559 - mixed_f1_macro: 0.4559\n",
      "Epoch 64/500\n",
      " — train_f1=0.5589 | val_f1=0.4387 | test_f1=0.4387 | mixed_f1=0.4387\n",
      "37/37 - 10s - 258ms/step - accuracy: 0.6926 - loss: 1.0172 - val_accuracy: 0.4231 - val_loss: 1.6920 - train_f1_macro: 0.5589 - val_f1_macro: 0.4387 - test_f1_macro: 0.4387 - mixed_f1_macro: 0.4387\n",
      "Epoch 65/500\n",
      " — train_f1=0.6867 | val_f1=0.5282 | test_f1=0.5282 | mixed_f1=0.5282\n",
      "37/37 - 5s - 136ms/step - accuracy: 0.6909 - loss: 1.0376 - val_accuracy: 0.5038 - val_loss: 1.4054 - train_f1_macro: 0.6867 - val_f1_macro: 0.5282 - test_f1_macro: 0.5282 - mixed_f1_macro: 0.5282\n",
      "Epoch 66/500\n",
      " — train_f1=0.6520 | val_f1=0.4341 | test_f1=0.4341 | mixed_f1=0.4341\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.7023 - loss: 0.9969 - val_accuracy: 0.4346 - val_loss: 1.5537 - train_f1_macro: 0.6520 - val_f1_macro: 0.4341 - test_f1_macro: 0.4341 - mixed_f1_macro: 0.4341\n",
      "Epoch 67/500\n",
      " — train_f1=0.5866 | val_f1=0.4168 | test_f1=0.4168 | mixed_f1=0.4168\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7065 - loss: 1.0005 - val_accuracy: 0.4269 - val_loss: 1.5758 - train_f1_macro: 0.5866 - val_f1_macro: 0.4168 - test_f1_macro: 0.4168 - mixed_f1_macro: 0.4168\n",
      "Epoch 68/500\n",
      " — train_f1=0.6328 | val_f1=0.5012 | test_f1=0.5012 | mixed_f1=0.5012\n",
      "37/37 - 10s - 265ms/step - accuracy: 0.7061 - loss: 1.0187 - val_accuracy: 0.4885 - val_loss: 1.4426 - train_f1_macro: 0.6328 - val_f1_macro: 0.5012 - test_f1_macro: 0.5012 - mixed_f1_macro: 0.5012\n",
      "Epoch 69/500\n",
      " — train_f1=0.5209 | val_f1=0.4466 | test_f1=0.4466 | mixed_f1=0.4466\n",
      "37/37 - 5s - 134ms/step - accuracy: 0.7124 - loss: 1.0095 - val_accuracy: 0.5115 - val_loss: 1.3368 - train_f1_macro: 0.5209 - val_f1_macro: 0.4466 - test_f1_macro: 0.4466 - mixed_f1_macro: 0.4466\n",
      "Epoch 70/500\n",
      " — train_f1=0.5493 | val_f1=0.4107 | test_f1=0.4107 | mixed_f1=0.4107\n",
      "37/37 - 6s - 157ms/step - accuracy: 0.7128 - loss: 0.9850 - val_accuracy: 0.4154 - val_loss: 1.7317 - train_f1_macro: 0.5493 - val_f1_macro: 0.4107 - test_f1_macro: 0.4107 - mixed_f1_macro: 0.4107\n",
      "Epoch 71/500\n",
      " — train_f1=0.6040 | val_f1=0.4856 | test_f1=0.4856 | mixed_f1=0.4856\n",
      "37/37 - 10s - 257ms/step - accuracy: 0.7035 - loss: 0.9983 - val_accuracy: 0.5308 - val_loss: 1.3259 - train_f1_macro: 0.6040 - val_f1_macro: 0.4856 - test_f1_macro: 0.4856 - mixed_f1_macro: 0.4856\n",
      "Epoch 72/500\n",
      " — train_f1=0.7651 | val_f1=0.5432 | test_f1=0.5432 | mixed_f1=0.5432\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7204 - loss: 0.9793 - val_accuracy: 0.5500 - val_loss: 1.3067 - train_f1_macro: 0.7651 - val_f1_macro: 0.5432 - test_f1_macro: 0.5432 - mixed_f1_macro: 0.5432\n",
      "Epoch 73/500\n",
      " — train_f1=0.6281 | val_f1=0.4791 | test_f1=0.4791 | mixed_f1=0.4791\n",
      "37/37 - 5s - 140ms/step - accuracy: 0.7293 - loss: 0.9707 - val_accuracy: 0.5346 - val_loss: 1.3316 - train_f1_macro: 0.6281 - val_f1_macro: 0.4791 - test_f1_macro: 0.4791 - mixed_f1_macro: 0.4791\n",
      "Epoch 74/500\n",
      " — train_f1=0.5516 | val_f1=0.3936 | test_f1=0.3936 | mixed_f1=0.3936\n",
      "37/37 - 6s - 151ms/step - accuracy: 0.7373 - loss: 0.9614 - val_accuracy: 0.3808 - val_loss: 1.6994 - train_f1_macro: 0.5516 - val_f1_macro: 0.3936 - test_f1_macro: 0.3936 - mixed_f1_macro: 0.3936\n",
      "Epoch 75/500\n",
      " — train_f1=0.5832 | val_f1=0.4447 | test_f1=0.4447 | mixed_f1=0.4447\n",
      "37/37 - 10s - 261ms/step - accuracy: 0.7247 - loss: 0.9671 - val_accuracy: 0.4308 - val_loss: 1.6686 - train_f1_macro: 0.5832 - val_f1_macro: 0.4447 - test_f1_macro: 0.4447 - mixed_f1_macro: 0.4447\n",
      "Epoch 76/500\n",
      " — train_f1=0.7474 | val_f1=0.4843 | test_f1=0.4843 | mixed_f1=0.4843\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7352 - loss: 0.9573 - val_accuracy: 0.5000 - val_loss: 1.4671 - train_f1_macro: 0.7474 - val_f1_macro: 0.4843 - test_f1_macro: 0.4843 - mixed_f1_macro: 0.4843\n",
      "Epoch 77/500\n",
      " — train_f1=0.7483 | val_f1=0.4993 | test_f1=0.4993 | mixed_f1=0.4993\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7141 - loss: 0.9885 - val_accuracy: 0.5192 - val_loss: 1.3483 - train_f1_macro: 0.7483 - val_f1_macro: 0.4993 - test_f1_macro: 0.4993 - mixed_f1_macro: 0.4993\n",
      "Epoch 78/500\n",
      " — train_f1=0.5694 | val_f1=0.4162 | test_f1=0.4162 | mixed_f1=0.4162\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7310 - loss: 0.9623 - val_accuracy: 0.4654 - val_loss: 1.3831 - train_f1_macro: 0.5694 - val_f1_macro: 0.4162 - test_f1_macro: 0.4162 - mixed_f1_macro: 0.4162\n",
      "Epoch 79/500\n",
      " — train_f1=0.4914 | val_f1=0.4045 | test_f1=0.4045 | mixed_f1=0.4045\n",
      "37/37 - 5s - 139ms/step - accuracy: 0.7411 - loss: 0.9518 - val_accuracy: 0.4423 - val_loss: 1.6739 - train_f1_macro: 0.4914 - val_f1_macro: 0.4045 - test_f1_macro: 0.4045 - mixed_f1_macro: 0.4045\n",
      "Epoch 80/500\n",
      " — train_f1=0.7442 | val_f1=0.5023 | test_f1=0.5023 | mixed_f1=0.5023\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7445 - loss: 0.9686 - val_accuracy: 0.5346 - val_loss: 1.3660 - train_f1_macro: 0.7442 - val_f1_macro: 0.5023 - test_f1_macro: 0.5023 - mixed_f1_macro: 0.5023\n",
      "Epoch 81/500\n",
      " — train_f1=0.6760 | val_f1=0.5023 | test_f1=0.5023 | mixed_f1=0.5023\n",
      "37/37 - 5s - 137ms/step - accuracy: 0.7606 - loss: 0.9376 - val_accuracy: 0.5500 - val_loss: 1.3420 - train_f1_macro: 0.6760 - val_f1_macro: 0.5023 - test_f1_macro: 0.5023 - mixed_f1_macro: 0.5023\n",
      "\n",
      "Fold 9 FINAL (Mixed Test): ACC=0.5808 F1w=0.5625 MCC=0.4522\n",
      "\n",
      "Best fold summary: {'fold': 6, 'f1': 0.6229131542396724, 'model_path': 'saved_models/merged_fold_6/best_val_f1_macro_epoch31_f10.6229_20260112_013040.h5'}\n",
      "Saved: merged_cv_histories.pkl, merged_cv_fold_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, pickle, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef,\n",
    "    precision_score, recall_score,\n",
    "    classification_report, accuracy_score\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Global config\n",
    "# ---------------------------------------------------------\n",
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "GLOBAL_LABELS  = list(range(len(GLOBAL_CLASSES)))\n",
    "num_classes = len(GLOBAL_CLASSES)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Eval helper\n",
    "# ---------------------------------------------------------\n",
    "def eval_split(model, X, y, target_names=GLOBAL_CLASSES, labels=GLOBAL_LABELS):\n",
    "    probs = model.predict(X, verbose=0)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    out = {}\n",
    "    out[\"acc\"]   = float(accuracy_score(y, preds))\n",
    "    out[\"f1w\"]   = float(f1_score(y, preds, average=\"weighted\", labels=labels, zero_division=0))\n",
    "    out[\"f1m\"]   = float(f1_score(y, preds, average=\"macro\",    labels=labels, zero_division=0))\n",
    "    out[\"mcc\"]   = float(matthews_corrcoef(y, preds))\n",
    "    out[\"precw\"] = float(precision_score(y, preds, average=\"weighted\", labels=labels, zero_division=0))\n",
    "    out[\"recw\"]  = float(recall_score(y, preds, average=\"weighted\",    labels=labels, zero_division=0))\n",
    "\n",
    "    out[\"report\"] = classification_report(\n",
    "        y, preds,\n",
    "        labels=labels,\n",
    "        target_names=target_names,\n",
    "        zero_division=0\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Fold adaptor: unify access for separate vs mixed\n",
    "# ---------------------------------------------------------\n",
    "def get_fold_splits(fold_dict):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      X_train, y_train,\n",
    "      X_val (can be None),\n",
    "      y_val (can be None),\n",
    "      X_test,\n",
    "      y_test,\n",
    "      X_mix,\n",
    "      y_mix\n",
    "    \"\"\"\n",
    "    X_train = fold_dict[\"X_train\"]\n",
    "    y_train = fold_dict[\"y_train\"]\n",
    "\n",
    "    has_separate = (\"X_test_baby\" in fold_dict) and (\"X_test_chinese\" in fold_dict)\n",
    "\n",
    "    if has_separate:\n",
    "        X_val  = fold_dict[\"X_test_baby\"]\n",
    "        y_val  = fold_dict[\"y_test_baby\"]\n",
    "        X_test = fold_dict[\"X_test_chinese\"]\n",
    "        y_test = fold_dict[\"y_test_chinese\"]\n",
    "\n",
    "        X_mix = np.concatenate([X_val, X_test], axis=0)\n",
    "        y_mix = np.concatenate([y_val, y_test], axis=0)\n",
    "    else:\n",
    "        # keep_separate_tests=False\n",
    "        X_val  = None\n",
    "        y_val  = None\n",
    "        X_test = fold_dict[\"X_test\"]\n",
    "        y_test = fold_dict[\"y_test\"]\n",
    "\n",
    "        X_mix = X_test\n",
    "        y_mix = y_test\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_mix, y_mix\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Callback: logs metrics every epoch (works both formats)\n",
    "# ---------------------------------------------------------\n",
    "class MultiEvalF1Callback(Callback):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, X_mix, y_mix,\n",
    "                 labels=GLOBAL_LABELS):\n",
    "        super().__init__()\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_val,   self.y_val   = X_val, y_val\n",
    "        self.X_test,  self.y_test  = X_test, y_test\n",
    "        self.X_mix,   self.y_mix   = X_mix, y_mix\n",
    "        self.labels = labels\n",
    "\n",
    "    def _f1(self, X, y):\n",
    "        preds = np.argmax(self.model.predict(X, verbose=0), axis=1)\n",
    "        return float(f1_score(y, preds, average=\"macro\", labels=self.labels, zero_division=0))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "\n",
    "        logs[\"train_f1_macro\"] = self._f1(self.X_train, self.y_train)\n",
    "\n",
    "        # If separate exists, val is baby-val; otherwise val is mixed test\n",
    "        if self.X_val is not None:\n",
    "            logs[\"val_f1_macro\"] = self._f1(self.X_val, self.y_val)\n",
    "        else:\n",
    "            logs[\"val_f1_macro\"] = self._f1(self.X_mix, self.y_mix)\n",
    "\n",
    "        # If separate exists, test is chinese-test; otherwise test is mixed test\n",
    "        logs[\"test_f1_macro\"] = self._f1(self.X_test, self.y_test)\n",
    "\n",
    "        # Always compute mixed (if mixed==test, still fine)\n",
    "        logs[\"mixed_f1_macro\"] = self._f1(self.X_mix, self.y_mix)\n",
    "\n",
    "        print(\n",
    "            f\" — train_f1={logs['train_f1_macro']:.4f}\"\n",
    "            f\" | val_f1={logs['val_f1_macro']:.4f}\"\n",
    "            f\" | test_f1={logs['test_f1_macro']:.4f}\"\n",
    "            f\" | mixed_f1={logs['mixed_f1_macro']:.4f}\"\n",
    "        )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SaveBest: monitor metric that exists in both formats\n",
    "# ---------------------------------------------------------\n",
    "class SaveBestModelOnF1Tracked(Callback):\n",
    "    def __init__(self, monitor=\"val_f1_macro\", save_dir=\"saved_models\"):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.save_dir = save_dir\n",
    "        self.best_f1 = -np.inf\n",
    "        self.best_epoch = -1\n",
    "        self.best_filepath = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor, None)\n",
    "        if current is None:\n",
    "            return\n",
    "        if float(current) > self.best_f1:\n",
    "            self.best_f1 = float(current)\n",
    "            self.best_epoch = int(epoch + 1)\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"best_{self.monitor}_epoch{self.best_epoch}_f1{self.best_f1:.4f}_{timestamp}.h5\"\n",
    "            filepath = os.path.join(self.save_dir, filename)\n",
    "            self.model.save(filepath)\n",
    "            self.best_filepath = filepath\n",
    "            print(f\"\\n✅ Saved BEST model ({self.monitor}) at epoch {self.best_epoch} | f1={self.best_f1:.4f}\")\n",
    "            print(f\"   → {self.best_filepath}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CV loop (robust)\n",
    "# ---------------------------------------------------------\n",
    "fold_results = []\n",
    "history_per_fold = []\n",
    "best_fold_summary = {\"fold\": None, \"f1\": -np.inf, \"model_path\": None}\n",
    "\n",
    "for fold in merged_folds:\n",
    "    fold_id = int(fold[\"fold\"])\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"TRAINING MERGED FOLD {fold_id}  (robust to keep_separate_tests True/False)\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, X_mix, y_mix = get_fold_splits(fold)\n",
    "\n",
    "    print(\"X_train:\", X_train.shape, \"uniq y:\", np.unique(y_train))\n",
    "    if X_val is not None:\n",
    "        print(\"X_val (baby):\", X_val.shape, \"uniq y:\", np.unique(y_val))\n",
    "    print(\"X_test:\", X_test.shape, \"uniq y:\", np.unique(y_test))\n",
    "    print(\"X_mix:\", X_mix.shape, \"uniq y:\", np.unique(y_mix))\n",
    "\n",
    "    # one-hot (global 5)\n",
    "    y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "    if X_val is not None:\n",
    "        y_val_oh = to_categorical(y_val, num_classes=num_classes)\n",
    "        val_data = (X_val, y_val_oh)\n",
    "    else:\n",
    "        # if no baby-val, use mixed test as validation_data (so Keras has val_loss)\n",
    "        y_mix_oh = to_categorical(y_mix, num_classes=num_classes)\n",
    "        val_data = (X_mix, y_mix_oh)\n",
    "\n",
    "    # class weights from present classes\n",
    "    present = np.unique(y_train)\n",
    "    cw = compute_class_weight(class_weight=\"balanced\", classes=present, y=y_train)\n",
    "    class_weight_dict = {int(c): float(w) for c, w in zip(present, cw)}\n",
    "    print(\"Class weights (present only):\", class_weight_dict)\n",
    "\n",
    "    # model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = build_model(input_shape, num_classes=num_classes)\n",
    "\n",
    "    # callbacks\n",
    "    multi_eval = MultiEvalF1Callback(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        X_test=X_test, y_test=y_test,\n",
    "        X_mix=X_mix, y_mix=y_mix\n",
    "    )\n",
    "\n",
    "    save_best = SaveBestModelOnF1Tracked(\n",
    "        monitor=\"val_f1_macro\",   # ✅ exists in both modes\n",
    "        save_dir=f\"saved_models/merged_fold_{fold_id}\"\n",
    "    )\n",
    "\n",
    "    early = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_f1_macro\",\n",
    "        mode=\"max\",\n",
    "        patience=30,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train_oh,\n",
    "        validation_data=val_data,\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        verbose=2,\n",
    "        callbacks=[multi_eval, save_best, early],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "    history_per_fold.append(history.history)\n",
    "\n",
    "    # Final evals:\n",
    "    # - If separate exists: report baby-val, chinese-test, mixed\n",
    "    # - Else: report test (=mixed)\n",
    "    if X_val is not None:\n",
    "        baby_metrics = eval_split(model, X_val, y_val)\n",
    "        test_metrics = eval_split(model, X_test, y_test)\n",
    "        mix_metrics  = eval_split(model, X_mix, y_mix)\n",
    "\n",
    "        print(f\"\\nFold {fold_id} FINAL (Baby-val):  ACC={baby_metrics['acc']:.4f} F1w={baby_metrics['f1w']:.4f} MCC={baby_metrics['mcc']:.4f}\")\n",
    "        print(f\"Fold {fold_id} FINAL (Chinese):   ACC={test_metrics['acc']:.4f} F1w={test_metrics['f1w']:.4f} MCC={test_metrics['mcc']:.4f}\")\n",
    "        print(f\"Fold {fold_id} FINAL (Mixed):     ACC={mix_metrics['acc']:.4f} F1w={mix_metrics['f1w']:.4f} MCC={mix_metrics['mcc']:.4f}\")\n",
    "\n",
    "        fold_info = {\n",
    "            \"fold\": fold_id,\n",
    "            \"baby_acc\": baby_metrics[\"acc\"], \"baby_f1w\": baby_metrics[\"f1w\"], \"baby_f1m\": baby_metrics[\"f1m\"], \"baby_mcc\": baby_metrics[\"mcc\"],\n",
    "            \"test_acc\": test_metrics[\"acc\"], \"test_f1w\": test_metrics[\"f1w\"], \"test_f1m\": test_metrics[\"f1m\"], \"test_mcc\": test_metrics[\"mcc\"],\n",
    "            \"mix_acc\":  mix_metrics[\"acc\"],  \"mix_f1w\":  mix_metrics[\"f1w\"],  \"mix_f1m\":  mix_metrics[\"f1m\"],  \"mix_mcc\":  mix_metrics[\"mcc\"],\n",
    "            \"best_val_f1\": float(save_best.best_f1),\n",
    "            \"best_epoch\": int(save_best.best_epoch),\n",
    "            \"best_model_path\": save_best.best_filepath\n",
    "        }\n",
    "    else:\n",
    "        test_metrics = eval_split(model, X_test, y_test)\n",
    "        print(f\"\\nFold {fold_id} FINAL (Mixed Test): ACC={test_metrics['acc']:.4f} F1w={test_metrics['f1w']:.4f} MCC={test_metrics['mcc']:.4f}\")\n",
    "\n",
    "        fold_info = {\n",
    "            \"fold\": fold_id,\n",
    "            \"test_acc\": test_metrics[\"acc\"], \"test_f1w\": test_metrics[\"f1w\"], \"test_f1m\": test_metrics[\"f1m\"], \"test_mcc\": test_metrics[\"mcc\"],\n",
    "            \"best_val_f1\": float(save_best.best_f1),\n",
    "            \"best_epoch\": int(save_best.best_epoch),\n",
    "            \"best_model_path\": save_best.best_filepath\n",
    "        }\n",
    "\n",
    "    fold_results.append(fold_info)\n",
    "\n",
    "    if fold_info[\"best_val_f1\"] > best_fold_summary[\"f1\"]:\n",
    "        best_fold_summary = {\"fold\": fold_id, \"f1\": fold_info[\"best_val_f1\"], \"model_path\": fold_info[\"best_model_path\"]}\n",
    "\n",
    "print(\"\\nBest fold summary:\", best_fold_summary)\n",
    "\n",
    "# Save\n",
    "with open(\"merged_cv_histories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history_per_fold, f)\n",
    "with open(\"merged_cv_fold_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fold_results, f)\n",
    "\n",
    "print(\"Saved: merged_cv_histories.pkl, merged_cv_fold_metrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a3ef52f-59f6-4f4b-bb95-3a4e06062c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean           = 54.609000\n",
      "Population std = 5.640893\n",
      "Sample std     = 5.946023\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "values = [55.89, 54.73, 52.73, 58.57, 40.23, 51.49, 62.29, 59, 56.16, 55 ]\n",
    "\n",
    "mean = statistics.mean(values)\n",
    "pop_std = statistics.pstdev(values)\n",
    "sample_std = statistics.stdev(values)\n",
    "\n",
    "print(f\"Mean           = {mean:.6f}\")\n",
    "print(f\"Population std = {pop_std:.6f}\")\n",
    "print(f\"Sample std     = {sample_std:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc1ca4-d287-46b3-8a76-71a6c822d92c",
   "metadata": {},
   "source": [
    "# Report on separate test not blind to datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00341921-b1f1-4626-80d6-a69d6c913812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 100, 280, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold0[\"X_test_baby\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbbef4e0-3f11-45e6-a35e-0ab981c6823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 100, 280, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold0[\"X_test_chinese\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c43aa0ba-c93d-4116-9d71-e1841f6d8e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5\n",
      "Model input shape: (None, 100, 280, 1) output: (None, 5)\n",
      "Baby test: (208, 100, 280, 1) labels: [0 1 2]\n",
      "Chinese test: (88, 100, 280, 1) labels: [1 3 4]\n",
      "7/7 - 0s - 56ms/step\n",
      "3/3 - 0s - 19ms/step\n",
      "\n",
      "=== BABY TEST (fold0) ===\n",
      "ACC=0.5192 | F1_macro(global5)=0.3066 | F1_weighted(global5)=0.5263 | MCC=0.2792\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Hungry       0.59      0.55      0.57        80\n",
      "       Sleepy       0.62      0.55      0.58        75\n",
      "       Wakeup       0.34      0.43      0.38        53\n",
      "       Diaper       0.00      0.00      0.00         0\n",
      "Uncomfortable       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.52       208\n",
      "    macro avg       0.31      0.31      0.31       208\n",
      " weighted avg       0.54      0.52      0.53       208\n",
      "\n",
      "\n",
      "=== CHINESE TEST (fixed) ===\n",
      "ACC=0.5795 | F1_macro(global5)=0.2832 | F1_weighted(global5)=0.4715 | MCC=0.4356\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Hungry       0.00      0.00      0.00         0\n",
      "       Sleepy       0.00      0.00      0.00        29\n",
      "       Wakeup       0.00      0.00      0.00         0\n",
      "       Diaper       0.75      0.78      0.76        27\n",
      "Uncomfortable       0.50      0.94      0.65        32\n",
      "\n",
      "     accuracy                           0.58        88\n",
      "    macro avg       0.25      0.34      0.28        88\n",
      " weighted avg       0.41      0.58      0.47        88\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 12ms/step\n",
      "\n",
      "=== BLIND MIXED TEST (Baby+Chinese together) ===\n",
      "ACC=0.5372 | F1_macro(global5)=0.5700 | F1_weighted(global5)=0.5321 | MCC=0.4161\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Hungry       0.59      0.55      0.57        80\n",
      "       Sleepy       0.62      0.39      0.48       104\n",
      "       Wakeup       0.34      0.43      0.38        53\n",
      "       Diaper       0.75      0.78      0.76        27\n",
      "Uncomfortable       0.50      0.94      0.65        32\n",
      "\n",
      "     accuracy                           0.54       296\n",
      "    macro avg       0.56      0.62      0.57       296\n",
      " weighted avg       0.56      0.54      0.53       296\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOD on Baby test (pred in Diaper/Uncomfortable): 0.000%\n",
      "OOD on Chinese test (pred in Hungry/Wakeup):      0.000%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5\"\n",
    "\n",
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "GLOBAL_LABELS  = list(range(len(GLOBAL_CLASSES)))  # [0,1,2,3,4]\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "# safe if you only need inference (and avoids loss/metrics mismatches)\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✅ Loaded model:\", MODEL_PATH)\n",
    "print(\"Model input shape:\", model.input_shape, \"output:\", model.output_shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Grab fold-0 test sets from merged_folds\n",
    "# -----------------------------\n",
    "fold0 = None\n",
    "for f in merged_folds:\n",
    "    if int(f[\"fold\"]) == 0:\n",
    "        fold0 = f\n",
    "        break\n",
    "assert fold0 is not None, \"Could not find fold 0 in merged_folds\"\n",
    "\n",
    "X_baby = fold0[\"X_test_baby\"]\n",
    "y_baby = fold0[\"y_test_baby\"]\n",
    "\n",
    "X_ch   = fold0[\"X_test_chinese\"]\n",
    "y_ch   = fold0[\"y_test_chinese\"]\n",
    "\n",
    "print(\"Baby test:\", X_baby.shape, \"labels:\", np.unique(y_baby))\n",
    "print(\"Chinese test:\", X_ch.shape, \"labels:\", np.unique(y_ch))\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: ensure numpy + correct dtype/shape\n",
    "# -----------------------------\n",
    "def prepare_X_for_predict(X, model):\n",
    "    expected = model.input_shape[1:]  # (H,W,C)\n",
    "    X = np.asarray(X)\n",
    "    if X.dtype == object:\n",
    "        X = np.stack(X, axis=0)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Add channel dim if missing\n",
    "    if len(expected) == 3 and X.ndim == 3:\n",
    "        X = X[..., None]\n",
    "\n",
    "    if X.shape[1:] != expected:\n",
    "        raise ValueError(f\"X has shape {X.shape}, but model expects (N,{expected})\")\n",
    "    return X\n",
    "\n",
    "X_baby = prepare_X_for_predict(X_baby, model)\n",
    "X_ch   = prepare_X_for_predict(X_ch, model)\n",
    "\n",
    "# -----------------------------\n",
    "# Prediction function\n",
    "# -----------------------------\n",
    "def predict_labels(model, X):\n",
    "    probs = model.predict(X, verbose=2)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion plotting (global 5x5)\n",
    "# -----------------------------\n",
    "def plot_confusion_global(cm, title, normalize=False):\n",
    "    if normalize:\n",
    "        cm_plot = cm.astype(float)\n",
    "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
    "        cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_plot = cm.astype(int)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=GLOBAL_CLASSES, yticklabels=GLOBAL_CLASSES)\n",
    "    plt.xlabel(\"Predicted (global)\")\n",
    "    plt.ylabel(\"True (global)\")\n",
    "    plt.title(title + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Eval helper\n",
    "# -----------------------------\n",
    "def eval_and_cm(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=GLOBAL_LABELS)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"ACC={acc:.4f} | F1_macro(global5)={f1m:.4f} | F1_weighted(global5)={f1w:.4f} | MCC={mcc:.4f}\")\n",
    "    print(classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=GLOBAL_LABELS,\n",
    "        target_names=GLOBAL_CLASSES,\n",
    "        zero_division=0\n",
    "    ))\n",
    "    return cm\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Separate (diagnostic) evals\n",
    "# -----------------------------\n",
    "pred_baby = predict_labels(model, X_baby)\n",
    "pred_ch   = predict_labels(model, X_ch)\n",
    "\n",
    "cm_baby = eval_and_cm(\"BABY TEST (fold0)\", y_baby, pred_baby)\n",
    "cm_ch   = eval_and_cm(\"CHINESE TEST (fixed)\", y_ch, pred_ch)\n",
    "\n",
    "# Optional: plot per-domain (still global 5x5)\n",
    "plot_confusion_global(cm_baby, \"Fold0 Baby Test — Global 5x5\", normalize=False)\n",
    "plot_confusion_global(cm_ch,   \"Fold0 Chinese Test — Global 5x5\", normalize=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BLIND overall test (concatenate and evaluate once)\n",
    "# -----------------------------\n",
    "X_mix = np.concatenate([X_baby, X_ch], axis=0)\n",
    "y_mix = np.concatenate([y_baby, y_ch], axis=0)\n",
    "\n",
    "pred_mix = predict_labels(model, X_mix)\n",
    "cm_mix = eval_and_cm(\"BLIND MIXED TEST (Baby+Chinese together)\", y_mix, pred_mix)\n",
    "\n",
    "# Plot overall blind confusion matrix\n",
    "plot_confusion_global(cm_mix, \"Fold0 Blind Mixed Test — Global 5x5\", normalize=False)\n",
    "plot_confusion_global(cm_mix, \"Fold0 Blind Mixed Test — Global 5x5\", normalize=True)\n",
    "\n",
    "# (Optional) How often baby samples predicted as Chinese-only labels (3,4) etc.\n",
    "ood_baby_rate = float(np.mean(np.isin(pred_baby, [3,4])))\n",
    "ood_ch_rate   = float(np.mean(np.isin(pred_ch,   [0,2])))  # Hungry/Wakeup are baby-only in your global set\n",
    "print(f\"\\nOOD on Baby test (pred in Diaper/Uncomfortable): {ood_baby_rate:.3%}\")\n",
    "print(f\"OOD on Chinese test (pred in Hungry/Wakeup):      {ood_ch_rate:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21671a8f-d208-4832-9a31-5d307dd686f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3557a935-6cb9-429c-9fe9-68834dc1c90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87ca95-4977-418d-8e01-9ae60eaae217",
   "metadata": {},
   "source": [
    "# Report on Test Blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f1eb41b-0a07-48cf-a049-fbc7b82132a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1723792/1687109832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# -----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# safe if you only need inference (and avoids loss/metrics mismatches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Loaded model:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model input shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5\"\n",
    "\n",
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "GLOBAL_LABELS  = list(range(len(GLOBAL_CLASSES)))  # [0,1,2,3,4]\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "# safe if you only need inference (and avoids loss/metrics mismatches)\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✅ Loaded model:\", MODEL_PATH)\n",
    "print(\"Model input shape:\", model.input_shape, \"output:\", model.output_shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Grab fold-0 test sets from merged_folds\n",
    "# -----------------------------\n",
    "fold0 = None\n",
    "for f in merged_folds:\n",
    "    if int(f[\"fold\"]) == 0:\n",
    "        fold0 = f\n",
    "        break\n",
    "assert fold0 is not None, \"Could not find fold 0 in merged_folds\"\n",
    "\n",
    "X_baby = fold0[\"X_test_baby\"]\n",
    "y_baby = fold0[\"y_test_baby\"]\n",
    "\n",
    "X_ch   = fold0[\"X_test_chinese\"]\n",
    "y_ch   = fold0[\"y_test_chinese\"]\n",
    "\n",
    "print(\"Baby test:\", X_baby.shape, \"labels:\", np.unique(y_baby))\n",
    "print(\"Chinese test:\", X_ch.shape, \"labels:\", np.unique(y_ch))\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: ensure numpy + correct dtype/shape\n",
    "# -----------------------------\n",
    "def prepare_X_for_predict(X, model):\n",
    "    expected = model.input_shape[1:]  # (H,W,C)\n",
    "    X = np.asarray(X)\n",
    "    if X.dtype == object:\n",
    "        X = np.stack(X, axis=0)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Add channel dim if missing\n",
    "    if len(expected) == 3 and X.ndim == 3:\n",
    "        X = X[..., None]\n",
    "\n",
    "    if X.shape[1:] != expected:\n",
    "        raise ValueError(f\"X has shape {X.shape}, but model expects (N,{expected})\")\n",
    "    return X\n",
    "\n",
    "X_baby = prepare_X_for_predict(X_baby, model)\n",
    "X_ch   = prepare_X_for_predict(X_ch, model)\n",
    "\n",
    "# -----------------------------\n",
    "# Prediction function\n",
    "# -----------------------------\n",
    "def predict_labels(model, X):\n",
    "    probs = model.predict(X, verbose=2)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion plotting (global 5x5)\n",
    "# -----------------------------\n",
    "def plot_confusion_global(cm, title, normalize=False):\n",
    "    if normalize:\n",
    "        cm_plot = cm.astype(float)\n",
    "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
    "        cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_plot = cm.astype(int)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=GLOBAL_CLASSES, yticklabels=GLOBAL_CLASSES)\n",
    "    plt.xlabel(\"Predicted (global)\")\n",
    "    plt.ylabel(\"True (global)\")\n",
    "    plt.title(title + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Eval helper\n",
    "# -----------------------------\n",
    "def eval_and_cm(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=GLOBAL_LABELS)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"ACC={acc:.4f} | F1_macro(global5)={f1m:.4f} | F1_weighted(global5)={f1w:.4f} | MCC={mcc:.4f}\")\n",
    "    print(classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=GLOBAL_LABELS,\n",
    "        target_names=GLOBAL_CLASSES,\n",
    "        zero_division=0\n",
    "    ))\n",
    "    return cm\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Separate (diagnostic) evals\n",
    "# -----------------------------\n",
    "pred_baby = predict_labels(model, X_baby)\n",
    "pred_ch   = predict_labels(model, X_ch)\n",
    "\n",
    "cm_baby = eval_and_cm(\"BABY TEST (fold0)\", y_baby, pred_baby)\n",
    "cm_ch   = eval_and_cm(\"CHINESE TEST (fixed)\", y_ch, pred_ch)\n",
    "\n",
    "# Optional: plot per-domain (still global 5x5)\n",
    "plot_confusion_global(cm_baby, \"Fold0 Baby Test — Global 5x5\", normalize=False)\n",
    "plot_confusion_global(cm_ch,   \"Fold0 Chinese Test — Global 5x5\", normalize=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BLIND overall test (concatenate and evaluate once)\n",
    "# -----------------------------\n",
    "X_mix = np.concatenate([X_baby, X_ch], axis=0)\n",
    "y_mix = np.concatenate([y_baby, y_ch], axis=0)\n",
    "\n",
    "pred_mix = predict_labels(model, X_mix)\n",
    "cm_mix = eval_and_cm(\"BLIND MIXED TEST (Baby+Chinese together)\", y_mix, pred_mix)\n",
    "\n",
    "# Plot overall blind confusion matrix\n",
    "plot_confusion_global(cm_mix, \"Fold0 Blind Mixed Test — Global 5x5\", normalize=False)\n",
    "plot_confusion_global(cm_mix, \"Fold0 Blind Mixed Test — Global 5x5\", normalize=True)\n",
    "\n",
    "# (Optional) How often baby samples predicted as Chinese-only labels (3,4) etc.\n",
    "ood_baby_rate = float(np.mean(np.isin(pred_baby, [3,4])))\n",
    "ood_ch_rate   = float(np.mean(np.isin(pred_ch,   [0,2])))  # Hungry/Wakeup are baby-only in your global set\n",
    "print(f\"\\nOOD on Baby test (pred in Diaper/Uncomfortable): {ood_baby_rate:.3%}\")\n",
    "print(f\"OOD on Chinese test (pred in Hungry/Wakeup):      {ood_ch_rate:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "901050b2-09d0-40a4-adee-b57a8da6f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred labels on baby: (array([0, 1, 2]), array([74, 66, 68]))\n",
      "Pred labels on ch  : (array([3, 4]), array([28, 60]))\n",
      "Mean prob on classes [3,4] for baby: 0.022392878 0.022425113\n",
      "Mean prob on classes [3,4] for ch  : 0.27830604 0.56883466\n"
     ]
    }
   ],
   "source": [
    "pred_baby = np.argmax(model.predict(X_baby, verbose=0), axis=1)\n",
    "pred_ch   = np.argmax(model.predict(X_ch,   verbose=0), axis=1)\n",
    "\n",
    "print(\"Pred labels on baby:\", np.unique(pred_baby, return_counts=True))\n",
    "print(\"Pred labels on ch  :\", np.unique(pred_ch,   return_counts=True))\n",
    "\n",
    "# Also inspect mean probability mass on classes 3 and 4\n",
    "pb = model.predict(X_baby, verbose=0)\n",
    "pc = model.predict(X_ch, verbose=0)\n",
    "print(\"Mean prob on classes [3,4] for baby:\", pb[:,3].mean(), pb[:,4].mean())\n",
    "print(\"Mean prob on classes [3,4] for ch  :\", pc[:,3].mean(), pc[:,4].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a407eb4f-32da-47fc-bb22-17002f8670a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby→(outside Baby labels) leakage: 0.000%\n",
      "Chinese→(outside Chinese labels) leakage: 0.000%\n",
      "Baby predicted as Chinese-only (3/4): 0.000%\n",
      "Chinese predicted as Baby-only (0/2): 0.000%\n"
     ]
    }
   ],
   "source": [
    "BABY_INDOMAIN = {0, 1, 2}      # Hungry, Sleepy, Wakeup\n",
    "CH_INDOMAIN   = {1, 3, 4}      # Sleepy(shared), Diaper, Uncomfortable\n",
    "\n",
    "# predictions you already computed:\n",
    "# pred_baby, pred_ch\n",
    "\n",
    "baby_leak = float(np.mean([p not in BABY_INDOMAIN for p in pred_baby]))\n",
    "ch_leak   = float(np.mean([p not in CH_INDOMAIN   for p in pred_ch]))\n",
    "\n",
    "print(f\"Baby→(outside Baby labels) leakage: {baby_leak:.3%}\")\n",
    "print(f\"Chinese→(outside Chinese labels) leakage: {ch_leak:.3%}\")\n",
    "\n",
    "# More specific: Baby predicted as Chinese-only labels (3/4)\n",
    "baby_to_ch_only = float(np.mean(np.isin(pred_baby, [3,4])))\n",
    "# Chinese predicted as Baby-only labels (0/2)\n",
    "ch_to_b_only = float(np.mean(np.isin(pred_ch, [0,2])))\n",
    "\n",
    "print(f\"Baby predicted as Chinese-only (3/4): {baby_to_ch_only:.3%}\")\n",
    "print(f\"Chinese predicted as Baby-only (0/2): {ch_to_b_only:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55014628-0ca5-4fe9-aa84-c6448217ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5\n",
      "Model input shape: (None, 100, 280, 1) output: (None, 5)\n",
      "Baby test: (208, 100, 280, 1) labels: [0 1 2]\n",
      "Chinese test: (88, 100, 280, 1) labels: [1 3 4]\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x14e668bd6830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "=== BLIND MIXED TEST (T=5.0) ===\n",
      "ACC=0.5372 | F1_macro(global5)=0.5700 | F1_weighted(global5)=0.5321 | MCC=0.4161\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Hungry       0.59      0.55      0.57        80\n",
      "       Sleepy       0.62      0.39      0.48       104\n",
      "       Wakeup       0.34      0.43      0.38        53\n",
      "       Diaper       0.75      0.78      0.76        27\n",
      "Uncomfortable       0.50      0.94      0.65        32\n",
      "\n",
      "     accuracy                           0.54       296\n",
      "    macro avg       0.56      0.62      0.57       296\n",
      " weighted avg       0.56      0.54      0.53       296\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entropy stats: mean= 1.5678788423538208 min= 1.512550950050354 max= 1.5981675386428833\n",
      "\n",
      "Examples (top-3 probs):\n",
      "sample 0 true=Wakeup [('Wakeup', 0.307120144367218), ('Hungry', 0.20091211795806885), ('Sleepy', 0.18621936440467834)]\n",
      "sample 1 true=Sleepy [('Sleepy', 0.3066898286342621), ('Wakeup', 0.20116980373859406), ('Hungry', 0.20018774271011353)]\n",
      "sample 2 true=Sleepy [('Hungry', 0.30886030197143555), ('Sleepy', 0.2086317539215088), ('Wakeup', 0.18573349714279175)]\n",
      "sample 3 true=Wakeup [('Hungry', 0.2982211112976074), ('Wakeup', 0.20709063112735748), ('Sleepy', 0.1808820217847824)]\n",
      "sample 4 true=Uncomfortable [('Uncomfortable', 0.3204057514667511), ('Sleepy', 0.21297988295555115), ('Diaper', 0.18224944174289703)]\n",
      "\n",
      "Mean predicted probability mass per class:\n",
      "         Hungry: 0.2195\n",
      "         Sleepy: 0.2203\n",
      "         Wakeup: 0.2039\n",
      "         Diaper: 0.1695\n",
      "  Uncomfortable: 0.1868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "MODEL_PATH = r\"saved_models/merged_fold_0/best_val_baby_f1_macro_epoch84_f10.5111_20260108_164108.h5\"\n",
    "\n",
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "GLOBAL_LABELS  = list(range(len(GLOBAL_CLASSES)))  # [0,1,2,3,4]\n",
    "\n",
    "# -----------------------------\n",
    "# Load model\n",
    "# -----------------------------\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✅ Loaded model:\", MODEL_PATH)\n",
    "print(\"Model input shape:\", model.input_shape, \"output:\", model.output_shape)\n",
    "assert model.output_shape[-1] == 5, \"This code expects a 5-class model output!\"\n",
    "\n",
    "# -----------------------------\n",
    "# Grab fold-0 test sets\n",
    "# -----------------------------\n",
    "fold0 = next((f for f in merged_folds if int(f[\"fold\"]) == 0), None)\n",
    "assert fold0 is not None, \"Could not find fold 0 in merged_folds\"\n",
    "\n",
    "X_baby = fold0[\"X_test_baby\"];     y_baby = fold0[\"y_test_baby\"]\n",
    "X_ch   = fold0[\"X_test_chinese\"];  y_ch   = fold0[\"y_test_chinese\"]\n",
    "\n",
    "print(\"Baby test:\", X_baby.shape, \"labels:\", np.unique(y_baby))\n",
    "print(\"Chinese test:\", X_ch.shape, \"labels:\", np.unique(y_ch))\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: ensure numpy + correct dtype/shape\n",
    "# -----------------------------\n",
    "def prepare_X_for_predict(X, model):\n",
    "    expected = model.input_shape[1:]\n",
    "    X = np.asarray(X)\n",
    "    if X.dtype == object:\n",
    "        X = np.stack(X, axis=0)\n",
    "    X = X.astype(np.float32)\n",
    "    if len(expected) == 3 and X.ndim == 3:\n",
    "        X = X[..., None]\n",
    "    if X.shape[1:] != expected:\n",
    "        raise ValueError(f\"X has shape {X.shape}, but model expects (N,{expected})\")\n",
    "    return X\n",
    "\n",
    "X_baby = prepare_X_for_predict(X_baby, model)\n",
    "X_ch   = prepare_X_for_predict(X_ch, model)\n",
    "\n",
    "# -----------------------------\n",
    "# Softmax with temperature (to \"soften\" a gated model)\n",
    "# T > 1.0 makes probs less peaky (more mass on other classes)\n",
    "# -----------------------------\n",
    "def softmax_np(logits, T=1.0):\n",
    "    z = logits / float(T)\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "def predict_probs(model, X, temperature=1.0, batch_size=64):\n",
    "    # Prefer logits if model provides them; otherwise use probabilities.\n",
    "    out = model.predict(X, verbose=0, batch_size=batch_size)\n",
    "\n",
    "    # If last layer is softmax, out are probs; convert to logits-ish by log\n",
    "    # then re-softmax with temperature. This is a practical \"smoothing\".\n",
    "    eps = 1e-9\n",
    "    logits_like = np.log(np.clip(out, eps, 1.0))\n",
    "    probs_T = softmax_np(logits_like, T=temperature)\n",
    "    return probs_T\n",
    "\n",
    "def topk_strings(probs, k=3):\n",
    "    topk = np.argsort(-probs, axis=1)[:, :k]\n",
    "    out = []\n",
    "    for i in range(probs.shape[0]):\n",
    "        pairs = [(GLOBAL_CLASSES[j], float(probs[i, j])) for j in topk[i]]\n",
    "        out.append(pairs)\n",
    "    return out\n",
    "\n",
    "def entropy(probs):\n",
    "    eps = 1e-12\n",
    "    p = np.clip(probs, eps, 1.0)\n",
    "    return -np.sum(p * np.log(p), axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Confusion plotting (global 5x5)\n",
    "# -----------------------------\n",
    "def plot_confusion_global(cm, title, normalize=False):\n",
    "    if normalize:\n",
    "        cm_plot = cm.astype(float)\n",
    "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
    "        cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_plot = cm.astype(int)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=GLOBAL_CLASSES, yticklabels=GLOBAL_CLASSES)\n",
    "    plt.xlabel(\"Predicted (global)\")\n",
    "    plt.ylabel(\"True (global)\")\n",
    "    plt.title(title + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Eval helper\n",
    "# -----------------------------\n",
    "def eval_global(name, y_true, probs):\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_true, preds)\n",
    "    f1m = f1_score(y_true, preds, average=\"macro\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    f1w = f1_score(y_true, preds, average=\"weighted\", labels=GLOBAL_LABELS, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, preds)\n",
    "\n",
    "    cm = confusion_matrix(y_true, preds, labels=GLOBAL_LABELS)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"ACC={acc:.4f} | F1_macro(global5)={f1m:.4f} | F1_weighted(global5)={f1w:.4f} | MCC={mcc:.4f}\")\n",
    "    print(classification_report(\n",
    "        y_true, preds,\n",
    "        labels=GLOBAL_LABELS,\n",
    "        target_names=GLOBAL_CLASSES,\n",
    "        zero_division=0\n",
    "    ))\n",
    "    return preds, cm\n",
    "\n",
    "# -----------------------------\n",
    "# BLIND MIXED TEST (single evaluation)\n",
    "# -----------------------------\n",
    "X_mix = np.concatenate([X_baby, X_ch], axis=0)\n",
    "y_mix = np.concatenate([y_baby, y_ch], axis=0)\n",
    "\n",
    "# Shuffle to make it \"visually blind\" too (optional)\n",
    "rng = np.random.default_rng(0)\n",
    "idx = rng.permutation(len(X_mix))\n",
    "X_mix = X_mix[idx]\n",
    "y_mix = y_mix[idx]\n",
    "\n",
    "# Choose temperature\n",
    "TEMPERATURE = 5.0   # try 1.0 (original), 2.0, 3.0, 5.0 to soften gating\n",
    "\n",
    "mix_probs = predict_probs(model, X_mix, temperature=TEMPERATURE)\n",
    "mix_preds, cm_mix = eval_global(f\"BLIND MIXED TEST (T={TEMPERATURE})\", y_mix, mix_probs)\n",
    "\n",
    "plot_confusion_global(cm_mix, f\"Blind Mixed Test — Global 5x5 (T={TEMPERATURE})\", normalize=False)\n",
    "plot_confusion_global(cm_mix, f\"Blind Mixed Test — Global 5x5 (T={TEMPERATURE})\", normalize=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Extra: prove we output 5 probs per sample + quantify \"other-class mass\"\n",
    "# -----------------------------\n",
    "ent = entropy(mix_probs)\n",
    "print(\"\\nEntropy stats:\", \"mean=\", float(ent.mean()), \"min=\", float(ent.min()), \"max=\", float(ent.max()))\n",
    "\n",
    "# Show a few samples: top-3 predicted classes with probabilities\n",
    "top3 = topk_strings(mix_probs, k=3)\n",
    "print(\"\\nExamples (top-3 probs):\")\n",
    "for i in range(5):\n",
    "    print(f\"sample {i} true={GLOBAL_CLASSES[int(y_mix[i])]}\", top3[i])\n",
    "\n",
    "# Measure probability mass assigned to each class on average\n",
    "mean_mass = mix_probs.mean(axis=0)\n",
    "print(\"\\nMean predicted probability mass per class:\")\n",
    "for c, m in zip(GLOBAL_CLASSES, mean_mass):\n",
    "    print(f\"  {c:>13s}: {m:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60026f09-97a7-4d11-8eb6-0b9e1ca3e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "GLOBAL_CLASSES = [\"Hungry\", \"Sleepy\", \"Wakeup\", \"Diaper\", \"Uncomfortable\"]\n",
    "GLOBAL_LABELS  = list(range(len(GLOBAL_CLASSES)))  # [0,1,2,3,4]\n",
    "\n",
    "def confusion_global_5x5(y_true, y_pred):\n",
    "    # Force 5x5 even if some classes are absent in y_true\n",
    "    return confusion_matrix(y_true, y_pred, labels=GLOBAL_LABELS)\n",
    "\n",
    "def plot_confusion_global(cm, title=\"Confusion Matrix (Global 5)\", normalize=False):\n",
    "    if normalize:\n",
    "        cm_plot = cm.astype(float)\n",
    "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
    "        cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_plot = cm.astype(int)\n",
    "        fmt = \"d\"\n",
    "\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(\n",
    "        cm_plot, annot=True, fmt=fmt, cmap=\"Blues\", cbar=False,\n",
    "        xticklabels=GLOBAL_CLASSES, yticklabels=GLOBAL_CLASSES\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label (global)\")\n",
    "    plt.ylabel(\"True label (global)\")\n",
    "    plt.title(title + (\" (normalized)\" if normalize else \"\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216b8df-55ef-4792-acfc-1c2dc8b7c329",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a3731-5b1c-4c3f-a115-019fc5f93efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "#  LOSS PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history.get('loss', []), label='Train Loss')\n",
    "plt.plot(history.history.get('val_loss', []), label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "#  ACCURACY PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history.get('accuracy', []), label='Train Accuracy')\n",
    "plt.plot(history.history.get('val_accuracy', []), label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "#  F1-SCORE PLOT  (From your callback)\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(f1_callback.train_f1s, label='Train F1 (macro)')\n",
    "plt.plot(f1_callback.val_f1s, label='Val F1 (macro)')\n",
    "plt.title(\"F1 Score Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score (macro)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f06280-7e04-4c1b-92fd-d79e9887f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_chinese[i] for i in labels]   # adjust mapping if not Chinese set\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – Validation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b47476c-eada-4e99-9d21-a1c426bfdb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curves(y_true_onehot, y_pred_prob, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    n_classes = y_true_onehot.shape[1]\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_onehot[:, c], y_pred_prob[:, c])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr, tpr, lw=2,\n",
    "                 label=f\"{class_names[c]} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    # Diagonal line\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves (One-vs-Rest)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    plt.show()\n",
    "\n",
    "y_pred_prob = model.predict(X_val_split)\n",
    "y_true_onehot = y_val_onehot\n",
    "\n",
    "class_names = list(le.classes_)   # <-- FIXED\n",
    "\n",
    "plot_roc_curves(y_true_onehot, y_pred_prob, class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d90e0b0e-3f81-4108-bd4e-5c39ee7cb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Validation Metrics =====\n",
      "Accuracy   : 0.6364\n",
      "F1-micro   : 0.6364\n",
      "F1-macro   : 0.6265\n",
      "MCC        : 0.4560\n",
      "ROC-AUC    : 0.7846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef, roc_auc_score,\n",
    "    accuracy_score, precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "acc = accuracy_score(y_val_split, val_preds)\n",
    "\n",
    "# ---- ROC-AUC (One-vs-Rest) ----\n",
    "y_val_bin = label_binarize(y_val_split, classes=labels)\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_val_bin, val_probs, multi_class=\"ovr\", average=\"macro\"\n",
    "    )\n",
    "except:\n",
    "    roc_auc = None\n",
    "\n",
    "print(\"\\n===== Validation Metrics =====\")\n",
    "print(f\"Accuracy   : {acc:.4f}\")\n",
    "print(f\"F1-micro   : {f1_micro:.4f}\")\n",
    "print(f\"F1-macro   : {f1_macro:.4f}\")\n",
    "print(f\"MCC        : {mcc:.4f}\")\n",
    "print(f\"ROC-AUC    : {roc_auc:.4f}\" if roc_auc is not None else \"ROC-AUC: unavailable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1dc42-a6d4-4c10-b8f4-bce30b3e80dd",
   "metadata": {},
   "source": [
    "## Plot and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba2fc81-3d2d-4b34-8bdc-dfcabf0a0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/1451947756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Keep only probs for classes of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mval_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_probs_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_classes\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape (N, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Recompute predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, matthews_corrcoef, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# -------------------- Setup --------------------\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Classes of interest in original encoding\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# Map to new encoded ids {0,1,2}\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# -------------------- Predictions --------------------\n",
    "val_probs_full = model.predict(X_val_split)\n",
    "\n",
    "# Keep only probs for classes of interest\n",
    "val_probs = val_probs_full[:, unique_classes]  # shape (N, 3)\n",
    "\n",
    "# Recompute predictions\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# -------------------- Confusion Matrix --------------------\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_merge_3mood[i] for i in labels]\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=tick_labels,\n",
    "    yticklabels=tick_labels,\n",
    "    annot_kws={\"size\": 16}\n",
    ")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "cm_path = os.path.join(output_dir, f\"confusion_matrix_{timestamp}.png\")\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "\n",
    "# Binarize labels for ROC AUC\n",
    "y_val_bin = label_binarize(y_val_split, classes=np.unique(y_val_split))\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_val_bin, val_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "except ValueError:\n",
    "    roc_auc = None\n",
    "\n",
    "report = classification_report(\n",
    "    y_val_split,\n",
    "    val_preds,\n",
    "    target_names=[id2cls_merge_3mood[i] for i in np.unique(y_val_split)],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "stats_path = os.path.join(output_dir, f\"validation_stats_{timestamp}.txt\")\n",
    "with open(stats_path, \"w\") as f:\n",
    "    f.write(\"Validation Metrics:\\n\")\n",
    "    f.write(f\"F1 (micro): {f1_micro:.4f}\\n\")\n",
    "    f.write(f\"F1 (macro): {f1_macro:.4f}\\n\")\n",
    "    f.write(f\"MCC       : {mcc:.4f}\\n\")\n",
    "    f.write(f\"ROC AUC   : {roc_auc:.4f}\\n\" if roc_auc is not None else \"ROC AUC not available\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"✅ Saved confusion matrix to {cm_path}\")\n",
    "print(f\"✅ Saved metrics to {stats_path}\")\n",
    "\n",
    "# -------------------- Training Curves --------------------\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "curve_path = os.path.join(output_dir, f\"training_curves_{timestamp}.png\")\n",
    "plt.savefig(curve_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved training curves to {curve_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fa5c24f-c8af-44b9-8011-95892c6fb5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/2052889078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Keep only columns for the 3 moods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mval_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_probs_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_classes\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# shape (N, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Recompute predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# -------------------- Setup --------------------\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Classes of interest in original encoding\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# Map old IDs -> new {0,1,2}\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# -------------------- Predictions --------------------\n",
    "val_probs_full = model.predict(X_val_split)     # shape (N, all_classes)\n",
    "\n",
    "# Keep only columns for the 3 moods\n",
    "val_probs = val_probs_full[:, unique_classes]   # shape (N, 3)\n",
    "\n",
    "# Recompute predictions\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# -------------------- Confusion Matrix --------------------\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_merge_3mood[i] for i in labels]\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=tick_labels,\n",
    "    yticklabels=tick_labels,\n",
    "    annot_kws={\"size\": 16}\n",
    ")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "cm_path = os.path.join(output_dir, f\"confusion_matrix_{timestamp}.png\")\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "\n",
    "# Binarize labels for ROC AUC (3 classes only)\n",
    "y_val_bin = label_binarize(y_val_split, classes=np.arange(len(unique_classes)))\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_val_bin, val_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "except ValueError:\n",
    "    roc_auc = None\n",
    "\n",
    "report = classification_report(\n",
    "    y_val_split,\n",
    "    val_preds,\n",
    "    target_names=[id2cls_merge_3mood[i] for i in np.unique(y_val_split)],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "stats_path = os.path.join(output_dir, f\"validation_stats_{timestamp}.txt\")\n",
    "with open(stats_path, \"w\") as f:\n",
    "    f.write(\"Validation Metrics:\\n\")\n",
    "    f.write(f\"F1 (micro): {f1_micro:.4f}\\n\")\n",
    "    f.write(f\"F1 (macro): {f1_macro:.4f}\\n\")\n",
    "    f.write(f\"MCC       : {mcc:.4f}\\n\")\n",
    "    f.write(f\"ROC AUC   : {roc_auc:.4f}\\n\" if roc_auc is not None else \"ROC AUC not available\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\nClass mapping:\\n\")\n",
    "    f.write(str(id2cls_merge_3mood))\n",
    "\n",
    "print(f\"✅ Saved confusion matrix to {cm_path}\")\n",
    "print(f\"✅ Saved metrics to {stats_path}\")\n",
    "\n",
    "# -------------------- Training Curves --------------------\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "curve_path = os.path.join(output_dir, f\"training_curves_{timestamp}.png\")\n",
    "plt.savefig(curve_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved training curves to {curve_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eab58be3-a19e-4ff9-a732-eef212800b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Total samples        : 88\n",
      "Top-1 correct        : 65\n",
      "Top-2 correct        : 79\n",
      "Wrong top-1 but fixed by 2nd : 14\n",
      "Top-1 Accuracy       : 0.7386\n",
      "Top-2 Accuracy       : 0.8977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get full probability predictions (shape: [n_samples, n_classes])\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)   # top-1 predictions\n",
    "\n",
    "# Sort predictions to get top-2 indices\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]  # last two = top-2\n",
    "\n",
    "# Boolean: was the correct label in top-2 predictions?\n",
    "correct_top2 = [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    "\n",
    "# Count stats\n",
    "top1_correct = np.sum(val_preds == y_val_split)\n",
    "top2_correct = np.sum(correct_top2)\n",
    "only_second_correct = np.sum((val_preds != y_val_split) & np.array(correct_top2))\n",
    "\n",
    "print(f\"Total samples        : {len(y_val_split)}\")\n",
    "print(f\"Top-1 correct        : {top1_correct}\")\n",
    "print(f\"Top-2 correct        : {top2_correct}\")\n",
    "print(f\"Wrong top-1 but fixed by 2nd : {only_second_correct}\")\n",
    "print(f\"Top-1 Accuracy       : {top1_correct/len(y_val_split):.4f}\")\n",
    "print(f\"Top-2 Accuracy       : {top2_correct/len(y_val_split):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67b63184-4420-4b2a-ac51-b493599647b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Wrong top-1 but correct at 2nd prediction (per class):\n",
      "awake          : 11\n",
      "diaper         : 6\n",
      "hug            : 4\n",
      "hungry         : 0\n",
      "sleepy         : 0\n",
      "uncomfortable  : 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get probability predictions\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# Top-2 indices per sample\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]\n",
    "\n",
    "# Identify \"wrong top-1 but fixed by top-2\"\n",
    "wrong_fixed = (val_preds != y_val_split) & np.array(\n",
    "    [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    ")\n",
    "\n",
    "# # Class mapping (example, update to match your dataset)\n",
    "# id2cls = {\n",
    "#     0: \"hungry\",\n",
    "#     1: \"awake\",\n",
    "#     2: \"sleepy\",\n",
    "#     3: \"diaper\",\n",
    "#     4: \"uncomfortable\"\n",
    "# }\n",
    "\n",
    "# Count per-class\n",
    "counts = {cls: 0 for cls in id2cls_chinese.values()}\n",
    "for i, flag in enumerate(wrong_fixed):\n",
    "    if flag:  # case where top-2 fixed it\n",
    "        cls_name = id2cls_chinese[y_val_split[i]]\n",
    "        counts[cls_name] += 1\n",
    "\n",
    "print(\"Wrong top-1 but correct at 2nd prediction (per class):\")\n",
    "for cls, c in counts.items():\n",
    "    print(f\"{cls:15s}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35bf1b1b-d9f3-4011-9a22-cd1e5860ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Wrong top-1 but correct at 2nd prediction (per class):\n",
      "awake          : 11 cases\n",
      "   → misclassified as hug: 8\n",
      "   → misclassified as diaper: 3\n",
      "diaper         : 6 cases\n",
      "   → misclassified as hug: 2\n",
      "   → misclassified as awake: 4\n",
      "hug            : 4 cases\n",
      "   → misclassified as diaper: 2\n",
      "   → misclassified as awake: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get probability predictions\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# Top-2 indices per sample\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]\n",
    "\n",
    "# Identify \"wrong top-1 but fixed by top-2\"\n",
    "wrong_fixed = (val_preds != y_val_split) & np.array(\n",
    "    [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    ")\n",
    "\n",
    "\n",
    "# Count per true class and record wrong top-1s\n",
    "counts = {cls: 0 for cls in id2cls_chinese.values()}\n",
    "confusions = {cls: [] for cls in id2cls_chinese.values()}\n",
    "\n",
    "for i, flag in enumerate(wrong_fixed):\n",
    "    if flag:\n",
    "        true_cls = id2cls_chinese[y_val_split[i]]\n",
    "        wrong_cls = id2cls_chinese[val_preds[i]]\n",
    "        counts[true_cls] += 1\n",
    "        confusions[true_cls].append(wrong_cls)\n",
    "\n",
    "# Print summary\n",
    "print(\"Wrong top-1 but correct at 2nd prediction (per class):\")\n",
    "for cls, c in counts.items():\n",
    "    if c > 0:\n",
    "        wrong_breakdown = {w: confusions[cls].count(w) for w in set(confusions[cls])}\n",
    "        print(f\"{cls:15s}: {c} cases\")\n",
    "        for wrong, wc in wrong_breakdown.items():\n",
    "            print(f\"   → misclassified as {wrong}: {wc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c5ab8-32f2-4bb9-90e6-fcaf48a9ae63",
   "metadata": {},
   "source": [
    "# Avg smooth Ensemble Chinese baby cry and reverb chinese baby cry and Baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de653c66-ea12-4eaf-a36e-604d73cd7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5225bdb-cb76-41f7-a63c-5d098c85fb93",
   "metadata": {},
   "source": [
    "# Agree vote Ensemble Chinese baby cry and reverb chinese baby cry and Baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732a77c-eaf6-4c33-be89-03c202e37834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e209a6-74dc-4f1f-807f-ffbfd54e0d2b",
   "metadata": {},
   "source": [
    "# Statistical test analysis of ensemble merged and single trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de640d-d76d-4385-8afb-1d47a545d5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "/usr/bin/python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
