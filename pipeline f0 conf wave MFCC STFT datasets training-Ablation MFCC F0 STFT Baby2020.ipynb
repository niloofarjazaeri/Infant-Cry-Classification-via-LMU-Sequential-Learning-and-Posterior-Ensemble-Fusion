{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07479379-0836-40cb-801d-16dc9a4dc399",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3719b62-d8d3-49b6-af63-a0847cb5274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_path = \"Chinese Babycry\"\n",
    "output_zip = \"Chinese Babycry\"\n",
    "\n",
    "# This will create myfolder.zip\n",
    "#shutil.make_archive(output_zip, 'zip', folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d50cc07-9964-442a-81d7-f5f3ac8d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_conf_wave_train_dir = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "f0_conf_wave_test_dir = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "audio_train_dir = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir = \"Chinese Babycry/Test_Split_20\"\n",
    "\n",
    "\n",
    "f0_conf_wave_train_dir = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "f0_conf_wave_test_dir = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "audio_train_dir = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir = \"Chinese Babycry/Test_Split_20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e192c-1689-42f6-b260-86e8f4d751f7",
   "metadata": {},
   "source": [
    "# Loading all F0 wave cof in big train test and labels dataset and encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9acc3d-de6b-4b83-8b93-c7ece9581915",
   "metadata": {},
   "source": [
    "It already extracted by Crepe and resized to median but even if it is not resized it is gonna be in this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cb19a-8f28-40aa-be52-3c4f3e0d13a2",
   "metadata": {},
   "source": [
    "## How I extracted F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a102a1e8-705b-4040-997e-76ddad9fd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# import os\n",
    "# import sys\n",
    "# import glob\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "# import crepe\n",
    "# from pathlib import Path\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # --------------------------\n",
    "# # CONFIG\n",
    "# # --------------------------\n",
    "# PATH_TRAIN = r\"H:\\Crynostics\\Datas\\Chinese Baby_Crying940\\Reverb_Test_Split_20\"  # root with class subfolders\n",
    "# OUT_ROOT   = r\"H:\\Crynostics\\Datas\\Chinese Baby_Crying940\\Reverb_Test_Split_20_f0_wave_conf_arrays\"            # where to save arrays\n",
    "# TARGET_SR  = 16000\n",
    "# STEP_SAMPLES = 200          # CREPE hop in samples @ 16k (200 -> 12.5 ms)\n",
    "# CREPE_CAPACITY = \"medium\"   # \"tiny\"|\"small\"|\"medium\"|\"large\"|\"full\"\n",
    "# USE_VITERBI = True\n",
    "# ALLOWED_EXT = (\".wav\", \".flac\", \".ogg\")  # extend if needed\n",
    "\n",
    "# # --------------------------\n",
    "# # HELPERS\n",
    "# # --------------------------\n",
    "# def load_mono_and_resample(path: str, target_sr: int) -> tuple[np.ndarray, int]:\n",
    "#     \"\"\"Load audio as mono float32 and resample to target_sr if needed.\"\"\"\n",
    "#     y, sr = sf.read(path, always_2d=False)\n",
    "#     if isinstance(y, np.ndarray) and y.ndim > 1:\n",
    "#         y = y.mean(axis=1)\n",
    "#     y = y.astype(np.float32, copy=False)\n",
    "#     if sr != target_sr:\n",
    "#         y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "#         sr = target_sr\n",
    "#     return y, sr\n",
    "\n",
    "# def f0_crepe(y16: np.ndarray, sr16: int, step_samples: int, capacity: str, viterbi: bool):\n",
    "#     \"\"\"Run CREPE F0; returns (time_s, f0_hz, confidence).\"\"\"\n",
    "#     time_s, f0_hz, conf, _ = crepe.predict(\n",
    "#         y16, sr16,\n",
    "#         step_size=step_samples,\n",
    "#         viterbi=viterbi,\n",
    "#         model_capacity=capacity,\n",
    "#         verbose=0\n",
    "#     )\n",
    "#     return time_s.astype(np.float32), f0_hz.astype(np.float32), conf.astype(np.float32)\n",
    "\n",
    "# def waveform_on_grid(y16: np.ndarray, sr16: int, t_grid_s: np.ndarray) -> np.ndarray:\n",
    "#     \"\"\"Sample waveform at exact CREPE frame centers (nearest-neighbor).\"\"\"\n",
    "#     idx = np.clip((t_grid_s * sr16).astype(int), 0, len(y16) - 1)\n",
    "#     return y16[idx].astype(np.float32)\n",
    "\n",
    "# def make_out_path(out_root: str, class_label: str, wav_path: str) -> str:\n",
    "#     \"\"\"Create class subdir and build .npy filename from input wav stem.\"\"\"\n",
    "#     stem = Path(wav_path).stem\n",
    "#     class_dir = Path(out_root) / class_label\n",
    "#     class_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     return str(class_dir / f\"{stem}_f0_wave_conf.npy\")\n",
    "\n",
    "# # --------------------------\n",
    "# # SCAN FILES\n",
    "# # --------------------------\n",
    "# def list_audio_files(root: str) -> list[tuple[str, str]]:\n",
    "#     \"\"\"\n",
    "#     Return a list of (wav_path, class_label), assuming structure:\n",
    "#       root/<class_label>/*.(wav/flac/ogg)\n",
    "#     \"\"\"\n",
    "#     out = []\n",
    "#     for class_dir in sorted(Path(root).glob(\"*\")):\n",
    "#         if not class_dir.is_dir():\n",
    "#             continue\n",
    "#         label = class_dir.name\n",
    "#         for ext in ALLOWED_EXT:\n",
    "#             for p in class_dir.rglob(f\"*{ext}\"):\n",
    "#                 out.append((str(p), label))\n",
    "#     return out\n",
    "\n",
    "# # --------------------------\n",
    "# # MAIN\n",
    "# # --------------------------\n",
    "# def main():\n",
    "#     files = list_audio_files(PATH_TRAIN)\n",
    "#     if not files:\n",
    "#         print(f\"No audio files found under: {PATH_TRAIN}\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "#     Path(OUT_ROOT).mkdir(parents=True, exist_ok=True)\n",
    "#     manifest_path = Path(OUT_ROOT) / \"manifest.csv\"\n",
    "\n",
    "#     # Write CSV header\n",
    "#     with open(manifest_path, \"w\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "#         w = csv.writer(fcsv)\n",
    "#         w.writerow([\n",
    "#             \"input_path\", \"class_label\", \"array_path\",\n",
    "#             \"n_frames\", \"duration_s\", \"sr\", \"step_samples\"\n",
    "#         ])\n",
    "\n",
    "#     with tqdm(total=len(files), desc=\"Processing files\", unit=\"file\") as pbar:\n",
    "#         for wav_path, label in files:\n",
    "#             try:\n",
    "#                 # 1) Load + resample to 16 kHz mono\n",
    "#                 y16, sr16 = load_mono_and_resample(wav_path, TARGET_SR)\n",
    "#                 duration_s = len(y16) / float(sr16)\n",
    "\n",
    "#                 # 2) CREPE F0\n",
    "#                 time_s, f0_hz, conf = f0_crepe(\n",
    "#                     y16, sr16,\n",
    "#                     step_samples=STEP_SAMPLES,\n",
    "#                     capacity=CREPE_CAPACITY,\n",
    "#                     viterbi=USE_VITERBI\n",
    "#                 )\n",
    "\n",
    "#                 # 3) Waveform sampled on the same grid\n",
    "#                 wave_grid = waveform_on_grid(y16, sr16, time_s)\n",
    "\n",
    "#                 # 4) Stack rows: [waveform; f0; confidence] -> (3, T)\n",
    "#                 arr = np.vstack([wave_grid, f0_hz, conf]).astype(np.float32)\n",
    "\n",
    "#                 # 5) Save\n",
    "#                 out_npy = make_out_path(OUT_ROOT, label, wav_path)\n",
    "#                 np.save(out_npy, arr)\n",
    "\n",
    "#                 # 6) Append manifest\n",
    "#                 with open(manifest_path, \"a\", newline=\"\", encoding=\"utf-8\") as fcsv:\n",
    "#                     w = csv.writer(fcsv)\n",
    "#                     w.writerow([\n",
    "#                         wav_path, label, out_npy,\n",
    "#                         arr.shape[1], f\"{duration_s:.6f}\", sr16, STEP_SAMPLES\n",
    "#                     ])\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 # Log failures but keep going\n",
    "#                 err_line = f\"[ERROR] {wav_path} ({label}): {e}\"\n",
    "#                 print(err_line)\n",
    "\n",
    "#             pbar.update(1)\n",
    "\n",
    "#     print(\"\\nDone.\")\n",
    "#     print(f\"Saved arrays under: {OUT_ROOT}\")\n",
    "#     print(f\"Manifest: {manifest_path}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d3e6f-3c2e-4ff6-a2b6-1744a639d775",
   "metadata": {},
   "source": [
    "# How I loaded f0 wave confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e3eb262-b4b7-4739-9a05-87ecc0d9e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F0 files: 184\n",
      "Train F0 files: 734\n",
      "Median length test: 107\n",
      "Median length train: 108\n",
      "resized version test:  (3, 108) old version test:  (3, 135)\n",
      "resized version train:  (3, 108) old version train:  (3, 126)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def load_npy_data(base_dir):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    array = np.load(file_path)  # shape (3, X)\n",
    "                    feature_list.append(array)\n",
    "                    label_list.append(os.path.basename(root))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_path}: {e}\")\n",
    "    features_df = pd.DataFrame({'features': feature_list})\n",
    "    labels_df = pd.DataFrame({'folder': label_list})\n",
    "    return features_df, labels_df\n",
    "\n",
    "\n",
    "# Load test STFT data\n",
    "test_F0_df, test_label = load_npy_data(f0_conf_wave_test_dir)\n",
    "\n",
    "# Load train MFCC data\n",
    "train_F0_df, train_label = load_npy_data(f0_conf_wave_train_dir)\n",
    "\n",
    "train_F0_df.reset_index(drop=True, inplace=True)\n",
    "test_F0_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Optional: check number of samples loaded\n",
    "print(f\"Test F0 files: {len(test_F0_df)}\")\n",
    "print(f\"Train F0 files: {len(train_F0_df)}\")\n",
    "\n",
    "# Compute lengths of each array (X dimension)\n",
    "lengths_test = test_F0_df['features'].apply(lambda x: x.shape[1])\n",
    "lengths_train = train_F0_df['features'].apply(lambda x: x.shape[1])\n",
    "\n",
    "median_length_test = int(np.median(lengths_test))\n",
    "median_length_train = int(np.median(lengths_train))\n",
    "\n",
    "print(\"Median length test:\", median_length_test)\n",
    "print(\"Median length train:\", median_length_train)\n",
    "\n",
    "\n",
    "def resize_sequence(seq, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (3, X) sequence along the X axis to target_len.\n",
    "    \"\"\"\n",
    "    seq = np.array(seq)\n",
    "    rows, current_len = seq.shape\n",
    "\n",
    "    if current_len == target_len:\n",
    "        return seq\n",
    "    else:\n",
    "        resized = np.zeros((rows, target_len))\n",
    "        original_idx = np.linspace(0, 1, current_len)\n",
    "        target_idx = np.linspace(0, 1, target_len)\n",
    "        for i in range(rows):\n",
    "            f = interp1d(original_idx, seq[i, :], kind='linear')\n",
    "            resized[i, :] = f(target_idx)\n",
    "        return resized\n",
    "\n",
    "\n",
    "# Usage example: resize all sequences in a DataFrame column\n",
    "target_length = median_length_train  # or any fixed length\n",
    "test_F0_df['resized_features'] = test_F0_df['features'].apply(lambda x: resize_sequence(x, target_length))\n",
    "train_F0_df['resized_features'] = train_F0_df['features'].apply(lambda x: resize_sequence(x, target_length))\n",
    "\n",
    "print(\"resized version test: \", test_F0_df['resized_features'][10].shape,\n",
    "      \"old version test: \", test_F0_df['features'][10].shape)\n",
    "\n",
    "print(\"resized version train: \", train_F0_df['resized_features'][10].shape,\n",
    "      \"old version train: \", train_F0_df['features'][10].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935ea13-19b2-4ba1-a372-37856ec43b21",
   "metadata": {},
   "source": [
    "# Integrate all Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5305c-8277-49b1-955d-d9cbc9a43ad2",
   "metadata": {},
   "source": [
    "# MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b7e4734-79c4-438e-92b7-6e32c119a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio files: 734\n",
      "Test  audio files: 184\n",
      "Median time frames (train): 1096 (win=480 samples, hop=240 samples @ 16000 Hz)\n",
      "Train sample shapes: (20, 1644) -> (20, 1096)\n",
      "Test  sample shapes: (20, 1201) -> (20, 1096)\n",
      "X_train: (734, 20, 1096) X_test: (184, 20, 1096)\n",
      "Classes: ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# Params\n",
    "# -----------------------------\n",
    "SR = 16000           # target sample rate\n",
    "FRAME_MS = 30.0      # window length (ms) = frame size\n",
    "HOP_MS = 15.0        # hop length (ms). Use 30.0 if you want no overlap\n",
    "N_MFCC = 20          # MFCC coefficients (common: 13 or 20)\n",
    "AUDIO_EXTS = {\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\"}\n",
    "\n",
    "WIN_LENGTH = int(round(SR * FRAME_MS / 1000.0))\n",
    "HOP_LENGTH = int(round(SR * HOP_MS   / 1000.0))\n",
    "N_FFT = 1\n",
    "while N_FFT < WIN_LENGTH:  # next power of two >= win_length (librosa-friendly)\n",
    "    N_FFT <<= 1\n",
    "\n",
    "def is_audio_file(path):\n",
    "    return os.path.splitext(path)[1].lower() in AUDIO_EXTS\n",
    "\n",
    "def compute_mfcc(file_path, sr=SR, n_mfcc=N_MFCC,\n",
    "                 n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Returns MFCC array of shape (n_mfcc, T).\n",
    "    \"\"\"\n",
    "    y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    # Use center=True (default) for better coverage at edges\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=n_mfcc,\n",
    "        n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "        center=True\n",
    "    )\n",
    "    return mfcc  # (n_mfcc, T)\n",
    "\n",
    "def load_mfcc_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Walks class-labeled subfolders under root_dir, computes MFCC for each audio.\n",
    "    Returns a DataFrame with columns: ['mfcc', 'label', 'path'].\n",
    "    \"\"\"\n",
    "    feats, labels, paths = [], [], []\n",
    "    for class_dir in sorted(os.listdir(root_dir)):\n",
    "        class_path = os.path.join(root_dir, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if not os.path.isfile(fpath) or not is_audio_file(fpath):\n",
    "                continue\n",
    "            try:\n",
    "                mfcc = compute_mfcc(fpath)\n",
    "                feats.append(mfcc)\n",
    "                labels.append(class_dir)\n",
    "                paths.append(fpath)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipped {fpath}: {e}\")\n",
    "    df = pd.DataFrame({\"mfcc\": feats, \"label\": labels, \"path\": paths})\n",
    "    return df\n",
    "\n",
    "def resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (C, T) feature matrix along time axis to target_len using linear interp.\n",
    "    C = channels/features (e.g., n_mfcc), T = time frames.\n",
    "    \"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "\n",
    "    # Build interpolation index\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (update these)\n",
    "# -----------------------------\n",
    "train_audio_root = r\".../Train\"  # each subfolder is a class\n",
    "test_audio_root  = r\".../Test\"   # each subfolder is a class\n",
    "\n",
    "# -----------------------------\n",
    "# Load MFCCs\n",
    "# -----------------------------\n",
    "train_df = load_mfcc_dataset(audio_train_dir)\n",
    "test_df  = load_mfcc_dataset(audio_test_dir)\n",
    "\n",
    "# Optional: sanity check\n",
    "print(f\"Train audio files: {len(train_df)}\")\n",
    "print(f\"Test  audio files: {len(test_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Determine target length (median frames of TRAIN)\n",
    "# -----------------------------\n",
    "train_lengths = train_df[\"mfcc\"].apply(lambda m: m.shape[1])\n",
    "test_lengths  = test_df[\"mfcc\"].apply(lambda m: m.shape[1])\n",
    "\n",
    "target_len = int(np.median(train_lengths))\n",
    "print(f\"Median time frames (train): {target_len} \"\n",
    "      f\"(win={WIN_LENGTH} samples, hop={HOP_LENGTH} samples @ {SR} Hz)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Resize MFCCs along time axis\n",
    "# -----------------------------\n",
    "train_df[\"mfcc_resized\"] = train_df[\"mfcc\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "test_df[\"mfcc_resized\"]  = test_df[\"mfcc\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "\n",
    "# Example: shapes before/after\n",
    "i = min(10, len(train_df)-1)\n",
    "j = min(10, len(test_df)-1)\n",
    "print(\"Train sample shapes:\", train_df.loc[i, \"mfcc\"].shape, \"->\", train_df.loc[i, \"mfcc_resized\"].shape)\n",
    "print(\"Test  sample shapes:\", test_df.loc[j, \"mfcc\"].shape, \"->\", test_df.loc[j, \"mfcc_resized\"].shape)\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Pack arrays for modeling\n",
    "# X_train: (N, n_mfcc, target_len), y_train: labels\n",
    "# -----------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df[\"label\"].values)\n",
    "y_test  = le.transform(test_df[\"label\"].values) if set(test_df[\"label\"]) <= set(le.classes_) else \\\n",
    "          le.fit_transform(test_df[\"label\"].values)  # fallback if classes differ\n",
    "\n",
    "X_train_mfcc = np.stack(train_df[\"mfcc_resized\"].values, axis=0)\n",
    "X_test_mfcc  = np.stack(test_df[\"mfcc_resized\"].values, axis=0)\n",
    "\n",
    "print(\"X_train:\", X_train_mfcc.shape, \"X_test:\", X_test_mfcc.shape)\n",
    "print(\"Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d09884-c355-4148-9438-663453c1e565",
   "metadata": {},
   "source": [
    "# STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73482e7c-bf19-422c-a0e8-f49ccfe10821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train audio files: 734\n",
      "Test  audio files: 184\n",
      "Median time frames (train): 1096 (win=480 samples, hop=240 samples @ 16000 Hz, n_fft=512)\n",
      "Train sample shapes: (257, 1644) -> (257, 1096)\n",
      "Test  sample shapes: (257, 1201) -> (257, 1096)\n",
      "X_train: (734, 257, 1096) X_test: (184, 257, 1096)\n",
      "Classes: ['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# Params\n",
    "# -----------------------------\n",
    "SR = 16000           # target sample rate\n",
    "FRAME_MS = 30.0      # window length (ms) = frame size\n",
    "HOP_MS = 15.0        # hop length (ms). Use 30.0 if you want no overlap\n",
    "AUDIO_EXTS = {\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\"}\n",
    "\n",
    "# STFT scaling options\n",
    "POWER = 1.0          # 1.0 = magnitude, 2.0 = power\n",
    "TO_DB = True         # convert to dB (log scale) for nicer dynamics\n",
    "DB_REF = 1.0         # reference for dB conversion (librosa default is max if ref=np.max)\n",
    "\n",
    "WIN_LENGTH = int(round(SR * FRAME_MS / 1000.0))\n",
    "HOP_LENGTH = int(round(SR * HOP_MS   / 1000.0))\n",
    "N_FFT = 1\n",
    "while N_FFT < WIN_LENGTH:  # next power of two >= win_length (librosa-friendly)\n",
    "    N_FFT <<= 1\n",
    "\n",
    "def is_audio_file(path):\n",
    "    return os.path.splitext(path)[1].lower() in AUDIO_EXTS\n",
    "\n",
    "def compute_stft(file_path,\n",
    "                 sr=SR, n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH,\n",
    "                 power=POWER, to_db=TO_DB, db_ref=DB_REF):\n",
    "    \"\"\"\n",
    "    Returns STFT feature of shape (freq_bins, T).\n",
    "    By default: |STFT|^POWER, optionally converted to dB.\n",
    "    \"\"\"\n",
    "    y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "    S_complex = librosa.stft(\n",
    "        y,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window='hann',\n",
    "        center=True\n",
    "    )\n",
    "    S_mag = np.abs(S_complex) ** power  # (n_fft//2+1, T)\n",
    "\n",
    "    if to_db:\n",
    "        # Avoid -inf by using a small floor; librosa handles this internally\n",
    "        S_feat = librosa.amplitude_to_db(S_mag, ref=db_ref) if power == 1.0 \\\n",
    "                 else librosa.power_to_db(S_mag, ref=db_ref)\n",
    "    else:\n",
    "        S_feat = S_mag\n",
    "\n",
    "    return S_feat.astype(np.float32)\n",
    "\n",
    "def load_stft_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Walks class-labeled subfolders under root_dir, computes STFT for each audio.\n",
    "    Returns a DataFrame with columns: ['stft', 'label', 'path'].\n",
    "    \"\"\"\n",
    "    feats, labels, paths = [], [], []\n",
    "    for class_dir in sorted(os.listdir(root_dir)):\n",
    "        class_path = os.path.join(root_dir, class_dir)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            fpath = os.path.join(class_path, fname)\n",
    "            if not os.path.isfile(fpath) or not is_audio_file(fpath):\n",
    "                continue\n",
    "            try:\n",
    "                stft = compute_stft(fpath)\n",
    "                feats.append(stft)           # (F, T)\n",
    "                labels.append(class_dir)\n",
    "                paths.append(fpath)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipped {fpath}: {e}\")\n",
    "    return pd.DataFrame({\"stft\": feats, \"label\": labels, \"path\": paths})\n",
    "\n",
    "def resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"\n",
    "    Resize a (C, T) feature matrix along the time axis to target_len using linear interpolation.\n",
    "    C = channels/frequency bins, T = time frames.\n",
    "    \"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (update these)\n",
    "# -----------------------------\n",
    "train_audio_root = r\".../Train\"  # each subfolder is a class\n",
    "test_audio_root  = r\".../Test\"   # each subfolder is a class\n",
    "\n",
    "# -----------------------------\n",
    "# Load STFTs\n",
    "# -----------------------------\n",
    "train_df = load_stft_dataset(audio_train_dir)\n",
    "test_df  = load_stft_dataset(audio_test_dir)\n",
    "\n",
    "print(f\"Train audio files: {len(train_df)}\")\n",
    "print(f\"Test  audio files: {len(test_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Determine target length (median frames of TRAIN)\n",
    "# -----------------------------\n",
    "train_lengths = train_df[\"stft\"].apply(lambda m: m.shape[1])\n",
    "test_lengths  = test_df[\"stft\"].apply(lambda m: m.shape[1])\n",
    "\n",
    "target_len = int(np.median(train_lengths))\n",
    "print(f\"Median time frames (train): {target_len} \"\n",
    "      f\"(win={WIN_LENGTH} samples, hop={HOP_LENGTH} samples @ {SR} Hz, n_fft={N_FFT})\")\n",
    "\n",
    "# -----------------------------\n",
    "# Resize STFTs along time axis\n",
    "# -----------------------------\n",
    "train_df[\"stft_resized\"] = train_df[\"stft\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "test_df[\"stft_resized\"]  = test_df[\"stft\"].apply(lambda M: resize_time_axis(M, target_len))\n",
    "\n",
    "# Example: shapes before/after\n",
    "i = min(10, len(train_df)-1)\n",
    "j = min(10, len(test_df)-1)\n",
    "print(\"Train sample shapes:\", train_df.loc[i, \"stft\"].shape, \"->\", train_df.loc[i, \"stft_resized\"].shape)\n",
    "print(\"Test  sample shapes:\", test_df.loc[j, \"stft\"].shape, \"->\", test_df.loc[j, \"stft_resized\"].shape)\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Pack arrays for modeling\n",
    "# X_train: (N, F, target_len), y_train: labels\n",
    "# -----------------------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([train_df[\"label\"], test_df[\"label\"]], axis=0))\n",
    "\n",
    "y_train_stft = le.transform(train_df[\"label\"].values)\n",
    "y_test  = le.transform(test_df[\"label\"].values)\n",
    "\n",
    "X_train_stft = np.stack(train_df[\"stft_resized\"].values, axis=0)  # (N, F, T)\n",
    "X_test_stft  = np.stack(test_df[\"stft_resized\"].values, axis=0)\n",
    "\n",
    "print(\"X_train:\", X_train_stft.shape, \"X_test:\", X_test_stft.shape)\n",
    "print(\"Classes:\", list(le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521370d-f638-4e48-94dc-668197181f77",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b5ecbff-94a9-421f-a7c0-7af0cacc113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PRE-COMBINE SUMMARY: TRAIN ===\n",
      "STFT_train: N=734, example (C,T)=(257,1096)\n",
      "  Channels (C) ~ 257 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "MFCC_train: N=734, example (C,T)=(20,1096)\n",
      "  Channels (C) ~ 20 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "F0_train: N=734, example (C,T)=(3,108)\n",
      "  Channels (C) ~ 3 (assumed constant)\n",
      "  Time frames (T): min=108, median=108, max=108\n",
      "\n",
      "=== PRE-COMBINE SUMMARY: TEST ===\n",
      "STFT_test: N=184, example (C,T)=(257,1096)\n",
      "  Channels (C) ~ 257 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "MFCC_test: N=184, example (C,T)=(20,1096)\n",
      "  Channels (C) ~ 20 (assumed constant)\n",
      "  Time frames (T): min=1096, median=1096, max=1096\n",
      "F0_test: N=184, example (C,T)=(3,108)\n",
      "  Channels (C) ~ 3 (assumed constant)\n",
      "  Time frames (T): min=108, median=108, max=108\n",
      "\n",
      "Target time length (frames): train=1096, test=1096\n",
      "\n",
      "=== POST-COMBINE SHAPES ===\n",
      "Train_combined (N, T, F): (734, 1096, 277)\n",
      "Test_combined  (N, T, F): (184, 1096, 277)\n",
      "One train sample (T,F): (1096, 277)\n",
      "One test  sample (T,F): (1096, 277)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _pick_col(df, candidates=(\"stft_resized\",\"mfcc_resized\",\"resized_features\",\"features\",\"stft\",\"mfcc\")):\n",
    "    for c in candidates:\n",
    "        if isinstance(df, pd.DataFrame) and c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(f\"No feature column found. Tried: {candidates}\")\n",
    "\n",
    "def _len_source(source):\n",
    "    if isinstance(source, pd.DataFrame):\n",
    "        return len(source)\n",
    "    return source.shape[0]  # assume ndarray (N, ...)\n",
    "\n",
    "def _get_sample_feat(source, i):\n",
    "    \"\"\"\n",
    "    Returns a (C, T) float32 array for sample i from either:\n",
    "      - DataFrame with a feature column, or\n",
    "      - NumPy array shaped (N, C, T)\n",
    "    \"\"\"\n",
    "    if isinstance(source, pd.DataFrame):\n",
    "        col = _pick_col(source)\n",
    "        arr = source[col].iloc[i]\n",
    "    else:  # ndarray\n",
    "        arr = source[i]\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"Expected per-sample 2D (C,T); got {arr.shape}\")\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def _resize_time_axis(feat_2d, target_len):\n",
    "    \"\"\"Resize (C, T) -> (C, target_len) by linear interpolation over time axis.\"\"\"\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d\n",
    "    orig = np.linspace(0.0, 1.0, T, endpoint=True)\n",
    "    tgt  = np.linspace(0.0, 1.0, target_len, endpoint=True)\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt)\n",
    "    return out\n",
    "\n",
    "def _combine_three_modalities(stft_feat, mfcc_feat, f0_feat, target_len):\n",
    "    \"\"\"\n",
    "    All inputs are (C, T). They are resized to the same target_len and concatenated on C.\n",
    "    Returns (T, C_total).\n",
    "    \"\"\"\n",
    "    stft_feat = _resize_time_axis(stft_feat, target_len)\n",
    "    mfcc_feat = _resize_time_axis(mfcc_feat, target_len)\n",
    "    f0_feat   = _resize_time_axis(f0_feat,   target_len)\n",
    "    CxT = np.concatenate([stft_feat, mfcc_feat, f0_feat], axis=0)  # (C_total, T) ################################################################ without f0\n",
    "    return CxT.T  # (T, C_total)\n",
    "\n",
    "def _time_lengths(source):\n",
    "    \"\"\"Return a list of T (time frames) for all samples in source.\"\"\"\n",
    "    n = _len_source(source)\n",
    "    Ts = []\n",
    "    for i in range(n):\n",
    "        C, T = _get_sample_feat(source, i).shape\n",
    "        Ts.append(T)\n",
    "    return np.array(Ts, dtype=int)\n",
    "\n",
    "def _channels_first(source):\n",
    "    \"\"\"Return channel dimension (C) of the first sample.\"\"\"\n",
    "    C, T = _get_sample_feat(source, 0).shape\n",
    "    return C\n",
    "\n",
    "def _summarize(name, source):\n",
    "    \"\"\"\n",
    "    Print N, example shape, channels, and time stats (min/median/max) for a dataset.\n",
    "    \"\"\"\n",
    "    n = _len_source(source)\n",
    "    C0 = _channels_first(source)\n",
    "    Ts = _time_lengths(source)\n",
    "    print(f\"{name}: N={n}, example (C,T)=({C0},{Ts[0]})\")\n",
    "    print(f\"  Channels (C) ~ {C0} (assumed constant)\")\n",
    "    print(f\"  Time frames (T): min={Ts.min()}, median={int(np.median(Ts))}, max={Ts.max()}\")\n",
    "\n",
    "def _stack_combined(stft_src, mfcc_src, f0_src, target_len=None):\n",
    "    \"\"\"\n",
    "    Build (N, T, F) by concatenating STFT, MFCC, F0 along features for each sample.\n",
    "    Ensures uniform T across samples by using:\n",
    "      - provided target_len, or\n",
    "      - median T of STFT set if target_len is None.\n",
    "    \"\"\"\n",
    "    n = min(_len_source(stft_src), _len_source(mfcc_src), _len_source(f0_src))\n",
    "    if n == 0:\n",
    "        raise ValueError(\"No samples to combine.\")\n",
    "\n",
    "    # Decide a uniform target length\n",
    "    if target_len is None:\n",
    "        target_len = int(np.median(_time_lengths(stft_src)))  # use STFT's median frames\n",
    "\n",
    "    combined = []\n",
    "    for i in range(n):\n",
    "        stft_i = _get_sample_feat(stft_src, i)   # (F_stft, T_s)\n",
    "        mfcc_i = _get_sample_feat(mfcc_src, i)   # (C_mfcc, T_m)\n",
    "        f0_i   = _get_sample_feat(f0_src, i)     # (3, T_f0)\n",
    "        combined_i = _combine_three_modalities(stft_i, mfcc_i, f0_i, target_len=target_len)  # (T, F_total)\n",
    "        combined.append(combined_i)\n",
    "    return np.stack(combined, axis=0)  # (N, T, F)\n",
    "\n",
    "# =========================================================\n",
    "# Your inputs (must already be in memory):\n",
    "#   train_F0_df, test_F0_df           -> DataFrames with (3, T) per sample in a feature col\n",
    "#   X_train_mfcc, X_test_mfcc         -> DataFrames or arrays with (C_mfcc, T)\n",
    "#   X_train_stft, X_test_stft         -> DataFrames or arrays with (F_stft, T)\n",
    "# =========================================================\n",
    "\n",
    "# -----------------------------\n",
    "# PRE-COMBINE SHAPE SUMMARIES\n",
    "# -----------------------------\n",
    "print(\"=== PRE-COMBINE SUMMARY: TRAIN ===\")\n",
    "_summarize(\"STFT_train\", X_train_stft)\n",
    "_summarize(\"MFCC_train\", X_train_mfcc)\n",
    "_summarize(\"F0_train\",   train_F0_df)\n",
    "\n",
    "print(\"\\n=== PRE-COMBINE SUMMARY: TEST ===\")\n",
    "_summarize(\"STFT_test\", X_test_stft)\n",
    "_summarize(\"MFCC_test\", X_test_mfcc)\n",
    "_summarize(\"F0_test\",   test_F0_df)\n",
    "\n",
    "# -----------------------------\n",
    "# CHOOSE UNIFORM TARGET LENGTH\n",
    "# Use train STFT median for both train & test (keeps shapes consistent for modeling)\n",
    "# -----------------------------\n",
    "target_len_train = int(np.median(_time_lengths(X_train_stft)))\n",
    "target_len_test  = target_len_train  # enforce same T across splits\n",
    "\n",
    "print(f\"\\nTarget time length (frames): train={target_len_train}, test={target_len_test}\")\n",
    "\n",
    "# -----------------------------\n",
    "# COMBINE (STFT + MFCC + F0) -> (N, T, F)\n",
    "# -----------------------------\n",
    "Train_combined = _stack_combined(X_train_stft, X_train_mfcc, train_F0_df, target_len=target_len_train)\n",
    "Test_combined  = _stack_combined(X_test_stft,  X_test_mfcc,  test_F0_df,  target_len=target_len_test)\n",
    "\n",
    "# -----------------------------\n",
    "# POST-COMBINE SHAPES\n",
    "# -----------------------------\n",
    "print(\"\\n=== POST-COMBINE SHAPES ===\")\n",
    "print(\"Train_combined (N, T, F):\", Train_combined.shape)\n",
    "print(\"Test_combined  (N, T, F):\", Test_combined.shape)\n",
    "\n",
    "# Optional peek at per-sample shapes\n",
    "if Train_combined.size:\n",
    "    print(\"One train sample (T,F):\", Train_combined[0].shape)\n",
    "if Test_combined.size:\n",
    "    print(\"One test  sample (T,F):\", Test_combined[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0ffcd-8116-4822-b0e6-775b7c6fff47",
   "metadata": {},
   "source": [
    "# Combined feature module for Feature extration modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b4820c-52b9-43fe-9bd0-a2f8865fddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple, Dict, Optional, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "\n",
    "# -----------------------------\n",
    "# General parameters (can be overridden per call)\n",
    "# -----------------------------\n",
    "AUDIO_EXTS = (\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\")\n",
    "\n",
    "def _is_audio(p: Path) -> bool:\n",
    "    return p.suffix.lower() in AUDIO_EXTS\n",
    "\n",
    "def _interp_resize_2d(feat_2d: np.ndarray, target_len: int) -> np.ndarray:\n",
    "    \"\"\"Resize a (C, T) feature matrix along time axis to target_len using linear interpolation.\"\"\"\n",
    "    feat_2d = np.asarray(feat_2d)\n",
    "    assert feat_2d.ndim == 2, f\"Expected 2D (C,T), got {feat_2d.shape}\"\n",
    "    C, T = feat_2d.shape\n",
    "    if T == target_len:\n",
    "        return feat_2d.astype(np.float32, copy=False)\n",
    "\n",
    "    orig_idx = np.linspace(0.0, 1.0, num=T, endpoint=True)\n",
    "    tgt_idx  = np.linspace(0.0, 1.0, num=target_len, endpoint=True)\n",
    "    out = np.empty((C, target_len), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        f = interp1d(orig_idx, feat_2d[c, :], kind=\"linear\", assume_sorted=True)\n",
    "        out[c, :] = f(tgt_idx)\n",
    "    return out\n",
    "\n",
    "def _choose_target_len(lengths: Iterable[int], policy: Literal[\"median\",\"max\"]=\"median\") -> int:\n",
    "    arr = np.array(list(lengths), dtype=int)\n",
    "    if len(arr) == 0:\n",
    "        raise ValueError(\"Cannot choose target length: empty lengths.\")\n",
    "    return int(np.median(arr)) if policy == \"median\" else int(arr.max())\n",
    "\n",
    "def _stft(\n",
    "    y: np.ndarray, sr: int,\n",
    "    n_fft: int, win_length: int, hop_length: int,\n",
    "    power: float = 1.0, to_db: bool = True\n",
    ") -> np.ndarray:\n",
    "    S_complex = librosa.stft(\n",
    "        y, n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "        window='hann', center=True\n",
    "    )\n",
    "    S_mag = np.abs(S_complex) ** power\n",
    "    if to_db:\n",
    "        # librosa uses 10*log10 for power and 20*log10 for amplitude internally\n",
    "        S_db = librosa.power_to_db(S_mag, ref=np.max) if power != 1.0 else librosa.amplitude_to_db(S_mag, ref=np.max)\n",
    "        return S_db.astype(np.float32)\n",
    "    return S_mag.astype(np.float32)\n",
    "\n",
    "def _mfcc(\n",
    "    y: np.ndarray, sr: int,\n",
    "    n_mfcc: int, n_fft: int, win_length: int, hop_length: int\n",
    ") -> np.ndarray:\n",
    "    M = librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_mfcc=n_mfcc,\n",
    "        n_fft=n_fft, hop_length=hop_length, win_length=win_length, center=True\n",
    "    )\n",
    "    return M.astype(np.float32)\n",
    "\n",
    "def _load_audio(path: Path, sr: int) -> np.ndarray:\n",
    "    y, _ = librosa.load(str(path), sr=sr, mono=True)\n",
    "    return y.astype(np.float32, copy=False)\n",
    "\n",
    "def _scan_pairs(\n",
    "    f0_dir: Path, audio_dir: Path\n",
    ") -> List[Tuple[str, str, Path, Path]]:\n",
    "    \"\"\"\n",
    "    Pair items by (class_folder, file stem). Returns list of tuples:\n",
    "      (class_label, stem, f0_npy_path, audio_path)\n",
    "\n",
    "    - f0_dir structure: f0_dir/<class>/*_f0_wave_conf.npy (or any .npy)\n",
    "    - audio_dir structure: audio_dir/<class>/*.(wav|mp3|...)\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    if not f0_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing F0 dir: {f0_dir}\")\n",
    "    if not audio_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing audio dir: {audio_dir}\")\n",
    "\n",
    "    # index audio by (class, stem) -> path\n",
    "    audio_index: Dict[Tuple[str,str], Path] = {}\n",
    "    for class_dir in sorted([d for d in audio_dir.iterdir() if d.is_dir()]):\n",
    "        cls = class_dir.name\n",
    "        for ap in class_dir.rglob(\"*\"):\n",
    "            if ap.is_file() and _is_audio(ap):\n",
    "                audio_index[(cls, ap.stem)] = ap\n",
    "\n",
    "    # walk f0 npy files and find matching audio\n",
    "    for class_dir in sorted([d for d in f0_dir.iterdir() if d.is_dir()]):\n",
    "        cls = class_dir.name\n",
    "        for npy in class_dir.rglob(\"*.npy\"):\n",
    "            stem = npy.stem\n",
    "            # allow suffixes like *_f0_wave_conf; use split at first suffix\n",
    "            stem_clean = stem.replace(\"_f0_wave_conf\", \"\")\n",
    "            key = (cls, stem_clean)\n",
    "            if key not in audio_index:\n",
    "                # fallback: try exact stem\n",
    "                if (cls, stem) in audio_index:\n",
    "                    key = (cls, stem)\n",
    "                else:\n",
    "                    # couldn't match — skip silently but could warn\n",
    "                    # print(f\"[WARN] No matching audio for {npy}\")\n",
    "                    continue\n",
    "            pairs.append((cls, key[1], npy, audio_index[key]))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def _load_f0_array(npy_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expect shape (3, T): [wave_on_grid; f0_hz; confidence].\n",
    "    \"\"\"\n",
    "    arr = np.load(str(npy_path))\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2 or arr.shape[0] != 3:\n",
    "        raise ValueError(f\"Expected F0 array shape (3, T). Got {arr.shape} from {npy_path}\")\n",
    "    return arr.astype(np.float32)\n",
    "\n",
    "def build_split(\n",
    "    f0_dir: str,\n",
    "    audio_dir: str,\n",
    "    *,\n",
    "    sr: int = 16000,\n",
    "    frame_ms: float = 30.0,\n",
    "    hop_ms: float = 15.0,\n",
    "    n_mfcc: int = 20,\n",
    "    stft_power: float = 1.0,\n",
    "    stft_to_db: bool = True,\n",
    "    fixed_target_len: int | None = None,   # <— NEW\n",
    "    target_len_policy: Literal[\"median\",\"max\"] = \"median\",\n",
    "    modalities: Iterable[Literal[\"stft\",\"mfcc\",\"f0\"]] = (\"stft\",\"mfcc\",\"f0\"),\n",
    "    strict_triplet: bool = True,\n",
    "    min_frames: int = 2,                         # <— NEW\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Build a single split (train OR test).\n",
    "\n",
    "    Returns:\n",
    "      X  : (N, T, F) float32 — concatenated [modalities] along feature dim\n",
    "      y  : (N,) int labels (encoded by alphabetical class order)\n",
    "      df : manifest with columns [class, stem, f0_path, audio_path, T_stft, T_mfcc, T_f0, T_final]\n",
    "\n",
    "    Notes:\n",
    "      - Only items where **all requested modalities** exist are kept.\n",
    "      - Time axis is resized to a **single target length** chosen from STFT (if present),\n",
    "        else MFCC, else F0 — according to `target_len_policy`.\n",
    "    \"\"\"\n",
    "    f0_dir = Path(f0_dir)\n",
    "    audio_dir = Path(audio_dir)\n",
    "    pairs = _scan_pairs(f0_dir, audio_dir)\n",
    "\n",
    "    if len(pairs) == 0:\n",
    "        raise ValueError(f\"No (F0, audio) pairs found between {f0_dir} and {audio_dir}.\")\n",
    "\n",
    "    # window sizes\n",
    "    win_length = int(round(sr * frame_ms / 1000.0))\n",
    "    hop_length = int(round(sr * hop_ms   / 1000.0))\n",
    "    # next power of two for n_fft\n",
    "    n_fft = 1\n",
    "    while n_fft < win_length:\n",
    "        n_fft <<= 1\n",
    "\n",
    "    rows = []\n",
    "    features_list = []\n",
    "    labels = []\n",
    "\n",
    "    # first pass: compute raw modality features + their T lengths\n",
    "    stft_list, mfcc_list, f0_list = [], [], []\n",
    "    Ts_stft, Ts_mfcc, Ts_f0 = [], [], []\n",
    "\n",
    "    kept = 0\n",
    "    skipped_short = 0\n",
    "    for cls, stem, f0_path, audio_path in pairs:\n",
    "        try:\n",
    "            f0_arr = _load_f0_array(f0_path) if \"f0\" in modalities else None\n",
    "            y = _load_audio(audio_path, sr=sr)\n",
    "\n",
    "            stft_feat = _stft(y, sr, n_fft, win_length, hop_length,\n",
    "                              power=stft_power, to_db=stft_to_db) if \"stft\" in modalities else None\n",
    "            mfcc_feat = _mfcc(y, sr, n_mfcc, n_fft, win_length, hop_length) if \"mfcc\" in modalities else None\n",
    "\n",
    "            # record lengths\n",
    "            Ts_stft.append(stft_feat.shape[1] if stft_feat is not None else -1)\n",
    "            Ts_mfcc.append(mfcc_feat.shape[1] if mfcc_feat is not None else -1)\n",
    "            Ts_f0.append(f0_arr.shape[1]   if f0_arr   is not None else -1)\n",
    "\n",
    "            # skip if any requested modality has too few frames\n",
    "            if strict_triplet:\n",
    "                if (\"stft\" in modalities and (stft_feat is None or stft_feat.shape[1] < min_frames)) \\\n",
    "                or (\"mfcc\" in modalities and (mfcc_feat is None or mfcc_feat.shape[1] < min_frames)) \\\n",
    "                or (\"f0\"   in modalities and (f0_arr   is None or f0_arr.shape[1]   < min_frames)):\n",
    "                    skipped_short += 1\n",
    "                    continue\n",
    "\n",
    "            stft_list.append(stft_feat)\n",
    "            mfcc_list.append(mfcc_feat)\n",
    "            f0_list.append(f0_arr)\n",
    "            labels.append(cls)\n",
    "            rows.append({\n",
    "                \"class\": cls, \"stem\": stem,\n",
    "                \"f0_path\": str(f0_path), \"audio_path\": str(audio_path)\n",
    "            })\n",
    "            kept += 1\n",
    "        except Exception as e:\n",
    "            # Skip problematic files but keep going\n",
    "            # print(f\"[WARN] Skipped ({cls}/{stem}): {e}\")\n",
    "            continue\n",
    "            \n",
    "    if kept == 0:\n",
    "        raise ValueError(f\"After loading, no usable items remained (skipped_short={skipped_short}).\")\n",
    "\n",
    "    if len(labels) == 0:\n",
    "        raise ValueError(\"After loading, no usable items remained. Check data.\")\n",
    "\n",
    "    # choose target T from the first available modality in priority order\n",
    "    def _valid_lengths(L): return [x for x in L if x > 0]\n",
    "    if fixed_target_len is not None: \n",
    "        T_target = int(fixed_target_len)\n",
    "    elif \"stft\" in modalities and len(_valid_lengths(Ts_stft)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_stft), policy=target_len_policy)\n",
    "    elif \"mfcc\" in modalities and len(_valid_lengths(Ts_mfcc)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_mfcc), policy=target_len_policy)\n",
    "    elif \"f0\" in modalities and len(_valid_lengths(Ts_f0)) > 0:\n",
    "        T_target = _choose_target_len(_valid_lengths(Ts_f0), policy=target_len_policy)\n",
    "    else:\n",
    "        raise ValueError(\"Could not infer target time length from requested modalities.\")\n",
    "\n",
    "    # second pass: resize and concatenate\n",
    "    X_list = []\n",
    "    keep_mask = []\n",
    "    for stft_feat, mfcc_feat, f0_feat in zip(stft_list, mfcc_list, f0_list):\n",
    "        if strict_triplet:\n",
    "            # ensure all requested modalities exist\n",
    "            if (\"stft\" in modalities and stft_feat is None) or \\\n",
    "               (\"mfcc\" in modalities and mfcc_feat is None) or \\\n",
    "               (\"f0\"   in modalities and f0_feat   is None):\n",
    "                keep_mask.append(False)\n",
    "                X_list.append(None)\n",
    "                continue\n",
    "\n",
    "        channels = []\n",
    "        if stft_feat is not None:\n",
    "            channels.append(_interp_resize_2d(stft_feat, T_target))\n",
    "        if mfcc_feat is not None:\n",
    "            channels.append(_interp_resize_2d(mfcc_feat, T_target))\n",
    "        if f0_feat is not None:\n",
    "            channels.append(_interp_resize_2d(f0_feat, T_target))  # (3, T)\n",
    "\n",
    "        if len(channels) == 0:\n",
    "            keep_mask.append(False)\n",
    "            X_list.append(None)\n",
    "            continue\n",
    "\n",
    "        CxT = np.concatenate(channels, axis=0)     # (C_total, T)\n",
    "        X_list.append(CxT.T.astype(np.float32))    # (T, C_total)\n",
    "        keep_mask.append(True)\n",
    "\n",
    "    # filter by keep_mask\n",
    "    keep_idx = [i for i, k in enumerate(keep_mask) if k]\n",
    "    if len(keep_idx) == 0:\n",
    "        raise ValueError(\"No samples had all requested modalities (strict_triplet=True).\")\n",
    "\n",
    "    X = np.stack([X_list[i] for i in keep_idx], axis=0)   # (N, T, F)\n",
    "    y_labels = [labels[i] for i in keep_idx]\n",
    "    df = pd.DataFrame([rows[i] for i in keep_idx])\n",
    "    df[\"T_final\"] = T_target\n",
    "    if \"stft\" in modalities: df[\"T_stft\"] = [Ts_stft[i] for i in keep_idx]\n",
    "    if \"mfcc\" in modalities: df[\"T_mfcc\"] = [Ts_mfcc[i] for i in keep_idx]\n",
    "    if \"f0\"   in modalities: df[\"T_f0\"]   = [Ts_f0[i]   for i in keep_idx]\n",
    "\n",
    "    # encode labels alphabetically (stable & reproducible)\n",
    "    classes = sorted(pd.unique(df[\"class\"]))\n",
    "    cls_to_id = {c:i for i,c in enumerate(classes)}\n",
    "    y = np.array([cls_to_id[c] for c in y_labels], dtype=np.int64)\n",
    "\n",
    "    return X, y, df.assign(label_id=[cls_to_id[c] for c in y_labels])\n",
    "\n",
    "def prepare_train_test(\n",
    "    f0_conf_wave_train_dir: str,\n",
    "    f0_conf_wave_test_dir: str,\n",
    "    audio_train_dir: str,\n",
    "    audio_test_dir: str,\n",
    "    *,\n",
    "    sr: int = 16000,\n",
    "    frame_ms: float = 30.0,\n",
    "    hop_ms: float = 15.0,\n",
    "    n_mfcc: int = 20,\n",
    "    stft_power: float = 1.0,\n",
    "    stft_to_db: bool = True,\n",
    "    target_len_policy: Literal[\"median\",\"max\"] = \"median\",\n",
    "    modalities: Iterable[Literal[\"stft\",\"mfcc\",\"f0\"]] = (\"stft\",\"mfcc\",\"f0\"),\n",
    "    strict_triplet: bool = True,\n",
    "    fixed_target_len: int | None = None,   # <— NEW\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int,str], pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Convenience wrapper to build train & test with identical settings.\n",
    "\n",
    "    Returns:\n",
    "      X_train, y_train, X_test, y_test,\n",
    "      id_to_class (dict), train_manifest (df), test_manifest (df)\n",
    "    \"\"\"\n",
    "    X_train, y_train, df_train = build_split(\n",
    "        f0_conf_wave_train_dir, audio_train_dir,\n",
    "        sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "        stft_power=stft_power, stft_to_db=stft_to_db,\n",
    "        target_len_policy=target_len_policy, modalities=modalities,\n",
    "        strict_triplet=strict_triplet,\n",
    "        fixed_target_len=fixed_target_len,         # <— pass through\n",
    "        min_frames=2,                    # <— NEW\n",
    "    )\n",
    "    X_test, y_test, df_test = build_split(\n",
    "        f0_conf_wave_test_dir, audio_test_dir,\n",
    "        sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "        stft_power=stft_power, stft_to_db=stft_to_db,\n",
    "        target_len_policy=target_len_policy, modalities=modalities,\n",
    "        strict_triplet=strict_triplet,\n",
    "        fixed_target_len=fixed_target_len,         # <— pass through\n",
    "        min_frames=2,                    # <— NEW\n",
    "    )\n",
    "\n",
    "    # harmonize label ids across splits (use train mapping)\n",
    "    classes = sorted(pd.unique(df_train[\"class\"]))\n",
    "    id_to_class = {i:c for i,c in enumerate(classes)}\n",
    "    cls_to_id = {c:i for i,c in id_to_class.items()}\n",
    "\n",
    "    # remap test if classes overlap; unknown classes get new ids at the end\n",
    "    test_classes = list(pd.unique(df_test[\"class\"]))\n",
    "    for c in test_classes:\n",
    "        if c not in cls_to_id:\n",
    "            cls_to_id[c] = len(cls_to_id)\n",
    "            id_to_class[cls_to_id[c]] = c\n",
    "\n",
    "    y_train = np.array([cls_to_id[c] for c in df_train[\"class\"].tolist()], dtype=np.int64)\n",
    "    y_test  = np.array([cls_to_id[c] for c in df_test[\"class\"].tolist()], dtype=np.int64)\n",
    "\n",
    "    df_train = df_train.assign(label_id=y_train)\n",
    "    df_test  = df_test.assign(label_id=y_test)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, id_to_class, df_train, df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4bf93-096c-43ef-868e-fba7eb4597b5",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7304a-acd4-4803-87cc-4e9fc3d99260",
   "metadata": {},
   "source": [
    "# Calling combined feature for Reverb Chinese Baby cry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3003aa-a757-4009-9b66-2a466657a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from feature_fusion import prepare_train_test\n",
    "\n",
    "# f0_conf_wave_train_dir_reverbChinese = \"Chinese Babycry/Reverb_Train_Split_80_f0_wave_conf_arrays\"\n",
    "# f0_conf_wave_test_dir_reverbChinese  = \"Chinese Babycry/Reverb_Test_Split_20_f0_wave_conf_arrays\"\n",
    "\n",
    "# audio_train_dir_reverbChinese        = \"Chinese Babycry/Reverb_Train_Split_80\"\n",
    "# audio_test_dir_reverbChinese         = \"Chinese Babycry/Reverb_Test_Split_20\"\n",
    "\n",
    "# X_train_reverbChinese, y_train_reverbChinese, X_test_reverbChinese, y_test_reverbChinese, id2cls_reverbChinese, train_manifest_reverbChinese, test_manifest_reverbChinese = prepare_train_test(\n",
    "#     f0_conf_wave_train_dir=f0_conf_wave_train_dir_reverbChinese,\n",
    "#     f0_conf_wave_test_dir=f0_conf_wave_test_dir_reverbChinese,\n",
    "#     audio_train_dir=audio_train_dir_reverbChinese,\n",
    "#     audio_test_dir=audio_test_dir_reverbChinese,\n",
    "#     sr=16000,\n",
    "#     frame_ms=30.0,\n",
    "#     hop_ms=15.0,\n",
    "#     n_mfcc=20,\n",
    "#     modalities=(\"stft\", \"mfcc\", \"f0\"),   # choose any subset e.g. (\"mfcc\",\"f0\")\n",
    "#     fixed_target_len=100, \n",
    "#     target_len_policy=\"median\",           # or \"max\"\n",
    "#     strict_triplet=True,                  # require all requested modalities per sample\n",
    "# )\n",
    "\n",
    "# print(\"X_train_reverbChinese:\", X_train_reverbChinese.shape, \"X_test_reverbChinese:\", X_test_reverbChinese.shape)\n",
    "# print(\"y_train_reverbChinese:\", y_train_reverbChinese.shape, \"y_test_reverbChinese:\", y_test_reverbChinese.shape)\n",
    "# print(\"Classes_reverbChinese:\", id2cls_reverbChinese)\n",
    "# display(train_manifest_reverbChinese.head())\n",
    "# display(test_manifest_reverbChinese.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510b72c-5c1b-407a-9a37-a717b38a1e67",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbc0fa-04ca-4408-97ab-75c4b2af28c5",
   "metadata": {},
   "source": [
    "# Also do the same  the same for chinese baby cry without reverbration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7830562-d091-4ebb-ab8e-f37fca4464e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_chinese: (734, 100, 280) X_test_cinese: (184, 100, 280)\n",
      "y_train_chinese: (734,) y_test_chinese: (184,)\n",
      "Classes_chinese: {0: 'awake', 1: 'diaper', 2: 'hug', 3: 'hungry', 4: 'sleepy', 5: 'uncomfortable'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_0</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_0.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_100</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_100...</td>\n",
       "      <td>100</td>\n",
       "      <td>1039</td>\n",
       "      <td>1039</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_101</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_101...</td>\n",
       "      <td>100</td>\n",
       "      <td>1713</td>\n",
       "      <td>1713</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_102</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_102...</td>\n",
       "      <td>100</td>\n",
       "      <td>1148</td>\n",
       "      <td>1148</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_103</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/awak...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/awake/awake_103...</td>\n",
       "      <td>100</td>\n",
       "      <td>1048</td>\n",
       "      <td>1048</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       stem                                            f0_path  \\\n",
       "0  awake    awake_0  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "1  awake  awake_100  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "2  awake  awake_101  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "3  awake  awake_102  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "4  awake  awake_103  Chinese Babycry/Chinese baby cry train_f0/awak...   \n",
       "\n",
       "                                          audio_path  T_final  T_stft  T_mfcc  \\\n",
       "0   Chinese Babycry/Train_Split_80/awake/awake_0.wav      100    1051    1051   \n",
       "1  Chinese Babycry/Train_Split_80/awake/awake_100...      100    1039    1039   \n",
       "2  Chinese Babycry/Train_Split_80/awake/awake_101...      100    1713    1713   \n",
       "3  Chinese Babycry/Train_Split_80/awake/awake_102...      100    1148    1148   \n",
       "4  Chinese Babycry/Train_Split_80/awake/awake_103...      100    1048    1048   \n",
       "\n",
       "   T_f0  label_id  \n",
       "0    79         0  \n",
       "1    78         0  \n",
       "2   129         0  \n",
       "3    87         0  \n",
       "4    79         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_110</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_110.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_113</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_113.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_116</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_116.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1074</td>\n",
       "      <td>1074</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_117</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_117.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1039</td>\n",
       "      <td>1039</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_131</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry test_f0/awake...</td>\n",
       "      <td>Chinese Babycry/Test_Split_20/awake/awake_131.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>1168</td>\n",
       "      <td>1168</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class       stem                                            f0_path  \\\n",
       "0  awake  awake_110  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "1  awake  awake_113  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "2  awake  awake_116  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "3  awake  awake_117  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "4  awake  awake_131  Chinese Babycry/Chinese baby cry test_f0/awake...   \n",
       "\n",
       "                                          audio_path  T_final  T_stft  T_mfcc  \\\n",
       "0  Chinese Babycry/Test_Split_20/awake/awake_110.wav      100    1292    1292   \n",
       "1  Chinese Babycry/Test_Split_20/awake/awake_113.wav      100    1112    1112   \n",
       "2  Chinese Babycry/Test_Split_20/awake/awake_116.wav      100    1074    1074   \n",
       "3  Chinese Babycry/Test_Split_20/awake/awake_117.wav      100    1039    1039   \n",
       "4  Chinese Babycry/Test_Split_20/awake/awake_131.wav      100    1168    1168   \n",
       "\n",
       "   T_f0  label_id  \n",
       "0    97         0  \n",
       "1    84         0  \n",
       "2    81         0  \n",
       "3    78         0  \n",
       "4    88         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from feature_fusion import prepare_train_test\n",
    "\n",
    "f0_conf_wave_train_chinese_dir = \"Chinese Babycry/Chinese baby cry train_f0\"\n",
    "f0_conf_wave_test_chinese_dir  = \"Chinese Babycry/Chinese baby cry test_f0\"\n",
    "\n",
    "audio_train_dir_chinese        = \"Chinese Babycry/Train_Split_80\"\n",
    "audio_test_dir_chinese         = \"Chinese Babycry/Test_Split_20\"\n",
    "\n",
    "X_train_chinese, y_train_chinese, X_test_chinese, y_test_chinese, id2cls_chinese, train_manifest_chinese, test_manifest_chinese = prepare_train_test(\n",
    "    f0_conf_wave_train_dir=f0_conf_wave_train_chinese_dir,\n",
    "    f0_conf_wave_test_dir=f0_conf_wave_test_chinese_dir,\n",
    "    audio_train_dir=audio_train_dir_chinese,\n",
    "    audio_test_dir=audio_test_dir_chinese,\n",
    "    sr=16000,\n",
    "    frame_ms=30.0,\n",
    "    hop_ms=15.0,\n",
    "    n_mfcc=20,\n",
    "    modalities=(\"stft\", \"mfcc\", \"f0\"),   # choose any subset e.g. (\"mfcc\",\"f0\")\n",
    "    fixed_target_len=100, \n",
    "    target_len_policy=\"median\",           # or \"max\"\n",
    "    strict_triplet=True,                  # require all requested modalities per sample\n",
    ")\n",
    "\n",
    "print(\"X_train_chinese:\", X_train_chinese.shape, \"X_test_cinese:\", X_test_chinese.shape)\n",
    "print(\"y_train_chinese:\", y_train_chinese.shape, \"y_test_chinese:\", y_test_chinese.shape)\n",
    "print(\"Classes_chinese:\", id2cls_chinese)\n",
    "display(train_manifest_chinese.head())\n",
    "display(test_manifest_chinese.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea4def-2513-4d15-9f32-591b3787bda1",
   "metadata": {},
   "source": [
    "# Filter on 3 mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378fb058-257f-4305-8c2c-45deebe9a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 'Diaper', 1: 'Sleepy', 2: 'Uncomfortable'}\n",
      "Train shape: (350, 100, 280, 1)  Val shape: (88, 100, 280, 1)\n",
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Classes of interest\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"Diaper\", 4: \"Sleepy\", 5: \"Uncomfortable\"}\n",
    "\n",
    "# --- Train filtering ---\n",
    "mask_train = np.isin(y_train_chinese, keep_classes)\n",
    "X_train_split = X_train_chinese[mask_train]\n",
    "y_train_split = y_train_chinese[mask_train]\n",
    "\n",
    "# --- Test filtering ---\n",
    "mask_test = np.isin(y_test_chinese, keep_classes)\n",
    "X_val_split = X_test_chinese[mask_test]\n",
    "y_val_split = y_test_chinese[mask_test]\n",
    "\n",
    "# --- Re-encode labels to [0,1,2] ---\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "y_train_Chinese_3mood = np.array([class2newid[y] for y in y_train_split])\n",
    "y_test_Chinese_3mood = np.array([class2newid[y] for y in y_val_split])\n",
    "\n",
    "# --- Add channel dimension ---\n",
    "X_train_Chinese_3mood = np.expand_dims(X_train_split, axis=-1)\n",
    "X_test_Chinese_3mood = np.expand_dims(X_val_split, axis=-1)\n",
    "\n",
    "print(\"Class mapping:\", id2cls_merge_3mood)\n",
    "print(\"Train shape:\", X_train_Chinese_3mood.shape, \" Val shape:\", X_test_Chinese_3mood.shape)\n",
    "print(\"Unique encoded y:\", np.unique(y_train_Chinese_3mood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c644e00-2826-4847-95b4-05924b90bf61",
   "metadata": {},
   "source": [
    "# Run this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e27351-31a9-467a-a580-f81c16c049e2",
   "metadata": {},
   "source": [
    "# make a merged version of chinese baby cry reverb and not reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e751b897-528a-4d82-9574-ab9e89b2519d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id2cls_chinese' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3855625/3622694484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 0) (Fix a small print bug from your snippet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classes_chinese:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2cls_chinese\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1) Sanity checks: same (T, F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id2cls_chinese' is not defined"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # 0) (Fix a small print bug from your snippet)\n",
    "# print(\"Classes_chinese:\", id2cls_chinese)\n",
    "\n",
    "# # 1) Sanity checks: same (T, F)\n",
    "# assert X_train_reverbChinese.shape[1:] == X_train_chinese.shape[1:], \\\n",
    "#     f\"Train shape mismatch: {X_train_reverbChinese.shape[1:]} vs {X_train_chinese.shape[1:]}\"\n",
    "# assert X_test_reverbChinese.shape[1:] == X_test_chinese.shape[1:], \\\n",
    "#     f\"Test shape mismatch:  {X_test_reverbChinese.shape[1:]} vs {X_test_chinese.shape[1:]}\"\n",
    "\n",
    "# # 2) Build a unified label space using class NAMES (safer than reusing ints)\n",
    "# all_classes = sorted(set(id2cls_reverbChinese.values()) | set(id2cls_chinese.values()))\n",
    "# cls2new = {c: i for i, c in enumerate(all_classes)}\n",
    "# id2cls_merged = {i: c for c, i in cls2new.items()}  # inverse mapping\n",
    "\n",
    "# def remap_labels(y_old: np.ndarray, id2cls: dict, cls2new: dict) -> np.ndarray:\n",
    "#     \"\"\"Map old integer IDs -> class names -> new integer IDs.\"\"\"\n",
    "#     return np.array([cls2new[id2cls[int(k)]] for k in y_old], dtype=np.int64)\n",
    "\n",
    "# y_train_reverb_m = remap_labels(y_train_reverbChinese, id2cls_reverbChinese, cls2new)\n",
    "# y_test_reverb_m  = remap_labels(y_test_reverbChinese,  id2cls_reverbChinese, cls2new)\n",
    "# y_train_chinese_m = remap_labels(y_train_chinese, id2cls_chinese, cls2new)\n",
    "# y_test_chinese_m  = remap_labels(y_test_chinese,  id2cls_chinese, cls2new)\n",
    "\n",
    "# # 3) Concatenate per split\n",
    "# X_train_merged = np.concatenate([X_train_reverbChinese, X_train_chinese], axis=0)\n",
    "# y_train_merged = np.concatenate([y_train_reverb_m,     y_train_chinese_m], axis=0)\n",
    "\n",
    "# X_test_merged  = np.concatenate([X_test_reverbChinese, X_test_chinese], axis=0)\n",
    "# y_test_merged  = np.concatenate([y_test_reverb_m,      y_test_chinese_m], axis=0)\n",
    "\n",
    "# # 4) (Optional) shuffle train\n",
    "# X_train_merged, y_train_merged = shuffle(X_train_merged, y_train_merged, random_state=42)\n",
    "\n",
    "# # 5) Merge manifests (keep origin + new label ids)\n",
    "# train_manifest_reverbChinese = train_manifest_reverbChinese.copy()\n",
    "# train_manifest_chinese       = train_manifest_chinese.copy()\n",
    "# test_manifest_reverbChinese  = test_manifest_reverbChinese.copy()\n",
    "# test_manifest_chinese        = test_manifest_chinese.copy()\n",
    "\n",
    "# train_manifest_reverbChinese[\"dataset\"] = \"reverbChinese\"\n",
    "# train_manifest_chinese[\"dataset\"]       = \"chinese\"\n",
    "# test_manifest_reverbChinese[\"dataset\"]  = \"reverbChinese\"\n",
    "# test_manifest_chinese[\"dataset\"]        = \"chinese\"\n",
    "\n",
    "# train_manifest_reverbChinese[\"label_id_merged\"] = y_train_reverb_m\n",
    "# train_manifest_chinese[\"label_id_merged\"]       = y_train_chinese_m\n",
    "# test_manifest_reverbChinese[\"label_id_merged\"]  = y_test_reverb_m\n",
    "# test_manifest_chinese[\"label_id_merged\"]        = y_test_chinese_m\n",
    "\n",
    "# train_manifest_merged = pd.concat(\n",
    "#     [train_manifest_reverbChinese, train_manifest_chinese], ignore_index=True\n",
    "# )\n",
    "# test_manifest_merged = pd.concat(\n",
    "#     [test_manifest_reverbChinese, test_manifest_chinese], ignore_index=True\n",
    "# )\n",
    "\n",
    "# print(\"X_train_merged:\", X_train_merged.shape, \"X_test_merged:\", X_test_merged.shape)\n",
    "# print(\"y_train_merged:\", y_train_merged.shape, \"y_test_merged:\", y_test_merged.shape)\n",
    "# print(\"Classes (merged):\", id2cls_merged)\n",
    "\n",
    "# # 6) (Optional) Save to disk\n",
    "# np.savez_compressed(\"Chinese_combined_train.npz\", X=X_train_merged, y=y_train_merged)\n",
    "# np.savez_compressed(\"Chinese_combined_test.npz\",  X=X_test_merged,  y=y_test_merged)\n",
    "# train_manifest_merged.to_csv(\"Chinese_combined_train_manifest.csv\", index=False)\n",
    "# test_manifest_merged.to_csv(\"Chinese_combined_test_manifest.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e01915-60a6-4607-be0b-1b37aac49b6f",
   "metadata": {},
   "source": [
    "# Also do the same (Test & Train) for baby 2020 M0 to 3 or 9 ans merge months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e696df81-826c-46da-b713-2091d409bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _remap_labels(y_old: np.ndarray, id2cls: dict, global_cls2id: dict) -> np.ndarray:\n",
    "    return np.array([global_cls2id[id2cls[int(k)]] for k in y_old], dtype=np.int64)\n",
    "\n",
    "def _append_month_feature(X, month_idx, n_months, mode=\"onehot\"):\n",
    "    \"\"\"\n",
    "    Append month info to X along feature dim.\n",
    "    mode=\"onehot\" -> +n_months features; mode=\"index\" -> +1 feature in [0,1].\n",
    "    \"\"\"\n",
    "    N, T, F = X.shape\n",
    "    month_idx = np.asarray(month_idx, dtype=int)\n",
    "    if mode == \"onehot\":\n",
    "        X_out = np.empty((N, T, F + n_months), dtype=np.float32)\n",
    "        X_out[..., :F] = X\n",
    "        for i in range(N):\n",
    "            one = np.zeros((T, n_months), dtype=np.float32)\n",
    "            one[:, month_idx[i]] = 1.0\n",
    "            X_out[i, :, F:] = one\n",
    "        return X_out\n",
    "    elif mode == \"index\":\n",
    "        denom = max(1, n_months - 1)\n",
    "        X_out = np.empty((N, T, F + 1), dtype=np.float32)\n",
    "        X_out[..., :F] = X\n",
    "        for i in range(N):\n",
    "            X_out[i, :, F:] = float(month_idx[i]) / denom\n",
    "        return X_out\n",
    "    else:\n",
    "        return X  # no change\n",
    "\n",
    "def load_all_months_train(\n",
    "    base_path: str,\n",
    "    *,\n",
    "    months=(\"0Month\",\"1Month\",\"2Month\",\"3Month\",\"4Month\",\"5Month\",\"6Month\",\"7Month\",\"8Month\",\"9Month\"),\n",
    "    f0_root_subdir=\"Baby2020/Baby2020_f0_wave_conf_arrays\",   # sits inside base_path\n",
    "    audio_month_subdir=\"\",                           # usually empty: classes live directly under each month\n",
    "    sr=16000, frame_ms=30.0, hop_ms=15.0, n_mfcc=20,\n",
    "    modalities=(\"stft\",\"mfcc\",\"f0\"),\n",
    "    fixed_target_len=100, target_len_policy=\"median\", strict_triplet=True,\n",
    "    label_from: Literal[\"class\",\"month\"] = \"class\",\n",
    "    month_feature_mode: Literal[\"onehot\",\"index\",None] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build ONE big training set from month folders only (no test split).\n",
    "\n",
    "    Returns:\n",
    "      X_all (N, T, F[+month_feat]), y_all (N,),\n",
    "      id2cls_all (dict), df_all (manifest with month_folder), months_used (list)\n",
    "    \"\"\"\n",
    "    base = Path(base_path)\n",
    "\n",
    "    # lists to collect month-wise outputs\n",
    "    X_list, y_list = [], []\n",
    "    df_list = []\n",
    "    id2cls_per_month = []\n",
    "    class_name_set = set()\n",
    "    months_used = []\n",
    "    month_idx_list = []\n",
    "\n",
    "    # Load each month by calling your existing build_split()\n",
    "    for mi, m in enumerate(months):\n",
    "        audio_dir = base / m / audio_month_subdir\n",
    "        f0_dir    = base / f0_root_subdir / m\n",
    "\n",
    "        if not (audio_dir.exists() and f0_dir.exists()):\n",
    "            print(f\"[WARN] Skipping {m}: missing {audio_dir} or {f0_dir}\")\n",
    "            continue\n",
    "\n",
    "        # build_split expects directories with CLASS subfolders inside\n",
    "        X_m, y_m, df_m = build_split(\n",
    "            f0_dir=str(f0_dir),\n",
    "            audio_dir=str(audio_dir),\n",
    "            sr=sr, frame_ms=frame_ms, hop_ms=hop_ms, n_mfcc=n_mfcc,\n",
    "            stft_power=1.0, stft_to_db=True,\n",
    "            fixed_target_len=fixed_target_len,\n",
    "            target_len_policy=target_len_policy,\n",
    "            modalities=modalities,\n",
    "            strict_triplet=strict_triplet,\n",
    "        )\n",
    "\n",
    "        # Add month info to manifest\n",
    "        df_m = df_m.copy()\n",
    "        df_m[\"month_folder\"] = m\n",
    "        df_list.append(df_m)\n",
    "\n",
    "        # Record id2cls for this month (class mapping from build_split)\n",
    "        # and collect class names for global map\n",
    "        # If label_from=\"month\", we'll override later anyway.\n",
    "        local_classes = sorted(pd.unique(df_m[\"class\"]))\n",
    "        id2cls_m = {i: c for i, c in enumerate(local_classes)}\n",
    "        id2cls_per_month.append(id2cls_m)\n",
    "        class_name_set.update(local_classes)\n",
    "\n",
    "        X_list.append(X_m)\n",
    "        y_list.append(y_m)\n",
    "        months_used.append(m)\n",
    "        month_idx_list.append(np.full(len(y_m), mi, dtype=int))\n",
    "\n",
    "        print(f\"[OK] {m}: {X_m.shape[0]} samples, X shape {X_m.shape}\")\n",
    "        \n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"No months loaded. Check base_path and folder names.\")\n",
    "\n",
    "    # Merge across months\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    month_idx = np.concatenate(month_idx_list, axis=0)\n",
    "\n",
    "    if label_from == \"class\":\n",
    "        # Build global class mapping and remap y from each month\n",
    "        all_classes = sorted(class_name_set)\n",
    "        cls2gid = {c:i for i,c in enumerate(all_classes)}\n",
    "        id2cls_all = {i:c for c,i in cls2gid.items()}\n",
    "        y_all = np.concatenate([\n",
    "            _remap_labels(y_m, id2cls_m, cls2gid) for y_m, id2cls_m in zip(y_list, id2cls_per_month)\n",
    "        ], axis=0)\n",
    "        df_all[\"label_id\"] = y_all\n",
    "    else:\n",
    "        # Label is the month itself (0..len(months_used)-1)\n",
    "        month2id = {m:i for i,m in enumerate(months_used)}\n",
    "        y_all = np.array([month2id[m] for m in df_all[\"month_folder\"]], dtype=np.int64)\n",
    "        id2cls_all = {i:m for m,i in month2id.items()}\n",
    "        df_all[\"label_id\"] = y_all\n",
    "\n",
    "    # Optional: append month feature to X\n",
    "    if month_feature_mode in (\"onehot\",\"index\"):\n",
    "        X_all = _append_month_feature(X_all, month_idx, n_months=len(months_used), mode=month_feature_mode)\n",
    "\n",
    "    return X_all, y_all, id2cls_all, df_all, months_used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30d1aa04-7761-4d71-8951-84c26c6cab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 0Month: 500 samples, X shape (500, 100, 277)\n",
      "[OK] 1Month: 550 samples, X shape (550, 100, 277)\n",
      "[OK] 2Month: 1070 samples, X shape (1070, 100, 277)\n",
      "[OK] 3Month: 1340 samples, X shape (1340, 100, 277)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=512 is too large for input signal of length=288\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 4Month: 1709 samples, X shape (1709, 100, 277)\n",
      "[OK] 5Month: 1650 samples, X shape (1650, 100, 277)\n",
      "[OK] 6Month: 1010 samples, X shape (1010, 100, 277)\n",
      "[OK] 7Month: 320 samples, X shape (320, 100, 277)\n",
      "[OK] 8Month: 399 samples, X shape (399, 100, 277)\n",
      "[OK] 9Month: 850 samples, X shape (850, 100, 277)\n",
      "Months loaded: ['0Month', '1Month', '2Month', '3Month', '4Month', '5Month', '6Month', '7Month', '8Month', '9Month']\n",
      "X_all: (9398, 100, 277) y_all: (9398,)\n",
      "Classes: {0: 'Hungry', 1: 'NeedHug', 2: 'Sleepy', 3: 'Temper', 4: 'UnComfy', 5: 'Uncomfy', 6: 'Wakeup'}\n",
      "    class month_folder  label_id\n",
      "0  Hungry       0Month         0\n",
      "1  Hungry       0Month         0\n",
      "2  Hungry       0Month         0\n",
      "3  Hungry       0Month         0\n",
      "4  Hungry       0Month         0\n"
     ]
    }
   ],
   "source": [
    "base = r\"Baby2020/\"  # <- use your real absolute path\n",
    "\n",
    "X_all, y_all, id2cls_all, df_all, months_used = load_all_months_train(\n",
    "    base_path=base,\n",
    "    months=(\"0Month\",\"1Month\",\"2Month\",\"3Month\",\"4Month\",\"5Month\",\"6Month\",\"7Month\",\"8Month\",\"9Month\"),\n",
    "    f0_root_subdir=\"Baby2020_f0_wave_conf_arrays\",  # under base, contains 0Month..6Month\n",
    "    audio_month_subdir=\"\",                          # classes live directly under each month folder\n",
    "    # features\n",
    "    modalities=(\"stft\",\"mfcc\",\"f0\"),\n",
    "    fixed_target_len=100,\n",
    "    # labels: choose \"class\" (default) or \"month\"\n",
    "    label_from=\"class\",\n",
    "    # optionally append month to X as features:\n",
    "    month_feature_mode=None,   # or \"onehot\" / \"index\"\n",
    ")\n",
    "\n",
    "print(\"Months loaded:\", months_used)\n",
    "print(\"X_all:\", X_all.shape, \"y_all:\", y_all.shape)\n",
    "print(\"Classes:\", id2cls_all)\n",
    "print(df_all[[\"class\",\"month_folder\",\"label_id\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5140281-547e-4165-9c02-346588807727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9398, 100, 277)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a14fd0c-7d04-4f26-9f99-bfb5bbb265db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.1945999e+01, -5.0404358e+01, -4.9002388e+01, ...,\n",
       "         -5.0539637e+00, -6.4985104e+00, -5.9833121e+00],\n",
       "        [-5.6915745e+01, -5.4696762e+01, -5.0768116e+01, ...,\n",
       "          2.2816479e+01,  6.9606261e+00,  2.1816986e-02],\n",
       "        [-6.3433399e+01, -5.6649033e+01, -4.4152809e+01, ...,\n",
       "         -3.3187748e+01, -2.8779354e+01, -5.0742168e+00],\n",
       "        ...,\n",
       "        [-6.4005219e+01, -5.1261467e+01, -4.3933140e+01, ...,\n",
       "          7.9711785e+00,  7.3752023e-02, -3.4291785e+00],\n",
       "        [-5.4690136e+01, -5.1790001e+01, -4.3621948e+01, ...,\n",
       "          8.6252174e+00, -1.5041940e+00, -5.5225554e+00],\n",
       "        [-5.1194679e+01, -6.1568497e+01, -4.0538029e+01, ...,\n",
       "          8.4409180e+00, -5.7916718e+00, -1.9484842e+00]],\n",
       "\n",
       "       [[-4.2535599e+01, -4.1338474e+01, -4.0294651e+01, ...,\n",
       "         -4.8910666e+00, -1.1067516e+01, -1.2657733e+01],\n",
       "        [-5.0429012e+01, -4.8760208e+01, -4.5538258e+01, ...,\n",
       "          1.4813020e+01,  5.0701842e+00, -7.7330880e+00],\n",
       "        [-5.0716618e+01, -4.7293198e+01, -4.0203789e+01, ...,\n",
       "         -1.1294737e+01, -2.6613415e+01, -4.9788487e-01],\n",
       "        ...,\n",
       "        [-4.8095097e+01, -4.3545494e+01, -4.2705608e+01, ...,\n",
       "          1.8408543e+01,  9.6502733e+00, -3.8958117e-01],\n",
       "        [-5.3124561e+01, -4.8255409e+01, -5.0072117e+01, ...,\n",
       "          7.2356610e+00, -3.3464525e+00, -9.0672741e+00],\n",
       "        [-4.7286022e+01, -3.8310947e+01, -3.7240074e+01, ...,\n",
       "          5.5399981e+00,  2.6389465e+00, -2.4315615e+00]],\n",
       "\n",
       "       [[-5.9483597e+01, -5.4592892e+01, -5.7223381e+01, ...,\n",
       "         -6.1496544e+00, -9.5571175e+00, -7.2116275e+00],\n",
       "        [-6.0749153e+01, -4.8834267e+01, -4.6676956e+01, ...,\n",
       "         -5.7020001e+00, -2.3287661e+01, -5.9552193e+00],\n",
       "        [-5.5360035e+01, -4.6987156e+01, -4.1385098e+01, ...,\n",
       "         -2.0679238e+00, -1.4506160e+01,  6.0070171e+00],\n",
       "        ...,\n",
       "        [-4.1914623e+01, -4.1935040e+01, -3.3679340e+01, ...,\n",
       "          3.1469436e+00, -1.2483286e+01, -1.7845064e+01],\n",
       "        [-3.6989067e+01, -4.8239502e+01, -2.8178555e+01, ...,\n",
       "          1.7175735e+01, -3.2063258e+00, -1.6429344e+01],\n",
       "        [-4.9989952e+01, -4.3909126e+01, -3.8223278e+01, ...,\n",
       "          2.1424616e+01,  2.2419807e+01, -3.3806744e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-6.7612114e+01, -6.3780689e+01, -6.0542057e+01, ...,\n",
       "         -3.4724324e+00, -5.2404034e-01, -2.9288292e-02],\n",
       "        [-7.1608086e+01, -5.7788010e+01, -4.9506119e+01, ...,\n",
       "         -3.4314406e+00, -2.9519153e-01,  1.0206763e+01],\n",
       "        [-4.0117290e+01, -4.0121601e+01, -4.4000145e+01, ...,\n",
       "         -6.6326437e+00,  2.2393990e+00,  1.4150950e+01],\n",
       "        ...,\n",
       "        [-4.2414734e+01, -4.5422489e+01, -5.0039131e+01, ...,\n",
       "          1.2059027e+01,  1.8216976e+01,  1.2279681e+01],\n",
       "        [-4.6453438e+01, -5.4166809e+01, -4.8785198e+01, ...,\n",
       "          7.7067308e+00,  1.5356925e+01,  8.0577755e+00],\n",
       "        [-4.8127510e+01, -5.1301537e+01, -6.3256474e+01, ...,\n",
       "          1.5303179e+01,  1.2302458e+01,  1.6535215e+00]],\n",
       "\n",
       "       [[-4.3037094e+01, -3.7587318e+01, -3.5704487e+01, ...,\n",
       "          1.5763831e+01, -1.0442580e+01,  8.2055140e+00],\n",
       "        [-4.8018078e+01, -2.9595776e+01, -3.1387712e+01, ...,\n",
       "          2.8101366e+01, -1.4212986e+00,  7.7469025e+00],\n",
       "        [-3.1957743e+01, -3.3426685e+01, -3.9381638e+01, ...,\n",
       "          5.1099396e+01,  1.9448488e+01,  2.5468990e+01],\n",
       "        ...,\n",
       "        [-4.7140812e+01, -4.3753643e+01, -4.5491035e+01, ...,\n",
       "         -6.6726112e-01,  4.9237709e+00,  1.9384903e+01],\n",
       "        [-5.1805714e+01, -5.4371532e+01, -4.0517601e+01, ...,\n",
       "         -1.7176284e+00, -4.8349957e+00,  1.3710614e+01],\n",
       "        [-4.0112656e+01, -4.2324120e+01, -5.5111656e+01, ...,\n",
       "         -1.5374980e+00,  1.5831485e+00, -3.3346176e+00]],\n",
       "\n",
       "       [[-5.2517704e+01, -4.7950089e+01, -4.4140038e+01, ...,\n",
       "         -8.0216322e+00, -3.2011666e+00,  6.0741339e+00],\n",
       "        [-3.9305332e+01, -4.0798157e+01, -5.7493294e+01, ...,\n",
       "          1.4819908e+01, -9.1425705e+00,  1.8599556e+01],\n",
       "        [-5.1471291e+01, -4.7628479e+01, -4.4979080e+01, ...,\n",
       "          1.1664302e+01, -1.1583115e+01,  9.4920340e+00],\n",
       "        ...,\n",
       "        [-3.4028316e+01, -3.7648914e+01, -3.6746033e+01, ...,\n",
       "          1.2796712e+01, -3.7830541e+00,  1.8454557e+01],\n",
       "        [-4.3762161e+01, -3.9333748e+01, -3.8654251e+01, ...,\n",
       "          5.1317482e+00,  6.5958734e+00,  1.7912313e+01],\n",
       "        [-3.3550289e+01, -3.4183075e+01, -3.6697456e+01, ...,\n",
       "          2.5562193e+00,  2.3361998e+00,  1.3608093e+01]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b909913c-9047-4732-aabb-a89a55c4edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "      <th>month_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_001</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_001.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_002</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_002.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_003</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_003.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_004</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_004.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hungry</td>\n",
       "      <td>Hungry00MB00007_2_005</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...</td>\n",
       "      <td>Baby2020/0Month/Hungry/Hungry00MB00007_2_005.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9393</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_004</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_004.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9394</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_005</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_005.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_006</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_006.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9396</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_007</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_007.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>Wakeup</td>\n",
       "      <td>Wakeup09MU00015_2_008</td>\n",
       "      <td>Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...</td>\n",
       "      <td>Baby2020/9Month/Wakeup/Wakeup09MU00015_2_008.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9Month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9398 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                   stem  \\\n",
       "0     Hungry  Hungry00MB00007_2_001   \n",
       "1     Hungry  Hungry00MB00007_2_002   \n",
       "2     Hungry  Hungry00MB00007_2_003   \n",
       "3     Hungry  Hungry00MB00007_2_004   \n",
       "4     Hungry  Hungry00MB00007_2_005   \n",
       "...      ...                    ...   \n",
       "9393  Wakeup  Wakeup09MU00015_2_004   \n",
       "9394  Wakeup  Wakeup09MU00015_2_005   \n",
       "9395  Wakeup  Wakeup09MU00015_2_006   \n",
       "9396  Wakeup  Wakeup09MU00015_2_007   \n",
       "9397  Wakeup  Wakeup09MU00015_2_008   \n",
       "\n",
       "                                                f0_path  \\\n",
       "0     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "1     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "2     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "3     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "4     Baby2020/Baby2020_f0_wave_conf_arrays/0Month/H...   \n",
       "...                                                 ...   \n",
       "9393  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9394  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9395  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9396  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "9397  Baby2020/Baby2020_f0_wave_conf_arrays/9Month/W...   \n",
       "\n",
       "                                            audio_path  T_final  T_stft  \\\n",
       "0     Baby2020/0Month/Hungry/Hungry00MB00007_2_001.wav      100     222   \n",
       "1     Baby2020/0Month/Hungry/Hungry00MB00007_2_002.wav      100     163   \n",
       "2     Baby2020/0Month/Hungry/Hungry00MB00007_2_003.wav      100     226   \n",
       "3     Baby2020/0Month/Hungry/Hungry00MB00007_2_004.wav      100     143   \n",
       "4     Baby2020/0Month/Hungry/Hungry00MB00007_2_005.wav      100     161   \n",
       "...                                                ...      ...     ...   \n",
       "9393  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_004.wav      100     132   \n",
       "9394  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_005.wav      100      91   \n",
       "9395  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_006.wav      100      96   \n",
       "9396  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_007.wav      100     123   \n",
       "9397  Baby2020/9Month/Wakeup/Wakeup09MU00015_2_008.wav      100     107   \n",
       "\n",
       "      T_mfcc  T_f0  label_id month_folder  \n",
       "0        222    17         0       0Month  \n",
       "1        163    13         0       0Month  \n",
       "2        226    17         0       0Month  \n",
       "3        143    11         0       0Month  \n",
       "4        161    13         0       0Month  \n",
       "...      ...   ...       ...          ...  \n",
       "9393     132    10         6       9Month  \n",
       "9394      91     7         6       9Month  \n",
       "9395      96     8         6       9Month  \n",
       "9396     123    10         6       9Month  \n",
       "9397     107     8         6       9Month  \n",
       "\n",
       "[9398 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb1377-a28a-4b49-a85b-6bba25eb3099",
   "metadata": {},
   "source": [
    "# Make a noneleakage selection randomly test train 20 80 for baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75ebddba-0665-470b-9c90-7eb90848322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def make_group_stratified_folds(\n",
    "    df_all: pd.DataFrame,\n",
    "    X_all: np.ndarray,\n",
    "    n_splits: int = 5,\n",
    "    group_from: str = \"audio_path\",\n",
    "    class_col: str = \"class\",\n",
    "    month_col: str = \"month_folder\",\n",
    "    selected_classes: list | None = None,\n",
    "    selected_months: list | None = None,\n",
    "    shuffle: bool = True,\n",
    "    random_state: int | None = None,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Leakage-safe, group-aware, stratified K-fold splits\n",
    "    with optional filtering and automatic label re-indexing.\n",
    "\n",
    "    IMPORTANT:\n",
    "    - Labels are re-indexed AFTER class/month selection\n",
    "      so they are contiguous: {0, 1, ..., K-1}\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(df_all) == len(X_all), \"df_all and X_all must be aligned\"\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 0. Optional filtering (NO leakage)\n",
    "    # --------------------------------------------------\n",
    "    mask = np.ones(len(df_all), dtype=bool)\n",
    "\n",
    "    if selected_classes is not None:\n",
    "        mask &= df_all[class_col].isin(selected_classes)\n",
    "\n",
    "    if selected_months is not None:\n",
    "        mask &= df_all[month_col].isin(selected_months)\n",
    "\n",
    "    df = df_all.loc[mask].copy().reset_index(drop=True)\n",
    "    X = X_all[mask]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nAfter filtering: {len(df)} samples\")\n",
    "        print(\"Class counts:\", df[class_col].value_counts().to_dict())\n",
    "        print(\"Month counts:\", df[month_col].value_counts().to_dict())\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Re-index labels AFTER selection (CRITICAL)\n",
    "    # --------------------------------------------------\n",
    "    unique_classes = sorted(df[class_col].unique())\n",
    "    class_to_label = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "    label_to_class = {i: cls for cls, i in class_to_label.items()}\n",
    "\n",
    "    df[\"label_id\"] = df[class_col].map(class_to_label)\n",
    "\n",
    "    num_classes = len(unique_classes)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nLabel re-indexing (used for training):\")\n",
    "        for cls, idx in class_to_label.items():\n",
    "            print(f\"  {cls} → {idx}\")\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Extract group_id (leakage-safe)\n",
    "    # --------------------------------------------------\n",
    "    df[\"group_id\"] = (\n",
    "        df[group_from]\n",
    "        .str.split(\"/\")\n",
    "        .str[-1]\n",
    "        .str.split(\"_\")\n",
    "        .str[0]\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Group-level dataframe for stratification\n",
    "    # --------------------------------------------------\n",
    "    group_df = (\n",
    "        df.groupby(\"group_id\")\n",
    "        .agg({\n",
    "            class_col: \"first\",\n",
    "            month_col: \"first\"\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    group_df[\"strata\"] = (\n",
    "        group_df[class_col].astype(str) + \"_\" +\n",
    "        group_df[month_col].astype(str)\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 4. Stratified K-fold on GROUPS\n",
    "    # --------------------------------------------------\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=shuffle,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 5. Build folds\n",
    "    # --------------------------------------------------\n",
    "    for fold_idx, (train_g_idx, test_g_idx) in enumerate(\n",
    "        skf.split(group_df[\"group_id\"], group_df[\"strata\"])\n",
    "    ):\n",
    "        train_group_ids = set(group_df.iloc[train_g_idx][\"group_id\"])\n",
    "        test_group_ids  = set(group_df.iloc[test_g_idx][\"group_id\"])\n",
    "\n",
    "        train_mask = df[\"group_id\"].isin(train_group_ids)\n",
    "        test_mask  = df[\"group_id\"].isin(test_group_ids)\n",
    "\n",
    "        X_train = X[train_mask.values]\n",
    "        X_test  = X[test_mask.values]\n",
    "\n",
    "        df_train = df.loc[train_mask].reset_index(drop=True)\n",
    "        df_test  = df.loc[test_mask].reset_index(drop=True)\n",
    "\n",
    "        # Sanity checks\n",
    "        assert train_group_ids.isdisjoint(test_group_ids)\n",
    "        assert len(X_train) + len(X_test) == len(X)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nFold {fold_idx}: \"\n",
    "                f\"train={len(X_train)} ({len(X_train)/len(X):.2%}), \"\n",
    "                f\"test={len(X_test)} ({len(X_test)/len(X):.2%})\"\n",
    "            )\n",
    "\n",
    "        folds.append({\n",
    "            \"fold\": fold_idx,\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"df_train\": df_train,\n",
    "            \"df_test\": df_test,\n",
    "            \"num_classes\": num_classes,\n",
    "            \"class_to_label\": class_to_label,\n",
    "            \"label_to_class\": label_to_class,\n",
    "            \"train_group_ids\": train_group_ids,\n",
    "            \"test_group_ids\": test_group_ids\n",
    "        })\n",
    "\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86554eee-22f6-4e32-b12e-df41e39192f7",
   "metadata": {},
   "source": [
    "# Reproduceable with random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62bc3a35-7b44-43e1-858f-4835b2519489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     shuffle=True,\n",
    "#     random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de68fa-2a96-4815-a650-4a2e05ebb152",
   "metadata": {},
   "source": [
    "## Random every run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "956535f2-41e7-4b7f-ba98-ca9ece732120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 9398 samples\n",
      "Classes: {'Hungry': 2000, 'Temper': 1600, 'Sleepy': 1599, 'NeedHug': 1500, 'Wakeup': 1300, 'UnComfy': 749, 'Uncomfy': 650}\n",
      "Months: {'4Month': 1709, '5Month': 1650, '3Month': 1340, '2Month': 1070, '6Month': 1010, '9Month': 850, '1Month': 550, '0Month': 500, '8Month': 399, '7Month': 320}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: train=7471 (79.50%), test=1927 (20.50%)\n",
      "Fold 1: train=7581 (80.67%), test=1817 (19.33%)\n",
      "Fold 2: train=7518 (80.00%), test=1880 (20.00%)\n",
      "Fold 3: train=7597 (80.84%), test=1801 (19.16%)\n",
      "Fold 4: train=7425 (79.01%), test=1973 (20.99%)\n"
     ]
    }
   ],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     shuffle=True,\n",
    "#     random_state=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb0e6f-b371-4f11-8107-6b9e0b756cba",
   "metadata": {},
   "source": [
    "## Only selected months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c195e1-8cc9-4757-b4a2-802990909e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = make_group_stratified_folds(\n",
    "#     df_all, X_all,\n",
    "#     n_splits=5,\n",
    "#     selected_months=[\"0Month\", \"9Month\"],\n",
    "#     random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b58ca-8e05-4e15-8055-31b5694c7457",
   "metadata": {},
   "source": [
    "# Selected months and selected moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4177e665-5686-4114-9042-f224e2c1f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering: 2190 samples\n",
      "Class counts: {'Hungry': 1000, 'Sleepy': 600, 'Wakeup': 590}\n",
      "Month counts: {'3Month': 750, '2Month': 700, '0Month': 400, '1Month': 340}\n",
      "\n",
      "Label re-indexing (used for training):\n",
      "  Hungry → 0\n",
      "  Sleepy → 1\n",
      "  Wakeup → 2\n",
      "\n",
      "Fold 0: train=1982 (90.50%), test=208 (9.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1: train=1989 (90.82%), test=201 (9.18%)\n",
      "\n",
      "Fold 2: train=1996 (91.14%), test=194 (8.86%)\n",
      "\n",
      "Fold 3: train=1987 (90.73%), test=203 (9.27%)\n",
      "\n",
      "Fold 4: train=2027 (92.56%), test=163 (7.44%)\n",
      "\n",
      "Fold 5: train=1871 (85.43%), test=319 (14.57%)\n",
      "\n",
      "Fold 6: train=1925 (87.90%), test=265 (12.10%)\n",
      "\n",
      "Fold 7: train=1964 (89.68%), test=226 (10.32%)\n",
      "\n",
      "Fold 8: train=1951 (89.09%), test=239 (10.91%)\n",
      "\n",
      "Fold 9: train=2018 (92.15%), test=172 (7.85%)\n"
     ]
    }
   ],
   "source": [
    "folds = make_group_stratified_folds(\n",
    "    df_all,\n",
    "    X_all,\n",
    "    n_splits=10,\n",
    "    selected_months=[\"0Month\", \"1Month\", \"2Month\", \"3Month\"],\n",
    "    selected_classes=[\"Sleepy\", \"Hungry\", \"Wakeup\"],\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d791d-1355-4162-a5bb-eeb3dc84a2a1",
   "metadata": {},
   "source": [
    "# Folds reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5734a56-764e-4dbf-b8d9-aa92ce2893cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FOLD 0\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.36\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=22, mean=7.70\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy03MB00008 Sleepy       3Month           22\n",
      "Sleepy03MB00031 Sleepy       3Month           22\n",
      "Wakeup01MB00001 Wakeup       1Month           18\n",
      "Sleepy01MB00005 Sleepy       1Month           15\n",
      "Hungry00MG00002 Hungry       0Month           12\n",
      "\n",
      "================================================================================\n",
      "FOLD 1\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.39\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=26, mean=7.44\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Hungry01MB00009 Hungry       1Month           26\n",
      "Hungry00MG00001 Hungry       0Month           20\n",
      "Hungry02MB00017 Hungry       2Month           17\n",
      "Sleepy01MB00003 Sleepy       1Month           17\n",
      "Hungry03MB00034 Hungry       3Month           13\n",
      "\n",
      "================================================================================\n",
      "FOLD 2\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.42\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=20, mean=7.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Hungry01MB00014 Hungry       1Month           20\n",
      "Hungry03MG00007 Hungry       3Month           20\n",
      "Hungry00MG00005 Hungry       0Month           18\n",
      "Hungry00MB00011 Hungry       0Month           17\n",
      "Hungry03MG00009 Hungry       3Month           15\n",
      "\n",
      "================================================================================\n",
      "FOLD 3\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 237\n",
      "Samples per ID: min=1, max=45, mean=8.38\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 27\n",
      "Samples per ID: min=1, max=34, mean=7.52\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Hungry00MG00006 Hungry       0Month           22\n",
      "Hungry03MG00006 Hungry       3Month           19\n",
      "Hungry00MU00016 Hungry       0Month           17\n",
      "Hungry03MG00005 Hungry       3Month           16\n",
      "\n",
      "================================================================================\n",
      "FOLD 4\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.52\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=32, mean=6.27\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup03MB00004 Wakeup       3Month           32\n",
      "Sleepy00MB00001 Sleepy       0Month           21\n",
      "Hungry01MB00010 Hungry       1Month           19\n",
      "Hungry02MB00016 Hungry       2Month           15\n",
      "Hungry00MB00007 Hungry       0Month           12\n",
      "\n",
      "================================================================================\n",
      "FOLD 5\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=7.86\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup03MB00004 Wakeup       3Month           32\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=40, mean=12.27\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Hungry01MB00013 Hungry       1Month           29\n",
      "Wakeup03MG00002 Wakeup       3Month           27\n",
      "Wakeup03MB00042 Wakeup       3Month           22\n",
      "\n",
      "================================================================================\n",
      "FOLD 6\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.09\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=34, mean=10.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup00MG00004 Wakeup       0Month           29\n",
      "Sleepy00MB00002 Sleepy       0Month           26\n",
      "Hungry01MB00016 Hungry       1Month           19\n",
      "Sleepy03MB00030 Sleepy       3Month           17\n",
      "\n",
      "================================================================================\n",
      "FOLD 7\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=40, mean=8.25\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=45, mean=8.69\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup02MG00002 Wakeup       2Month           22\n",
      "Sleepy03MG00001 Sleepy       3Month           15\n",
      "Hungry00MU00003 Hungry       0Month           12\n",
      "Sleepy01MB00004 Sleepy       1Month           11\n",
      "\n",
      "================================================================================\n",
      "FOLD 8\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.20\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Wakeup02MB00010 Wakeup       2Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=36, mean=9.19\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Hungry01MB00002 Hungry       1Month           25\n",
      "Wakeup03MG00001 Wakeup       3Month           24\n",
      "Hungry00MB00010 Hungry       0Month           23\n",
      "Sleepy01MG00001 Sleepy       1Month           22\n",
      "\n",
      "================================================================================\n",
      "FOLD 9\n",
      "================================================================================\n",
      "\n",
      "--- TRAIN SPLIT ---\n",
      "Number of unique IDs: 238\n",
      "Samples per ID: min=1, max=45, mean=8.48\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Wakeup00MG00003 Wakeup       0Month           45\n",
      "Wakeup00MG00005 Wakeup       0Month           40\n",
      "Wakeup00MG00002 Wakeup       0Month           36\n",
      "Wakeup02MB00005 Wakeup       2Month           34\n",
      "Sleepy03MB00011 Sleepy       3Month           34\n",
      "\n",
      "--- TEST SPLIT ---\n",
      "Number of unique IDs: 26\n",
      "Samples per ID: min=1, max=20, mean=6.62\n",
      "\n",
      "Top 5 IDs with most samples:\n",
      "       group_id  class month_folder  num_samples\n",
      "Sleepy01MB00006 Sleepy       1Month           20\n",
      "Wakeup02MU00015 Wakeup       2Month           14\n",
      "Sleepy02MG00003 Sleepy       2Month           12\n",
      "Sleepy03MB00034 Sleepy       3Month           12\n",
      "Hungry00MG00004 Hungry       0Month           12\n"
     ]
    }
   ],
   "source": [
    "def print_group_statistics(folds, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Print statistics of number of samples per (group_id, class, month)\n",
    "    for each fold, separately for train and test.\n",
    "    \"\"\"\n",
    "\n",
    "    for f in folds:\n",
    "        fold_id = f[\"fold\"]\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"FOLD {fold_id}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for split_name, df_split in [\n",
    "            (\"TRAIN\", f[\"df_train\"]),\n",
    "            (\"TEST\",  f[\"df_test\"])\n",
    "        ]:\n",
    "            print(f\"\\n--- {split_name} SPLIT ---\")\n",
    "\n",
    "            # Count samples per (group_id, class, month)\n",
    "            counts = (\n",
    "                df_split\n",
    "                .groupby([\"group_id\", \"class\", \"month_folder\"])\n",
    "                .size()\n",
    "                .reset_index(name=\"num_samples\")\n",
    "            )\n",
    "\n",
    "            # Summary statistics\n",
    "            print(f\"Number of unique IDs: {counts['group_id'].nunique()}\")\n",
    "            print(\n",
    "                \"Samples per ID: \"\n",
    "                f\"min={counts['num_samples'].min()}, \"\n",
    "                f\"max={counts['num_samples'].max()}, \"\n",
    "                f\"mean={counts['num_samples'].mean():.2f}\"\n",
    "            )\n",
    "\n",
    "            # Show largest groups\n",
    "            print(f\"\\nTop {top_k} IDs with most samples:\")\n",
    "            print(\n",
    "                counts\n",
    "                .sort_values(\"num_samples\", ascending=False)\n",
    "                .head(top_k)\n",
    "                .to_string(index=False)\n",
    "            )\n",
    "\n",
    "\n",
    "print_group_statistics(folds, top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48367afd-9a0d-46d8-a98d-7628456d5eb8",
   "metadata": {},
   "source": [
    "# Network Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2df4088d-e80f-4860-a335-fae695e281d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://artifacts.uottawa.ca/artifactory/api/pypi/python/simple\n",
      "Requirement already satisfied: tensorflow in /usr/lib/python3/dist-packages (2.19.0)\n",
      "Collecting tensorflow\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/e5/9e/0d57922cf46b9e91de636cd5b5e0d7a424ebe98f3245380a713f1f6c2a0b/tensorflow-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.4/620.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.30.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.1.0)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting tensorboard~=2.20.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/9c/d9/a5db55f88f258ac669a92858b70a714bbbd5acd993820b41ec4a96a4d77f/tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.5.1)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/b1/45/e1a754dc7cd465ba35e438e28557119221ac89b20aaebef48282654e3dc7/h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=3.6.6 in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/a3/61/8001b38461d751cd1a0c3a6ae84346796a5758123f3ed97a1b121dfbf4f3/gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting protobuf>=5.28.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/40/01/2e730bd1c25392fc32e3268e02446f0d77cb51a2c3a8486b1798e34d5805/protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/lib/python3/dist-packages (from tensorflow) (3.10.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading https://artifacts.uottawa.ca/artifactory/api/pypi/python/packages/packages/fd/75/a1991dd64b331d199935e096cc9daa3415ee5ccbe9f909aa48eded7bba34/grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: pillow in /home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Installing collected packages: libclang, flatbuffers, tensorboard-data-server, protobuf, h5py, grpcio, gast, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/uottawa.o.univ/njaza024/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/home/uottawa.o.univ/njaza024/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed flatbuffers-25.2.10 gast-0.6.0 grpcio-1.74.0 h5py-3.14.0 libclang-18.1.1 protobuf-6.32.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff92fab-ecb7-4602-9cdc-5e526bff9444",
   "metadata": {},
   "source": [
    "## Integrate with Cross-Fold or 5 random seed\n",
    "\n",
    "### and std and avg between all MCC F1 micro and macro score precision recall and specificity and sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c25b6f0-355c-43f2-919c-0e1c5d7dc472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1468, 100, 280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee78a11b-8d42-48e8-9b42-1cd73feb3168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>stem</th>\n",
       "      <th>f0_path</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>T_final</th>\n",
       "      <th>T_stft</th>\n",
       "      <th>T_mfcc</th>\n",
       "      <th>T_f0</th>\n",
       "      <th>label_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label_id_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_0_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1384</td>\n",
       "      <td>1384</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_100_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1373</td>\n",
       "      <td>1373</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_101_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>2047</td>\n",
       "      <td>2047</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_102_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1482</td>\n",
       "      <td>1482</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>awake</td>\n",
       "      <td>awake_103_filtered</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80_f0_wave_...</td>\n",
       "      <td>Chinese Babycry/Reverb_Train_Split_80/awake/aw...</td>\n",
       "      <td>100</td>\n",
       "      <td>1381</td>\n",
       "      <td>1381</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>reverbChinese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_95</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1066</td>\n",
       "      <td>1066</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_96</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1136</td>\n",
       "      <td>1136</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_97</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1058</td>\n",
       "      <td>1058</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_98</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_99</td>\n",
       "      <td>Chinese Babycry/Chinese baby cry train_f0/unco...</td>\n",
       "      <td>Chinese Babycry/Train_Split_80/uncomfortable/u...</td>\n",
       "      <td>100</td>\n",
       "      <td>1347</td>\n",
       "      <td>1347</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1468 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              class                stem  \\\n",
       "0             awake    awake_0_filtered   \n",
       "1             awake  awake_100_filtered   \n",
       "2             awake  awake_101_filtered   \n",
       "3             awake  awake_102_filtered   \n",
       "4             awake  awake_103_filtered   \n",
       "...             ...                 ...   \n",
       "1463  uncomfortable    uncomfortable_95   \n",
       "1464  uncomfortable    uncomfortable_96   \n",
       "1465  uncomfortable    uncomfortable_97   \n",
       "1466  uncomfortable    uncomfortable_98   \n",
       "1467  uncomfortable    uncomfortable_99   \n",
       "\n",
       "                                                f0_path  \\\n",
       "0     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "1     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "2     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "3     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "4     Chinese Babycry/Reverb_Train_Split_80_f0_wave_...   \n",
       "...                                                 ...   \n",
       "1463  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1464  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1465  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1466  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "1467  Chinese Babycry/Chinese baby cry train_f0/unco...   \n",
       "\n",
       "                                             audio_path  T_final  T_stft  \\\n",
       "0     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1384   \n",
       "1     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1373   \n",
       "2     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    2047   \n",
       "3     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1482   \n",
       "4     Chinese Babycry/Reverb_Train_Split_80/awake/aw...      100    1381   \n",
       "...                                                 ...      ...     ...   \n",
       "1463  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1066   \n",
       "1464  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1136   \n",
       "1465  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1058   \n",
       "1466  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1033   \n",
       "1467  Chinese Babycry/Train_Split_80/uncomfortable/u...      100    1347   \n",
       "\n",
       "      T_mfcc  T_f0  label_id        dataset  label_id_merged  \n",
       "0       1384   104         0  reverbChinese                0  \n",
       "1       1373   103         0  reverbChinese                0  \n",
       "2       2047   154         0  reverbChinese                0  \n",
       "3       1482   112         0  reverbChinese                0  \n",
       "4       1381   104         0  reverbChinese                0  \n",
       "...      ...   ...       ...            ...              ...  \n",
       "1463    1066    80         5        chinese                5  \n",
       "1464    1136    86         5        chinese                5  \n",
       "1465    1058    80         5        chinese                5  \n",
       "1466    1033    78         5        chinese                5  \n",
       "1467    1347   101         5        chinese                5  \n",
       "\n",
       "[1468 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_manifest_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d2120-9135-450a-a594-7caaf936e2f7",
   "metadata": {},
   "source": [
    "# Label verification encoded if I haven't used the fold noneleakage of baby2020 or working with nother dataset than baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b4b4dc8-7c22-4e62-8cca-080a2d4d07da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Every class maps to exactly one label_id_merged.\n",
      "✅ Every label_id_merged maps to exactly one class.\n",
      "Mapping looks good. Example: [('awake', 0), ('diaper', 1), ('hug', 2), ('hungry', 3), ('sleepy', 4)]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # df = train_manifest_merged.copy()\n",
    "# df = train_manifest_chinese.copy()\n",
    "\n",
    "# # If X_train_chinese is ndarray and you have y_train_chinese separately:\n",
    "# # df = pd.DataFrame({\n",
    "# #     \"class\": X_train_chinese,     # supply your class column\n",
    "# #     \"label_id_merged\": y_train_chinese  # supply your label column\n",
    "# # })\n",
    "\n",
    "\n",
    "# # Handle possible typo\n",
    "# label_col = \"label_id_merged\" if \"label_id_merged\" in df.columns else \"labe_id_merged\"\n",
    "# assert label_col in df.columns, f\"Column '{label_col}' not found.\"\n",
    "\n",
    "# # Use only unique (class, label) pairs\n",
    "# pairs = df[[\"class\", label_col]].drop_duplicates()\n",
    "\n",
    "# # 1) class -> label is unique?\n",
    "# class_to_n = pairs.groupby(\"class\")[label_col].nunique()\n",
    "# bad_classes = class_to_n[class_to_n != 1]\n",
    "\n",
    "# # 2) label -> class is unique? (optional but recommended)\n",
    "# label_to_n = pairs.groupby(label_col)[\"class\"].nunique()\n",
    "# bad_labels = label_to_n[label_to_n != 1]\n",
    "\n",
    "# if bad_classes.empty:\n",
    "#     print(\"✅ Every class maps to exactly one label_id_merged.\")\n",
    "# else:\n",
    "#     print(\"❌ Some classes map to multiple label_id_merged values:\")\n",
    "#     print(bad_classes.sort_values(ascending=False))\n",
    "\n",
    "# if bad_labels.empty:\n",
    "#     print(\"✅ Every label_id_merged maps to exactly one class.\")\n",
    "# else:\n",
    "#     print(\"❌ Some label_id_merged values are shared by multiple classes:\")\n",
    "#     print(bad_labels.sort_values(ascending=False))\n",
    "\n",
    "# # If everything is 1–1, this is the mapping dict (class -> label_id_merged):\n",
    "# if bad_classes.empty and bad_labels.empty:\n",
    "#     class_to_label = pairs.set_index(\"class\")[label_col].to_dict()\n",
    "#     print(\"Mapping looks good. Example:\", list(class_to_label.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd48279-9d46-4004-ad19-b7339d0722b7",
   "metadata": {},
   "source": [
    "# Test Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a9801-63c6-44cb-b4be-a4f516085a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chinese, y_train_chinese, X_test_chinese, y_test_chinese, id2cls_chinese, train_manifest_chinese, test_manifest_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e482b14a-461e-4fa1-8c87-acb5ba4cc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = X_train_merged\n",
    "# # y_train = y_train_merged\n",
    "# # X_test = X_test_merged\n",
    "# # y_test = y_test_merged\n",
    "\n",
    "X_train = X_train_Chinese_3mood\n",
    "y_train = y_train_Chinese_3mood\n",
    "X_test = X_test_Chinese_3mood\n",
    "y_test = y_test_Chinese_3mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c90c533a-447b-46c6-a97b-4e8074251382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 100, 280, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad333270-f6a0-4ece-848c-5f70ff1d3e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f40e59-9925-4a2d-9d2b-553987d2dfe7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad961b34-fb47-4cb0-ae2b-f1aa2ca38f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"best_Chinese_baby20202_merged.keras\"\n",
    "history_name = 'history_Chinese_baby20202_merged.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb09a28-7eb6-43bf-bfad-681463290289",
   "metadata": {},
   "source": [
    "# IF there is no folding strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c404ad-0a65-47c4-a841-8dd1b1bf34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and validation sets (80% training, 20% validation, change as needed)  \n",
    "\n",
    "# # X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train) \n",
    "\n",
    "# X_train_split = X_train\n",
    "# X_val_split = X_test\n",
    "# y_train_split = y_train\n",
    "# y_val_split = y_test\n",
    "\n",
    "# # # # Add the channel dimension\n",
    "# X_train_split = np.expand_dims(X_train_split, axis=-1)\n",
    "# X_val_split = np.expand_dims(X_val_split, axis=-1)\n",
    "# # X_test= np.expand_dims(X_test, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272f361-007b-4bf6-8674-01a868123c1a",
   "metadata": {},
   "source": [
    "# Filter moods (for chinese baby cry or again baby2020 while no folding and filtering applied)\n",
    "\n",
    "### please comment the expand part in orevious command and run the 2 previous command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b047d4-3cc8-4468-8cbc-d3424c287bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 'diaper', 1: 'sleepy', 2: 'uncomfortable'}\n",
      "Train shape: (350, 100, 280, 1)  Val shape: (88, 100, 280, 1)\n",
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Classes of interest\n",
    "# keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "# class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# # --- Train filtering ---\n",
    "# mask_train = np.isin(y_train, keep_classes)\n",
    "# X_train_split = X_train[mask_train]\n",
    "# y_train_split = y_train[mask_train]\n",
    "\n",
    "# # --- Test filtering ---\n",
    "# mask_test = np.isin(y_test, keep_classes)\n",
    "# X_val_split = X_test[mask_test]\n",
    "# y_val_split = y_test[mask_test]\n",
    "\n",
    "# # --- Re-encode labels to [0,1,2] ---\n",
    "# unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "# class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "# id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# y_train_split = np.array([class2newid[y] for y in y_train_split])\n",
    "# y_val_split = np.array([class2newid[y] for y in y_val_split])\n",
    "\n",
    "# # --- Add channel dimension ---\n",
    "# X_train_split = np.expand_dims(X_train_split, axis=-1)\n",
    "# X_val_split = np.expand_dims(X_val_split, axis=-1)\n",
    "\n",
    "# print(\"Class mapping:\", id2cls_merge_3mood)\n",
    "# print(\"Train shape:\", X_train_split.shape, \" Val shape:\", X_val_split.shape)\n",
    "# print(\"Unique encoded y:\", np.unique(y_train_split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9aa4ea-0efd-4227-93d4-7548fd590ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60e20aa-d17a-4856-bc3c-91e576575fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"diaper\", \"sleepy\", \"uncomfortable\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3bbb4f7-d476-4c49-97e3-ae298459435b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique encoded y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique encoded y:\", np.unique(y_val_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934fba1-e034-43f2-8669-e5d31d39489f",
   "metadata": {},
   "source": [
    "## Cancel GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8848208a-ca72-45a8-a31f-602977fbf271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "XLA JIT?: \n"
     ]
    }
   ],
   "source": [
    "# # === MUST RUN AS FIRST CELL, BEFORE 'import tensorflow' ===\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"                 # hide all GPUs\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0 --tf_xla_enable_xla_devices=false\"\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"                  # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.config.optimizer.set_jit(False)                        # double-check\n",
    "\n",
    "# print(\"Physical devices:\", tf.config.list_physical_devices())\n",
    "# print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "# print(\"XLA JIT?:\", tf.config.optimizer.get_jit())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df9967-8f9a-4ae2-b144-7b3e7408bd54",
   "metadata": {},
   "source": [
    "## Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a32dd4f8-4c0b-4eb8-895b-27d106b4e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # 1) Make sure XLA is OFF at runtime\n",
    "# tf.config.optimizer.set_jit(False)                  # disable global XLA\n",
    "# tf.config.experimental.enable_mlir_graph_optimization(False)  # extra guard\n",
    "\n",
    "# # 2) Don't JIT-compile functions (if you use tf.function)\n",
    "# tf.config.run_functions_eagerly(False)              # keep graph mode, but no JIT\n",
    "\n",
    "# # 3) Keep GPU but avoid huge preallocs\n",
    "# for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "#     try: tf.config.experimental.set_memory_growth(g, True)\n",
    "#     except: pass\n",
    "\n",
    "# print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fadce-6908-4826-9cd4-5e517dd0a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ---- disable XLA JIT before importing TF ----\n",
    "# import os\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"\n",
    "# os.environ[\"TF_XLA_ENABLE_XLA_DEVICES\"] = \"0\"   # older TF env, harmless if unused\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"        # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # safety: also disable via API\n",
    "# tf.config.optimizer.set_jit(False)\n",
    "\n",
    "# # optional: make GPU memory grow as needed (avoid big prealloc)\n",
    "# gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# for gpu in gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "# import os\n",
    "# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/usr/local/cuda\"  # adjust to your CUDA root\n",
    "\n",
    "# # === CPU-ONLY, no XLA ===\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"            # hide all GPUs\n",
    "# os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_auto_jit=0\"   # no XLA\n",
    "# os.environ[\"TF_XLA_ENABLE_XLA_DEVICES\"] = \"0\"\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"             # quieter logs\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.config.optimizer.set_jit(False)                   # double-check\n",
    "# print(\"Devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ebede6-c195-4ca9-96c0-c78d9eee9b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-31 20:29:37.091509: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-31 20:29:37.102709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767230977.116187  360842 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767230977.120511  360842 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767230977.130222  360842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767230977.130231  360842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767230977.130233  360842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767230977.130234  360842 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-31 20:29:37.133480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, precision_score, recall_score, matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K, regularizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea5438-572d-4267-950b-d7665ab6ddf5",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce58eeda-7423-4069-90fe-77c1b78a7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def bootstrap_ci(metric_fn, y_true, y_pred, class_index=None, n_boot=1000, ci=95):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for AUC, PR-AUC, etc.\n",
    "    metric_fn should accept (y_true, y_pred).\n",
    "    If multi-class, you can pass class_index to slice class column.\n",
    "    \"\"\"\n",
    "\n",
    "    boot_scores = []\n",
    "    n = len(y_true)\n",
    "\n",
    "    rng = np.random.default_rng(42)   # reproducible\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)   # sample with replacement\n",
    "        yt = y_true[idx]\n",
    "        yp = y_pred[idx]\n",
    "\n",
    "        if class_index is not None:\n",
    "            yt = yt[:, class_index]\n",
    "            yp = yp[:, class_index]\n",
    "\n",
    "        try:\n",
    "            score = metric_fn(yt, yp)\n",
    "            boot_scores.append(score)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    lower = np.percentile(boot_scores, (100-ci)/2)\n",
    "    upper = np.percentile(boot_scores, 100 - (100-ci)/2)\n",
    "    return np.mean(boot_scores), lower, upper\n",
    "\n",
    "\n",
    "class AUCPlotsCallback(Callback):\n",
    "    def __init__(self, X_val, y_val_onehot, class_names):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val_onehot = y_val_onehot\n",
    "        self.class_names = class_names\n",
    "        self.n_classes = len(class_names)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        y_prob = self.model.predict(self.X_val)\n",
    "        y_true = self.y_val_onehot\n",
    "\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"  CONFIDENCE INTERVALS (95%)\")\n",
    "        print(\"==============================\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Macro AUC with CI\n",
    "        # -------------------------\n",
    "        def auc_macro_fn(y_true, y_pred):\n",
    "            return roc_auc_score(\n",
    "                y_true, y_pred,\n",
    "                average=\"macro\",\n",
    "                multi_class=\"ovr\"\n",
    "            )\n",
    "\n",
    "        macro_mean, macro_low, macro_high = bootstrap_ci(\n",
    "            auc_macro_fn, y_true, y_prob, n_boot=1000\n",
    "        )\n",
    "\n",
    "        print(f\"\\nMacro AUC = {macro_mean:.4f}  (95% CI: {macro_low:.4f} – {macro_high:.4f})\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-Class ROC AUC\n",
    "        # -------------------------\n",
    "        print(\"\\nPer-class ROC AUC with 95% CI:\")\n",
    "        for c in range(self.n_classes):\n",
    "\n",
    "            def auc_single(y_true_c, y_pred_c):\n",
    "                fpr, tpr, _ = roc_curve(y_true_c, y_pred_c)\n",
    "                return auc(fpr, tpr)\n",
    "\n",
    "            mean_auc, low_auc, high_auc = bootstrap_ci(\n",
    "                auc_single, y_true, y_prob, class_index=c, n_boot=800\n",
    "            )\n",
    "            print(f\"  {self.class_names[c]}: {mean_auc:.4f}  (95% CI: {low_auc:.4f} – {high_auc:.4f})\")\n",
    "\n",
    "        # -------------------------\n",
    "        # Per-Class PR AUC with CI\n",
    "        # -------------------------\n",
    "        print(\"\\nPer-class Precision–Recall AUC with 95% CI:\")\n",
    "        for c in range(self.n_classes):\n",
    "\n",
    "            def pr_auc_single(y_true_c, y_pred_c):\n",
    "                precision, recall, _ = precision_recall_curve(y_true_c, y_pred_c)\n",
    "                return auc(recall, precision)\n",
    "\n",
    "            mean_pr, low_pr, high_pr = bootstrap_ci(\n",
    "                pr_auc_single, y_true, y_prob, class_index=c, n_boot=800\n",
    "            )\n",
    "\n",
    "            print(f\"  {self.class_names[c]} PR-AUC: {mean_pr:.4f}  (95% CI: {low_pr:.4f} – {high_pr:.4f})\")\n",
    "\n",
    "        print(\"\\nDone computing bootstrap confidence intervals.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, num_heads=4, key_dim=32, ff_dim=64, dropout=0.1):\n",
    "    # Multi-head self-attention\n",
    "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attn = layers.Dropout(dropout)(attn)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn)\n",
    "\n",
    "    # Feed-forward\n",
    "    ffn = layers.Dense(ff_dim, activation=\"relu\")(out1)\n",
    "    ffn = layers.Dense(inputs.shape[-1])(ffn)\n",
    "    ffn = layers.Dropout(dropout)(ffn)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(out1 + ffn)\n",
    "\n",
    "\n",
    "# X_train = Train_Dac_result_3d\n",
    "# X_test = Test_DaC_result_3d\n",
    "\n",
    "# X_train = X_train_reduced  #Train_Dac_result_3d\n",
    "# X_test = X_test_reduced   #Test_DaC_result_3d\n",
    "\n",
    "# y_train = y_train_reduced\n",
    "# y_test = y_test_reduced\n",
    "\n",
    "\n",
    "# checkpoint_path = \"Combined_Cinese_CNN_LSTM_3_balanced.keras\"  \n",
    "# def build_model(input_shape, num_classes):\n",
    "#     inputs = Input(shape=input_shape)\n",
    "    \n",
    "#     # CNN Feature Extractor with only one Conv2D layer\n",
    "#     x = Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "#     x = Dropout(0.5)(x)  # Dropout added after pooling\n",
    "\n",
    "#     # Convert CNN output to time-distributed format for LSTM\n",
    "#     x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "#     # LSTM Layer\n",
    "#     x = LSTM(4, return_sequences=False)(x)\n",
    "#     x = Dropout(0.5)(x)  # Dropout added after LSTM\n",
    "\n",
    "#     # Fully Connected Layers\n",
    "#     x = Dense(4, activation=\"relu\")(x)\n",
    "#     output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.00001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    l2_reg = regularizers.l2(0.001)  # You can tune this value (e.g., 0.0001 or 0.01)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN layers with L2 regularization\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # LSTM layer with L2 regularization\n",
    "    x = LSTM(\n",
    "    32,\n",
    "    return_sequences=False,\n",
    "    kernel_regularizer=l2_reg\n",
    "    )(x)\n",
    "\n",
    "    #################################################### Transformer\n",
    "    # # Multi-head self-attention\n",
    "    # x = transformer_encoder(x)\n",
    "    # x = layers.GlobalAveragePooling1D()(x)  # like LSTM(return_sequences=False)\n",
    "\n",
    "    ####################################################  GRU\n",
    "    \n",
    "    # x = GRU(32, return_sequences=False, kernel_regularizer=l2_reg)(x)\n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Dense layers with L2\n",
    "    x = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    output = Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2_reg)(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    # sparse_categorical_crossentropy los\n",
    "    # model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    # Focal Loss\n",
    "    # model.compile(optimizer=Adam(learning_rate=0.000001), loss=focal_loss(alpha=0.25, gamma=2.0), metrics=['accuracy'])\n",
    "    \n",
    "    loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy']\n",
    "             ,jit_compile=False\n",
    "                 )   # <- important\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.train_f1s = []\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        train_preds = np.argmax(self.model.predict(self.X_train), axis=1)\n",
    "        val_preds = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "\n",
    "        # Use 'macro' for unweighted mean of class F1 scores\n",
    "        train_f1 = f1_score(self.y_train, train_preds, average='macro')\n",
    "        val_f1 = f1_score(self.y_val, val_preds, average='macro')\n",
    "\n",
    "        self.train_f1s.append(train_f1)\n",
    "        self.val_f1s.append(val_f1)\n",
    "\n",
    "        # NEW: expose metrics to Keras callback chain\n",
    "        logs[\"train_f1_score\"] = float(train_f1)\n",
    "        logs[\"val_f1_score\"]   = float(val_f1)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train F1={train_f1:.4f} - Val F1={val_f1:.4f}\")\n",
    "\n",
    "class TestF1Callback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.test_f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(self.X_test), axis=1)\n",
    "        test_f1 = f1_score(self.y_test, y_pred, average='macro')  # macro mean of class F1\n",
    "        self.test_f1_scores.append(test_f1)\n",
    "        print(f\"Epoch {epoch+1}: Test F1 Score = {test_f1:.4f}\")\n",
    "\n",
    "\n",
    "# Custom callback to monitor val F1 score\n",
    "class SaveBestModelOnF1(Callback):\n",
    "    def __init__(self, monitor='val_f1_score', save_dir='models_Kaggle/'):\n",
    "        super().__init__()\n",
    "        self.best_f1 = -np.Inf\n",
    "        self.monitor = monitor\n",
    "        self.save_dir = save_dir\n",
    "        self.best_epoch = -1\n",
    "        # Create directory if not exists\n",
    "        import os\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # Save initial best filename\n",
    "        self.best_filepath = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get current val_f1_score from logs (we'll provide it manually)\n",
    "        # Alternatively, fetch from a global variable if needed.\n",
    "        current_f1 = logs.get(self.monitor)\n",
    "        if current_f1 is None:\n",
    "            return  # Can't monitor if metric isn't in logs\n",
    "        if current_f1 > self.best_f1:\n",
    "            self.best_f1 = current_f1\n",
    "            self.best_epoch = epoch + 1\n",
    "            # Save model with timestamp and val_f1\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"model_{timestamp}_epoch{self.best_epoch}_f1{current_f1:.4f}.h5\"\n",
    "            filepath = os.path.join(self.save_dir, filename)\n",
    "            self.model.save(filepath)\n",
    "            print(f\"\\nSaved best model at epoch {self.best_epoch} with val_f1={current_f1:.4f}\")\n",
    "\n",
    "\n",
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict on validation data\n",
    "        preds = np.argmax(self.model.predict(self.X_val), axis=1)\n",
    "        # Get classification report\n",
    "        report = classification_report(self.y_val, preds, output_dict=True)\n",
    "        # Print per-class precision & recall\n",
    "        print(f\"\\nEpoch {epoch+1}: Per-class metrics\")\n",
    "        for label, metrics in report.items():\n",
    "            if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                print(f\"  Class {label}: Precision={metrics['precision']:.3f} Recall={metrics['recall']:.3f}\")\n",
    "        # Optional: you can also print macro or weighted averages if you want:\n",
    "\n",
    "        print(f\"  Macro Avg: Precision={report['macro avg']['precision']:.3f} Recall={report['macro avg']['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a01d0-a5d2-4714-b193-5672592d3d3c",
   "metadata": {},
   "source": [
    "## Training with Folding Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4e6837-a787-4acc-b5bf-00c8b31abd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/2987579411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m }\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mfold_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'folds' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef,\n",
    "    precision_score, recall_score,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0) Helper: 95% CI across folds (t-distribution)\n",
    "# =========================================================\n",
    "def mean_std_ci(values, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Returns (mean, std, ci_low, ci_high) using t-distribution.\n",
    "    Falls back to normal approx if scipy isn't available.\n",
    "    \"\"\"\n",
    "    vals = np.array(values, dtype=float)\n",
    "    mean = float(np.mean(vals))\n",
    "    std = float(np.std(vals, ddof=1)) if len(vals) > 1 else 0.0\n",
    "    n = len(vals)\n",
    "\n",
    "    if n <= 1:\n",
    "        return mean, std, mean, mean\n",
    "\n",
    "    try:\n",
    "        from scipy.stats import t\n",
    "        se = std / np.sqrt(n)\n",
    "        h = se * t.ppf((1 + confidence) / 2, df=n - 1)\n",
    "        return mean, std, mean - h, mean + h\n",
    "    except Exception:\n",
    "        # normal approx fallback\n",
    "        z = 1.96  # ~95%\n",
    "        se = std / np.sqrt(n)\n",
    "        return mean, std, mean - z * se, mean + z * se\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Helper: plot learning curves (per fold + mean curve)\n",
    "# =========================================================\n",
    "def plot_learning_curves(history_per_fold, key, title=None):\n",
    "    \"\"\"\n",
    "    Plot per-fold curves and the mean curve.\n",
    "    key examples:\n",
    "      - \"loss\"\n",
    "      - \"accuracy\"\n",
    "      - \"train_f1_score\"\n",
    "      - \"val_f1_score\"\n",
    "    \"\"\"\n",
    "    # Collect arrays with variable lengths\n",
    "    curves = []\n",
    "    max_len = 0\n",
    "    for h in history_per_fold:\n",
    "        if key in h:\n",
    "            arr = np.array(h[key], dtype=float)\n",
    "            curves.append(arr)\n",
    "            max_len = max(max_len, len(arr))\n",
    "\n",
    "    if not curves:\n",
    "        print(f\"⚠️ No curves found for key='{key}' in history.\")\n",
    "        return\n",
    "\n",
    "    # Pad with NaNs for mean\n",
    "    padded = np.full((len(curves), max_len), np.nan, dtype=float)\n",
    "    for i, arr in enumerate(curves):\n",
    "        padded[i, :len(arr)] = arr\n",
    "\n",
    "    mean_curve = np.nanmean(padded, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    for i in range(len(curves)):\n",
    "        plt.plot(padded[i], alpha=0.25)\n",
    "    plt.plot(mean_curve, linewidth=2.5)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(key)\n",
    "    plt.title(title if title else f\"Learning Curve: {key}\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Enhanced callback: Save BEST model based on val_f1_score\n",
    "#    (This is your \"validation == test\" criterion in CV)\n",
    "# =========================================================\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class SaveBestModelOnF1Tracked(Callback):\n",
    "    \"\"\"\n",
    "    Saves the model whenever monitored F1 improves.\n",
    "    Tracks best score, epoch, and filepath for later best-fold selection.\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor=\"val_f1_score\", save_dir=\"saved_models\"):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.save_dir = save_dir\n",
    "        self.best_f1 = -np.inf\n",
    "        self.best_epoch = -1\n",
    "        self.best_filepath = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current = logs.get(self.monitor, None)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        if current > self.best_f1:\n",
    "            self.best_f1 = float(current)\n",
    "            self.best_epoch = int(epoch + 1)\n",
    "\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"best_{self.monitor}_epoch{self.best_epoch}_f1{self.best_f1:.4f}_{timestamp}.h5\"\n",
    "            filepath = os.path.join(self.save_dir, filename)\n",
    "\n",
    "            self.model.save(filepath)\n",
    "            self.best_filepath = filepath\n",
    "            print(f\"\\n✅ Saved BEST model ({self.monitor}) at epoch {self.best_epoch} | f1={self.best_f1:.4f}\")\n",
    "            print(f\"   → {self.best_filepath}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) CV loop (your code + additions)\n",
    "# =========================================================\n",
    "\n",
    "# Containers for fold results\n",
    "fold_results = []            # dict per fold with metrics + model path\n",
    "history_per_fold = []        # list of history.history dicts\n",
    "\n",
    "# Optional: keep track of best fold by fold-level F1 (post-training)\n",
    "best_fold_summary = {\n",
    "    \"fold\": None,\n",
    "    \"f1\": -np.inf,\n",
    "    \"model_path\": None\n",
    "}\n",
    "\n",
    "for fold in folds:\n",
    "    fold_id = fold[\"fold\"]\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"TRAINING FOLD {fold_id}  (validation == test fold)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1) Extract fold data\n",
    "    X_train = fold[\"X_train\"]\n",
    "    X_val   = fold[\"X_test\"]\n",
    "\n",
    "    y_train = fold[\"df_train\"][\"label_id\"].values\n",
    "    y_val   = fold[\"df_test\"][\"label_id\"].values\n",
    "\n",
    "    num_classes = fold[\"num_classes\"]\n",
    "    class_names_fold = fold[\"label_to_class\"]\n",
    "\n",
    "    # 2) Add channel dim\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_val   = np.expand_dims(X_val, axis=-1)\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n",
    "    print(\"Unique y_train:\", np.unique(y_train))\n",
    "\n",
    "    # 3) One-hot encoding\n",
    "    y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val_oh   = to_categorical(y_val, num_classes=num_classes)\n",
    "\n",
    "    # 4) Class weights (per fold)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = {cls: w for cls, w in zip(np.unique(y_train), class_weights)}\n",
    "    print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "    # 5) Build fresh model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = build_model(input_shape, num_classes)\n",
    "\n",
    "    # 6) Callbacks (fold-aware)\n",
    "\n",
    "    # This saves the BEST model based on val_f1_score\n",
    "    # In CV, \"val\" is your held-out fold (validation == test fold)\n",
    "    save_best_callback = SaveBestModelOnF1Tracked(\n",
    "        monitor=\"val_f1_score\",\n",
    "        save_dir=f\"saved_models/fold_{fold_id}\"\n",
    "    )\n",
    "\n",
    "    # Your F1 callback must write logs[\"val_f1_score\"] each epoch (you already do that)\n",
    "    f1_callback = F1ScoreCallback(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    metrics_logger = MetricsLogger(X_val, y_val)\n",
    "\n",
    "    auc_callback = AUCPlotsCallback(\n",
    "        X_val,\n",
    "        y_val_oh,\n",
    "        class_names=[class_names_fold[i] for i in range(num_classes)]\n",
    "    )\n",
    "\n",
    "    # 7) Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train_oh,\n",
    "        validation_data=(X_val, y_val_oh),\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        verbose=2,\n",
    "        callbacks=[\n",
    "            f1_callback,\n",
    "            save_best_callback,  # <-- best model saved on val_f1_score (val==test fold)\n",
    "            metrics_logger,\n",
    "            auc_callback\n",
    "        ],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    history_per_fold.append(history.history)\n",
    "\n",
    "    # 8) Evaluate fold (final epoch weights)\n",
    "    val_probs = model.predict(X_val)\n",
    "    val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "    acc = float(np.mean(val_preds == y_val))\n",
    "    f1w = float(f1_score(y_val, val_preds, average=\"weighted\"))\n",
    "    mcc = float(matthews_corrcoef(y_val, val_preds))\n",
    "    prec = float(precision_score(y_val, val_preds, average=\"weighted\"))\n",
    "    rec = float(recall_score(y_val, val_preds, average=\"weighted\"))\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold_id} — ACC={acc:.4f}, F1w={f1w:.4f}, MCC={mcc:.4f}, \"\n",
    "        f\"Precision={prec:.4f}, Recall={rec:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Per-class report\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    report = classification_report(\n",
    "        y_val,\n",
    "        val_preds,\n",
    "        target_names=[class_names_fold[i] for i in range(num_classes)]\n",
    "    )\n",
    "    print(report)\n",
    "\n",
    "    # Save fold results\n",
    "    fold_info = {\n",
    "        \"fold\": fold_id,\n",
    "        \"acc\": acc,\n",
    "        \"f1w\": f1w,\n",
    "        \"mcc\": mcc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        # Best-by-F1-on-val==test (saved during training)\n",
    "        \"best_val_f1\": float(save_best_callback.best_f1),\n",
    "        \"best_val_f1_epoch\": int(save_best_callback.best_epoch),\n",
    "        \"best_val_f1_model_path\": save_best_callback.best_filepath\n",
    "    }\n",
    "    fold_results.append(fold_info)\n",
    "\n",
    "    # Best fold selection (by best saved val_f1, NOT final epoch)\n",
    "    if fold_info[\"best_val_f1\"] > best_fold_summary[\"f1\"]:\n",
    "        best_fold_summary[\"fold\"] = fold_id\n",
    "        best_fold_summary[\"f1\"] = fold_info[\"best_val_f1\"]\n",
    "        best_fold_summary[\"model_path\"] = fold_info[\"best_val_f1_model_path\"]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4) Aggregate CV results + statistical significance\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "accs = [r[\"acc\"] for r in fold_results]\n",
    "f1s  = [r[\"f1w\"] for r in fold_results]\n",
    "mccs = [r[\"mcc\"] for r in fold_results]\n",
    "precs = [r[\"precision\"] for r in fold_results]\n",
    "recs  = [r[\"recall\"] for r in fold_results]\n",
    "\n",
    "def print_stat(name, vals):\n",
    "    mean, std, lo, hi = mean_std_ci(vals, confidence=0.95)\n",
    "    print(f\"{name}: mean={mean:.4f}  std={std:.4f}  95% CI=[{lo:.4f}, {hi:.4f}]\")\n",
    "\n",
    "print_stat(\"Accuracy\", accs)\n",
    "print_stat(\"F1 (weighted)\", f1s)\n",
    "print_stat(\"MCC\", mccs)\n",
    "print_stat(\"Precision (weighted)\", precs)\n",
    "print_stat(\"Recall (weighted)\", recs)\n",
    "\n",
    "# Also show \"best saved model\" F1 per fold\n",
    "best_saved_f1s = [r[\"best_val_f1\"] for r in fold_results]\n",
    "print_stat(\"Best saved val==test F1 per fold\", best_saved_f1s)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5) Best fold selection summary\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST FOLD (by best saved val==test F1)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best fold: {best_fold_summary['fold']}\")\n",
    "print(f\"Best val==test F1: {best_fold_summary['f1']:.4f}\")\n",
    "print(f\"Best model path: {best_fold_summary['model_path']}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 6) Learning-curve plots (Loss, Accuracy, F1)\n",
    "# =========================================================\n",
    "# These keys exist if:\n",
    "# - Keras logs 'loss', 'accuracy', 'val_loss', 'val_accuracy'\n",
    "# - Your F1ScoreCallback writes logs['train_f1_score'] and logs['val_f1_score']\n",
    "plot_learning_curves(history_per_fold, \"loss\", title=\"Loss (train)\")\n",
    "plot_learning_curves(history_per_fold, \"val_loss\", title=\"Loss (val)\")\n",
    "\n",
    "plot_learning_curves(history_per_fold, \"accuracy\", title=\"Accuracy (train)\")\n",
    "plot_learning_curves(history_per_fold, \"val_accuracy\", title=\"Accuracy (val)\")\n",
    "\n",
    "plot_learning_curves(history_per_fold, \"train_f1_score\", title=\"F1 (train, macro)\")\n",
    "plot_learning_curves(history_per_fold, \"val_f1_score\", title=\"F1 (val==test fold, macro)\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 7) Save outputs (histories + fold results)\n",
    "# =========================================================\n",
    "# Save histories\n",
    "with open(history_name, \"wb\") as f:\n",
    "    pickle.dump(history_per_fold, f)\n",
    "\n",
    "# Save fold metrics (very useful for papers / tables)\n",
    "metrics_out = history_name.replace(\".pkl\", \"_fold_metrics.pkl\")\n",
    "with open(metrics_out, \"wb\") as f:\n",
    "    pickle.dump(fold_results, f)\n",
    "\n",
    "print(f\"\\nSaved histories to: {history_name}\")\n",
    "print(f\"Saved fold metrics to: {metrics_out}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57ef54-6d74-4ff1-949f-53129dbe25f8",
   "metadata": {},
   "source": [
    "# No folding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf921b7-2458-4d1e-91c2-9f4f120db321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.0903426791277258, 1: 1.0144927536231885, 2: 0.9114583333333334}\n",
      "X_train_split shape: (350, 100, 280)\n",
      "X_val_split shape: (88, 100, 280)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 280)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/2084203596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Create a new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_360842/3956264150.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# CNN layers with L2 regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    203\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 100, 280)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# To include this callback:\n",
    "save_best_callback = SaveBestModelOnF1(monitor='val_f1_score', save_dir='saved_models')\n",
    "\n",
    "\n",
    "\n",
    "# Assuming y_train contains class labels as integers\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "# Create a dictionary: class_label -> weight\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "\n",
    "# Get input shape and number of classes  \n",
    "input_shape = X_train_split.shape[1:] #  feature shape  \n",
    "num_classes = len(np.unique(y_train))  \n",
    "\n",
    "# Verify shape\n",
    "print(\"X_train_split shape:\", X_train_split.shape)  # Should be (None, 1201, 120, 1)\n",
    "print(\"X_val_split shape:\", X_val_split.shape)  # Should be (None, 1201, 120, 1) \n",
    "\n",
    "\n",
    "# Initialize metrics  \n",
    "fold_accuracies = []  \n",
    "fold_f1_scores = []  \n",
    "fold_mcc_scores = []  \n",
    "fold_precision_scores = []  \n",
    "fold_recall_scores = []  \n",
    "history_per_fold = []  # Store history for later plotting  \n",
    "f1_callback = F1ScoreCallback(X_train_split, y_train_split, X_val_split, y_val_split)\n",
    "test_f1_callback = TestF1Callback(X_test, y_test)\n",
    "metrics_logger = MetricsLogger(X_val_split, y_val_split)\n",
    "\n",
    "\n",
    "\n",
    "# Create a new model  \n",
    "model = build_model(input_shape, num_classes)   \n",
    "\n",
    "\n",
    "# Define checkpoint path  \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=2)  \n",
    "\n",
    "# Fit the model  \n",
    "# During fit\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode labels for CategoricalCrossentropy\n",
    "y_train_onehot = to_categorical(y_train_split, num_classes=num_classes)\n",
    "y_val_onehot = to_categorical(y_val_split, num_classes=num_classes)\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_f1_score',     # You can change to 'val_accuracy' or 'val_f1_score'\n",
    "    factor=0.5,             # Reduce LR by a factor of 0.5\n",
    "    patience=5,             # Wait 8 epochs before reducing\n",
    "    min_lr=1e-6,            # Lower bound on LR\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Stop training when validation performance stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Should match the metric you're optimizing\n",
    "    patience=50,            # Stop after 15 epochs without improvement\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "auc_callback = AUCPlotsCallback(\n",
    "    X_val_split,\n",
    "    y_val_onehot,\n",
    "    class_names=list(class_names)\n",
    ")\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_onehot,\n",
    "    validation_data=(X_val_split, y_val_onehot),\n",
    "    epochs=700,\n",
    "    batch_size=32,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        model_checkpoint,\n",
    "        f1_callback,\n",
    "        save_best_callback,\n",
    "        metrics_logger,\n",
    "        auc_callback  \n",
    "        # reduce_lr,           # 👈 Add this\n",
    "        # early_stopping       # 👈 Add this\n",
    "    ],\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Store history for later plotting  \n",
    "history_per_fold.append(history.history)  \n",
    "\n",
    "# Evaluate on Validation Set  \n",
    "val_preds = np.argmax(model.predict(X_val_split), axis=1)  \n",
    "\n",
    "# Calculate metrics  \n",
    "val_f1 = f1_score(y_val_split, val_preds, average='weighted')   \n",
    "val_mcc = matthews_corrcoef(y_val_split, val_preds)  \n",
    "val_precision = precision_score(y_val_split, val_preds, average='weighted')  \n",
    "val_recall = recall_score(y_val_split, val_preds, average='weighted')  \n",
    "\n",
    "# Append metrics  \n",
    "fold_f1_scores.append(val_f1)  \n",
    "fold_mcc_scores.append(val_mcc)  \n",
    "fold_precision_scores.append(val_precision)  \n",
    "fold_recall_scores.append(val_recall)  \n",
    "accuracy = np.mean(val_preds == y_val_split)  \n",
    "fold_accuracies.append(accuracy)  \n",
    "\n",
    "# Print results  \n",
    "print(f\"Validation - F1 Score: {val_f1:.4f}, MCC: {val_mcc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {accuracy:.4f}\")  \n",
    "\n",
    "# Per-class metrics  \n",
    "class_report = classification_report(y_val_split, val_preds, output_dict=True)  \n",
    "print(\"Per-Class Metrics:\")  \n",
    "for class_label, metrics in class_report.items():  \n",
    "    if class_label != 'accuracy' and class_label != 'macro avg' and class_label != 'weighted avg':  \n",
    "        print(f\"  Class {class_label}: Precision={metrics['precision']:.4f}, Recall={metrics['recall']:.4f}, F1-score={metrics['f1-score']:.4f}\")  \n",
    "\n",
    "# Calculate overall metrics  \n",
    "average_accuracy = np.mean(fold_accuracies)  \n",
    "print(f\"Average Accuracy: {average_accuracy:.4f}\")  \n",
    "print(f\"Average F1 Score: {np.mean(fold_f1_scores):.4f}\")  \n",
    "print(f\"Average MCC: {np.mean(fold_mcc_scores):.4f}\")  \n",
    "print(f\"Precision: {np.mean(fold_precision_scores):.4f}\")  \n",
    "print(f\"Recall: {np.mean(fold_recall_scores):.4f}\")\n",
    "\n",
    "\n",
    "checkpoint_path\n",
    "# Save the history object\n",
    "with open(history_name, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a938962-5349-4ec1-bf75-c80bab57760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_train_split already 4D: (350, 100, 280, 1)\n",
      "✅ X_val_split already 4D: (88, 100, 280, 1)\n",
      "✅ X_test already 4D: (88, 100, 280, 1)\n",
      "X_train_split shape: (350, 100, 280, 1)\n",
      "X_val_split shape  : (88, 100, 280, 1)\n",
      "✅ Remapped labels:\n",
      "  unique y_train_split: [0 1 2]\n",
      "  unique y_val_split  : [0 1 2]\n",
      "  mapping: {0: 'Diaper', 1: 'Sleepy', 2: 'Uncomfortable'}\n",
      "✅ num_classes: 3\n",
      "✅ num_classes: 3 | unique y_train_split: [0 1 2]\n",
      "✅ Class weights: {0: 1.0903426791277258, 1: 1.0144927536231885, 2: 0.9114583333333334}\n",
      "✅ input_shape: (100, 280, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767231459.288061  360842 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5880 MB memory:  -> device: 0, name: NVIDIA H100 PCIe MIG 1g.10gb, pci bus id: 0000:65:00.0, compute capability: 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model built\n",
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1767231462.409325  360842 meta_optimizer.cc:967] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1767231462.786263  407599 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.34091, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train F1=0.2548 - Val F1=0.2379\n",
      "\n",
      "Saved best model at epoch 1 with val_f1=0.2379\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 1: Per-class metrics\n",
      "  Class 0: Precision=0.200 Recall=0.037\n",
      "  Class 1: Precision=0.351 Recall=0.897\n",
      "  Class 2: Precision=0.333 Recall=0.094\n",
      "  Macro Avg: Precision=0.295 Recall=0.342\n",
      "11/11 - 10s - 909ms/step - accuracy: 0.3371 - loss: 1.4310 - val_accuracy: 0.3409 - val_loss: 1.3477 - train_f1_score: 0.2548 - val_f1_score: 0.2379\n",
      "Epoch 2/700\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 2: Train F1=0.2405 - Val F1=0.2261\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 2: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.074\n",
      "  Class 1: Precision=0.087 Recall=0.069\n",
      "  Class 2: Precision=0.355 Recall=0.688\n",
      "  Macro Avg: Precision=0.369 Recall=0.277\n",
      "11/11 - 4s - 335ms/step - accuracy: 0.3400 - loss: 1.3919 - val_accuracy: 0.2955 - val_loss: 1.3445 - train_f1_score: 0.2405 - val_f1_score: 0.2261\n",
      "Epoch 3/700\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 3: Train F1=0.2463 - Val F1=0.1978\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 3: Per-class metrics\n",
      "  Class 0: Precision=0.000 Recall=0.000\n",
      "  Class 1: Precision=0.316 Recall=0.828\n",
      "  Class 2: Precision=0.250 Recall=0.094\n",
      "  Macro Avg: Precision=0.189 Recall=0.307\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.3371 - loss: 1.3637 - val_accuracy: 0.3068 - val_loss: 1.3362 - train_f1_score: 0.2463 - val_f1_score: 0.1978\n",
      "Epoch 4/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 4: Train F1=0.2561 - Val F1=0.2014\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 4: Per-class metrics\n",
      "  Class 0: Precision=0.000 Recall=0.000\n",
      "  Class 1: Precision=0.290 Recall=0.690\n",
      "  Class 2: Precision=0.263 Recall=0.156\n",
      "  Macro Avg: Precision=0.184 Recall=0.282\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.3600 - loss: 1.3390 - val_accuracy: 0.2841 - val_loss: 1.3302 - train_f1_score: 0.2561 - val_f1_score: 0.2014\n",
      "Epoch 5/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train F1=0.3346 - Val F1=0.2699\n",
      "\n",
      "Saved best model at epoch 5 with val_f1=0.2699\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 5: Per-class metrics\n",
      "  Class 0: Precision=0.364 Recall=0.444\n",
      "  Class 1: Precision=0.315 Recall=0.586\n",
      "  Class 2: Precision=0.000 Recall=0.000\n",
      "  Macro Avg: Precision=0.226 Recall=0.344\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.3571 - loss: 1.3435 - val_accuracy: 0.3295 - val_loss: 1.3252 - train_f1_score: 0.3346 - val_f1_score: 0.2699\n",
      "Epoch 6/700\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 6: Train F1=0.2221 - Val F1=0.2220\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 6: Per-class metrics\n",
      "  Class 0: Precision=0.329 Recall=0.889\n",
      "  Class 1: Precision=0.286 Recall=0.138\n",
      "  Class 2: Precision=0.000 Recall=0.000\n",
      "  Macro Avg: Precision=0.205 Recall=0.342\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.3486 - loss: 1.3259 - val_accuracy: 0.3182 - val_loss: 1.3135 - train_f1_score: 0.2221 - val_f1_score: 0.2220\n",
      "Epoch 7/700\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 7: Train F1=0.2740 - Val F1=0.2570\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 7: Per-class metrics\n",
      "  Class 0: Precision=0.319 Recall=0.852\n",
      "  Class 1: Precision=0.333 Recall=0.138\n",
      "  Class 2: Precision=0.500 Recall=0.062\n",
      "  Macro Avg: Precision=0.384 Recall=0.351\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.3286 - loss: 1.3345 - val_accuracy: 0.3295 - val_loss: 1.3052 - train_f1_score: 0.2740 - val_f1_score: 0.2570\n",
      "Epoch 8/700\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train F1=0.3756 - Val F1=0.2862\n",
      "\n",
      "Saved best model at epoch 8 with val_f1=0.2862\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 8: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.296\n",
      "  Class 1: Precision=0.263 Recall=0.345\n",
      "  Class 2: Precision=0.171 Recall=0.188\n",
      "  Macro Avg: Precision=0.323 Recall=0.276\n",
      "11/11 - 1s - 99ms/step - accuracy: 0.3543 - loss: 1.3166 - val_accuracy: 0.2727 - val_loss: 1.2983 - train_f1_score: 0.3756 - val_f1_score: 0.2862\n",
      "Epoch 9/700\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.34091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 9: Train F1=0.3291 - Val F1=0.2806\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 9: Per-class metrics\n",
      "  Class 0: Precision=0.395 Recall=0.630\n",
      "  Class 1: Precision=0.295 Recall=0.448\n",
      "  Class 2: Precision=0.000 Recall=0.000\n",
      "  Macro Avg: Precision=0.230 Recall=0.359\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.3143 - loss: 1.3097 - val_accuracy: 0.3409 - val_loss: 1.2921 - train_f1_score: 0.3291 - val_f1_score: 0.2806\n",
      "Epoch 10/700\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.34091 to 0.35227, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 10: Train F1=0.3457 - Val F1=0.2849\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 10: Per-class metrics\n",
      "  Class 0: Precision=0.408 Recall=0.741\n",
      "  Class 1: Precision=0.289 Recall=0.379\n",
      "  Class 2: Precision=0.000 Recall=0.000\n",
      "  Macro Avg: Precision=0.233 Recall=0.373\n",
      "11/11 - 1s - 122ms/step - accuracy: 0.3600 - loss: 1.2893 - val_accuracy: 0.3523 - val_loss: 1.2858 - train_f1_score: 0.3457 - val_f1_score: 0.2849\n",
      "Epoch 11/700\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.35227\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 11: Train F1=0.2031 - Val F1=0.1728\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 11: Per-class metrics\n",
      "  Class 0: Precision=0.309 Recall=0.926\n",
      "  Class 1: Precision=0.143 Recall=0.034\n",
      "  Class 2: Precision=0.000 Recall=0.000\n",
      "  Macro Avg: Precision=0.150 Recall=0.320\n",
      "11/11 - 1s - 107ms/step - accuracy: 0.3286 - loss: 1.2930 - val_accuracy: 0.2955 - val_loss: 1.2823 - train_f1_score: 0.2031 - val_f1_score: 0.1728\n",
      "Epoch 12/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: val_accuracy improved from 0.35227 to 0.39773, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train F1=0.3218 - Val F1=0.3631\n",
      "\n",
      "Saved best model at epoch 12 with val_f1=0.3631\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 12: Per-class metrics\n",
      "  Class 0: Precision=0.370 Recall=0.741\n",
      "  Class 1: Precision=0.379 Recall=0.379\n",
      "  Class 2: Precision=0.800 Recall=0.125\n",
      "  Macro Avg: Precision=0.517 Recall=0.415\n",
      "11/11 - 1s - 123ms/step - accuracy: 0.3743 - loss: 1.2784 - val_accuracy: 0.3977 - val_loss: 1.2732 - train_f1_score: 0.3218 - val_f1_score: 0.3631\n",
      "Epoch 13/700\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.39773 to 0.42045, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train F1=0.4386 - Val F1=0.4079\n",
      "\n",
      "Saved best model at epoch 13 with val_f1=0.4079\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 13: Per-class metrics\n",
      "  Class 0: Precision=0.415 Recall=0.630\n",
      "  Class 1: Precision=0.394 Recall=0.448\n",
      "  Class 2: Precision=0.500 Recall=0.219\n",
      "  Macro Avg: Precision=0.436 Recall=0.432\n",
      "11/11 - 1s - 101ms/step - accuracy: 0.3229 - loss: 1.2757 - val_accuracy: 0.4205 - val_loss: 1.2645 - train_f1_score: 0.4386 - val_f1_score: 0.4079\n",
      "Epoch 14/700\n",
      "\n",
      "Epoch 14: val_accuracy improved from 0.42045 to 0.46591, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train F1=0.3864 - Val F1=0.4341\n",
      "\n",
      "Saved best model at epoch 14 with val_f1=0.4341\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 14: Per-class metrics\n",
      "  Class 0: Precision=0.483 Recall=0.519\n",
      "  Class 1: Precision=0.449 Recall=0.759\n",
      "  Class 2: Precision=0.500 Recall=0.156\n",
      "  Macro Avg: Precision=0.477 Recall=0.478\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.3400 - loss: 1.2655 - val_accuracy: 0.4659 - val_loss: 1.2590 - train_f1_score: 0.3864 - val_f1_score: 0.4341\n",
      "Epoch 15/700\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.46591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 15: Train F1=0.3871 - Val F1=0.4235\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 15: Per-class metrics\n",
      "  Class 0: Precision=0.588 Recall=0.370\n",
      "  Class 1: Precision=0.426 Recall=0.897\n",
      "  Class 2: Precision=0.500 Recall=0.156\n",
      "  Macro Avg: Precision=0.505 Recall=0.474\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.3514 - loss: 1.2606 - val_accuracy: 0.4659 - val_loss: 1.2525 - train_f1_score: 0.3871 - val_f1_score: 0.4235\n",
      "Epoch 16/700\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.46591 to 0.50000, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train F1=0.4560 - Val F1=0.4966\n",
      "\n",
      "Saved best model at epoch 16 with val_f1=0.4966\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 16: Per-class metrics\n",
      "  Class 0: Precision=0.818 Recall=0.333\n",
      "  Class 1: Precision=0.472 Recall=0.586\n",
      "  Class 2: Precision=0.439 Recall=0.562\n",
      "  Macro Avg: Precision=0.576 Recall=0.494\n",
      "11/11 - 1s - 124ms/step - accuracy: 0.3543 - loss: 1.2543 - val_accuracy: 0.5000 - val_loss: 1.2459 - train_f1_score: 0.4560 - val_f1_score: 0.4966\n",
      "Epoch 17/700\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 17: Train F1=0.3908 - Val F1=0.3556\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 17: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.333\n",
      "  Class 1: Precision=0.500 Recall=0.034\n",
      "  Class 2: Precision=0.397 Recall=0.906\n",
      "  Macro Avg: Precision=0.530 Recall=0.425\n",
      "11/11 - 1s - 108ms/step - accuracy: 0.3914 - loss: 1.2448 - val_accuracy: 0.4432 - val_loss: 1.2393 - train_f1_score: 0.3908 - val_f1_score: 0.3556\n",
      "Epoch 18/700\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 18: Train F1=0.4289 - Val F1=0.4617\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 18: Per-class metrics\n",
      "  Class 0: Precision=0.889 Recall=0.296\n",
      "  Class 1: Precision=0.442 Recall=0.793\n",
      "  Class 2: Precision=0.407 Recall=0.344\n",
      "  Macro Avg: Precision=0.580 Recall=0.478\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.3200 - loss: 1.2581 - val_accuracy: 0.4773 - val_loss: 1.2334 - train_f1_score: 0.4289 - val_f1_score: 0.4617\n",
      "Epoch 19/700\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 19: Train F1=0.4151 - Val F1=0.4647\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 19: Per-class metrics\n",
      "  Class 0: Precision=0.857 Recall=0.222\n",
      "  Class 1: Precision=0.465 Recall=0.690\n",
      "  Class 2: Precision=0.447 Recall=0.531\n",
      "  Macro Avg: Precision=0.590 Recall=0.481\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.3714 - loss: 1.2419 - val_accuracy: 0.4886 - val_loss: 1.2282 - train_f1_score: 0.4151 - val_f1_score: 0.4647\n",
      "Epoch 20/700\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 20: Train F1=0.3808 - Val F1=0.3863\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 20: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.111\n",
      "  Class 1: Precision=0.422 Recall=0.931\n",
      "  Class 2: Precision=0.500 Recall=0.312\n",
      "  Macro Avg: Precision=0.557 Recall=0.452\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.4286 - loss: 1.2319 - val_accuracy: 0.4545 - val_loss: 1.2233 - train_f1_score: 0.3808 - val_f1_score: 0.3863\n",
      "Epoch 21/700\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 21: Train F1=0.2734 - Val F1=0.3375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 21: Per-class metrics\n",
      "  Class 0: Precision=0.833 Recall=0.185\n",
      "  Class 1: Precision=0.377 Recall=1.000\n",
      "  Class 2: Precision=0.600 Recall=0.094\n",
      "  Macro Avg: Precision=0.603 Recall=0.426\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.3600 - loss: 1.2414 - val_accuracy: 0.4205 - val_loss: 1.2209 - train_f1_score: 0.2734 - val_f1_score: 0.3375\n",
      "Epoch 22/700\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 22: Train F1=0.3040 - Val F1=0.3562\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 22: Per-class metrics\n",
      "  Class 0: Precision=0.857 Recall=0.222\n",
      "  Class 1: Precision=0.387 Recall=1.000\n",
      "  Class 2: Precision=0.500 Recall=0.094\n",
      "  Macro Avg: Precision=0.581 Recall=0.439\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.3514 - loss: 1.2411 - val_accuracy: 0.4318 - val_loss: 1.2151 - train_f1_score: 0.3040 - val_f1_score: 0.3562\n",
      "Epoch 23/700\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 23: Train F1=0.4153 - Val F1=0.3704\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 23: Per-class metrics\n",
      "  Class 0: Precision=0.550 Recall=0.407\n",
      "  Class 1: Precision=0.407 Recall=0.828\n",
      "  Class 2: Precision=0.222 Recall=0.062\n",
      "  Macro Avg: Precision=0.393 Recall=0.432\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.3371 - loss: 1.2347 - val_accuracy: 0.4205 - val_loss: 1.2131 - train_f1_score: 0.4153 - val_f1_score: 0.3704\n",
      "Epoch 24/700\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 24: Train F1=0.4034 - Val F1=0.3976\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 24: Per-class metrics\n",
      "  Class 0: Precision=0.833 Recall=0.185\n",
      "  Class 1: Precision=0.406 Recall=0.448\n",
      "  Class 2: Precision=0.380 Recall=0.594\n",
      "  Macro Avg: Precision=0.540 Recall=0.409\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.3657 - loss: 1.2268 - val_accuracy: 0.4205 - val_loss: 1.2102 - train_f1_score: 0.4034 - val_f1_score: 0.3976\n",
      "Epoch 25/700\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 25: Train F1=0.3587 - Val F1=0.3429\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 25: Per-class metrics\n",
      "  Class 0: Precision=1.000 Recall=0.074\n",
      "  Class 1: Precision=0.417 Recall=0.690\n",
      "  Class 2: Precision=0.342 Recall=0.406\n",
      "  Macro Avg: Precision=0.586 Recall=0.390\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.3229 - loss: 1.2252 - val_accuracy: 0.3977 - val_loss: 1.2093 - train_f1_score: 0.3587 - val_f1_score: 0.3429\n",
      "Epoch 26/700\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 26: Train F1=0.4273 - Val F1=0.4174\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 26: Per-class metrics\n",
      "  Class 0: Precision=0.857 Recall=0.222\n",
      "  Class 1: Precision=0.442 Recall=0.655\n",
      "  Class 2: Precision=0.342 Recall=0.406\n",
      "  Macro Avg: Precision=0.547 Recall=0.428\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.3343 - loss: 1.2241 - val_accuracy: 0.4318 - val_loss: 1.2019 - train_f1_score: 0.4273 - val_f1_score: 0.4174\n",
      "Epoch 27/700\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 27: Train F1=0.3965 - Val F1=0.4233\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 27: Per-class metrics\n",
      "  Class 0: Precision=0.857 Recall=0.222\n",
      "  Class 1: Precision=0.444 Recall=0.414\n",
      "  Class 2: Precision=0.389 Recall=0.656\n",
      "  Macro Avg: Precision=0.563 Recall=0.431\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.4114 - loss: 1.2076 - val_accuracy: 0.4432 - val_loss: 1.1964 - train_f1_score: 0.3965 - val_f1_score: 0.4233\n",
      "Epoch 28/700\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 28: Train F1=0.3336 - Val F1=0.3669\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 28: Per-class metrics\n",
      "  Class 0: Precision=0.875 Recall=0.259\n",
      "  Class 1: Precision=0.375 Recall=0.103\n",
      "  Class 2: Precision=0.389 Recall=0.875\n",
      "  Macro Avg: Precision=0.546 Recall=0.413\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.3371 - loss: 1.2137 - val_accuracy: 0.4318 - val_loss: 1.1923 - train_f1_score: 0.3336 - val_f1_score: 0.3669\n",
      "Epoch 29/700\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 29: Train F1=0.2767 - Val F1=0.2796\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 29: Per-class metrics\n",
      "  Class 0: Precision=0.833 Recall=0.185\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.375 Recall=0.938\n",
      "  Macro Avg: Precision=0.403 Recall=0.374\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.3457 - loss: 1.2094 - val_accuracy: 0.3977 - val_loss: 1.1891 - train_f1_score: 0.2767 - val_f1_score: 0.2796\n",
      "Epoch 30/700\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 30: Train F1=0.3117 - Val F1=0.2764\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 30: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.074\n",
      "  Class 1: Precision=0.300 Recall=0.103\n",
      "  Class 2: Precision=0.387 Recall=0.906\n",
      "  Macro Avg: Precision=0.451 Recall=0.361\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.3829 - loss: 1.2075 - val_accuracy: 0.3864 - val_loss: 1.1878 - train_f1_score: 0.3117 - val_f1_score: 0.2764\n",
      "Epoch 31/700\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 31: Train F1=0.2923 - Val F1=0.3305\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 31: Per-class metrics\n",
      "  Class 0: Precision=0.778 Recall=0.259\n",
      "  Class 1: Precision=0.250 Recall=0.034\n",
      "  Class 2: Precision=0.387 Recall=0.906\n",
      "  Macro Avg: Precision=0.471 Recall=0.400\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.3657 - loss: 1.2018 - val_accuracy: 0.4205 - val_loss: 1.1799 - train_f1_score: 0.2923 - val_f1_score: 0.3305\n",
      "Epoch 32/700\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 32: Train F1=0.3303 - Val F1=0.3651\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 32: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.411 Recall=0.938\n",
      "  Macro Avg: Precision=0.381 Recall=0.448\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.3543 - loss: 1.1943 - val_accuracy: 0.4659 - val_loss: 1.1758 - train_f1_score: 0.3303 - val_f1_score: 0.3651\n",
      "Epoch 33/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 33: Train F1=0.3006 - Val F1=0.3561\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 33: Per-class metrics\n",
      "  Class 0: Precision=0.833 Recall=0.370\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.395 Recall=0.938\n",
      "  Macro Avg: Precision=0.409 Recall=0.436\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.3543 - loss: 1.1977 - val_accuracy: 0.4545 - val_loss: 1.1729 - train_f1_score: 0.3006 - val_f1_score: 0.3561\n",
      "Epoch 34/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 34: Train F1=0.2424 - Val F1=0.3030\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 34: Per-class metrics\n",
      "  Class 0: Precision=0.833 Recall=0.185\n",
      "  Class 1: Precision=0.250 Recall=0.034\n",
      "  Class 2: Precision=0.385 Recall=0.938\n",
      "  Macro Avg: Precision=0.489 Recall=0.386\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.3743 - loss: 1.1882 - val_accuracy: 0.4091 - val_loss: 1.1748 - train_f1_score: 0.2424 - val_f1_score: 0.3030\n",
      "Epoch 35/700\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 35: Train F1=0.2314 - Val F1=0.2588\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 35: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.148\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.366 Recall=0.938\n",
      "  Macro Avg: Precision=0.389 Recall=0.362\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.4400 - loss: 1.1685 - val_accuracy: 0.3864 - val_loss: 1.1744 - train_f1_score: 0.2314 - val_f1_score: 0.2588\n",
      "Epoch 36/700\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 36: Train F1=0.2522 - Val F1=0.2929\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 36: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.222\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.375 Recall=0.938\n",
      "  Macro Avg: Precision=0.375 Recall=0.387\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.4543 - loss: 1.1732 - val_accuracy: 0.4091 - val_loss: 1.1669 - train_f1_score: 0.2522 - val_f1_score: 0.2929\n",
      "Epoch 37/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 37: Train F1=0.2281 - Val F1=0.2662\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 37: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.148\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.383 Recall=0.969\n",
      "  Macro Avg: Precision=0.394 Recall=0.372\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.3600 - loss: 1.1884 - val_accuracy: 0.3977 - val_loss: 1.1740 - train_f1_score: 0.2281 - val_f1_score: 0.2662\n",
      "Epoch 38/700\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 38: Train F1=0.3436 - Val F1=0.3716\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 38: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.333\n",
      "  Class 1: Precision=0.500 Recall=0.069\n",
      "  Class 2: Precision=0.394 Recall=0.875\n",
      "  Macro Avg: Precision=0.529 Recall=0.426\n",
      "11/11 - 1s - 109ms/step - accuracy: 0.4029 - loss: 1.1683 - val_accuracy: 0.4432 - val_loss: 1.1547 - train_f1_score: 0.3436 - val_f1_score: 0.3716\n",
      "Epoch 39/700\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 39: Train F1=0.2479 - Val F1=0.2619\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 39: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.148\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.375 Recall=0.938\n",
      "  Macro Avg: Precision=0.392 Recall=0.362\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.3943 - loss: 1.1759 - val_accuracy: 0.3864 - val_loss: 1.1702 - train_f1_score: 0.2479 - val_f1_score: 0.2619\n",
      "Epoch 40/700\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 40: Train F1=0.2810 - Val F1=0.3285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 40: Per-class metrics\n",
      "  Class 0: Precision=0.778 Recall=0.259\n",
      "  Class 1: Precision=0.500 Recall=0.034\n",
      "  Class 2: Precision=0.377 Recall=0.906\n",
      "  Macro Avg: Precision=0.551 Recall=0.400\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.4343 - loss: 1.1553 - val_accuracy: 0.4205 - val_loss: 1.1631 - train_f1_score: 0.2810 - val_f1_score: 0.3285\n",
      "Epoch 41/700\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 41: Train F1=0.2036 - Val F1=0.2448\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 41: Per-class metrics\n",
      "  Class 0: Precision=1.000 Recall=0.111\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.369 Recall=0.969\n",
      "  Macro Avg: Precision=0.456 Recall=0.360\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.4457 - loss: 1.1601 - val_accuracy: 0.3864 - val_loss: 1.1900 - train_f1_score: 0.2036 - val_f1_score: 0.2448\n",
      "Epoch 42/700\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 42: Train F1=0.2090 - Val F1=0.2184\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Epoch 42: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.074\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.361 Recall=0.938\n",
      "  Macro Avg: Precision=0.343 Recall=0.337\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.4514 - loss: 1.1485 - val_accuracy: 0.3636 - val_loss: 1.1964 - train_f1_score: 0.2090 - val_f1_score: 0.2184\n",
      "Epoch 43/700\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 43: Train F1=0.2153 - Val F1=0.2400\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 43: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.111\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.366 Recall=0.938\n",
      "  Macro Avg: Precision=0.372 Recall=0.350\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.4171 - loss: 1.1539 - val_accuracy: 0.3750 - val_loss: 1.2150 - train_f1_score: 0.2153 - val_f1_score: 0.2400\n",
      "Epoch 44/700\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 44: Train F1=0.2337 - Val F1=0.2480\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 44: Per-class metrics\n",
      "  Class 0: Precision=1.000 Recall=0.111\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.378 Recall=0.969\n",
      "  Macro Avg: Precision=0.459 Recall=0.360\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.4429 - loss: 1.1541 - val_accuracy: 0.3864 - val_loss: 1.2006 - train_f1_score: 0.2337 - val_f1_score: 0.2480\n",
      "Epoch 45/700\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 45: Train F1=0.3444 - Val F1=0.4218\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 45: Per-class metrics\n",
      "  Class 0: Precision=0.818 Recall=0.333\n",
      "  Class 1: Precision=0.667 Recall=0.138\n",
      "  Class 2: Precision=0.408 Recall=0.906\n",
      "  Macro Avg: Precision=0.631 Recall=0.459\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.4486 - loss: 1.1405 - val_accuracy: 0.4773 - val_loss: 1.1487 - train_f1_score: 0.3444 - val_f1_score: 0.4218\n",
      "Epoch 46/700\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 46: Train F1=0.3587 - Val F1=0.4418\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 46: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.296\n",
      "  Class 1: Precision=0.750 Recall=0.207\n",
      "  Class 2: Precision=0.414 Recall=0.906\n",
      "  Macro Avg: Precision=0.655 Recall=0.470\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.4686 - loss: 1.1438 - val_accuracy: 0.4886 - val_loss: 1.1505 - train_f1_score: 0.3587 - val_f1_score: 0.4418\n",
      "Epoch 47/700\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 47: Train F1=0.2639 - Val F1=0.3041\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 47: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.111\n",
      "  Class 1: Precision=0.333 Recall=0.103\n",
      "  Class 2: Precision=0.400 Recall=0.938\n",
      "  Macro Avg: Precision=0.494 Recall=0.384\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.4514 - loss: 1.1407 - val_accuracy: 0.4091 - val_loss: 1.1877 - train_f1_score: 0.2639 - val_f1_score: 0.3041\n",
      "Epoch 48/700\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 48: Train F1=0.1851 - Val F1=0.1797\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 48: Per-class metrics\n",
      "  Class 0: Precision=0.000 Recall=0.000\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.373 Recall=0.969\n",
      "  Macro Avg: Precision=0.124 Recall=0.323\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.4600 - loss: 1.1373 - val_accuracy: 0.3523 - val_loss: 1.2650 - train_f1_score: 0.1851 - val_f1_score: 0.1797\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 49: Train F1=0.2662 - Val F1=0.2431\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 49: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.111\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.375 Recall=0.938\n",
      "  Macro Avg: Precision=0.375 Recall=0.350\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.4429 - loss: 1.1317 - val_accuracy: 0.3750 - val_loss: 1.1956 - train_f1_score: 0.2662 - val_f1_score: 0.2431\n",
      "Epoch 50/700\n",
      "\n",
      "Epoch 50: val_accuracy improved from 0.50000 to 0.51136, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 50: Train F1=0.4122 - Val F1=0.4723\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 50: Per-class metrics\n",
      "  Class 0: Precision=0.688 Recall=0.407\n",
      "  Class 1: Precision=0.667 Recall=0.207\n",
      "  Class 2: Precision=0.444 Recall=0.875\n",
      "  Macro Avg: Precision=0.600 Recall=0.496\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.4657 - loss: 1.1198 - val_accuracy: 0.5114 - val_loss: 1.1258 - train_f1_score: 0.4122 - val_f1_score: 0.4723\n",
      "Epoch 51/700\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.51136\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 51: Train F1=0.4123 - Val F1=0.4304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 51: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.296\n",
      "  Class 1: Precision=0.500 Recall=0.207\n",
      "  Class 2: Precision=0.431 Recall=0.875\n",
      "  Macro Avg: Precision=0.553 Recall=0.459\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.4914 - loss: 1.1044 - val_accuracy: 0.4773 - val_loss: 1.1549 - train_f1_score: 0.4123 - val_f1_score: 0.4304\n",
      "Epoch 52/700\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.51136\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 52: Train F1=0.2153 - Val F1=0.2630\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 52: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.148\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.373 Recall=0.969\n",
      "  Macro Avg: Precision=0.391 Recall=0.372\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.4886 - loss: 1.1170 - val_accuracy: 0.3977 - val_loss: 1.2676 - train_f1_score: 0.2153 - val_f1_score: 0.2630\n",
      "Epoch 53/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.51136\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 53: Train F1=0.1972 - Val F1=0.1766\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 53: Per-class metrics\n",
      "  Class 0: Precision=0.000 Recall=0.000\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.365 Recall=0.969\n",
      "  Macro Avg: Precision=0.122 Recall=0.323\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.5086 - loss: 1.0937 - val_accuracy: 0.3523 - val_loss: 1.2857 - train_f1_score: 0.1972 - val_f1_score: 0.1766\n",
      "Epoch 54/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.51136\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 54: Train F1=0.3113 - Val F1=0.3179\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 54: Per-class metrics\n",
      "  Class 0: Precision=0.875 Recall=0.259\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.388 Recall=0.969\n",
      "  Macro Avg: Precision=0.421 Recall=0.409\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.5343 - loss: 1.1227 - val_accuracy: 0.4318 - val_loss: 1.2118 - train_f1_score: 0.3113 - val_f1_score: 0.3179\n",
      "Epoch 55/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/uottawa.o.univ/njaza024/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.51136\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 55: Train F1=0.3405 - Val F1=0.3390\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 55: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.222\n",
      "  Class 1: Precision=0.400 Recall=0.069\n",
      "  Class 2: Precision=0.405 Recall=0.938\n",
      "  Macro Avg: Precision=0.491 Recall=0.410\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.5086 - loss: 1.0978 - val_accuracy: 0.4318 - val_loss: 1.1631 - train_f1_score: 0.3405 - val_f1_score: 0.3390\n",
      "Epoch 56/700\n",
      "\n",
      "Epoch 56: val_accuracy improved from 0.51136 to 0.56818, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train F1=0.5969 - Val F1=0.5648\n",
      "\n",
      "Saved best model at epoch 56 with val_f1=0.5648\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 56: Per-class metrics\n",
      "  Class 0: Precision=0.567 Recall=0.630\n",
      "  Class 1: Precision=0.513 Recall=0.690\n",
      "  Class 2: Precision=0.684 Recall=0.406\n",
      "  Macro Avg: Precision=0.588 Recall=0.575\n",
      "11/11 - 1s - 102ms/step - accuracy: 0.4743 - loss: 1.1028 - val_accuracy: 0.5682 - val_loss: 1.0701 - train_f1_score: 0.5969 - val_f1_score: 0.5648\n",
      "Epoch 57/700\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.56818\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 57: Train F1=0.5851 - Val F1=0.5490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 57: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.565 Recall=0.448\n",
      "  Class 2: Precision=0.523 Recall=0.719\n",
      "  Macro Avg: Precision=0.569 Recall=0.550\n",
      "11/11 - 1s - 105ms/step - accuracy: 0.5629 - loss: 1.0727 - val_accuracy: 0.5568 - val_loss: 1.0855 - train_f1_score: 0.5851 - val_f1_score: 0.5490\n",
      "Epoch 58/700\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.56818\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 58: Train F1=0.4847 - Val F1=0.5051\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 58: Per-class metrics\n",
      "  Class 0: Precision=0.769 Recall=0.370\n",
      "  Class 1: Precision=0.562 Recall=0.310\n",
      "  Class 2: Precision=0.475 Recall=0.875\n",
      "  Macro Avg: Precision=0.602 Recall=0.519\n",
      "11/11 - 1s - 121ms/step - accuracy: 0.5514 - loss: 1.0927 - val_accuracy: 0.5341 - val_loss: 1.1132 - train_f1_score: 0.4847 - val_f1_score: 0.5051\n",
      "Epoch 59/700\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.56818\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 59: Train F1=0.6366 - Val F1=0.5627\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 59: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.444\n",
      "  Class 1: Precision=0.541 Recall=0.690\n",
      "  Class 2: Precision=0.581 Recall=0.562\n",
      "  Macro Avg: Precision=0.574 Recall=0.566\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.5429 - loss: 1.0621 - val_accuracy: 0.5682 - val_loss: 1.0586 - train_f1_score: 0.6366 - val_f1_score: 0.5627\n",
      "Epoch 60/700\n",
      "\n",
      "Epoch 60: val_accuracy improved from 0.56818 to 0.59091, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train F1=0.6202 - Val F1=0.5808\n",
      "\n",
      "Saved best model at epoch 60 with val_f1=0.5808\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 60: Per-class metrics\n",
      "  Class 0: Precision=0.647 Recall=0.407\n",
      "  Class 1: Precision=0.568 Recall=0.724\n",
      "  Class 2: Precision=0.588 Recall=0.625\n",
      "  Macro Avg: Precision=0.601 Recall=0.586\n",
      "11/11 - 1s - 123ms/step - accuracy: 0.5486 - loss: 1.0738 - val_accuracy: 0.5909 - val_loss: 1.0612 - train_f1_score: 0.6202 - val_f1_score: 0.5808\n",
      "Epoch 61/700\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 61: Train F1=0.5978 - Val F1=0.4918\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 61: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.333\n",
      "  Class 1: Precision=0.462 Recall=0.414\n",
      "  Class 2: Precision=0.500 Recall=0.750\n",
      "  Macro Avg: Precision=0.535 Recall=0.499\n",
      "11/11 - 1s - 107ms/step - accuracy: 0.5771 - loss: 1.0567 - val_accuracy: 0.5114 - val_loss: 1.0995 - train_f1_score: 0.5978 - val_f1_score: 0.4918\n",
      "Epoch 62/700\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 62: Train F1=0.6278 - Val F1=0.5026\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 62: Per-class metrics\n",
      "  Class 0: Precision=0.550 Recall=0.407\n",
      "  Class 1: Precision=0.481 Recall=0.448\n",
      "  Class 2: Precision=0.512 Recall=0.656\n",
      "  Macro Avg: Precision=0.515 Recall=0.504\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.5486 - loss: 1.0484 - val_accuracy: 0.5114 - val_loss: 1.0615 - train_f1_score: 0.6278 - val_f1_score: 0.5026\n",
      "Epoch 63/700\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 63: Train F1=0.6466 - Val F1=0.5468\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 63: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.370\n",
      "  Class 1: Precision=0.500 Recall=0.655\n",
      "  Class 2: Precision=0.571 Recall=0.625\n",
      "  Macro Avg: Precision=0.579 Recall=0.550\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.5457 - loss: 1.0407 - val_accuracy: 0.5568 - val_loss: 1.0649 - train_f1_score: 0.6466 - val_f1_score: 0.5468\n",
      "Epoch 64/700\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 64: Train F1=0.5832 - Val F1=0.5404\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 64: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.556\n",
      "  Class 1: Precision=0.556 Recall=0.345\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.556 Recall=0.550\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.5543 - loss: 1.0429 - val_accuracy: 0.5568 - val_loss: 1.0672 - train_f1_score: 0.5832 - val_f1_score: 0.5404\n",
      "Epoch 65/700\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 65: Train F1=0.6060 - Val F1=0.5156\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 65: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.455 Recall=0.345\n",
      "  Class 2: Precision=0.532 Recall=0.781\n",
      "  Macro Avg: Precision=0.539 Recall=0.524\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.5829 - loss: 1.0194 - val_accuracy: 0.5341 - val_loss: 1.1077 - train_f1_score: 0.6060 - val_f1_score: 0.5156\n",
      "Epoch 66/700\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 66: Train F1=0.5618 - Val F1=0.5483\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 66: Per-class metrics\n",
      "  Class 0: Precision=0.565 Recall=0.481\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.570 Recall=0.558\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.5971 - loss: 1.0021 - val_accuracy: 0.5682 - val_loss: 1.1342 - train_f1_score: 0.5618 - val_f1_score: 0.5483\n",
      "Epoch 67/700\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 67: Train F1=0.5827 - Val F1=0.4872\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 67: Per-class metrics\n",
      "  Class 0: Precision=0.542 Recall=0.481\n",
      "  Class 1: Precision=0.396 Recall=0.655\n",
      "  Class 2: Precision=0.688 Recall=0.344\n",
      "  Macro Avg: Precision=0.542 Recall=0.493\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.6257 - loss: 0.9886 - val_accuracy: 0.4886 - val_loss: 1.1566 - train_f1_score: 0.5827 - val_f1_score: 0.4872\n",
      "Epoch 68/700\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 68: Train F1=0.5968 - Val F1=0.5085\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 68: Per-class metrics\n",
      "  Class 0: Precision=0.463 Recall=0.704\n",
      "  Class 1: Precision=0.452 Recall=0.483\n",
      "  Class 2: Precision=0.750 Recall=0.375\n",
      "  Macro Avg: Precision=0.555 Recall=0.520\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.6057 - loss: 1.0157 - val_accuracy: 0.5114 - val_loss: 1.0870 - train_f1_score: 0.5968 - val_f1_score: 0.5085\n",
      "Epoch 69/700\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 69: Train F1=0.5016 - Val F1=0.4172\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 69: Per-class metrics\n",
      "  Class 0: Precision=0.390 Recall=0.593\n",
      "  Class 1: Precision=0.353 Recall=0.414\n",
      "  Class 2: Precision=0.692 Recall=0.281\n",
      "  Macro Avg: Precision=0.478 Recall=0.429\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.6200 - loss: 0.9718 - val_accuracy: 0.4205 - val_loss: 1.1703 - train_f1_score: 0.5016 - val_f1_score: 0.4172\n",
      "Epoch 70/700\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 70: Train F1=0.6952 - Val F1=0.5612\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 70: Per-class metrics\n",
      "  Class 0: Precision=0.545 Recall=0.444\n",
      "  Class 1: Precision=0.531 Recall=0.586\n",
      "  Class 2: Precision=0.618 Recall=0.656\n",
      "  Macro Avg: Precision=0.565 Recall=0.562\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.6257 - loss: 0.9828 - val_accuracy: 0.5682 - val_loss: 1.0446 - train_f1_score: 0.6952 - val_f1_score: 0.5612\n",
      "Epoch 71/700\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 71: Train F1=0.6355 - Val F1=0.5076\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 71: Per-class metrics\n",
      "  Class 0: Precision=0.647 Recall=0.407\n",
      "  Class 1: Precision=0.440 Recall=0.379\n",
      "  Class 2: Precision=0.522 Recall=0.750\n",
      "  Macro Avg: Precision=0.536 Recall=0.512\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.6343 - loss: 0.9886 - val_accuracy: 0.5227 - val_loss: 1.1583 - train_f1_score: 0.6355 - val_f1_score: 0.5076\n",
      "Epoch 72/700\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 72: Train F1=0.7285 - Val F1=0.5615\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 72: Per-class metrics\n",
      "  Class 0: Precision=0.529 Recall=0.333\n",
      "  Class 1: Precision=0.524 Recall=0.759\n",
      "  Class 2: Precision=0.690 Recall=0.625\n",
      "  Macro Avg: Precision=0.581 Recall=0.572\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.6514 - loss: 0.9647 - val_accuracy: 0.5795 - val_loss: 1.0468 - train_f1_score: 0.7285 - val_f1_score: 0.5615\n",
      "Epoch 73/700\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 73: Train F1=0.7160 - Val F1=0.5221\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 73: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.444\n",
      "  Class 1: Precision=0.500 Recall=0.414\n",
      "  Class 2: Precision=0.535 Recall=0.719\n",
      "  Macro Avg: Precision=0.535 Recall=0.526\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.6686 - loss: 0.9429 - val_accuracy: 0.5341 - val_loss: 1.0878 - train_f1_score: 0.7160 - val_f1_score: 0.5221\n",
      "Epoch 74/700\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.59091\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 74: Train F1=0.5173 - Val F1=0.4609\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 74: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.556 Recall=0.172\n",
      "  Class 2: Precision=0.448 Recall=0.812\n",
      "  Macro Avg: Precision=0.541 Recall=0.489\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.6229 - loss: 0.9823 - val_accuracy: 0.5000 - val_loss: 1.2142 - train_f1_score: 0.5173 - val_f1_score: 0.4609\n",
      "Epoch 75/700\n",
      "\n",
      "Epoch 75: val_accuracy improved from 0.59091 to 0.60227, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train F1=0.7290 - Val F1=0.5910\n",
      "\n",
      "Saved best model at epoch 75 with val_f1=0.5910\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 75: Per-class metrics\n",
      "  Class 0: Precision=0.647 Recall=0.407\n",
      "  Class 1: Precision=0.553 Recall=0.724\n",
      "  Class 2: Precision=0.636 Recall=0.656\n",
      "  Macro Avg: Precision=0.612 Recall=0.596\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.6171 - loss: 0.9672 - val_accuracy: 0.6023 - val_loss: 1.0903 - train_f1_score: 0.7290 - val_f1_score: 0.5910\n",
      "Epoch 76/700\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.60227\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 76: Train F1=0.7007 - Val F1=0.5907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 76: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.593\n",
      "  Class 1: Precision=0.548 Recall=0.586\n",
      "  Class 2: Precision=0.704 Recall=0.594\n",
      "  Macro Avg: Precision=0.595 Recall=0.591\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.6600 - loss: 0.9581 - val_accuracy: 0.5909 - val_loss: 1.0287 - train_f1_score: 0.7007 - val_f1_score: 0.5907\n",
      "Epoch 77/700\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.60227\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 77: Train F1=0.5097 - Val F1=0.4506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 77: Per-class metrics\n",
      "  Class 0: Precision=0.444 Recall=0.593\n",
      "  Class 1: Precision=0.375 Recall=0.517\n",
      "  Class 2: Precision=0.750 Recall=0.281\n",
      "  Macro Avg: Precision=0.523 Recall=0.464\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.6714 - loss: 0.9075 - val_accuracy: 0.4545 - val_loss: 1.1623 - train_f1_score: 0.5097 - val_f1_score: 0.4506\n",
      "Epoch 78/700\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.60227\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 78: Train F1=0.6240 - Val F1=0.5269\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 78: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.370\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.481 Recall=0.812\n",
      "  Macro Avg: Precision=0.593 Recall=0.532\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.6571 - loss: 0.9596 - val_accuracy: 0.5455 - val_loss: 1.1951 - train_f1_score: 0.6240 - val_f1_score: 0.5269\n",
      "Epoch 79/700\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.60227\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 79: Train F1=0.6507 - Val F1=0.4949\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 79: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.296\n",
      "  Class 1: Precision=0.571 Recall=0.414\n",
      "  Class 2: Precision=0.481 Recall=0.812\n",
      "  Macro Avg: Precision=0.556 Recall=0.508\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.6800 - loss: 0.9405 - val_accuracy: 0.5227 - val_loss: 1.2469 - train_f1_score: 0.6507 - val_f1_score: 0.4949\n",
      "Epoch 80/700\n",
      "\n",
      "Epoch 80: val_accuracy improved from 0.60227 to 0.62500, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train F1=0.7316 - Val F1=0.6239\n",
      "\n",
      "Saved best model at epoch 80 with val_f1=0.6239\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 80: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.600 Recall=0.621\n",
      "  Class 2: Precision=0.636 Recall=0.656\n",
      "  Macro Avg: Precision=0.625 Recall=0.623\n",
      "11/11 - 1s - 124ms/step - accuracy: 0.6971 - loss: 0.9076 - val_accuracy: 0.6250 - val_loss: 1.0387 - train_f1_score: 0.7316 - val_f1_score: 0.6239\n",
      "Epoch 81/700\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train F1=0.7962 - Val F1=0.6248\n",
      "\n",
      "Saved best model at epoch 81 with val_f1=0.6248\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 81: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.567 Recall=0.586\n",
      "  Class 2: Precision=0.714 Recall=0.625\n",
      "  Macro Avg: Precision=0.627 Recall=0.626\n",
      "11/11 - 1s - 98ms/step - accuracy: 0.6914 - loss: 0.9084 - val_accuracy: 0.6250 - val_loss: 1.0346 - train_f1_score: 0.7962 - val_f1_score: 0.6248\n",
      "Epoch 82/700\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 82: Train F1=0.7230 - Val F1=0.5183\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 82: Per-class metrics\n",
      "  Class 0: Precision=0.591 Recall=0.481\n",
      "  Class 1: Precision=0.526 Recall=0.345\n",
      "  Class 2: Precision=0.511 Recall=0.750\n",
      "  Macro Avg: Precision=0.543 Recall=0.525\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.7143 - loss: 0.8672 - val_accuracy: 0.5341 - val_loss: 1.1898 - train_f1_score: 0.7230 - val_f1_score: 0.5183\n",
      "Epoch 83/700\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 83: Train F1=0.7058 - Val F1=0.5530\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 83: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.588 Recall=0.345\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.575 Recall=0.562\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.7086 - loss: 0.8743 - val_accuracy: 0.5682 - val_loss: 1.1743 - train_f1_score: 0.7058 - val_f1_score: 0.5530\n",
      "Epoch 84/700\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 84: Train F1=0.7032 - Val F1=0.5588\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 84: Per-class metrics\n",
      "  Class 0: Precision=0.531 Recall=0.630\n",
      "  Class 1: Precision=0.472 Recall=0.586\n",
      "  Class 2: Precision=0.750 Recall=0.469\n",
      "  Macro Avg: Precision=0.584 Recall=0.562\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.6914 - loss: 0.8856 - val_accuracy: 0.5568 - val_loss: 1.1005 - train_f1_score: 0.7032 - val_f1_score: 0.5588\n",
      "Epoch 85/700\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 85: Train F1=0.8237 - Val F1=0.5969\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 85: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.500 Recall=0.414\n",
      "  Class 2: Precision=0.611 Recall=0.688\n",
      "  Macro Avg: Precision=0.597 Recall=0.602\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.7143 - loss: 0.8652 - val_accuracy: 0.6023 - val_loss: 1.0485 - train_f1_score: 0.8237 - val_f1_score: 0.5969\n",
      "Epoch 86/700\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 86: Train F1=0.6802 - Val F1=0.4962\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 86: Per-class metrics\n",
      "  Class 0: Precision=0.524 Recall=0.407\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.491 Recall=0.812\n",
      "  Macro Avg: Precision=0.552 Recall=0.510\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.7400 - loss: 0.8362 - val_accuracy: 0.5227 - val_loss: 1.1697 - train_f1_score: 0.6802 - val_f1_score: 0.4962\n",
      "Epoch 87/700\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 87: Train F1=0.4365 - Val F1=0.4155\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 87: Per-class metrics\n",
      "  Class 0: Precision=0.441 Recall=0.556\n",
      "  Class 1: Precision=0.500 Recall=0.138\n",
      "  Class 2: Precision=0.457 Recall=0.656\n",
      "  Macro Avg: Precision=0.466 Recall=0.450\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.7429 - loss: 0.8274 - val_accuracy: 0.4545 - val_loss: 1.3548 - train_f1_score: 0.4365 - val_f1_score: 0.4155\n",
      "Epoch 88/700\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 88: Train F1=0.4503 - Val F1=0.4071\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 88: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.519\n",
      "  Class 1: Precision=0.500 Recall=0.069\n",
      "  Class 2: Precision=0.464 Recall=0.812\n",
      "  Macro Avg: Precision=0.488 Recall=0.467\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.7429 - loss: 0.8382 - val_accuracy: 0.4773 - val_loss: 1.4482 - train_f1_score: 0.4503 - val_f1_score: 0.4071\n",
      "Epoch 89/700\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 89: Train F1=0.7995 - Val F1=0.6011\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 89: Per-class metrics\n",
      "  Class 0: Precision=0.647 Recall=0.407\n",
      "  Class 1: Precision=0.564 Recall=0.759\n",
      "  Class 2: Precision=0.656 Recall=0.656\n",
      "  Macro Avg: Precision=0.622 Recall=0.607\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.7486 - loss: 0.8308 - val_accuracy: 0.6136 - val_loss: 1.0330 - train_f1_score: 0.7995 - val_f1_score: 0.6011\n",
      "Epoch 90/700\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 90: Train F1=0.7255 - Val F1=0.5147\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 90: Per-class metrics\n",
      "  Class 0: Precision=0.545 Recall=0.444\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.500 Recall=0.781\n",
      "  Macro Avg: Precision=0.557 Recall=0.524\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.7800 - loss: 0.7997 - val_accuracy: 0.5341 - val_loss: 1.2276 - train_f1_score: 0.7255 - val_f1_score: 0.5147\n",
      "Epoch 91/700\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 91: Train F1=0.7181 - Val F1=0.5161\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 91: Per-class metrics\n",
      "  Class 0: Precision=0.650 Recall=0.481\n",
      "  Class 1: Precision=0.562 Recall=0.310\n",
      "  Class 2: Precision=0.481 Recall=0.781\n",
      "  Macro Avg: Precision=0.564 Recall=0.524\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.7743 - loss: 0.8346 - val_accuracy: 0.5341 - val_loss: 1.2656 - train_f1_score: 0.7181 - val_f1_score: 0.5161\n",
      "Epoch 92/700\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 92: Train F1=0.6645 - Val F1=0.4978\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 92: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.562 Recall=0.310\n",
      "  Class 2: Precision=0.481 Recall=0.812\n",
      "  Macro Avg: Precision=0.552 Recall=0.510\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.7429 - loss: 0.8129 - val_accuracy: 0.5227 - val_loss: 1.3507 - train_f1_score: 0.6645 - val_f1_score: 0.4978\n",
      "Epoch 93/700\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 93: Train F1=0.6378 - Val F1=0.4749\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 93: Per-class metrics\n",
      "  Class 0: Precision=0.565 Recall=0.481\n",
      "  Class 1: Precision=0.538 Recall=0.241\n",
      "  Class 2: Precision=0.462 Recall=0.750\n",
      "  Macro Avg: Precision=0.522 Recall=0.491\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.7714 - loss: 0.8159 - val_accuracy: 0.5000 - val_loss: 1.3159 - train_f1_score: 0.6378 - val_f1_score: 0.4749\n",
      "Epoch 94/700\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 94: Train F1=0.3923 - Val F1=0.3779\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 94: Per-class metrics\n",
      "  Class 0: Precision=0.358 Recall=0.704\n",
      "  Class 1: Precision=0.444 Recall=0.138\n",
      "  Class 2: Precision=0.500 Recall=0.406\n",
      "  Macro Avg: Precision=0.434 Recall=0.416\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.7714 - loss: 0.7914 - val_accuracy: 0.4091 - val_loss: 1.4071 - train_f1_score: 0.3923 - val_f1_score: 0.3779\n",
      "Epoch 95/700\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 95: Train F1=0.6804 - Val F1=0.4744\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 95: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.333\n",
      "  Class 1: Precision=0.455 Recall=0.345\n",
      "  Class 2: Precision=0.490 Recall=0.781\n",
      "  Macro Avg: Precision=0.515 Recall=0.486\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.7829 - loss: 0.7639 - val_accuracy: 0.5000 - val_loss: 1.3264 - train_f1_score: 0.6804 - val_f1_score: 0.4744\n",
      "Epoch 96/700\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 96: Train F1=0.4233 - Val F1=0.4080\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 96: Per-class metrics\n",
      "  Class 0: Precision=0.439 Recall=0.667\n",
      "  Class 1: Precision=0.286 Recall=0.069\n",
      "  Class 2: Precision=0.525 Recall=0.656\n",
      "  Macro Avg: Precision=0.417 Recall=0.464\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.8143 - loss: 0.7439 - val_accuracy: 0.4659 - val_loss: 1.4458 - train_f1_score: 0.4233 - val_f1_score: 0.4080\n",
      "Epoch 97/700\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 97: Train F1=0.3225 - Val F1=0.3010\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 97: Per-class metrics\n",
      "  Class 0: Precision=0.333 Recall=0.778\n",
      "  Class 1: Precision=0.000 Recall=0.000\n",
      "  Class 2: Precision=0.522 Recall=0.375\n",
      "  Macro Avg: Precision=0.285 Recall=0.384\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.7714 - loss: 0.7965 - val_accuracy: 0.3750 - val_loss: 1.5390 - train_f1_score: 0.3225 - val_f1_score: 0.3010\n",
      "Epoch 98/700\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 98: Train F1=0.5261 - Val F1=0.4921\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 98: Per-class metrics\n",
      "  Class 0: Precision=0.475 Recall=0.704\n",
      "  Class 1: Precision=0.625 Recall=0.172\n",
      "  Class 2: Precision=0.575 Recall=0.719\n",
      "  Macro Avg: Precision=0.558 Recall=0.532\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.8029 - loss: 0.7474 - val_accuracy: 0.5341 - val_loss: 1.3445 - train_f1_score: 0.5261 - val_f1_score: 0.4921\n",
      "Epoch 99/700\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 99: Train F1=0.5615 - Val F1=0.4660\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 99: Per-class metrics\n",
      "  Class 0: Precision=0.400 Recall=0.444\n",
      "  Class 1: Precision=0.533 Recall=0.276\n",
      "  Class 2: Precision=0.535 Recall=0.719\n",
      "  Macro Avg: Precision=0.489 Recall=0.480\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.8000 - loss: 0.7487 - val_accuracy: 0.4886 - val_loss: 1.3308 - train_f1_score: 0.5615 - val_f1_score: 0.4660\n",
      "Epoch 100/700\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 100: Train F1=0.7834 - Val F1=0.5638\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 100: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.444\n",
      "  Class 1: Precision=0.478 Recall=0.759\n",
      "  Class 2: Precision=0.667 Recall=0.500\n",
      "  Macro Avg: Precision=0.604 Recall=0.568\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8229 - loss: 0.7633 - val_accuracy: 0.5682 - val_loss: 1.1593 - train_f1_score: 0.7834 - val_f1_score: 0.5638\n",
      "Epoch 101/700\n",
      "\n",
      "Epoch 101: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 101: Train F1=0.7222 - Val F1=0.4724\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 101: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.593\n",
      "  Class 1: Precision=0.556 Recall=0.172\n",
      "  Class 2: Precision=0.490 Recall=0.750\n",
      "  Macro Avg: Precision=0.526 Recall=0.505\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.8086 - loss: 0.7791 - val_accuracy: 0.5114 - val_loss: 1.3103 - train_f1_score: 0.7222 - val_f1_score: 0.4724\n",
      "Epoch 102/700\n",
      "\n",
      "Epoch 102: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 102: Train F1=0.8409 - Val F1=0.6196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 102: Per-class metrics\n",
      "  Class 0: Precision=0.650 Recall=0.481\n",
      "  Class 1: Precision=0.535 Recall=0.793\n",
      "  Class 2: Precision=0.760 Recall=0.594\n",
      "  Macro Avg: Precision=0.648 Recall=0.623\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.7857 - loss: 0.7798 - val_accuracy: 0.6250 - val_loss: 1.0666 - train_f1_score: 0.8409 - val_f1_score: 0.6196\n",
      "Epoch 103/700\n",
      "\n",
      "Epoch 103: val_accuracy did not improve from 0.62500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 103: Train F1=0.8171 - Val F1=0.5840\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 103: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.733 Recall=0.379\n",
      "  Class 2: Precision=0.511 Recall=0.719\n",
      "  Macro Avg: Precision=0.629 Recall=0.588\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8229 - loss: 0.7193 - val_accuracy: 0.5909 - val_loss: 1.1444 - train_f1_score: 0.8171 - val_f1_score: 0.5840\n",
      "Epoch 104/700\n",
      "\n",
      "Epoch 104: val_accuracy improved from 0.62500 to 0.65909, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104: Train F1=0.9046 - Val F1=0.6587\n",
      "\n",
      "Saved best model at epoch 104 with val_f1=0.6587\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 104: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.600 Recall=0.724\n",
      "  Class 2: Precision=0.677 Recall=0.656\n",
      "  Macro Avg: Precision=0.668 Recall=0.658\n",
      "11/11 - 1s - 122ms/step - accuracy: 0.8571 - loss: 0.6956 - val_accuracy: 0.6591 - val_loss: 1.0738 - train_f1_score: 0.9046 - val_f1_score: 0.6587\n",
      "Epoch 105/700\n",
      "\n",
      "Epoch 105: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 105: Train F1=0.8569 - Val F1=0.6076\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 105: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.778\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.645 Recall=0.624\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.8200 - loss: 0.7320 - val_accuracy: 0.6250 - val_loss: 1.1130 - train_f1_score: 0.8569 - val_f1_score: 0.6076\n",
      "Epoch 106/700\n",
      "\n",
      "Epoch 106: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 106: Train F1=0.6386 - Val F1=0.4747\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 106: Per-class metrics\n",
      "  Class 0: Precision=0.462 Recall=0.444\n",
      "  Class 1: Precision=0.533 Recall=0.276\n",
      "  Class 2: Precision=0.511 Recall=0.750\n",
      "  Macro Avg: Precision=0.502 Recall=0.490\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.8171 - loss: 0.7187 - val_accuracy: 0.5000 - val_loss: 1.3600 - train_f1_score: 0.6386 - val_f1_score: 0.4747\n",
      "Epoch 107/700\n",
      "\n",
      "Epoch 107: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 107: Train F1=0.5847 - Val F1=0.3889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 107: Per-class metrics\n",
      "  Class 0: Precision=0.370 Recall=0.630\n",
      "  Class 1: Precision=0.500 Recall=0.138\n",
      "  Class 2: Precision=0.471 Recall=0.500\n",
      "  Macro Avg: Precision=0.447 Recall=0.423\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8743 - loss: 0.6839 - val_accuracy: 0.4205 - val_loss: 1.3346 - train_f1_score: 0.5847 - val_f1_score: 0.3889\n",
      "Epoch 108/700\n",
      "\n",
      "Epoch 108: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 108: Train F1=0.7677 - Val F1=0.4810\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 108: Per-class metrics\n",
      "  Class 0: Precision=0.520 Recall=0.481\n",
      "  Class 1: Precision=0.538 Recall=0.241\n",
      "  Class 2: Precision=0.500 Recall=0.781\n",
      "  Macro Avg: Precision=0.519 Recall=0.501\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.8829 - loss: 0.6595 - val_accuracy: 0.5114 - val_loss: 1.3051 - train_f1_score: 0.7677 - val_f1_score: 0.4810\n",
      "Epoch 109/700\n",
      "\n",
      "Epoch 109: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 109: Train F1=0.7213 - Val F1=0.5442\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 109: Per-class metrics\n",
      "  Class 0: Precision=0.517 Recall=0.556\n",
      "  Class 1: Precision=0.550 Recall=0.379\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.552 Recall=0.551\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8514 - loss: 0.7016 - val_accuracy: 0.5568 - val_loss: 1.2505 - train_f1_score: 0.7213 - val_f1_score: 0.5442\n",
      "Epoch 110/700\n",
      "\n",
      "Epoch 110: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 110: Train F1=0.7319 - Val F1=0.5164\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 110: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.636 Recall=0.241\n",
      "  Class 2: Precision=0.510 Recall=0.781\n",
      "  Macro Avg: Precision=0.573 Recall=0.538\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.8200 - loss: 0.7313 - val_accuracy: 0.5455 - val_loss: 1.2753 - train_f1_score: 0.7319 - val_f1_score: 0.5164\n",
      "Epoch 111/700\n",
      "\n",
      "Epoch 111: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 111: Train F1=0.3519 - Val F1=0.3164\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 111: Per-class metrics\n",
      "  Class 0: Precision=0.327 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.034\n",
      "  Class 2: Precision=0.432 Recall=0.500\n",
      "  Macro Avg: Precision=0.420 Recall=0.376\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.8486 - loss: 0.7083 - val_accuracy: 0.3750 - val_loss: 1.5308 - train_f1_score: 0.3519 - val_f1_score: 0.3164\n",
      "Epoch 112/700\n",
      "\n",
      "Epoch 112: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 112: Train F1=0.7748 - Val F1=0.5325\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 112: Per-class metrics\n",
      "  Class 0: Precision=0.560 Recall=0.519\n",
      "  Class 1: Precision=0.600 Recall=0.310\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.567 Recall=0.547\n",
      "11/11 - 1s - 108ms/step - accuracy: 0.8600 - loss: 0.6666 - val_accuracy: 0.5568 - val_loss: 1.2941 - train_f1_score: 0.7748 - val_f1_score: 0.5325\n",
      "Epoch 113/700\n",
      "\n",
      "Epoch 113: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 113: Train F1=0.4234 - Val F1=0.4168\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 113: Per-class metrics\n",
      "  Class 0: Precision=0.388 Recall=0.704\n",
      "  Class 1: Precision=0.800 Recall=0.138\n",
      "  Class 2: Precision=0.500 Recall=0.531\n",
      "  Macro Avg: Precision=0.563 Recall=0.458\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.8600 - loss: 0.6606 - val_accuracy: 0.4545 - val_loss: 1.5022 - train_f1_score: 0.4234 - val_f1_score: 0.4168\n",
      "Epoch 114/700\n",
      "\n",
      "Epoch 114: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 114: Train F1=0.6737 - Val F1=0.5592\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 114: Per-class metrics\n",
      "  Class 0: Precision=0.579 Recall=0.815\n",
      "  Class 1: Precision=0.667 Recall=0.207\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.618 Recall=0.601\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.8686 - loss: 0.6575 - val_accuracy: 0.6023 - val_loss: 1.3306 - train_f1_score: 0.6737 - val_f1_score: 0.5592\n",
      "Epoch 115/700\n",
      "\n",
      "Epoch 115: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 115: Train F1=0.6737 - Val F1=0.4229\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 115: Per-class metrics\n",
      "  Class 0: Precision=0.405 Recall=0.556\n",
      "  Class 1: Precision=0.462 Recall=0.207\n",
      "  Class 2: Precision=0.474 Recall=0.562\n",
      "  Macro Avg: Precision=0.447 Recall=0.442\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.8629 - loss: 0.6734 - val_accuracy: 0.4432 - val_loss: 1.3901 - train_f1_score: 0.6737 - val_f1_score: 0.4229\n",
      "Epoch 116/700\n",
      "\n",
      "Epoch 116: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 116: Train F1=0.5937 - Val F1=0.4180\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 116: Per-class metrics\n",
      "  Class 0: Precision=0.391 Recall=0.667\n",
      "  Class 1: Precision=0.583 Recall=0.241\n",
      "  Class 2: Precision=0.433 Recall=0.406\n",
      "  Macro Avg: Precision=0.469 Recall=0.438\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.8800 - loss: 0.6449 - val_accuracy: 0.4318 - val_loss: 1.4411 - train_f1_score: 0.5937 - val_f1_score: 0.4180\n",
      "Epoch 117/700\n",
      "\n",
      "Epoch 117: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 117: Train F1=0.3917 - Val F1=0.3307\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 117: Per-class metrics\n",
      "  Class 0: Precision=0.344 Recall=0.815\n",
      "  Class 1: Precision=0.667 Recall=0.138\n",
      "  Class 2: Precision=0.389 Recall=0.219\n",
      "  Macro Avg: Precision=0.466 Recall=0.390\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8771 - loss: 0.6455 - val_accuracy: 0.3750 - val_loss: 1.5452 - train_f1_score: 0.3917 - val_f1_score: 0.3307\n",
      "Epoch 118/700\n",
      "\n",
      "Epoch 118: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 118: Train F1=0.6412 - Val F1=0.4520\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 118: Per-class metrics\n",
      "  Class 0: Precision=0.432 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.207\n",
      "  Class 2: Precision=0.513 Recall=0.625\n",
      "  Macro Avg: Precision=0.482 Recall=0.475\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.8943 - loss: 0.6357 - val_accuracy: 0.4773 - val_loss: 1.4277 - train_f1_score: 0.6412 - val_f1_score: 0.4520\n",
      "Epoch 119/700\n",
      "\n",
      "Epoch 119: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 119: Train F1=0.7855 - Val F1=0.5049\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 119: Per-class metrics\n",
      "  Class 0: Precision=0.488 Recall=0.741\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.529 Recall=0.562\n",
      "  Macro Avg: Precision=0.544 Recall=0.526\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.8800 - loss: 0.6656 - val_accuracy: 0.5227 - val_loss: 1.2982 - train_f1_score: 0.7855 - val_f1_score: 0.5049\n",
      "Epoch 120/700\n",
      "\n",
      "Epoch 120: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 120: Train F1=0.8891 - Val F1=0.6163\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 120: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.778\n",
      "  Class 1: Precision=0.667 Recall=0.345\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.643 Recall=0.635\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.8829 - loss: 0.6241 - val_accuracy: 0.6364 - val_loss: 1.1937 - train_f1_score: 0.8891 - val_f1_score: 0.6163\n",
      "Epoch 121/700\n",
      "\n",
      "Epoch 121: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 121: Train F1=0.5552 - Val F1=0.3948\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 121: Per-class metrics\n",
      "  Class 0: Precision=0.412 Recall=0.778\n",
      "  Class 1: Precision=0.400 Recall=0.138\n",
      "  Class 2: Precision=0.481 Recall=0.406\n",
      "  Macro Avg: Precision=0.431 Recall=0.441\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.8829 - loss: 0.6353 - val_accuracy: 0.4318 - val_loss: 1.4055 - train_f1_score: 0.5552 - val_f1_score: 0.3948\n",
      "Epoch 122/700\n",
      "\n",
      "Epoch 122: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 122: Train F1=0.9461 - Val F1=0.6467\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 122: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.655 Recall=0.646\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9000 - loss: 0.5846 - val_accuracy: 0.6477 - val_loss: 1.0237 - train_f1_score: 0.9461 - val_f1_score: 0.6467\n",
      "Epoch 123/700\n",
      "\n",
      "Epoch 123: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 123: Train F1=0.9395 - Val F1=0.6560\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 123: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.666 Recall=0.655\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9143 - loss: 0.5939 - val_accuracy: 0.6591 - val_loss: 1.0506 - train_f1_score: 0.9395 - val_f1_score: 0.6560\n",
      "Epoch 124/700\n",
      "\n",
      "Epoch 124: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 124: Train F1=0.8386 - Val F1=0.6454\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 124: Per-class metrics\n",
      "  Class 0: Precision=0.629 Recall=0.815\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.667 Recall=0.500\n",
      "  Macro Avg: Precision=0.650 Recall=0.657\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.8800 - loss: 0.6441 - val_accuracy: 0.6477 - val_loss: 1.0811 - train_f1_score: 0.8386 - val_f1_score: 0.6454\n",
      "Epoch 125/700\n",
      "\n",
      "Epoch 125: val_accuracy did not improve from 0.65909\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 125: Train F1=0.8947 - Val F1=0.6138\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 125: Per-class metrics\n",
      "  Class 0: Precision=0.559 Recall=0.704\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.613 Recall=0.594\n",
      "  Macro Avg: Precision=0.622 Recall=0.616\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.8971 - loss: 0.6180 - val_accuracy: 0.6136 - val_loss: 1.0794 - train_f1_score: 0.8947 - val_f1_score: 0.6138\n",
      "Epoch 126/700\n",
      "\n",
      "Epoch 126: val_accuracy improved from 0.65909 to 0.68182, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Train F1=0.9428 - Val F1=0.6794\n",
      "\n",
      "Saved best model at epoch 126 with val_f1=0.6794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 126: Per-class metrics\n",
      "  Class 0: Precision=0.688 Recall=0.815\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.683 Recall=0.685\n",
      "11/11 - 1s - 125ms/step - accuracy: 0.8914 - loss: 0.6396 - val_accuracy: 0.6818 - val_loss: 1.0544 - train_f1_score: 0.9428 - val_f1_score: 0.6794\n",
      "Epoch 127/700\n",
      "\n",
      "Epoch 127: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 127: Train F1=0.8488 - Val F1=0.5639\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 127: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.597 Recall=0.569\n",
      "11/11 - 1s - 108ms/step - accuracy: 0.9086 - loss: 0.6365 - val_accuracy: 0.5795 - val_loss: 1.2074 - train_f1_score: 0.8488 - val_f1_score: 0.5639\n",
      "Epoch 128/700\n",
      "\n",
      "Epoch 128: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 128: Train F1=0.8289 - Val F1=0.5735\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 128: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.741\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.633 Recall=0.594\n",
      "  Macro Avg: Precision=0.600 Recall=0.583\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.8714 - loss: 0.6486 - val_accuracy: 0.5795 - val_loss: 1.1850 - train_f1_score: 0.8289 - val_f1_score: 0.5735\n",
      "Epoch 129/700\n",
      "\n",
      "Epoch 129: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 129: Train F1=0.9198 - Val F1=0.6023\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 129: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.513 Recall=0.690\n",
      "  Class 2: Precision=0.655 Recall=0.594\n",
      "  Macro Avg: Precision=0.623 Recall=0.601\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.8971 - loss: 0.6196 - val_accuracy: 0.6023 - val_loss: 1.1301 - train_f1_score: 0.9198 - val_f1_score: 0.6023\n",
      "Epoch 130/700\n",
      "\n",
      "Epoch 130: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 130: Train F1=0.9395 - Val F1=0.6164\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 130: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.633 Recall=0.622\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9057 - loss: 0.6088 - val_accuracy: 0.6250 - val_loss: 1.1448 - train_f1_score: 0.9395 - val_f1_score: 0.6164\n",
      "Epoch 131/700\n",
      "\n",
      "Epoch 131: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 131: Train F1=0.8711 - Val F1=0.5066\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 131: Per-class metrics\n",
      "  Class 0: Precision=0.476 Recall=0.370\n",
      "  Class 1: Precision=0.481 Recall=0.448\n",
      "  Class 2: Precision=0.575 Recall=0.719\n",
      "  Macro Avg: Precision=0.511 Recall=0.512\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9086 - loss: 0.5990 - val_accuracy: 0.5227 - val_loss: 1.2013 - train_f1_score: 0.8711 - val_f1_score: 0.5066\n",
      "Epoch 132/700\n",
      "\n",
      "Epoch 132: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 132: Train F1=0.9281 - Val F1=0.5936\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 132: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.650 Recall=0.448\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.609 Recall=0.597\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9286 - loss: 0.5884 - val_accuracy: 0.6023 - val_loss: 1.1716 - train_f1_score: 0.9281 - val_f1_score: 0.5936\n",
      "Epoch 133/700\n",
      "\n",
      "Epoch 133: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 133: Train F1=0.8657 - Val F1=0.6364\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 133: Per-class metrics\n",
      "  Class 0: Precision=0.568 Recall=0.778\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.633 Recall=0.594\n",
      "  Macro Avg: Precision=0.654 Recall=0.641\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9286 - loss: 0.5865 - val_accuracy: 0.6364 - val_loss: 1.1147 - train_f1_score: 0.8657 - val_f1_score: 0.6364\n",
      "Epoch 134/700\n",
      "\n",
      "Epoch 134: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 134: Train F1=0.7356 - Val F1=0.5093\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 134: Per-class metrics\n",
      "  Class 0: Precision=0.476 Recall=0.741\n",
      "  Class 1: Precision=0.778 Recall=0.241\n",
      "  Class 2: Precision=0.541 Recall=0.625\n",
      "  Macro Avg: Precision=0.598 Recall=0.536\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9200 - loss: 0.5770 - val_accuracy: 0.5341 - val_loss: 1.3263 - train_f1_score: 0.7356 - val_f1_score: 0.5093\n",
      "Epoch 135/700\n",
      "\n",
      "Epoch 135: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 135: Train F1=0.8582 - Val F1=0.5480\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 135: Per-class metrics\n",
      "  Class 0: Precision=0.594 Recall=0.704\n",
      "  Class 1: Precision=0.700 Recall=0.241\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.612 Recall=0.575\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9286 - loss: 0.5928 - val_accuracy: 0.5795 - val_loss: 1.2616 - train_f1_score: 0.8582 - val_f1_score: 0.5480\n",
      "Epoch 136/700\n",
      "\n",
      "Epoch 136: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 136: Train F1=0.7086 - Val F1=0.4597\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 136: Per-class metrics\n",
      "  Class 0: Precision=0.432 Recall=0.704\n",
      "  Class 1: Precision=0.700 Recall=0.241\n",
      "  Class 2: Precision=0.471 Recall=0.500\n",
      "  Macro Avg: Precision=0.534 Recall=0.482\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9314 - loss: 0.5728 - val_accuracy: 0.4773 - val_loss: 1.3168 - train_f1_score: 0.7086 - val_f1_score: 0.4597\n",
      "Epoch 137/700\n",
      "\n",
      "Epoch 137: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 137: Train F1=0.9340 - Val F1=0.6353\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 137: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.789 Recall=0.517\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.676 Recall=0.630\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9143 - loss: 0.5860 - val_accuracy: 0.6364 - val_loss: 1.1264 - train_f1_score: 0.9340 - val_f1_score: 0.6353\n",
      "Epoch 138/700\n",
      "\n",
      "Epoch 138: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 138: Train F1=0.9163 - Val F1=0.6182\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 138: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.789 Recall=0.517\n",
      "  Class 2: Precision=0.553 Recall=0.812\n",
      "  Macro Avg: Precision=0.660 Recall=0.616\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9429 - loss: 0.5650 - val_accuracy: 0.6250 - val_loss: 1.1380 - train_f1_score: 0.9163 - val_f1_score: 0.6182\n",
      "Epoch 139/700\n",
      "\n",
      "Epoch 139: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 139: Train F1=0.3900 - Val F1=0.3889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 139: Per-class metrics\n",
      "  Class 0: Precision=0.345 Recall=0.704\n",
      "  Class 1: Precision=0.667 Recall=0.138\n",
      "  Class 2: Precision=0.519 Recall=0.438\n",
      "  Macro Avg: Precision=0.510 Recall=0.426\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9286 - loss: 0.5757 - val_accuracy: 0.4205 - val_loss: 1.5998 - train_f1_score: 0.3900 - val_f1_score: 0.3889\n",
      "Epoch 140/700\n",
      "\n",
      "Epoch 140: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 140: Train F1=0.8283 - Val F1=0.4994\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 140: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.714 Recall=0.172\n",
      "  Class 2: Precision=0.500 Recall=0.844\n",
      "  Macro Avg: Precision=0.602 Recall=0.536\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9229 - loss: 0.5720 - val_accuracy: 0.5455 - val_loss: 1.3220 - train_f1_score: 0.8283 - val_f1_score: 0.4994\n",
      "Epoch 141/700\n",
      "\n",
      "Epoch 141: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 141: Train F1=0.8749 - Val F1=0.5327\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 141: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.500 Recall=0.844\n",
      "  Macro Avg: Precision=0.604 Recall=0.545\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9229 - loss: 0.5731 - val_accuracy: 0.5568 - val_loss: 1.2388 - train_f1_score: 0.8749 - val_f1_score: 0.5327\n",
      "Epoch 142/700\n",
      "\n",
      "Epoch 142: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 142: Train F1=0.4689 - Val F1=0.3777\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 142: Per-class metrics\n",
      "  Class 0: Precision=0.367 Recall=0.667\n",
      "  Class 1: Precision=0.750 Recall=0.103\n",
      "  Class 2: Precision=0.457 Recall=0.500\n",
      "  Macro Avg: Precision=0.525 Recall=0.423\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9200 - loss: 0.5771 - val_accuracy: 0.4205 - val_loss: 1.4146 - train_f1_score: 0.4689 - val_f1_score: 0.3777\n",
      "Epoch 143/700\n",
      "\n",
      "Epoch 143: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 143: Train F1=0.5926 - Val F1=0.4246\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 143: Per-class metrics\n",
      "  Class 0: Precision=0.450 Recall=0.667\n",
      "  Class 1: Precision=0.600 Recall=0.103\n",
      "  Class 2: Precision=0.488 Recall=0.656\n",
      "  Macro Avg: Precision=0.513 Recall=0.475\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9486 - loss: 0.5620 - val_accuracy: 0.4773 - val_loss: 1.3507 - train_f1_score: 0.5926 - val_f1_score: 0.4246\n",
      "Epoch 144/700\n",
      "\n",
      "Epoch 144: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 144: Train F1=0.9624 - Val F1=0.5611\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 144: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.594 Recall=0.655\n",
      "  Class 2: Precision=0.526 Recall=0.625\n",
      "  Macro Avg: Precision=0.577 Recall=0.563\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9200 - loss: 0.5871 - val_accuracy: 0.5682 - val_loss: 1.1720 - train_f1_score: 0.9624 - val_f1_score: 0.5611\n",
      "Epoch 145/700\n",
      "\n",
      "Epoch 145: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 145: Train F1=0.8766 - Val F1=0.5858\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 145: Per-class metrics\n",
      "  Class 0: Precision=0.519 Recall=0.519\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.575 Recall=0.719\n",
      "  Macro Avg: Precision=0.603 Recall=0.585\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9314 - loss: 0.5643 - val_accuracy: 0.5909 - val_loss: 1.1240 - train_f1_score: 0.8766 - val_f1_score: 0.5858\n",
      "Epoch 146/700\n",
      "\n",
      "Epoch 146: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 146: Train F1=0.6665 - Val F1=0.4450\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 146: Per-class metrics\n",
      "  Class 0: Precision=0.375 Recall=0.667\n",
      "  Class 1: Precision=0.533 Recall=0.276\n",
      "  Class 2: Precision=0.560 Recall=0.438\n",
      "  Macro Avg: Precision=0.489 Recall=0.460\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9457 - loss: 0.5495 - val_accuracy: 0.4545 - val_loss: 1.2843 - train_f1_score: 0.6665 - val_f1_score: 0.4450\n",
      "Epoch 147/700\n",
      "\n",
      "Epoch 147: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 147: Train F1=0.9512 - Val F1=0.6570\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 147: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.682 Recall=0.652\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9400 - loss: 0.5582 - val_accuracy: 0.6591 - val_loss: 1.1163 - train_f1_score: 0.9512 - val_f1_score: 0.6570\n",
      "Epoch 148/700\n",
      "\n",
      "Epoch 148: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 148: Train F1=0.9489 - Val F1=0.6347\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 148: Per-class metrics\n",
      "  Class 0: Precision=0.606 Recall=0.741\n",
      "  Class 1: Precision=0.615 Recall=0.552\n",
      "  Class 2: Precision=0.690 Recall=0.625\n",
      "  Macro Avg: Precision=0.637 Recall=0.639\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9314 - loss: 0.5657 - val_accuracy: 0.6364 - val_loss: 1.0956 - train_f1_score: 0.9489 - val_f1_score: 0.6347\n",
      "Epoch 149/700\n",
      "\n",
      "Epoch 149: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 149: Train F1=0.8998 - Val F1=0.5962\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 149: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.722 Recall=0.448\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.628 Recall=0.597\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9314 - loss: 0.5667 - val_accuracy: 0.6023 - val_loss: 1.1800 - train_f1_score: 0.8998 - val_f1_score: 0.5962\n",
      "Epoch 150/700\n",
      "\n",
      "Epoch 150: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 150: Train F1=0.9553 - Val F1=0.6367\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 150: Per-class metrics\n",
      "  Class 0: Precision=0.633 Recall=0.704\n",
      "  Class 1: Precision=0.613 Recall=0.655\n",
      "  Class 2: Precision=0.667 Recall=0.562\n",
      "  Macro Avg: Precision=0.638 Recall=0.640\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9086 - loss: 0.5769 - val_accuracy: 0.6364 - val_loss: 1.1243 - train_f1_score: 0.9553 - val_f1_score: 0.6367\n",
      "Epoch 151/700\n",
      "\n",
      "Epoch 151: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 151: Train F1=0.7160 - Val F1=0.4714\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 151: Per-class metrics\n",
      "  Class 0: Precision=0.447 Recall=0.778\n",
      "  Class 1: Precision=0.571 Recall=0.276\n",
      "  Class 2: Precision=0.519 Recall=0.438\n",
      "  Macro Avg: Precision=0.512 Recall=0.497\n",
      "11/11 - 1s - 123ms/step - accuracy: 0.9457 - loss: 0.5389 - val_accuracy: 0.4886 - val_loss: 1.2791 - train_f1_score: 0.7160 - val_f1_score: 0.4714\n",
      "Epoch 152/700\n",
      "\n",
      "Epoch 152: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 152: Train F1=0.8113 - Val F1=0.5293\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 152: Per-class metrics\n",
      "  Class 0: Precision=0.515 Recall=0.630\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.537 Recall=0.688\n",
      "  Macro Avg: Precision=0.565 Recall=0.542\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9743 - loss: 0.5047 - val_accuracy: 0.5455 - val_loss: 1.2773 - train_f1_score: 0.8113 - val_f1_score: 0.5293\n",
      "Epoch 153/700\n",
      "\n",
      "Epoch 153: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 153: Train F1=0.8822 - Val F1=0.5589\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 153: Per-class metrics\n",
      "  Class 0: Precision=0.514 Recall=0.667\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.583 Recall=0.656\n",
      "  Macro Avg: Precision=0.582 Recall=0.567\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9343 - loss: 0.5504 - val_accuracy: 0.5682 - val_loss: 1.1962 - train_f1_score: 0.8822 - val_f1_score: 0.5589\n",
      "Epoch 154/700\n",
      "\n",
      "Epoch 154: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 154: Train F1=0.6749 - Val F1=0.4358\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 154: Per-class metrics\n",
      "  Class 0: Precision=0.408 Recall=0.741\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.552 Recall=0.500\n",
      "  Macro Avg: Precision=0.487 Recall=0.471\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9657 - loss: 0.5149 - val_accuracy: 0.4659 - val_loss: 1.4570 - train_f1_score: 0.6749 - val_f1_score: 0.4358\n",
      "Epoch 155/700\n",
      "\n",
      "Epoch 155: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 155: Train F1=0.7671 - Val F1=0.4796\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 155: Per-class metrics\n",
      "  Class 0: Precision=0.419 Recall=0.667\n",
      "  Class 1: Precision=0.529 Recall=0.310\n",
      "  Class 2: Precision=0.571 Recall=0.500\n",
      "  Macro Avg: Precision=0.506 Recall=0.492\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9657 - loss: 0.5167 - val_accuracy: 0.4886 - val_loss: 1.3509 - train_f1_score: 0.7671 - val_f1_score: 0.4796\n",
      "Epoch 156/700\n",
      "\n",
      "Epoch 156: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 156: Train F1=0.6521 - Val F1=0.4450\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 156: Per-class metrics\n",
      "  Class 0: Precision=0.426 Recall=0.741\n",
      "  Class 1: Precision=0.556 Recall=0.172\n",
      "  Class 2: Precision=0.531 Recall=0.531\n",
      "  Macro Avg: Precision=0.504 Recall=0.481\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9457 - loss: 0.5259 - val_accuracy: 0.4773 - val_loss: 1.4145 - train_f1_score: 0.6521 - val_f1_score: 0.4450\n",
      "Epoch 157/700\n",
      "\n",
      "Epoch 157: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 157: Train F1=0.8579 - Val F1=0.5357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Epoch 157: Per-class metrics\n",
      "  Class 0: Precision=0.457 Recall=0.778\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.607 Recall=0.531\n",
      "  Macro Avg: Precision=0.593 Recall=0.551\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9543 - loss: 0.5318 - val_accuracy: 0.5455 - val_loss: 1.2062 - train_f1_score: 0.8579 - val_f1_score: 0.5357\n",
      "Epoch 158/700\n",
      "\n",
      "Epoch 158: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 158: Train F1=0.8280 - Val F1=0.4230\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 158: Per-class metrics\n",
      "  Class 0: Precision=0.417 Recall=0.556\n",
      "  Class 1: Precision=0.462 Recall=0.207\n",
      "  Class 2: Precision=0.462 Recall=0.562\n",
      "  Macro Avg: Precision=0.447 Recall=0.442\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9514 - loss: 0.5337 - val_accuracy: 0.4432 - val_loss: 1.2643 - train_f1_score: 0.8280 - val_f1_score: 0.4230\n",
      "Epoch 159/700\n",
      "\n",
      "Epoch 159: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 159: Train F1=0.8828 - Val F1=0.5617\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 159: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.815\n",
      "  Class 1: Precision=0.600 Recall=0.517\n",
      "  Class 2: Precision=0.684 Recall=0.406\n",
      "  Macro Avg: Precision=0.595 Recall=0.579\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9514 - loss: 0.5306 - val_accuracy: 0.5682 - val_loss: 1.1417 - train_f1_score: 0.8828 - val_f1_score: 0.5617\n",
      "Epoch 160/700\n",
      "\n",
      "Epoch 160: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 160: Train F1=0.9885 - Val F1=0.6316\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 160: Per-class metrics\n",
      "  Class 0: Precision=0.645 Recall=0.741\n",
      "  Class 1: Precision=0.609 Recall=0.483\n",
      "  Class 2: Precision=0.647 Recall=0.688\n",
      "  Macro Avg: Precision=0.634 Recall=0.637\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9571 - loss: 0.5231 - val_accuracy: 0.6364 - val_loss: 1.1886 - train_f1_score: 0.9885 - val_f1_score: 0.6316\n",
      "Epoch 161/700\n",
      "\n",
      "Epoch 161: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 161: Train F1=0.9830 - Val F1=0.5950\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 161: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.545 Recall=0.414\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.601 Recall=0.600\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9571 - loss: 0.5151 - val_accuracy: 0.6023 - val_loss: 1.2243 - train_f1_score: 0.9830 - val_f1_score: 0.5950\n",
      "Epoch 162/700\n",
      "\n",
      "Epoch 162: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 162: Train F1=0.9004 - Val F1=0.6019\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 162: Per-class metrics\n",
      "  Class 0: Precision=0.543 Recall=0.704\n",
      "  Class 1: Precision=0.778 Recall=0.483\n",
      "  Class 2: Precision=0.571 Recall=0.625\n",
      "  Macro Avg: Precision=0.631 Recall=0.604\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9286 - loss: 0.5461 - val_accuracy: 0.6023 - val_loss: 1.2378 - train_f1_score: 0.9004 - val_f1_score: 0.6019\n",
      "Epoch 163/700\n",
      "\n",
      "Epoch 163: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 163: Train F1=0.7966 - Val F1=0.4738\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 163: Per-class metrics\n",
      "  Class 0: Precision=0.457 Recall=0.778\n",
      "  Class 1: Precision=0.625 Recall=0.172\n",
      "  Class 2: Precision=0.559 Recall=0.594\n",
      "  Macro Avg: Precision=0.547 Recall=0.515\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9457 - loss: 0.5516 - val_accuracy: 0.5114 - val_loss: 1.3006 - train_f1_score: 0.7966 - val_f1_score: 0.4738\n",
      "Epoch 164/700\n",
      "\n",
      "Epoch 164: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 164: Train F1=0.6512 - Val F1=0.4814\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 164: Per-class metrics\n",
      "  Class 0: Precision=0.408 Recall=0.741\n",
      "  Class 1: Precision=0.591 Recall=0.448\n",
      "  Class 2: Precision=0.588 Recall=0.312\n",
      "  Macro Avg: Precision=0.529 Recall=0.501\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9571 - loss: 0.5098 - val_accuracy: 0.4886 - val_loss: 1.3338 - train_f1_score: 0.6512 - val_f1_score: 0.4814\n",
      "Epoch 165/700\n",
      "\n",
      "Epoch 165: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 165: Train F1=0.9202 - Val F1=0.6013\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 165: Per-class metrics\n",
      "  Class 0: Precision=0.579 Recall=0.815\n",
      "  Class 1: Precision=0.733 Recall=0.379\n",
      "  Class 2: Precision=0.600 Recall=0.656\n",
      "  Macro Avg: Precision=0.637 Recall=0.617\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9543 - loss: 0.5219 - val_accuracy: 0.6136 - val_loss: 1.1272 - train_f1_score: 0.9202 - val_f1_score: 0.6013\n",
      "Epoch 166/700\n",
      "\n",
      "Epoch 166: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 166: Train F1=0.8422 - Val F1=0.5005\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 166: Per-class metrics\n",
      "  Class 0: Precision=0.462 Recall=0.444\n",
      "  Class 1: Precision=0.667 Recall=0.276\n",
      "  Class 2: Precision=0.540 Recall=0.844\n",
      "  Macro Avg: Precision=0.556 Recall=0.521\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9714 - loss: 0.5023 - val_accuracy: 0.5341 - val_loss: 1.3691 - train_f1_score: 0.8422 - val_f1_score: 0.5005\n",
      "Epoch 167/700\n",
      "\n",
      "Epoch 167: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 167: Train F1=0.9744 - Val F1=0.6333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 167: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.643 Recall=0.634\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9657 - loss: 0.4961 - val_accuracy: 0.6364 - val_loss: 1.1503 - train_f1_score: 0.9744 - val_f1_score: 0.6333\n",
      "Epoch 168/700\n",
      "\n",
      "Epoch 168: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 168: Train F1=0.9201 - Val F1=0.6138\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Epoch 168: Per-class metrics\n",
      "  Class 0: Precision=0.559 Recall=0.704\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.613 Recall=0.594\n",
      "  Macro Avg: Precision=0.622 Recall=0.616\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9514 - loss: 0.5210 - val_accuracy: 0.6136 - val_loss: 1.1605 - train_f1_score: 0.9201 - val_f1_score: 0.6138\n",
      "Epoch 169/700\n",
      "\n",
      "Epoch 169: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 169: Train F1=0.9288 - Val F1=0.6003\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 169: Per-class metrics\n",
      "  Class 0: Precision=0.545 Recall=0.667\n",
      "  Class 1: Precision=0.625 Recall=0.517\n",
      "  Class 2: Precision=0.645 Recall=0.625\n",
      "  Macro Avg: Precision=0.605 Recall=0.603\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9714 - loss: 0.5066 - val_accuracy: 0.6023 - val_loss: 1.1991 - train_f1_score: 0.9288 - val_f1_score: 0.6003\n",
      "Epoch 170/700\n",
      "\n",
      "Epoch 170: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 170: Train F1=0.8818 - Val F1=0.5431\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 170: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.529 Recall=0.844\n",
      "  Macro Avg: Precision=0.594 Recall=0.558\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9514 - loss: 0.5158 - val_accuracy: 0.5682 - val_loss: 1.2710 - train_f1_score: 0.8818 - val_f1_score: 0.5431\n",
      "Epoch 171/700\n",
      "\n",
      "Epoch 171: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 171: Train F1=0.8333 - Val F1=0.4923\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 171: Per-class metrics\n",
      "  Class 0: Precision=0.514 Recall=0.704\n",
      "  Class 1: Precision=0.714 Recall=0.172\n",
      "  Class 2: Precision=0.523 Recall=0.719\n",
      "  Macro Avg: Precision=0.584 Recall=0.532\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9571 - loss: 0.5286 - val_accuracy: 0.5341 - val_loss: 1.2826 - train_f1_score: 0.8333 - val_f1_score: 0.4923\n",
      "Epoch 172/700\n",
      "\n",
      "Epoch 172: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 172: Train F1=0.8119 - Val F1=0.5398\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 172: Per-class metrics\n",
      "  Class 0: Precision=0.513 Recall=0.741\n",
      "  Class 1: Precision=0.571 Recall=0.414\n",
      "  Class 2: Precision=0.571 Recall=0.500\n",
      "  Macro Avg: Precision=0.552 Recall=0.552\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9514 - loss: 0.5104 - val_accuracy: 0.5455 - val_loss: 1.2296 - train_f1_score: 0.8119 - val_f1_score: 0.5398\n",
      "Epoch 173/700\n",
      "\n",
      "Epoch 173: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 173: Train F1=0.9317 - Val F1=0.6527\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 173: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.778\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.657 Recall=0.719\n",
      "  Macro Avg: Precision=0.665 Recall=0.660\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9200 - loss: 0.5651 - val_accuracy: 0.6591 - val_loss: 1.0279 - train_f1_score: 0.9317 - val_f1_score: 0.6527\n",
      "Epoch 174/700\n",
      "\n",
      "Epoch 174: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 174: Train F1=0.8293 - Val F1=0.5407\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 174: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.533 Recall=0.276\n",
      "  Class 2: Precision=0.540 Recall=0.844\n",
      "  Macro Avg: Precision=0.575 Recall=0.558\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.5089 - val_accuracy: 0.5682 - val_loss: 1.2472 - train_f1_score: 0.8293 - val_f1_score: 0.5407\n",
      "Epoch 175/700\n",
      "\n",
      "Epoch 175: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 175: Train F1=0.9799 - Val F1=0.6116\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 175: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.611 Recall=0.379\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.628 Recall=0.621\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9686 - loss: 0.5049 - val_accuracy: 0.6250 - val_loss: 1.2428 - train_f1_score: 0.9799 - val_f1_score: 0.6116\n",
      "Epoch 176/700\n",
      "\n",
      "Epoch 176: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 176: Train F1=0.9915 - Val F1=0.6465\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 176: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.815\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.661 Recall=0.660\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9686 - loss: 0.5002 - val_accuracy: 0.6591 - val_loss: 1.1216 - train_f1_score: 0.9915 - val_f1_score: 0.6465\n",
      "Epoch 177/700\n",
      "\n",
      "Epoch 177: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 177: Train F1=0.9798 - Val F1=0.6061\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 177: Per-class metrics\n",
      "  Class 0: Precision=0.590 Recall=0.852\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.627 Recall=0.628\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9600 - loss: 0.4998 - val_accuracy: 0.6250 - val_loss: 1.2244 - train_f1_score: 0.9798 - val_f1_score: 0.6061\n",
      "Epoch 178/700\n",
      "\n",
      "Epoch 178: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 178: Train F1=0.9689 - Val F1=0.6019\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 178: Per-class metrics\n",
      "  Class 0: Precision=0.645 Recall=0.741\n",
      "  Class 1: Precision=0.611 Recall=0.379\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.615 Recall=0.613\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9686 - loss: 0.4957 - val_accuracy: 0.6136 - val_loss: 1.2397 - train_f1_score: 0.9689 - val_f1_score: 0.6019\n",
      "Epoch 179/700\n",
      "\n",
      "Epoch 179: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 179: Train F1=0.9494 - Val F1=0.5197\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 179: Per-class metrics\n",
      "  Class 0: Precision=0.607 Recall=0.630\n",
      "  Class 1: Precision=0.500 Recall=0.241\n",
      "  Class 2: Precision=0.522 Recall=0.750\n",
      "  Macro Avg: Precision=0.543 Recall=0.540\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9686 - loss: 0.5024 - val_accuracy: 0.5455 - val_loss: 1.2498 - train_f1_score: 0.9494 - val_f1_score: 0.5197\n",
      "Epoch 180/700\n",
      "\n",
      "Epoch 180: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 180: Train F1=0.8155 - Val F1=0.5239\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 180: Per-class metrics\n",
      "  Class 0: Precision=0.531 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.276\n",
      "  Class 2: Precision=0.523 Recall=0.719\n",
      "  Macro Avg: Precision=0.574 Recall=0.541\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9714 - loss: 0.4852 - val_accuracy: 0.5455 - val_loss: 1.2761 - train_f1_score: 0.8155 - val_f1_score: 0.5239\n",
      "Epoch 181/700\n",
      "\n",
      "Epoch 181: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 181: Train F1=0.9578 - Val F1=0.5657\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 181: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.571 Recall=0.276\n",
      "  Class 2: Precision=0.553 Recall=0.812\n",
      "  Macro Avg: Precision=0.597 Recall=0.585\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9686 - loss: 0.4911 - val_accuracy: 0.5909 - val_loss: 1.2664 - train_f1_score: 0.9578 - val_f1_score: 0.5657\n",
      "Epoch 182/700\n",
      "\n",
      "Epoch 182: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 182: Train F1=0.9079 - Val F1=0.5247\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 182: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.241\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.546 Recall=0.549\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9600 - loss: 0.5100 - val_accuracy: 0.5568 - val_loss: 1.2712 - train_f1_score: 0.9079 - val_f1_score: 0.5247\n",
      "Epoch 183/700\n",
      "\n",
      "Epoch 183: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 183: Train F1=0.9516 - Val F1=0.5318\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 183: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.276\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.547 Recall=0.550\n",
      "11/11 - 1s - 109ms/step - accuracy: 0.9800 - loss: 0.4980 - val_accuracy: 0.5568 - val_loss: 1.3458 - train_f1_score: 0.9516 - val_f1_score: 0.5318\n",
      "Epoch 184/700\n",
      "\n",
      "Epoch 184: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 184: Train F1=0.8474 - Val F1=0.4628\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 184: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.500 Recall=0.719\n",
      "  Macro Avg: Precision=0.500 Recall=0.495\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9543 - loss: 0.5117 - val_accuracy: 0.5000 - val_loss: 1.3044 - train_f1_score: 0.8474 - val_f1_score: 0.4628\n",
      "Epoch 185/700\n",
      "\n",
      "Epoch 185: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 185: Train F1=0.9743 - Val F1=0.6025\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 185: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.593 Recall=0.552\n",
      "  Class 2: Precision=0.550 Recall=0.688\n",
      "  Macro Avg: Precision=0.619 Recall=0.598\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9600 - loss: 0.5126 - val_accuracy: 0.6023 - val_loss: 1.2040 - train_f1_score: 0.9743 - val_f1_score: 0.6025\n",
      "Epoch 186/700\n",
      "\n",
      "Epoch 186: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 186: Train F1=0.9001 - Val F1=0.6013\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 186: Per-class metrics\n",
      "  Class 0: Precision=0.548 Recall=0.630\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.583 Recall=0.656\n",
      "  Macro Avg: Precision=0.615 Recall=0.601\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9771 - loss: 0.4867 - val_accuracy: 0.6023 - val_loss: 1.1064 - train_f1_score: 0.9001 - val_f1_score: 0.6013\n",
      "Epoch 187/700\n",
      "\n",
      "Epoch 187: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 187: Train F1=0.8557 - Val F1=0.5419\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 187: Per-class metrics\n",
      "  Class 0: Precision=0.531 Recall=0.630\n",
      "  Class 1: Precision=0.727 Recall=0.276\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.605 Recall=0.562\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9743 - loss: 0.4990 - val_accuracy: 0.5682 - val_loss: 1.2406 - train_f1_score: 0.8557 - val_f1_score: 0.5419\n",
      "Epoch 188/700\n",
      "\n",
      "Epoch 188: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188: Train F1=0.9175 - Val F1=0.6810\n",
      "\n",
      "Saved best model at epoch 188 with val_f1=0.6810\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 188: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.815\n",
      "  Class 1: Precision=0.714 Recall=0.690\n",
      "  Class 2: Precision=0.750 Recall=0.562\n",
      "  Macro Avg: Precision=0.692 Recall=0.689\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9571 - loss: 0.5031 - val_accuracy: 0.6818 - val_loss: 0.9971 - train_f1_score: 0.9175 - val_f1_score: 0.6810\n",
      "Epoch 189/700\n",
      "\n",
      "Epoch 189: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 189: Train F1=0.9771 - Val F1=0.6578\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 189: Per-class metrics\n",
      "  Class 0: Precision=0.618 Recall=0.778\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.714 Recall=0.625\n",
      "  Macro Avg: Precision=0.662 Recall=0.663\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9886 - loss: 0.4886 - val_accuracy: 0.6591 - val_loss: 1.0503 - train_f1_score: 0.9771 - val_f1_score: 0.6578\n",
      "Epoch 190/700\n",
      "\n",
      "Epoch 190: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 190: Train F1=0.9485 - Val F1=0.6266\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 190: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.591 Recall=0.812\n",
      "  Macro Avg: Precision=0.652 Recall=0.630\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.4657 - val_accuracy: 0.6364 - val_loss: 1.1420 - train_f1_score: 0.9485 - val_f1_score: 0.6266\n",
      "Epoch 191/700\n",
      "\n",
      "Epoch 191: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 191: Train F1=0.9519 - Val F1=0.6054\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 191: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.616 Recall=0.609\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9829 - loss: 0.4677 - val_accuracy: 0.6136 - val_loss: 1.1591 - train_f1_score: 0.9519 - val_f1_score: 0.6054\n",
      "Epoch 192/700\n",
      "\n",
      "Epoch 192: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 192: Train F1=0.9748 - Val F1=0.6552\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 192: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.671 Recall=0.655\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9657 - loss: 0.4843 - val_accuracy: 0.6591 - val_loss: 1.1621 - train_f1_score: 0.9748 - val_f1_score: 0.6552\n",
      "Epoch 193/700\n",
      "\n",
      "Epoch 193: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 193: Train F1=0.9971 - Val F1=0.6548\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 193: Per-class metrics\n",
      "  Class 0: Precision=0.690 Recall=0.741\n",
      "  Class 1: Precision=0.737 Recall=0.483\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.675 Recall=0.658\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9686 - loss: 0.4947 - val_accuracy: 0.6591 - val_loss: 1.0995 - train_f1_score: 0.9971 - val_f1_score: 0.6548\n",
      "Epoch 194/700\n",
      "\n",
      "Epoch 194: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 194: Train F1=0.9913 - Val F1=0.6342\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 194: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.655 Recall=0.632\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9514 - loss: 0.5015 - val_accuracy: 0.6364 - val_loss: 1.0713 - train_f1_score: 0.9913 - val_f1_score: 0.6342\n",
      "Epoch 195/700\n",
      "\n",
      "Epoch 195: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 195: Train F1=0.9884 - Val F1=0.5909\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 195: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.616 Recall=0.599\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9714 - loss: 0.4920 - val_accuracy: 0.6023 - val_loss: 1.1418 - train_f1_score: 0.9884 - val_f1_score: 0.5909\n",
      "Epoch 196/700\n",
      "\n",
      "Epoch 196: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Epoch 196: Train F1=0.8069 - Val F1=0.5017\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 196: Per-class metrics\n",
      "  Class 0: Precision=0.517 Recall=0.556\n",
      "  Class 1: Precision=0.571 Recall=0.276\n",
      "  Class 2: Precision=0.511 Recall=0.719\n",
      "  Macro Avg: Precision=0.533 Recall=0.517\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9829 - loss: 0.4764 - val_accuracy: 0.5227 - val_loss: 1.2847 - train_f1_score: 0.8069 - val_f1_score: 0.5017\n",
      "Epoch 197/700\n",
      "\n",
      "Epoch 197: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 197: Train F1=0.8511 - Val F1=0.4989\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 197: Per-class metrics\n",
      "  Class 0: Precision=0.457 Recall=0.593\n",
      "  Class 1: Precision=0.600 Recall=0.310\n",
      "  Class 2: Precision=0.526 Recall=0.625\n",
      "  Macro Avg: Precision=0.528 Recall=0.509\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4642 - val_accuracy: 0.5114 - val_loss: 1.2280 - train_f1_score: 0.8511 - val_f1_score: 0.4989\n",
      "Epoch 198/700\n",
      "\n",
      "Epoch 198: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 198: Train F1=0.9535 - Val F1=0.6571\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 198: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.739 Recall=0.586\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.669 Recall=0.655\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9771 - loss: 0.4819 - val_accuracy: 0.6591 - val_loss: 1.0632 - train_f1_score: 0.9535 - val_f1_score: 0.6571\n",
      "Epoch 199/700\n",
      "\n",
      "Epoch 199: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 199: Train F1=0.9622 - Val F1=0.6305\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 199: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.648 Recall=0.630\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9743 - loss: 0.4836 - val_accuracy: 0.6364 - val_loss: 1.1395 - train_f1_score: 0.9622 - val_f1_score: 0.6305\n",
      "Epoch 200/700\n",
      "\n",
      "Epoch 200: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 200: Train F1=0.9971 - Val F1=0.6072\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 200: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.635 Recall=0.607\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9800 - loss: 0.4697 - val_accuracy: 0.6136 - val_loss: 1.1437 - train_f1_score: 0.9971 - val_f1_score: 0.6072\n",
      "Epoch 201/700\n",
      "\n",
      "Epoch 201: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 201: Train F1=1.0000 - Val F1=0.6571\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 201: Per-class metrics\n",
      "  Class 0: Precision=0.690 Recall=0.741\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.670 Recall=0.659\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9800 - loss: 0.4687 - val_accuracy: 0.6591 - val_loss: 1.0582 - train_f1_score: 1.0000 - val_f1_score: 0.6571\n",
      "Epoch 202/700\n",
      "\n",
      "Epoch 202: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 202: Train F1=0.9486 - Val F1=0.5722\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 202: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.564 Recall=0.688\n",
      "  Macro Avg: Precision=0.583 Recall=0.577\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9629 - loss: 0.4849 - val_accuracy: 0.5795 - val_loss: 1.1459 - train_f1_score: 0.9486 - val_f1_score: 0.5722\n",
      "Epoch 203/700\n",
      "\n",
      "Epoch 203: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 203: Train F1=0.9685 - Val F1=0.5373\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 203: Per-class metrics\n",
      "  Class 0: Precision=0.581 Recall=0.667\n",
      "  Class 1: Precision=0.538 Recall=0.241\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.562 Recall=0.563\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4665 - val_accuracy: 0.5682 - val_loss: 1.2520 - train_f1_score: 0.9685 - val_f1_score: 0.5373\n",
      "Epoch 204/700\n",
      "\n",
      "Epoch 204: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 204: Train F1=0.9944 - Val F1=0.6392\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 204: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.658 Recall=0.644\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9800 - loss: 0.4691 - val_accuracy: 0.6477 - val_loss: 1.1267 - train_f1_score: 0.9944 - val_f1_score: 0.6392\n",
      "Epoch 205/700\n",
      "\n",
      "Epoch 205: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 205: Train F1=0.7199 - Val F1=0.4759\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 205: Per-class metrics\n",
      "  Class 0: Precision=0.404 Recall=0.704\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.571 Recall=0.500\n",
      "  Macro Avg: Precision=0.530 Recall=0.493\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9514 - loss: 0.4929 - val_accuracy: 0.4886 - val_loss: 1.3620 - train_f1_score: 0.7199 - val_f1_score: 0.4759\n",
      "Epoch 206/700\n",
      "\n",
      "Epoch 206: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 206: Train F1=0.7590 - Val F1=0.5196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 206: Per-class metrics\n",
      "  Class 0: Precision=0.472 Recall=0.630\n",
      "  Class 1: Precision=0.545 Recall=0.414\n",
      "  Class 2: Precision=0.567 Recall=0.531\n",
      "  Macro Avg: Precision=0.528 Recall=0.525\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9829 - loss: 0.4646 - val_accuracy: 0.5227 - val_loss: 1.3563 - train_f1_score: 0.7590 - val_f1_score: 0.5196\n",
      "Epoch 207/700\n",
      "\n",
      "Epoch 207: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207: Train F1=0.9717 - Val F1=0.6814\n",
      "\n",
      "Saved best model at epoch 207 with val_f1=0.6814\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 207: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.657 Recall=0.719\n",
      "  Macro Avg: Precision=0.685 Recall=0.681\n",
      "11/11 - 1s - 98ms/step - accuracy: 0.9514 - loss: 0.4981 - val_accuracy: 0.6818 - val_loss: 1.1020 - train_f1_score: 0.9717 - val_f1_score: 0.6814\n",
      "Epoch 208/700\n",
      "\n",
      "Epoch 208: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 208: Train F1=0.9426 - Val F1=0.6412\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 208: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.615 Recall=0.552\n",
      "  Class 2: Precision=0.658 Recall=0.781\n",
      "  Macro Avg: Precision=0.647 Recall=0.642\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9600 - loss: 0.4872 - val_accuracy: 0.6477 - val_loss: 1.1406 - train_f1_score: 0.9426 - val_f1_score: 0.6412\n",
      "Epoch 209/700\n",
      "\n",
      "Epoch 209: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 209: Train F1=0.9856 - Val F1=0.6213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 209: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.653 Recall=0.617\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9743 - loss: 0.4818 - val_accuracy: 0.6250 - val_loss: 1.1297 - train_f1_score: 0.9856 - val_f1_score: 0.6213\n",
      "Epoch 210/700\n",
      "\n",
      "Epoch 210: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 210: Train F1=0.7052 - Val F1=0.4650\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 210: Per-class metrics\n",
      "  Class 0: Precision=0.375 Recall=0.667\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.524 Recall=0.344\n",
      "  Macro Avg: Precision=0.510 Recall=0.475\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9657 - loss: 0.4956 - val_accuracy: 0.4659 - val_loss: 1.3022 - train_f1_score: 0.7052 - val_f1_score: 0.4650\n",
      "Epoch 211/700\n",
      "\n",
      "Epoch 211: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 211: Train F1=0.9223 - Val F1=0.5446\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 211: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.444\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.488 Recall=0.625\n",
      "  Macro Avg: Precision=0.561 Recall=0.540\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9486 - loss: 0.5012 - val_accuracy: 0.5455 - val_loss: 1.1633 - train_f1_score: 0.9223 - val_f1_score: 0.5446\n",
      "Epoch 212/700\n",
      "\n",
      "Epoch 212: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 212: Train F1=0.9972 - Val F1=0.6587\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 212: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.666 Recall=0.656\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9600 - loss: 0.4817 - val_accuracy: 0.6591 - val_loss: 1.0525 - train_f1_score: 0.9972 - val_f1_score: 0.6587\n",
      "Epoch 213/700\n",
      "\n",
      "Epoch 213: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 213: Train F1=0.9375 - Val F1=0.6496\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 213: Per-class metrics\n",
      "  Class 0: Precision=0.613 Recall=0.704\n",
      "  Class 1: Precision=0.867 Recall=0.448\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.700 Recall=0.655\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9771 - loss: 0.4657 - val_accuracy: 0.6591 - val_loss: 1.0958 - train_f1_score: 0.9375 - val_f1_score: 0.6496\n",
      "Epoch 214/700\n",
      "\n",
      "Epoch 214: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 214: Train F1=0.7475 - Val F1=0.5745\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 214: Per-class metrics\n",
      "  Class 0: Precision=0.444 Recall=0.741\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.786 Recall=0.344\n",
      "  Macro Avg: Precision=0.640 Recall=0.591\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9657 - loss: 0.4814 - val_accuracy: 0.5795 - val_loss: 1.1298 - train_f1_score: 0.7475 - val_f1_score: 0.5745\n",
      "Epoch 215/700\n",
      "\n",
      "Epoch 215: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 215: Train F1=0.9944 - Val F1=0.5557\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 215: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.510 Recall=0.781\n",
      "  Macro Avg: Precision=0.598 Recall=0.560\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9200 - loss: 0.5490 - val_accuracy: 0.5682 - val_loss: 1.2049 - train_f1_score: 0.9944 - val_f1_score: 0.5557\n",
      "Epoch 216/700\n",
      "\n",
      "Epoch 216: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 216: Train F1=0.8173 - Val F1=0.5081\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 216: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.667\n",
      "  Class 1: Precision=0.636 Recall=0.241\n",
      "  Class 2: Precision=0.537 Recall=0.688\n",
      "  Macro Avg: Precision=0.558 Recall=0.532\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9686 - loss: 0.4943 - val_accuracy: 0.5341 - val_loss: 1.2320 - train_f1_score: 0.8173 - val_f1_score: 0.5081\n",
      "Epoch 217/700\n",
      "\n",
      "Epoch 217: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 217: Train F1=0.6476 - Val F1=0.4753\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 217: Per-class metrics\n",
      "  Class 0: Precision=0.447 Recall=0.630\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.486 Recall=0.562\n",
      "  Macro Avg: Precision=0.516 Recall=0.489\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9714 - loss: 0.4926 - val_accuracy: 0.4886 - val_loss: 1.3245 - train_f1_score: 0.6476 - val_f1_score: 0.4753\n",
      "Epoch 218/700\n",
      "\n",
      "Epoch 218: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 218: Train F1=0.8282 - Val F1=0.5475\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 218: Per-class metrics\n",
      "  Class 0: Precision=0.436 Recall=0.630\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.609 Recall=0.438\n",
      "  Macro Avg: Precision=0.566 Recall=0.551\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4602 - val_accuracy: 0.5455 - val_loss: 1.1122 - train_f1_score: 0.8282 - val_f1_score: 0.5475\n",
      "Epoch 219/700\n",
      "\n",
      "Epoch 219: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 219: Train F1=0.8992 - Val F1=0.6137\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 219: Per-class metrics\n",
      "  Class 0: Precision=0.529 Recall=0.667\n",
      "  Class 1: Precision=0.875 Recall=0.483\n",
      "  Class 2: Precision=0.579 Recall=0.688\n",
      "  Macro Avg: Precision=0.661 Recall=0.612\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9686 - loss: 0.4809 - val_accuracy: 0.6136 - val_loss: 1.0883 - train_f1_score: 0.8992 - val_f1_score: 0.6137\n",
      "Epoch 220/700\n",
      "\n",
      "Epoch 220: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220: Train F1=0.9804 - Val F1=0.6815\n",
      "\n",
      "Saved best model at epoch 220 with val_f1=0.6815\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 220: Per-class metrics\n",
      "  Class 0: Precision=0.656 Recall=0.778\n",
      "  Class 1: Precision=0.621 Recall=0.621\n",
      "  Class 2: Precision=0.778 Recall=0.656\n",
      "  Macro Avg: Precision=0.685 Recall=0.685\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9771 - loss: 0.4732 - val_accuracy: 0.6818 - val_loss: 1.0600 - train_f1_score: 0.9804 - val_f1_score: 0.6815\n",
      "Epoch 221/700\n",
      "\n",
      "Epoch 221: val_accuracy did not improve from 0.68182\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 221: Train F1=0.9468 - Val F1=0.5259\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 221: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.500 Recall=0.719\n",
      "  Macro Avg: Precision=0.567 Recall=0.541\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9743 - loss: 0.4796 - val_accuracy: 0.5455 - val_loss: 1.2823 - train_f1_score: 0.9468 - val_f1_score: 0.5259\n",
      "Epoch 222/700\n",
      "\n",
      "Epoch 222: val_accuracy improved from 0.68182 to 0.69318, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222: Train F1=0.9942 - Val F1=0.6919\n",
      "\n",
      "Saved best model at epoch 222 with val_f1=0.6919\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 222: Per-class metrics\n",
      "  Class 0: Precision=0.655 Recall=0.704\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.767 Recall=0.719\n",
      "  Macro Avg: Precision=0.692 Recall=0.693\n",
      "11/11 - 1s - 123ms/step - accuracy: 0.9686 - loss: 0.4916 - val_accuracy: 0.6932 - val_loss: 1.0876 - train_f1_score: 0.9942 - val_f1_score: 0.6919\n",
      "Epoch 223/700\n",
      "\n",
      "Epoch 223: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 223: Train F1=0.9483 - Val F1=0.6440\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 223: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.657 Recall=0.793\n",
      "  Class 2: Precision=0.696 Recall=0.500\n",
      "  Macro Avg: Precision=0.651 Recall=0.653\n",
      "11/11 - 1s - 105ms/step - accuracy: 0.9571 - loss: 0.4944 - val_accuracy: 0.6477 - val_loss: 1.0155 - train_f1_score: 0.9483 - val_f1_score: 0.6440\n",
      "Epoch 224/700\n",
      "\n",
      "Epoch 224: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 224: Train F1=0.9540 - Val F1=0.6248\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 224: Per-class metrics\n",
      "  Class 0: Precision=0.588 Recall=0.741\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.613 Recall=0.594\n",
      "  Macro Avg: Precision=0.632 Recall=0.629\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9743 - loss: 0.4721 - val_accuracy: 0.6250 - val_loss: 1.0586 - train_f1_score: 0.9540 - val_f1_score: 0.6248\n",
      "Epoch 225/700\n",
      "\n",
      "Epoch 225: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 225: Train F1=0.9458 - Val F1=0.6114\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 225: Per-class metrics\n",
      "  Class 0: Precision=0.576 Recall=0.704\n",
      "  Class 1: Precision=0.625 Recall=0.517\n",
      "  Class 2: Precision=0.645 Recall=0.625\n",
      "  Macro Avg: Precision=0.615 Recall=0.615\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9943 - loss: 0.4446 - val_accuracy: 0.6136 - val_loss: 1.0612 - train_f1_score: 0.9458 - val_f1_score: 0.6114\n",
      "Epoch 226/700\n",
      "\n",
      "Epoch 226: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 226: Train F1=0.7665 - Val F1=0.5011\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 226: Per-class metrics\n",
      "  Class 0: Precision=0.450 Recall=0.667\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.514 Recall=0.562\n",
      "  Macro Avg: Precision=0.552 Recall=0.513\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4675 - val_accuracy: 0.5114 - val_loss: 1.2527 - train_f1_score: 0.7665 - val_f1_score: 0.5011\n",
      "Epoch 227/700\n",
      "\n",
      "Epoch 227: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 227: Train F1=0.9545 - Val F1=0.6578\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 227: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.684 Recall=0.654\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9743 - loss: 0.4647 - val_accuracy: 0.6591 - val_loss: 1.0401 - train_f1_score: 0.9545 - val_f1_score: 0.6578\n",
      "Epoch 228/700\n",
      "\n",
      "Epoch 228: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 228: Train F1=0.8676 - Val F1=0.6100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 228: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.556\n",
      "  Class 1: Precision=0.611 Recall=0.759\n",
      "  Class 2: Precision=0.630 Recall=0.531\n",
      "  Macro Avg: Precision=0.614 Recall=0.615\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4513 - val_accuracy: 0.6136 - val_loss: 1.0854 - train_f1_score: 0.8676 - val_f1_score: 0.6100\n",
      "Epoch 229/700\n",
      "\n",
      "Epoch 229: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 229: Train F1=0.9690 - Val F1=0.6463\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 229: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.664 Recall=0.644\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4578 - val_accuracy: 0.6477 - val_loss: 1.0175 - train_f1_score: 0.9690 - val_f1_score: 0.6463\n",
      "Epoch 230/700\n",
      "\n",
      "Epoch 230: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 230: Train F1=0.9913 - Val F1=0.6666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 230: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.741\n",
      "  Class 1: Precision=0.750 Recall=0.517\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.683 Recall=0.669\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9657 - loss: 0.4714 - val_accuracy: 0.6705 - val_loss: 1.0581 - train_f1_score: 0.9913 - val_f1_score: 0.6666\n",
      "Epoch 231/700\n",
      "\n",
      "Epoch 231: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 231: Train F1=0.9233 - Val F1=0.6234\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 231: Per-class metrics\n",
      "  Class 0: Precision=0.553 Recall=0.778\n",
      "  Class 1: Precision=0.704 Recall=0.655\n",
      "  Class 2: Precision=0.652 Recall=0.469\n",
      "  Macro Avg: Precision=0.636 Recall=0.634\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9600 - loss: 0.5024 - val_accuracy: 0.6250 - val_loss: 1.0268 - train_f1_score: 0.9233 - val_f1_score: 0.6234\n",
      "Epoch 232/700\n",
      "\n",
      "Epoch 232: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 232: Train F1=0.9970 - Val F1=0.6109\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 232: Per-class metrics\n",
      "  Class 0: Precision=0.607 Recall=0.630\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.618 Recall=0.611\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9600 - loss: 0.5063 - val_accuracy: 0.6136 - val_loss: 1.1597 - train_f1_score: 0.9970 - val_f1_score: 0.6109\n",
      "Epoch 233/700\n",
      "\n",
      "Epoch 233: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 233: Train F1=0.9828 - Val F1=0.6434\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 233: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.568 Recall=0.862\n",
      "  Class 2: Precision=0.759 Recall=0.688\n",
      "  Macro Avg: Precision=0.687 Recall=0.652\n",
      "11/11 - 1s - 121ms/step - accuracy: 0.9686 - loss: 0.4779 - val_accuracy: 0.6591 - val_loss: 1.0217 - train_f1_score: 0.9828 - val_f1_score: 0.6434\n",
      "Epoch 234/700\n",
      "\n",
      "Epoch 234: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 234: Train F1=1.0000 - Val F1=0.6474\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 234: Per-class metrics\n",
      "  Class 0: Precision=0.688 Recall=0.815\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.662 Recall=0.660\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9686 - loss: 0.4762 - val_accuracy: 0.6591 - val_loss: 1.0550 - train_f1_score: 1.0000 - val_f1_score: 0.6474\n",
      "Epoch 235/700\n",
      "\n",
      "Epoch 235: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 235: Train F1=1.0000 - Val F1=0.6247\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 235: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.567 Recall=0.586\n",
      "  Class 2: Precision=0.656 Recall=0.656\n",
      "  Macro Avg: Precision=0.626 Recall=0.624\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9800 - loss: 0.4603 - val_accuracy: 0.6250 - val_loss: 1.1304 - train_f1_score: 1.0000 - val_f1_score: 0.6247\n",
      "Epoch 236/700\n",
      "\n",
      "Epoch 236: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 236: Train F1=1.0000 - Val F1=0.6309\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 236: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.648 Recall=0.633\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9771 - loss: 0.4561 - val_accuracy: 0.6364 - val_loss: 1.1166 - train_f1_score: 1.0000 - val_f1_score: 0.6309\n",
      "Epoch 237/700\n",
      "\n",
      "Epoch 237: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 237: Train F1=0.9971 - Val F1=0.6658\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 237: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.741\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.677 Recall=0.669\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4503 - val_accuracy: 0.6705 - val_loss: 1.1052 - train_f1_score: 0.9971 - val_f1_score: 0.6658\n",
      "Epoch 238/700\n",
      "\n",
      "Epoch 238: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 238: Train F1=0.9372 - Val F1=0.5730\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 238: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.778\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.667 Recall=0.562\n",
      "  Macro Avg: Precision=0.599 Recall=0.585\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4552 - val_accuracy: 0.5795 - val_loss: 1.1891 - train_f1_score: 0.9372 - val_f1_score: 0.5730\n",
      "Epoch 239/700\n",
      "\n",
      "Epoch 239: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 239: Train F1=0.9856 - Val F1=0.5832\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 239: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.561 Recall=0.719\n",
      "  Macro Avg: Precision=0.597 Recall=0.587\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4565 - val_accuracy: 0.5909 - val_loss: 1.1787 - train_f1_score: 0.9856 - val_f1_score: 0.5832\n",
      "Epoch 240/700\n",
      "\n",
      "Epoch 240: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 240: Train F1=0.9375 - Val F1=0.5498\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 240: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.556\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.579 Recall=0.561\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9886 - loss: 0.4404 - val_accuracy: 0.5682 - val_loss: 1.1788 - train_f1_score: 0.9375 - val_f1_score: 0.5498\n",
      "Epoch 241/700\n",
      "\n",
      "Epoch 241: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 241: Train F1=0.9017 - Val F1=0.5498\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 241: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.556\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.579 Recall=0.561\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9657 - loss: 0.4826 - val_accuracy: 0.5682 - val_loss: 1.1429 - train_f1_score: 0.9017 - val_f1_score: 0.5498\n",
      "Epoch 242/700\n",
      "\n",
      "Epoch 242: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 242: Train F1=0.8538 - Val F1=0.4570\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 242: Per-class metrics\n",
      "  Class 0: Precision=0.542 Recall=0.481\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.481 Recall=0.812\n",
      "  Macro Avg: Precision=0.508 Recall=0.489\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4575 - val_accuracy: 0.5000 - val_loss: 1.2988 - train_f1_score: 0.8538 - val_f1_score: 0.4570\n",
      "Epoch 243/700\n",
      "\n",
      "Epoch 243: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 243: Train F1=0.6820 - Val F1=0.4257\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 243: Per-class metrics\n",
      "  Class 0: Precision=0.413 Recall=0.704\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.500 Recall=0.500\n",
      "  Macro Avg: Precision=0.471 Recall=0.459\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.4521 - val_accuracy: 0.4545 - val_loss: 1.3408 - train_f1_score: 0.6820 - val_f1_score: 0.4257\n",
      "Epoch 244/700\n",
      "\n",
      "Epoch 244: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 244: Train F1=0.6876 - Val F1=0.4178\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 244: Per-class metrics\n",
      "  Class 0: Precision=0.378 Recall=0.630\n",
      "  Class 1: Precision=0.455 Recall=0.172\n",
      "  Class 2: Precision=0.531 Recall=0.531\n",
      "  Macro Avg: Precision=0.455 Recall=0.444\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.9943 - loss: 0.4434 - val_accuracy: 0.4432 - val_loss: 1.3267 - train_f1_score: 0.6876 - val_f1_score: 0.4178\n",
      "Epoch 245/700\n",
      "\n",
      "Epoch 245: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 245: Train F1=0.8045 - Val F1=0.4990\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 245: Per-class metrics\n",
      "  Class 0: Precision=0.475 Recall=0.704\n",
      "  Class 1: Precision=0.583 Recall=0.241\n",
      "  Class 2: Precision=0.556 Recall=0.625\n",
      "  Macro Avg: Precision=0.538 Recall=0.523\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9914 - loss: 0.4396 - val_accuracy: 0.5227 - val_loss: 1.2662 - train_f1_score: 0.8045 - val_f1_score: 0.4990\n",
      "Epoch 246/700\n",
      "\n",
      "Epoch 246: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 246: Train F1=0.9196 - Val F1=0.5450\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 246: Per-class metrics\n",
      "  Class 0: Precision=0.528 Recall=0.704\n",
      "  Class 1: Precision=0.588 Recall=0.345\n",
      "  Class 2: Precision=0.571 Recall=0.625\n",
      "  Macro Avg: Precision=0.562 Recall=0.558\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9800 - loss: 0.4479 - val_accuracy: 0.5568 - val_loss: 1.1573 - train_f1_score: 0.9196 - val_f1_score: 0.5450\n",
      "Epoch 247/700\n",
      "\n",
      "Epoch 247: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 247: Train F1=0.8723 - Val F1=0.5300\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 247: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.667\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.553 Recall=0.656\n",
      "  Macro Avg: Precision=0.565 Recall=0.544\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9943 - loss: 0.4465 - val_accuracy: 0.5455 - val_loss: 1.1916 - train_f1_score: 0.8723 - val_f1_score: 0.5300\n",
      "Epoch 248/700\n",
      "\n",
      "Epoch 248: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 248: Train F1=0.7362 - Val F1=0.4704\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 248: Per-class metrics\n",
      "  Class 0: Precision=0.432 Recall=0.593\n",
      "  Class 1: Precision=0.545 Recall=0.207\n",
      "  Class 2: Precision=0.550 Recall=0.688\n",
      "  Macro Avg: Precision=0.509 Recall=0.496\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4491 - val_accuracy: 0.5000 - val_loss: 1.3675 - train_f1_score: 0.7362 - val_f1_score: 0.4704\n",
      "Epoch 249/700\n",
      "\n",
      "Epoch 249: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 249: Train F1=0.8839 - Val F1=0.6007\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 249: Per-class metrics\n",
      "  Class 0: Precision=0.514 Recall=0.704\n",
      "  Class 1: Precision=0.737 Recall=0.483\n",
      "  Class 2: Precision=0.625 Recall=0.625\n",
      "  Macro Avg: Precision=0.625 Recall=0.604\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9857 - loss: 0.4467 - val_accuracy: 0.6023 - val_loss: 1.1619 - train_f1_score: 0.8839 - val_f1_score: 0.6007\n",
      "Epoch 250/700\n",
      "\n",
      "Epoch 250: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 250: Train F1=0.9739 - Val F1=0.6706\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 250: Per-class metrics\n",
      "  Class 0: Precision=0.633 Recall=0.704\n",
      "  Class 1: Precision=0.704 Recall=0.655\n",
      "  Class 2: Precision=0.677 Recall=0.656\n",
      "  Macro Avg: Precision=0.671 Recall=0.672\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9629 - loss: 0.4716 - val_accuracy: 0.6705 - val_loss: 1.0194 - train_f1_score: 0.9739 - val_f1_score: 0.6706\n",
      "Epoch 251/700\n",
      "\n",
      "Epoch 251: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251: Train F1=1.0000 - Val F1=0.6934\n",
      "\n",
      "Saved best model at epoch 251 with val_f1=0.6934\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 251: Per-class metrics\n",
      "  Class 0: Precision=0.677 Recall=0.778\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.698 Recall=0.695\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9743 - loss: 0.4535 - val_accuracy: 0.6932 - val_loss: 1.0328 - train_f1_score: 1.0000 - val_f1_score: 0.6934\n",
      "Epoch 252/700\n",
      "\n",
      "Epoch 252: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 252: Train F1=0.9971 - Val F1=0.6752\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 252: Per-class metrics\n",
      "  Class 0: Precision=0.710 Recall=0.815\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.686 Recall=0.683\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.4530 - val_accuracy: 0.6818 - val_loss: 1.0675 - train_f1_score: 0.9971 - val_f1_score: 0.6752\n",
      "Epoch 253/700\n",
      "\n",
      "Epoch 253: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 253: Train F1=0.9943 - Val F1=0.6540\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 253: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.666 Recall=0.655\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9886 - loss: 0.4503 - val_accuracy: 0.6591 - val_loss: 1.1174 - train_f1_score: 0.9943 - val_f1_score: 0.6540\n",
      "Epoch 254/700\n",
      "\n",
      "Epoch 254: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 254: Train F1=1.0000 - Val F1=0.6673\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 254: Per-class metrics\n",
      "  Class 0: Precision=0.731 Recall=0.704\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.685 Recall=0.667\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9857 - loss: 0.4347 - val_accuracy: 0.6705 - val_loss: 1.1371 - train_f1_score: 1.0000 - val_f1_score: 0.6673\n",
      "Epoch 255/700\n",
      "\n",
      "Epoch 255: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 255: Train F1=1.0000 - Val F1=0.6304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 255: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.625 Recall=0.517\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.634 Recall=0.632\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4459 - val_accuracy: 0.6364 - val_loss: 1.1743 - train_f1_score: 1.0000 - val_f1_score: 0.6304\n",
      "Epoch 256/700\n",
      "\n",
      "Epoch 256: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 256: Train F1=0.9942 - Val F1=0.6452\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 256: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.643 Recall=0.621\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.649 Recall=0.644\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4415 - val_accuracy: 0.6477 - val_loss: 1.2027 - train_f1_score: 0.9942 - val_f1_score: 0.6452\n",
      "Epoch 257/700\n",
      "\n",
      "Epoch 257: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 257: Train F1=1.0000 - Val F1=0.6345\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 257: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.654 Recall=0.632\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4450 - val_accuracy: 0.6364 - val_loss: 1.1248 - train_f1_score: 1.0000 - val_f1_score: 0.6345\n",
      "Epoch 258/700\n",
      "\n",
      "Epoch 258: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 258: Train F1=0.9775 - Val F1=0.6932\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 258: Per-class metrics\n",
      "  Class 0: Precision=0.690 Recall=0.741\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.759 Recall=0.688\n",
      "  Macro Avg: Precision=0.694 Recall=0.694\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9743 - loss: 0.4569 - val_accuracy: 0.6932 - val_loss: 1.0175 - train_f1_score: 0.9775 - val_f1_score: 0.6932\n",
      "Epoch 259/700\n",
      "\n",
      "Epoch 259: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 259: Train F1=0.9945 - Val F1=0.6104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 259: Per-class metrics\n",
      "  Class 0: Precision=0.655 Recall=0.704\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.620 Recall=0.621\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9686 - loss: 0.4746 - val_accuracy: 0.6250 - val_loss: 1.1616 - train_f1_score: 0.9945 - val_f1_score: 0.6104\n",
      "Epoch 260/700\n",
      "\n",
      "Epoch 260: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 260: Train F1=0.9886 - Val F1=0.6330\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 260: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.600 Recall=0.621\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.640 Recall=0.632\n",
      "11/11 - 1s - 94ms/step - accuracy: 1.0000 - loss: 0.4263 - val_accuracy: 0.6364 - val_loss: 1.1671 - train_f1_score: 0.9886 - val_f1_score: 0.6330\n",
      "Epoch 261/700\n",
      "\n",
      "Epoch 261: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 261: Train F1=0.9944 - Val F1=0.6311\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 261: Per-class metrics\n",
      "  Class 0: Precision=0.633 Recall=0.704\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.641 Recall=0.635\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9800 - loss: 0.4468 - val_accuracy: 0.6364 - val_loss: 1.2199 - train_f1_score: 0.9944 - val_f1_score: 0.6311\n",
      "Epoch 262/700\n",
      "\n",
      "Epoch 262: val_accuracy did not improve from 0.69318\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 262: Train F1=0.9971 - Val F1=0.6816\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 262: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.667\n",
      "  Class 1: Precision=0.739 Recall=0.586\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.700 Recall=0.678\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4512 - val_accuracy: 0.6818 - val_loss: 1.0656 - train_f1_score: 0.9971 - val_f1_score: 0.6816\n",
      "Epoch 263/700\n",
      "\n",
      "Epoch 263: val_accuracy improved from 0.69318 to 0.70455, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263: Train F1=0.9856 - Val F1=0.7044\n",
      "\n",
      "Saved best model at epoch 263 with val_f1=0.7044\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 263: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.714 Recall=0.690\n",
      "  Class 2: Precision=0.697 Recall=0.719\n",
      "  Macro Avg: Precision=0.705 Recall=0.704\n",
      "11/11 - 1s - 122ms/step - accuracy: 0.9857 - loss: 0.4339 - val_accuracy: 0.7045 - val_loss: 0.9883 - train_f1_score: 0.9856 - val_f1_score: 0.7044\n",
      "Epoch 264/700\n",
      "\n",
      "Epoch 264: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 264: Train F1=0.9722 - Val F1=0.6542\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 264: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.741\n",
      "  Class 1: Precision=0.824 Recall=0.483\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.688 Recall=0.658\n",
      "11/11 - 1s - 108ms/step - accuracy: 0.9857 - loss: 0.4388 - val_accuracy: 0.6591 - val_loss: 1.0442 - train_f1_score: 0.9722 - val_f1_score: 0.6542\n",
      "Epoch 265/700\n",
      "\n",
      "Epoch 265: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 265: Train F1=1.0000 - Val F1=0.6583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 265: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.630 Recall=0.586\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.658 Recall=0.659\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4374 - val_accuracy: 0.6591 - val_loss: 1.0951 - train_f1_score: 1.0000 - val_f1_score: 0.6583\n",
      "Epoch 266/700\n",
      "\n",
      "Epoch 266: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 266: Train F1=0.9971 - Val F1=0.6691\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 266: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.682 Recall=0.668\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9771 - loss: 0.4628 - val_accuracy: 0.6705 - val_loss: 1.0837 - train_f1_score: 0.9971 - val_f1_score: 0.6691\n",
      "Epoch 267/700\n",
      "\n",
      "Epoch 267: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 267: Train F1=0.9432 - Val F1=0.6447\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 267: Per-class metrics\n",
      "  Class 0: Precision=0.613 Recall=0.704\n",
      "  Class 1: Precision=0.750 Recall=0.517\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.662 Recall=0.647\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9743 - loss: 0.4494 - val_accuracy: 0.6477 - val_loss: 1.0603 - train_f1_score: 0.9432 - val_f1_score: 0.6447\n",
      "Epoch 268/700\n",
      "\n",
      "Epoch 268: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 268: Train F1=0.9550 - Val F1=0.6056\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 268: Per-class metrics\n",
      "  Class 0: Precision=0.606 Recall=0.741\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.643 Recall=0.622\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9829 - loss: 0.4367 - val_accuracy: 0.6250 - val_loss: 1.1563 - train_f1_score: 0.9550 - val_f1_score: 0.6056\n",
      "Epoch 269/700\n",
      "\n",
      "Epoch 269: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 269: Train F1=0.9745 - Val F1=0.6423\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 269: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.657 Recall=0.643\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4331 - val_accuracy: 0.6477 - val_loss: 1.2149 - train_f1_score: 0.9745 - val_f1_score: 0.6423\n",
      "Epoch 270/700\n",
      "\n",
      "Epoch 270: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 270: Train F1=0.9545 - Val F1=0.6141\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 270: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.631 Recall=0.621\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9886 - loss: 0.4419 - val_accuracy: 0.6250 - val_loss: 1.2661 - train_f1_score: 0.9545 - val_f1_score: 0.6141\n",
      "Epoch 271/700\n",
      "\n",
      "Epoch 271: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 271: Train F1=0.8496 - Val F1=0.5412\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 271: Per-class metrics\n",
      "  Class 0: Precision=0.559 Recall=0.704\n",
      "  Class 1: Precision=0.500 Recall=0.310\n",
      "  Class 2: Precision=0.583 Recall=0.656\n",
      "  Macro Avg: Precision=0.547 Recall=0.557\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.4313 - val_accuracy: 0.5568 - val_loss: 1.3361 - train_f1_score: 0.8496 - val_f1_score: 0.5412\n",
      "Epoch 272/700\n",
      "\n",
      "Epoch 272: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 272: Train F1=0.9664 - Val F1=0.6654\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 272: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.676 Recall=0.667\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9943 - loss: 0.4274 - val_accuracy: 0.6705 - val_loss: 1.2128 - train_f1_score: 0.9664 - val_f1_score: 0.6654\n",
      "Epoch 273/700\n",
      "\n",
      "Epoch 273: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 273: Train F1=0.8951 - Val F1=0.6217\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 273: Per-class metrics\n",
      "  Class 0: Precision=0.579 Recall=0.815\n",
      "  Class 1: Precision=0.786 Recall=0.379\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.668 Recall=0.638\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9800 - loss: 0.4427 - val_accuracy: 0.6364 - val_loss: 1.1810 - train_f1_score: 0.8951 - val_f1_score: 0.6217\n",
      "Epoch 274/700\n",
      "\n",
      "Epoch 274: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 274: Train F1=0.8673 - Val F1=0.6104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 274: Per-class metrics\n",
      "  Class 0: Precision=0.633 Recall=0.704\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.639 Recall=0.621\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9886 - loss: 0.4383 - val_accuracy: 0.6250 - val_loss: 1.2186 - train_f1_score: 0.8673 - val_f1_score: 0.6104\n",
      "Epoch 275/700\n",
      "\n",
      "Epoch 275: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 275: Train F1=0.9916 - Val F1=0.6515\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 275: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.778\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.667 Recall=0.659\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9771 - loss: 0.4537 - val_accuracy: 0.6591 - val_loss: 1.1208 - train_f1_score: 0.9916 - val_f1_score: 0.6515\n",
      "Epoch 276/700\n",
      "\n",
      "Epoch 276: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 276: Train F1=0.8062 - Val F1=0.5484\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 276: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.741\n",
      "  Class 1: Precision=0.538 Recall=0.241\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.570 Recall=0.577\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9800 - loss: 0.4512 - val_accuracy: 0.5795 - val_loss: 1.3455 - train_f1_score: 0.8062 - val_f1_score: 0.5484\n",
      "Epoch 277/700\n",
      "\n",
      "Epoch 277: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 277: Train F1=0.8257 - Val F1=0.4996\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 277: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.630\n",
      "  Class 1: Precision=0.500 Recall=0.207\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.524 Recall=0.529\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4306 - val_accuracy: 0.5341 - val_loss: 1.4080 - train_f1_score: 0.8257 - val_f1_score: 0.4996\n",
      "Epoch 278/700\n",
      "\n",
      "Epoch 278: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 278: Train F1=0.9914 - Val F1=0.6453\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 278: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.706 Recall=0.414\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.674 Recall=0.654\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4313 - val_accuracy: 0.6591 - val_loss: 1.1933 - train_f1_score: 0.9914 - val_f1_score: 0.6453\n",
      "Epoch 279/700\n",
      "\n",
      "Epoch 279: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 279: Train F1=0.9653 - Val F1=0.6315\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 279: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.571 Recall=0.875\n",
      "  Macro Avg: Precision=0.685 Recall=0.634\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4393 - val_accuracy: 0.6477 - val_loss: 1.1097 - train_f1_score: 0.9653 - val_f1_score: 0.6315\n",
      "Epoch 280/700\n",
      "\n",
      "Epoch 280: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 280: Train F1=0.9971 - Val F1=0.6812\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 280: Per-class metrics\n",
      "  Class 0: Precision=0.655 Recall=0.704\n",
      "  Class 1: Precision=0.679 Recall=0.655\n",
      "  Class 2: Precision=0.710 Recall=0.688\n",
      "  Macro Avg: Precision=0.681 Recall=0.682\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4417 - val_accuracy: 0.6818 - val_loss: 1.1092 - train_f1_score: 0.9971 - val_f1_score: 0.6812\n",
      "Epoch 281/700\n",
      "\n",
      "Epoch 281: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 281: Train F1=0.9971 - Val F1=0.6568\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 281: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.741\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.662 Recall=0.660\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9829 - loss: 0.4418 - val_accuracy: 0.6591 - val_loss: 1.1619 - train_f1_score: 0.9971 - val_f1_score: 0.6568\n",
      "Epoch 282/700\n",
      "\n",
      "Epoch 282: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 282: Train F1=0.9830 - Val F1=0.6045\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 282: Per-class metrics\n",
      "  Class 0: Precision=0.588 Recall=0.741\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.611 Recall=0.688\n",
      "  Macro Avg: Precision=0.622 Recall=0.614\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9886 - loss: 0.4369 - val_accuracy: 0.6136 - val_loss: 1.2269 - train_f1_score: 0.9830 - val_f1_score: 0.6045\n",
      "Epoch 283/700\n",
      "\n",
      "Epoch 283: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 283: Train F1=0.9972 - Val F1=0.6949\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 283: Per-class metrics\n",
      "  Class 0: Precision=0.810 Recall=0.630\n",
      "  Class 1: Precision=0.677 Recall=0.724\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.709 Recall=0.691\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9771 - loss: 0.4478 - val_accuracy: 0.6932 - val_loss: 1.0615 - train_f1_score: 0.9972 - val_f1_score: 0.6949\n",
      "Epoch 284/700\n",
      "\n",
      "Epoch 284: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 284: Train F1=0.9509 - Val F1=0.6190\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 284: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.637 Recall=0.617\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9743 - loss: 0.4567 - val_accuracy: 0.6250 - val_loss: 1.0470 - train_f1_score: 0.9509 - val_f1_score: 0.6190\n",
      "Epoch 285/700\n",
      "\n",
      "Epoch 285: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 285: Train F1=0.9307 - Val F1=0.5983\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 285: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.259\n",
      "  Class 1: Precision=0.686 Recall=0.828\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.656 Recall=0.623\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9857 - loss: 0.4412 - val_accuracy: 0.6364 - val_loss: 1.1500 - train_f1_score: 0.9307 - val_f1_score: 0.5983\n",
      "Epoch 286/700\n",
      "\n",
      "Epoch 286: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 286: Train F1=0.9687 - Val F1=0.6756\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 286: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.628 Recall=0.844\n",
      "  Macro Avg: Precision=0.699 Recall=0.675\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4522 - val_accuracy: 0.6818 - val_loss: 1.1194 - train_f1_score: 0.9687 - val_f1_score: 0.6756\n",
      "Epoch 287/700\n",
      "\n",
      "Epoch 287: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 287: Train F1=0.7745 - Val F1=0.4627\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 287: Per-class metrics\n",
      "  Class 0: Precision=0.400 Recall=0.222\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.517 Recall=0.969\n",
      "  Macro Avg: Precision=0.536 Recall=0.500\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4401 - val_accuracy: 0.5227 - val_loss: 1.3343 - train_f1_score: 0.7745 - val_f1_score: 0.4627\n",
      "Epoch 288/700\n",
      "\n",
      "Epoch 288: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 288: Train F1=0.7522 - Val F1=0.4930\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 288: Per-class metrics\n",
      "  Class 0: Precision=0.417 Recall=0.556\n",
      "  Class 1: Precision=0.727 Recall=0.276\n",
      "  Class 2: Precision=0.537 Recall=0.688\n",
      "  Macro Avg: Precision=0.560 Recall=0.506\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9714 - loss: 0.4633 - val_accuracy: 0.5114 - val_loss: 1.2432 - train_f1_score: 0.7522 - val_f1_score: 0.4930\n",
      "Epoch 289/700\n",
      "\n",
      "Epoch 289: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 289: Train F1=0.6964 - Val F1=0.4030\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 289: Per-class metrics\n",
      "  Class 0: Precision=0.429 Recall=0.444\n",
      "  Class 1: Precision=0.750 Recall=0.103\n",
      "  Class 2: Precision=0.464 Recall=0.812\n",
      "  Macro Avg: Precision=0.548 Recall=0.453\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9829 - loss: 0.4481 - val_accuracy: 0.4659 - val_loss: 1.4068 - train_f1_score: 0.6964 - val_f1_score: 0.4030\n",
      "Epoch 290/700\n",
      "\n",
      "Epoch 290: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 290: Train F1=0.9029 - Val F1=0.6217\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 290: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.765 Recall=0.448\n",
      "  Class 2: Precision=0.583 Recall=0.875\n",
      "  Macro Avg: Precision=0.667 Recall=0.626\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9714 - loss: 0.4658 - val_accuracy: 0.6364 - val_loss: 1.1162 - train_f1_score: 0.9029 - val_f1_score: 0.6217\n",
      "Epoch 291/700\n",
      "\n",
      "Epoch 291: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 291: Train F1=0.9377 - Val F1=0.5876\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 291: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.618 Recall=0.597\n",
      "11/11 - 1s - 98ms/step - accuracy: 0.9857 - loss: 0.4471 - val_accuracy: 0.6023 - val_loss: 1.1557 - train_f1_score: 0.9377 - val_f1_score: 0.5876\n",
      "Epoch 292/700\n",
      "\n",
      "Epoch 292: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 292: Train F1=0.6314 - Val F1=0.4352\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 292: Per-class metrics\n",
      "  Class 0: Precision=0.415 Recall=0.630\n",
      "  Class 1: Precision=0.571 Recall=0.138\n",
      "  Class 2: Precision=0.525 Recall=0.656\n",
      "  Macro Avg: Precision=0.504 Recall=0.475\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9829 - loss: 0.4526 - val_accuracy: 0.4773 - val_loss: 1.3292 - train_f1_score: 0.6314 - val_f1_score: 0.4352\n",
      "Epoch 293/700\n",
      "\n",
      "Epoch 293: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 293: Train F1=0.7716 - Val F1=0.4987\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 293: Per-class metrics\n",
      "  Class 0: Precision=0.565 Recall=0.481\n",
      "  Class 1: Precision=0.750 Recall=0.207\n",
      "  Class 2: Precision=0.509 Recall=0.906\n",
      "  Macro Avg: Precision=0.608 Recall=0.532\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4290 - val_accuracy: 0.5455 - val_loss: 1.4124 - train_f1_score: 0.7716 - val_f1_score: 0.4987\n",
      "Epoch 294/700\n",
      "\n",
      "Epoch 294: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 294: Train F1=0.8882 - Val F1=0.5544\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 294: Per-class metrics\n",
      "  Class 0: Precision=0.471 Recall=0.593\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.571 Recall=0.625\n",
      "  Macro Avg: Precision=0.575 Recall=0.555\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9714 - loss: 0.4559 - val_accuracy: 0.5568 - val_loss: 1.1870 - train_f1_score: 0.8882 - val_f1_score: 0.5544\n",
      "Epoch 295/700\n",
      "\n",
      "Epoch 295: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 295: Train F1=0.8620 - Val F1=0.4705\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 295: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.103\n",
      "  Class 2: Precision=0.500 Recall=0.875\n",
      "  Macro Avg: Precision=0.538 Recall=0.524\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9686 - loss: 0.4618 - val_accuracy: 0.5341 - val_loss: 1.3910 - train_f1_score: 0.8620 - val_f1_score: 0.4705\n",
      "Epoch 296/700\n",
      "\n",
      "Epoch 296: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 296: Train F1=0.9721 - Val F1=0.5556\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 296: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.519\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.521 Recall=0.781\n",
      "  Macro Avg: Precision=0.589 Recall=0.560\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9714 - loss: 0.4599 - val_accuracy: 0.5682 - val_loss: 1.2045 - train_f1_score: 0.9721 - val_f1_score: 0.5556\n",
      "Epoch 297/700\n",
      "\n",
      "Epoch 297: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 297: Train F1=0.9691 - Val F1=0.5670\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 297: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.595 Recall=0.571\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9829 - loss: 0.4449 - val_accuracy: 0.5795 - val_loss: 1.1937 - train_f1_score: 0.9691 - val_f1_score: 0.5670\n",
      "Epoch 298/700\n",
      "\n",
      "Epoch 298: val_accuracy did not improve from 0.70455\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 298: Train F1=0.9571 - Val F1=0.6208\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 298: Per-class metrics\n",
      "  Class 0: Precision=0.545 Recall=0.667\n",
      "  Class 1: Precision=0.778 Recall=0.483\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.648 Recall=0.623\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9829 - loss: 0.4362 - val_accuracy: 0.6250 - val_loss: 1.1573 - train_f1_score: 0.9571 - val_f1_score: 0.6208\n",
      "Epoch 299/700\n",
      "\n",
      "Epoch 299: val_accuracy improved from 0.70455 to 0.71591, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: Train F1=0.9566 - Val F1=0.7160\n",
      "\n",
      "Saved best model at epoch 299 with val_f1=0.7160\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 299: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.733 Recall=0.759\n",
      "  Class 2: Precision=0.710 Recall=0.688\n",
      "  Macro Avg: Precision=0.716 Recall=0.717\n",
      "11/11 - 1s - 122ms/step - accuracy: 0.9886 - loss: 0.4291 - val_accuracy: 0.7159 - val_loss: 1.0074 - train_f1_score: 0.9566 - val_f1_score: 0.7160\n",
      "Epoch 300/700\n",
      "\n",
      "Epoch 300: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 300: Train F1=0.9856 - Val F1=0.6774\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 300: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.694 Recall=0.675\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9943 - loss: 0.4341 - val_accuracy: 0.6818 - val_loss: 1.1341 - train_f1_score: 0.9856 - val_f1_score: 0.6774\n",
      "Epoch 301/700\n",
      "\n",
      "Epoch 301: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 301: Train F1=0.9858 - Val F1=0.5972\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 301: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.621 Recall=0.596\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9657 - loss: 0.4483 - val_accuracy: 0.6023 - val_loss: 1.1689 - train_f1_score: 0.9858 - val_f1_score: 0.5972\n",
      "Epoch 302/700\n",
      "\n",
      "Epoch 302: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 302: Train F1=0.9858 - Val F1=0.5905\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 302: Per-class metrics\n",
      "  Class 0: Precision=0.650 Recall=0.481\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.553 Recall=0.812\n",
      "  Macro Avg: Precision=0.623 Recall=0.592\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9829 - loss: 0.4350 - val_accuracy: 0.6023 - val_loss: 1.2483 - train_f1_score: 0.9858 - val_f1_score: 0.5905\n",
      "Epoch 303/700\n",
      "\n",
      "Epoch 303: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 303: Train F1=0.9970 - Val F1=0.6159\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 303: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.650 Recall=0.448\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.633 Recall=0.620\n",
      "11/11 - 1s - 116ms/step - accuracy: 1.0000 - loss: 0.4198 - val_accuracy: 0.6250 - val_loss: 1.2581 - train_f1_score: 0.9970 - val_f1_score: 0.6159\n",
      "Epoch 304/700\n",
      "\n",
      "Epoch 304: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 304: Train F1=1.0000 - Val F1=0.6393\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 304: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.636 Recall=0.483\n",
      "  Class 2: Precision=0.658 Recall=0.781\n",
      "  Macro Avg: Precision=0.646 Recall=0.644\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9914 - loss: 0.4280 - val_accuracy: 0.6477 - val_loss: 1.1917 - train_f1_score: 1.0000 - val_f1_score: 0.6393\n",
      "Epoch 305/700\n",
      "\n",
      "Epoch 305: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 305: Train F1=0.9858 - Val F1=0.6794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 305: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.697 Recall=0.679\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9943 - loss: 0.4299 - val_accuracy: 0.6818 - val_loss: 1.0854 - train_f1_score: 0.9858 - val_f1_score: 0.6794\n",
      "Epoch 306/700\n",
      "\n",
      "Epoch 306: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 306: Train F1=0.9001 - Val F1=0.5545\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 306: Per-class metrics\n",
      "  Class 0: Precision=0.455 Recall=0.741\n",
      "  Class 1: Precision=0.750 Recall=0.414\n",
      "  Class 2: Precision=0.607 Recall=0.531\n",
      "  Macro Avg: Precision=0.604 Recall=0.562\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.4231 - val_accuracy: 0.5568 - val_loss: 1.1863 - train_f1_score: 0.9001 - val_f1_score: 0.5545\n",
      "Epoch 307/700\n",
      "\n",
      "Epoch 307: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 307: Train F1=0.9684 - Val F1=0.6232\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 307: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.641 Recall=0.621\n",
      "11/11 - 1s - 117ms/step - accuracy: 1.0000 - loss: 0.4143 - val_accuracy: 0.6250 - val_loss: 1.1126 - train_f1_score: 0.9684 - val_f1_score: 0.6232\n",
      "Epoch 308/700\n",
      "\n",
      "Epoch 308: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 308: Train F1=0.9914 - Val F1=0.6343\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 308: Per-class metrics\n",
      "  Class 0: Precision=0.621 Recall=0.667\n",
      "  Class 1: Precision=0.750 Recall=0.517\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.653 Recall=0.634\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4251 - val_accuracy: 0.6364 - val_loss: 1.0948 - train_f1_score: 0.9914 - val_f1_score: 0.6343\n",
      "Epoch 309/700\n",
      "\n",
      "Epoch 309: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 309: Train F1=0.9801 - Val F1=0.6604\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 309: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.773 Recall=0.586\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.676 Recall=0.657\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4240 - val_accuracy: 0.6591 - val_loss: 1.0471 - train_f1_score: 0.9801 - val_f1_score: 0.6604\n",
      "Epoch 310/700\n",
      "\n",
      "Epoch 310: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 310: Train F1=0.9712 - Val F1=0.6553\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 310: Per-class metrics\n",
      "  Class 0: Precision=0.621 Recall=0.667\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.666 Recall=0.656\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4163 - val_accuracy: 0.6591 - val_loss: 1.0598 - train_f1_score: 0.9712 - val_f1_score: 0.6553\n",
      "Epoch 311/700\n",
      "\n",
      "Epoch 311: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 311: Train F1=0.8771 - Val F1=0.5747\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 311: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.587 Recall=0.575\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9714 - loss: 0.4450 - val_accuracy: 0.5795 - val_loss: 1.3158 - train_f1_score: 0.8771 - val_f1_score: 0.5747\n",
      "Epoch 312/700\n",
      "\n",
      "Epoch 312: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 312: Train F1=0.6398 - Val F1=0.4321\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 312: Per-class metrics\n",
      "  Class 0: Precision=0.407 Recall=0.815\n",
      "  Class 1: Precision=0.625 Recall=0.172\n",
      "  Class 2: Precision=0.538 Recall=0.438\n",
      "  Macro Avg: Precision=0.524 Recall=0.475\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9857 - loss: 0.4273 - val_accuracy: 0.4659 - val_loss: 1.4580 - train_f1_score: 0.6398 - val_f1_score: 0.4321\n",
      "Epoch 313/700\n",
      "\n",
      "Epoch 313: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 313: Train F1=0.9350 - Val F1=0.7108\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 313: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.684 Recall=0.897\n",
      "  Class 2: Precision=0.769 Recall=0.625\n",
      "  Macro Avg: Precision=0.721 Recall=0.717\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9800 - loss: 0.4400 - val_accuracy: 0.7159 - val_loss: 1.0126 - train_f1_score: 0.9350 - val_f1_score: 0.7108\n",
      "Epoch 314/700\n",
      "\n",
      "Epoch 314: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 314: Train F1=0.9944 - Val F1=0.6789\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 314: Per-class metrics\n",
      "  Class 0: Precision=0.731 Recall=0.704\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.689 Recall=0.679\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9829 - loss: 0.4310 - val_accuracy: 0.6818 - val_loss: 1.0742 - train_f1_score: 0.9944 - val_f1_score: 0.6789\n",
      "Epoch 315/700\n",
      "\n",
      "Epoch 315: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 315: Train F1=0.9914 - Val F1=0.6442\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 315: Per-class metrics\n",
      "  Class 0: Precision=0.588 Recall=0.741\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.656 Recall=0.648\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9800 - loss: 0.4283 - val_accuracy: 0.6477 - val_loss: 1.1379 - train_f1_score: 0.9914 - val_f1_score: 0.6442\n",
      "Epoch 316/700\n",
      "\n",
      "Epoch 316: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 316: Train F1=1.0000 - Val F1=0.6911\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 316: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.658 Recall=0.781\n",
      "  Macro Avg: Precision=0.699 Recall=0.690\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9829 - loss: 0.4351 - val_accuracy: 0.6932 - val_loss: 1.0820 - train_f1_score: 1.0000 - val_f1_score: 0.6911\n",
      "Epoch 317/700\n",
      "\n",
      "Epoch 317: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 317: Train F1=1.0000 - Val F1=0.6766\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 317: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.690 Recall=0.675\n",
      "11/11 - 1s - 94ms/step - accuracy: 1.0000 - loss: 0.4115 - val_accuracy: 0.6818 - val_loss: 1.0778 - train_f1_score: 1.0000 - val_f1_score: 0.6766\n",
      "Epoch 318/700\n",
      "\n",
      "Epoch 318: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 318: Train F1=0.9944 - Val F1=0.6691\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 318: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.659 Recall=0.844\n",
      "  Macro Avg: Precision=0.690 Recall=0.672\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9943 - loss: 0.4137 - val_accuracy: 0.6818 - val_loss: 1.0467 - train_f1_score: 0.9944 - val_f1_score: 0.6691\n",
      "Epoch 319/700\n",
      "\n",
      "Epoch 319: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 319: Train F1=0.9571 - Val F1=0.5837\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 319: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.296\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.562 Recall=0.844\n",
      "  Macro Avg: Precision=0.648 Recall=0.598\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4268 - val_accuracy: 0.6136 - val_loss: 1.1546 - train_f1_score: 0.9571 - val_f1_score: 0.5837\n",
      "Epoch 320/700\n",
      "\n",
      "Epoch 320: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 320: Train F1=0.9717 - Val F1=0.6422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 320: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.677 Recall=0.724\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.677 Recall=0.648\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9971 - loss: 0.4119 - val_accuracy: 0.6591 - val_loss: 1.0699 - train_f1_score: 0.9717 - val_f1_score: 0.6422\n",
      "Epoch 321/700\n",
      "\n",
      "Epoch 321: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 321: Train F1=0.9971 - Val F1=0.6348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 321: Per-class metrics\n",
      "  Class 0: Precision=0.645 Recall=0.741\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.651 Recall=0.645\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4276 - val_accuracy: 0.6477 - val_loss: 1.1719 - train_f1_score: 0.9971 - val_f1_score: 0.6348\n",
      "Epoch 322/700\n",
      "\n",
      "Epoch 322: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 322: Train F1=0.9574 - Val F1=0.6610\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 322: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.609 Recall=0.875\n",
      "  Macro Avg: Precision=0.695 Recall=0.661\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9800 - loss: 0.4362 - val_accuracy: 0.6705 - val_loss: 1.0875 - train_f1_score: 0.9574 - val_f1_score: 0.6610\n",
      "Epoch 323/700\n",
      "\n",
      "Epoch 323: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 323: Train F1=0.9513 - Val F1=0.6448\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 323: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.722 Recall=0.448\n",
      "  Class 2: Precision=0.622 Recall=0.875\n",
      "  Macro Avg: Precision=0.675 Recall=0.651\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4451 - val_accuracy: 0.6591 - val_loss: 1.0996 - train_f1_score: 0.9513 - val_f1_score: 0.6448\n",
      "Epoch 324/700\n",
      "\n",
      "Epoch 324: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 324: Train F1=0.9944 - Val F1=0.6485\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 324: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.778 Recall=0.483\n",
      "  Class 2: Precision=0.628 Recall=0.844\n",
      "  Macro Avg: Precision=0.678 Recall=0.652\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4120 - val_accuracy: 0.6591 - val_loss: 1.1420 - train_f1_score: 0.9944 - val_f1_score: 0.6485\n",
      "Epoch 325/700\n",
      "\n",
      "Epoch 325: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 325: Train F1=0.9188 - Val F1=0.6704\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 325: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.792 Recall=0.655\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.686 Recall=0.666\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.4151 - val_accuracy: 0.6705 - val_loss: 1.0117 - train_f1_score: 0.9188 - val_f1_score: 0.6704\n",
      "Epoch 326/700\n",
      "\n",
      "Epoch 326: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 326: Train F1=0.9049 - Val F1=0.5867\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 326: Per-class metrics\n",
      "  Class 0: Precision=0.560 Recall=0.519\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.548 Recall=0.719\n",
      "  Macro Avg: Precision=0.607 Recall=0.585\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4183 - val_accuracy: 0.5909 - val_loss: 1.1325 - train_f1_score: 0.9049 - val_f1_score: 0.5867\n",
      "Epoch 327/700\n",
      "\n",
      "Epoch 327: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 327: Train F1=0.8830 - Val F1=0.5689\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 327: Per-class metrics\n",
      "  Class 0: Precision=0.514 Recall=0.704\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.552 Recall=0.500\n",
      "  Macro Avg: Precision=0.582 Recall=0.574\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4203 - val_accuracy: 0.5682 - val_loss: 1.1492 - train_f1_score: 0.8830 - val_f1_score: 0.5689\n",
      "Epoch 328/700\n",
      "\n",
      "Epoch 328: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 328: Train F1=0.8384 - Val F1=0.5631\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 328: Per-class metrics\n",
      "  Class 0: Precision=0.515 Recall=0.630\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.605 Recall=0.575\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9743 - loss: 0.4440 - val_accuracy: 0.5795 - val_loss: 1.3306 - train_f1_score: 0.8384 - val_f1_score: 0.5631\n",
      "Epoch 329/700\n",
      "\n",
      "Epoch 329: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 329: Train F1=0.9364 - Val F1=0.5631\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 329: Per-class metrics\n",
      "  Class 0: Precision=0.548 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.345\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.595 Recall=0.575\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9857 - loss: 0.4355 - val_accuracy: 0.5795 - val_loss: 1.2840 - train_f1_score: 0.9364 - val_f1_score: 0.5631\n",
      "Epoch 330/700\n",
      "\n",
      "Epoch 330: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 330: Train F1=0.9659 - Val F1=0.6073\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 330: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.733 Recall=0.379\n",
      "  Class 2: Precision=0.587 Recall=0.844\n",
      "  Macro Avg: Precision=0.650 Recall=0.618\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4190 - val_accuracy: 0.6250 - val_loss: 1.1992 - train_f1_score: 0.9659 - val_f1_score: 0.6073\n",
      "Epoch 331/700\n",
      "\n",
      "Epoch 331: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 331: Train F1=0.9015 - Val F1=0.5849\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 331: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.667\n",
      "  Class 1: Precision=0.800 Recall=0.414\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.632 Recall=0.589\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9971 - loss: 0.4138 - val_accuracy: 0.5909 - val_loss: 1.2070 - train_f1_score: 0.9015 - val_f1_score: 0.5849\n",
      "Epoch 332/700\n",
      "\n",
      "Epoch 332: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 332: Train F1=0.9071 - Val F1=0.5889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 332: Per-class metrics\n",
      "  Class 0: Precision=0.531 Recall=0.630\n",
      "  Class 1: Precision=0.846 Recall=0.379\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.653 Recall=0.597\n",
      "11/11 - 1s - 109ms/step - accuracy: 0.9943 - loss: 0.4179 - val_accuracy: 0.6023 - val_loss: 1.2197 - train_f1_score: 0.9071 - val_f1_score: 0.5889\n",
      "Epoch 333/700\n",
      "\n",
      "Epoch 333: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 333: Train F1=0.8963 - Val F1=0.5889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 333: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.596 Recall=0.875\n",
      "  Macro Avg: Precision=0.634 Recall=0.604\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9829 - loss: 0.4277 - val_accuracy: 0.6136 - val_loss: 1.2423 - train_f1_score: 0.8963 - val_f1_score: 0.5889\n",
      "Epoch 334/700\n",
      "\n",
      "Epoch 334: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 334: Train F1=0.7642 - Val F1=0.5079\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 334: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.556\n",
      "  Class 1: Precision=0.500 Recall=0.207\n",
      "  Class 2: Precision=0.519 Recall=0.844\n",
      "  Macro Avg: Precision=0.548 Recall=0.535\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4230 - val_accuracy: 0.5455 - val_loss: 1.4525 - train_f1_score: 0.7642 - val_f1_score: 0.5079\n",
      "Epoch 335/700\n",
      "\n",
      "Epoch 335: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 335: Train F1=0.9453 - Val F1=0.6452\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 335: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.643 Recall=0.621\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.649 Recall=0.644\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9800 - loss: 0.4357 - val_accuracy: 0.6477 - val_loss: 1.1703 - train_f1_score: 0.9453 - val_f1_score: 0.6452\n",
      "Epoch 336/700\n",
      "\n",
      "Epoch 336: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 336: Train F1=0.9856 - Val F1=0.6399\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 336: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.673 Recall=0.638\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4307 - val_accuracy: 0.6477 - val_loss: 1.1610 - train_f1_score: 0.9856 - val_f1_score: 0.6399\n",
      "Epoch 337/700\n",
      "\n",
      "Epoch 337: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 337: Train F1=0.8910 - Val F1=0.5789\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 337: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.556\n",
      "  Class 1: Precision=0.630 Recall=0.586\n",
      "  Class 2: Precision=0.613 Recall=0.594\n",
      "  Macro Avg: Precision=0.581 Recall=0.579\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4212 - val_accuracy: 0.5795 - val_loss: 1.0586 - train_f1_score: 0.8910 - val_f1_score: 0.5789\n",
      "Epoch 338/700\n",
      "\n",
      "Epoch 338: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 338: Train F1=0.9279 - Val F1=0.6719\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 338: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.683 Recall=0.669\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4292 - val_accuracy: 0.6705 - val_loss: 1.0181 - train_f1_score: 0.9279 - val_f1_score: 0.6719\n",
      "Epoch 339/700\n",
      "\n",
      "Epoch 339: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 339: Train F1=0.9236 - Val F1=0.6573\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 339: Per-class metrics\n",
      "  Class 0: Precision=0.553 Recall=0.778\n",
      "  Class 1: Precision=0.833 Recall=0.517\n",
      "  Class 2: Precision=0.688 Recall=0.688\n",
      "  Macro Avg: Precision=0.691 Recall=0.661\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.4382 - val_accuracy: 0.6591 - val_loss: 1.0512 - train_f1_score: 0.9236 - val_f1_score: 0.6573\n",
      "Epoch 340/700\n",
      "\n",
      "Epoch 340: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 340: Train F1=0.9548 - Val F1=0.5673\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 340: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.523 Recall=0.719\n",
      "  Macro Avg: Precision=0.612 Recall=0.577\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9971 - loss: 0.4119 - val_accuracy: 0.5795 - val_loss: 1.2297 - train_f1_score: 0.9548 - val_f1_score: 0.5673\n",
      "Epoch 341/700\n",
      "\n",
      "Epoch 341: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 341: Train F1=0.9490 - Val F1=0.5593\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 341: Per-class metrics\n",
      "  Class 0: Precision=0.607 Recall=0.630\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.598 Recall=0.574\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9886 - loss: 0.4204 - val_accuracy: 0.5795 - val_loss: 1.4036 - train_f1_score: 0.9490 - val_f1_score: 0.5593\n",
      "Epoch 342/700\n",
      "\n",
      "Epoch 342: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 342: Train F1=1.0000 - Val F1=0.6914\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 342: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.704 Recall=0.655\n",
      "  Class 2: Precision=0.686 Recall=0.750\n",
      "  Macro Avg: Precision=0.694 Recall=0.691\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9800 - loss: 0.4301 - val_accuracy: 0.6932 - val_loss: 1.1107 - train_f1_score: 1.0000 - val_f1_score: 0.6914\n",
      "Epoch 343/700\n",
      "\n",
      "Epoch 343: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 343: Train F1=0.9637 - Val F1=0.6197\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 343: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.846 Recall=0.379\n",
      "  Class 2: Precision=0.547 Recall=0.906\n",
      "  Macro Avg: Precision=0.707 Recall=0.626\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4289 - val_accuracy: 0.6364 - val_loss: 1.2222 - train_f1_score: 0.9637 - val_f1_score: 0.6197\n",
      "Epoch 344/700\n",
      "\n",
      "Epoch 344: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 344: Train F1=0.9027 - Val F1=0.5668\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 344: Per-class metrics\n",
      "  Class 0: Precision=0.552 Recall=0.593\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.599 Recall=0.574\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4331 - val_accuracy: 0.5795 - val_loss: 1.2368 - train_f1_score: 0.9027 - val_f1_score: 0.5668\n",
      "Epoch 345/700\n",
      "\n",
      "Epoch 345: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 345: Train F1=0.9830 - Val F1=0.6068\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 345: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.609 Recall=0.483\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.616 Recall=0.608\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9857 - loss: 0.4261 - val_accuracy: 0.6136 - val_loss: 1.2146 - train_f1_score: 0.9830 - val_f1_score: 0.6068\n",
      "Epoch 346/700\n",
      "\n",
      "Epoch 346: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 346: Train F1=0.9766 - Val F1=0.6025\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 346: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.616 Recall=0.610\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9800 - loss: 0.4222 - val_accuracy: 0.6136 - val_loss: 1.2234 - train_f1_score: 0.9766 - val_f1_score: 0.6025\n",
      "Epoch 347/700\n",
      "\n",
      "Epoch 347: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 347: Train F1=0.9972 - Val F1=0.6454\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 347: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.649 Recall=0.645\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9971 - loss: 0.4122 - val_accuracy: 0.6477 - val_loss: 1.1454 - train_f1_score: 0.9972 - val_f1_score: 0.6454\n",
      "Epoch 348/700\n",
      "\n",
      "Epoch 348: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 348: Train F1=0.9913 - Val F1=0.6584\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 348: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.665 Recall=0.656\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9771 - loss: 0.4254 - val_accuracy: 0.6591 - val_loss: 1.1150 - train_f1_score: 0.9913 - val_f1_score: 0.6584\n",
      "Epoch 349/700\n",
      "\n",
      "Epoch 349: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 349: Train F1=0.9971 - Val F1=0.6685\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 349: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.739 Recall=0.586\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.686 Recall=0.666\n",
      "11/11 - 1s - 94ms/step - accuracy: 1.0000 - loss: 0.4018 - val_accuracy: 0.6705 - val_loss: 1.1503 - train_f1_score: 0.9971 - val_f1_score: 0.6685\n",
      "Epoch 350/700\n",
      "\n",
      "Epoch 350: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 350: Train F1=0.9971 - Val F1=0.6577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 350: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.662 Recall=0.656\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4101 - val_accuracy: 0.6591 - val_loss: 1.0761 - train_f1_score: 0.9971 - val_f1_score: 0.6577\n",
      "Epoch 351/700\n",
      "\n",
      "Epoch 351: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 351: Train F1=0.9971 - Val F1=0.6584\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 351: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.665 Recall=0.656\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9971 - loss: 0.4034 - val_accuracy: 0.6591 - val_loss: 1.0323 - train_f1_score: 0.9971 - val_f1_score: 0.6584\n",
      "Epoch 352/700\n",
      "\n",
      "Epoch 352: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 352: Train F1=1.0000 - Val F1=0.6684\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 352: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.675 Recall=0.667\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9914 - loss: 0.4172 - val_accuracy: 0.6705 - val_loss: 1.1155 - train_f1_score: 1.0000 - val_f1_score: 0.6684\n",
      "Epoch 353/700\n",
      "\n",
      "Epoch 353: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 353: Train F1=0.9037 - Val F1=0.5461\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 353: Per-class metrics\n",
      "  Class 0: Precision=0.581 Recall=0.667\n",
      "  Class 1: Precision=0.476 Recall=0.345\n",
      "  Class 2: Precision=0.583 Recall=0.656\n",
      "  Macro Avg: Precision=0.547 Recall=0.556\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9886 - loss: 0.4248 - val_accuracy: 0.5568 - val_loss: 1.4068 - train_f1_score: 0.9037 - val_f1_score: 0.5461\n",
      "Epoch 354/700\n",
      "\n",
      "Epoch 354: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 354: Train F1=0.9945 - Val F1=0.6684\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 354: Per-class metrics\n",
      "  Class 0: Precision=0.633 Recall=0.704\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.676 Recall=0.719\n",
      "  Macro Avg: Precision=0.673 Recall=0.670\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9857 - loss: 0.4302 - val_accuracy: 0.6705 - val_loss: 1.2029 - train_f1_score: 0.9945 - val_f1_score: 0.6684\n",
      "Epoch 355/700\n",
      "\n",
      "Epoch 355: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 355: Train F1=1.0000 - Val F1=0.6550\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 355: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.664 Recall=0.657\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4321 - val_accuracy: 0.6591 - val_loss: 1.1196 - train_f1_score: 1.0000 - val_f1_score: 0.6550\n",
      "Epoch 356/700\n",
      "\n",
      "Epoch 356: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356: Train F1=0.9854 - Val F1=0.7166\n",
      "\n",
      "Saved best model at epoch 356 with val_f1=0.7166\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 356: Per-class metrics\n",
      "  Class 0: Precision=0.677 Recall=0.778\n",
      "  Class 1: Precision=0.769 Recall=0.690\n",
      "  Class 2: Precision=0.710 Recall=0.688\n",
      "  Macro Avg: Precision=0.719 Recall=0.718\n",
      "11/11 - 1s - 122ms/step - accuracy: 0.9800 - loss: 0.4239 - val_accuracy: 0.7159 - val_loss: 1.0165 - train_f1_score: 0.9854 - val_f1_score: 0.7166\n",
      "Epoch 357/700\n",
      "\n",
      "Epoch 357: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 357: Train F1=0.9652 - Val F1=0.7049\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 357: Per-class metrics\n",
      "  Class 0: Precision=0.656 Recall=0.778\n",
      "  Class 1: Precision=0.741 Recall=0.690\n",
      "  Class 2: Precision=0.724 Recall=0.656\n",
      "  Macro Avg: Precision=0.707 Recall=0.708\n",
      "11/11 - 1s - 107ms/step - accuracy: 0.9914 - loss: 0.4209 - val_accuracy: 0.7045 - val_loss: 0.9981 - train_f1_score: 0.9652 - val_f1_score: 0.7049\n",
      "Epoch 358/700\n",
      "\n",
      "Epoch 358: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 358: Train F1=0.9416 - Val F1=0.6979\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 358: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.710 Recall=0.759\n",
      "  Class 2: Precision=0.694 Recall=0.781\n",
      "  Macro Avg: Precision=0.706 Recall=0.698\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4187 - val_accuracy: 0.7045 - val_loss: 1.0178 - train_f1_score: 0.9416 - val_f1_score: 0.6979\n",
      "Epoch 359/700\n",
      "\n",
      "Epoch 359: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 359: Train F1=0.9417 - Val F1=0.6831\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 359: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.677 Recall=0.724\n",
      "  Class 2: Precision=0.703 Recall=0.812\n",
      "  Macro Avg: Precision=0.693 Recall=0.685\n",
      "11/11 - 1s - 120ms/step - accuracy: 1.0000 - loss: 0.4057 - val_accuracy: 0.6932 - val_loss: 1.0419 - train_f1_score: 0.9417 - val_f1_score: 0.6831\n",
      "Epoch 360/700\n",
      "\n",
      "Epoch 360: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 360: Train F1=0.9705 - Val F1=0.6887\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 360: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.731 Recall=0.655\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.703 Recall=0.687\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9857 - loss: 0.4266 - val_accuracy: 0.6932 - val_loss: 1.0572 - train_f1_score: 0.9705 - val_f1_score: 0.6887\n",
      "Epoch 361/700\n",
      "\n",
      "Epoch 361: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 361: Train F1=1.0000 - Val F1=0.6906\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 361: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.739 Recall=0.586\n",
      "  Class 2: Precision=0.658 Recall=0.781\n",
      "  Macro Avg: Precision=0.700 Recall=0.690\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9943 - loss: 0.4029 - val_accuracy: 0.6932 - val_loss: 1.1309 - train_f1_score: 1.0000 - val_f1_score: 0.6906\n",
      "Epoch 362/700\n",
      "\n",
      "Epoch 362: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 362: Train F1=0.9916 - Val F1=0.7028\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 362: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.714 Recall=0.690\n",
      "  Class 2: Precision=0.706 Recall=0.750\n",
      "  Macro Avg: Precision=0.704 Recall=0.702\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9971 - loss: 0.3992 - val_accuracy: 0.7045 - val_loss: 1.1169 - train_f1_score: 0.9916 - val_f1_score: 0.7028\n",
      "Epoch 363/700\n",
      "\n",
      "Epoch 363: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 363: Train F1=0.9549 - Val F1=0.6029\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 363: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.558 Recall=0.906\n",
      "  Macro Avg: Precision=0.666 Recall=0.615\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9914 - loss: 0.4139 - val_accuracy: 0.6250 - val_loss: 1.2063 - train_f1_score: 0.9549 - val_f1_score: 0.6029\n",
      "Epoch 364/700\n",
      "\n",
      "Epoch 364: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 364: Train F1=0.9827 - Val F1=0.6900\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 364: Per-class metrics\n",
      "  Class 0: Precision=0.762 Recall=0.593\n",
      "  Class 1: Precision=0.731 Recall=0.655\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.709 Recall=0.687\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4115 - val_accuracy: 0.6932 - val_loss: 0.9957 - train_f1_score: 0.9827 - val_f1_score: 0.6900\n",
      "Epoch 365/700\n",
      "\n",
      "Epoch 365: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 365: Train F1=0.9748 - Val F1=0.6339\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 365: Per-class metrics\n",
      "  Class 0: Precision=0.739 Recall=0.630\n",
      "  Class 1: Precision=0.706 Recall=0.414\n",
      "  Class 2: Precision=0.583 Recall=0.875\n",
      "  Macro Avg: Precision=0.676 Recall=0.639\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9686 - loss: 0.4556 - val_accuracy: 0.6477 - val_loss: 1.1341 - train_f1_score: 0.9748 - val_f1_score: 0.6339\n",
      "Epoch 366/700\n",
      "\n",
      "Epoch 366: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 366: Train F1=0.7199 - Val F1=0.4413\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 366: Per-class metrics\n",
      "  Class 0: Precision=0.440 Recall=0.407\n",
      "  Class 1: Precision=0.450 Recall=0.310\n",
      "  Class 2: Precision=0.465 Recall=0.625\n",
      "  Macro Avg: Precision=0.452 Recall=0.448\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9743 - loss: 0.4400 - val_accuracy: 0.4545 - val_loss: 1.5674 - train_f1_score: 0.7199 - val_f1_score: 0.4413\n",
      "Epoch 367/700\n",
      "\n",
      "Epoch 367: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 367: Train F1=0.9658 - Val F1=0.5546\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 367: Per-class metrics\n",
      "  Class 0: Precision=0.536 Recall=0.556\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.580 Recall=0.562\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9743 - loss: 0.4443 - val_accuracy: 0.5682 - val_loss: 1.2909 - train_f1_score: 0.9658 - val_f1_score: 0.5546\n",
      "Epoch 368/700\n",
      "\n",
      "Epoch 368: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 368: Train F1=0.9708 - Val F1=0.5146\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 368: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.333\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.481 Recall=0.781\n",
      "  Macro Avg: Precision=0.567 Recall=0.521\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.4335 - val_accuracy: 0.5341 - val_loss: 1.2710 - train_f1_score: 0.9708 - val_f1_score: 0.5146\n",
      "Epoch 369/700\n",
      "\n",
      "Epoch 369: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 369: Train F1=0.9714 - Val F1=0.5592\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 369: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.444\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.561 Recall=0.719\n",
      "  Macro Avg: Precision=0.571 Recall=0.560\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9857 - loss: 0.4191 - val_accuracy: 0.5682 - val_loss: 1.2201 - train_f1_score: 0.9714 - val_f1_score: 0.5592\n",
      "Epoch 370/700\n",
      "\n",
      "Epoch 370: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 370: Train F1=0.9481 - Val F1=0.5803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 370: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.444\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.610 Recall=0.581\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4227 - val_accuracy: 0.5909 - val_loss: 1.1760 - train_f1_score: 0.9481 - val_f1_score: 0.5803\n",
      "Epoch 371/700\n",
      "\n",
      "Epoch 371: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 371: Train F1=1.0000 - Val F1=0.6218\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 371: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.657 Recall=0.619\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4155 - val_accuracy: 0.6250 - val_loss: 1.1970 - train_f1_score: 1.0000 - val_f1_score: 0.6218\n",
      "Epoch 372/700\n",
      "\n",
      "Epoch 372: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 372: Train F1=1.0000 - Val F1=0.6422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 372: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.621 Recall=0.621\n",
      "  Class 2: Precision=0.667 Recall=0.750\n",
      "  Macro Avg: Precision=0.647 Recall=0.642\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4176 - val_accuracy: 0.6477 - val_loss: 1.1609 - train_f1_score: 1.0000 - val_f1_score: 0.6422\n",
      "Epoch 373/700\n",
      "\n",
      "Epoch 373: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 373: Train F1=0.9912 - Val F1=0.5966\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 373: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.609 Recall=0.598\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4138 - val_accuracy: 0.6023 - val_loss: 1.2670 - train_f1_score: 0.9912 - val_f1_score: 0.5966\n",
      "Epoch 374/700\n",
      "\n",
      "Epoch 374: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 374: Train F1=0.9768 - Val F1=0.5439\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 374: Per-class metrics\n",
      "  Class 0: Precision=0.531 Recall=0.630\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.550 Recall=0.688\n",
      "  Macro Avg: Precision=0.569 Recall=0.554\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4248 - val_accuracy: 0.5568 - val_loss: 1.3173 - train_f1_score: 0.9768 - val_f1_score: 0.5439\n",
      "Epoch 375/700\n",
      "\n",
      "Epoch 375: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 375: Train F1=0.9972 - Val F1=0.6073\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 375: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.636 Recall=0.483\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.621 Recall=0.608\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4330 - val_accuracy: 0.6136 - val_loss: 1.2433 - train_f1_score: 0.9972 - val_f1_score: 0.6073\n",
      "Epoch 376/700\n",
      "\n",
      "Epoch 376: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 376: Train F1=0.9484 - Val F1=0.5566\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 376: Per-class metrics\n",
      "  Class 0: Precision=0.457 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.594 Recall=0.594\n",
      "  Macro Avg: Precision=0.573 Recall=0.556\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9971 - loss: 0.4106 - val_accuracy: 0.5568 - val_loss: 1.2548 - train_f1_score: 0.9484 - val_f1_score: 0.5566\n",
      "Epoch 377/700\n",
      "\n",
      "Epoch 377: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 377: Train F1=0.9687 - Val F1=0.6748\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 377: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.759\n",
      "  Class 2: Precision=0.667 Recall=0.750\n",
      "  Macro Avg: Precision=0.690 Recall=0.676\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9943 - loss: 0.4185 - val_accuracy: 0.6818 - val_loss: 1.0754 - train_f1_score: 0.9687 - val_f1_score: 0.6748\n",
      "Epoch 378/700\n",
      "\n",
      "Epoch 378: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 378: Train F1=0.9915 - Val F1=0.6304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 378: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.664 Recall=0.629\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4261 - val_accuracy: 0.6364 - val_loss: 1.1927 - train_f1_score: 0.9915 - val_f1_score: 0.6304\n",
      "Epoch 379/700\n",
      "\n",
      "Epoch 379: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 379: Train F1=0.9913 - Val F1=0.7151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 379: Per-class metrics\n",
      "  Class 0: Precision=0.731 Recall=0.704\n",
      "  Class 1: Precision=0.760 Recall=0.655\n",
      "  Class 2: Precision=0.676 Recall=0.781\n",
      "  Macro Avg: Precision=0.722 Recall=0.713\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9800 - loss: 0.4276 - val_accuracy: 0.7159 - val_loss: 0.9932 - train_f1_score: 0.9913 - val_f1_score: 0.7151\n",
      "Epoch 380/700\n",
      "\n",
      "Epoch 380: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 380: Train F1=0.9118 - Val F1=0.6120\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 380: Per-class metrics\n",
      "  Class 0: Precision=0.538 Recall=0.778\n",
      "  Class 1: Precision=0.630 Recall=0.586\n",
      "  Class 2: Precision=0.727 Recall=0.500\n",
      "  Macro Avg: Precision=0.632 Recall=0.621\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9714 - loss: 0.4568 - val_accuracy: 0.6136 - val_loss: 1.1983 - train_f1_score: 0.9118 - val_f1_score: 0.6120\n",
      "Epoch 381/700\n",
      "\n",
      "Epoch 381: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 381: Train F1=0.9886 - Val F1=0.6190\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 381: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.556\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.627 Recall=0.619\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4335 - val_accuracy: 0.6250 - val_loss: 1.2329 - train_f1_score: 0.9886 - val_f1_score: 0.6190\n",
      "Epoch 382/700\n",
      "\n",
      "Epoch 382: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 382: Train F1=0.8617 - Val F1=0.5741\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 382: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.786 Recall=0.379\n",
      "  Class 2: Precision=0.529 Recall=0.844\n",
      "  Macro Avg: Precision=0.641 Recall=0.581\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9971 - loss: 0.4115 - val_accuracy: 0.5909 - val_loss: 1.3406 - train_f1_score: 0.8617 - val_f1_score: 0.5741\n",
      "Epoch 383/700\n",
      "\n",
      "Epoch 383: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 383: Train F1=0.9097 - Val F1=0.5673\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "Epoch 383: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.444\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.571 Recall=0.875\n",
      "  Macro Avg: Precision=0.601 Recall=0.578\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4121 - val_accuracy: 0.5909 - val_loss: 1.2705 - train_f1_score: 0.9097 - val_f1_score: 0.5673\n",
      "Epoch 384/700\n",
      "\n",
      "Epoch 384: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 384: Train F1=0.9826 - Val F1=0.6258\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 384: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.587 Recall=0.844\n",
      "  Macro Avg: Precision=0.656 Recall=0.627\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4052 - val_accuracy: 0.6364 - val_loss: 1.2076 - train_f1_score: 0.9826 - val_f1_score: 0.6258\n",
      "Epoch 385/700\n",
      "\n",
      "Epoch 385: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 385: Train F1=0.9624 - Val F1=0.5981\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 385: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.574 Recall=0.844\n",
      "  Macro Avg: Precision=0.631 Recall=0.604\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.4113 - val_accuracy: 0.6136 - val_loss: 1.2170 - train_f1_score: 0.9624 - val_f1_score: 0.5981\n",
      "Epoch 386/700\n",
      "\n",
      "Epoch 386: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 386: Train F1=0.9857 - Val F1=0.5996\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 386: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.631 Recall=0.607\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4058 - val_accuracy: 0.6136 - val_loss: 1.2522 - train_f1_score: 0.9857 - val_f1_score: 0.5996\n",
      "Epoch 387/700\n",
      "\n",
      "Epoch 387: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 387: Train F1=0.9363 - Val F1=0.5568\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 387: Per-class metrics\n",
      "  Class 0: Precision=0.538 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.584 Recall=0.561\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9943 - loss: 0.4076 - val_accuracy: 0.5682 - val_loss: 1.2676 - train_f1_score: 0.9363 - val_f1_score: 0.5568\n",
      "Epoch 388/700\n",
      "\n",
      "Epoch 388: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 388: Train F1=0.8784 - Val F1=0.5500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 388: Per-class metrics\n",
      "  Class 0: Precision=0.485 Recall=0.593\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.600 Recall=0.656\n",
      "  Macro Avg: Precision=0.562 Recall=0.554\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4241 - val_accuracy: 0.5568 - val_loss: 1.2972 - train_f1_score: 0.8784 - val_f1_score: 0.5500\n",
      "Epoch 389/700\n",
      "\n",
      "Epoch 389: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 389: Train F1=0.9859 - Val F1=0.5574\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 389: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.533 Recall=0.276\n",
      "  Class 2: Precision=0.531 Recall=0.812\n",
      "  Macro Avg: Precision=0.591 Recall=0.573\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9943 - loss: 0.4069 - val_accuracy: 0.5795 - val_loss: 1.3571 - train_f1_score: 0.9859 - val_f1_score: 0.5574\n",
      "Epoch 390/700\n",
      "\n",
      "Epoch 390: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 390: Train F1=0.9482 - Val F1=0.6207\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 390: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.615 Recall=0.552\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.623 Recall=0.621\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9800 - loss: 0.4275 - val_accuracy: 0.6250 - val_loss: 1.1298 - train_f1_score: 0.9482 - val_f1_score: 0.6207\n",
      "Epoch 391/700\n",
      "\n",
      "Epoch 391: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 391: Train F1=0.9425 - Val F1=0.6341\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 391: Per-class metrics\n",
      "  Class 0: Precision=0.517 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.690\n",
      "  Class 2: Precision=0.724 Recall=0.656\n",
      "  Macro Avg: Precision=0.636 Recall=0.634\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4139 - val_accuracy: 0.6364 - val_loss: 1.0817 - train_f1_score: 0.9425 - val_f1_score: 0.6341\n",
      "Epoch 392/700\n",
      "\n",
      "Epoch 392: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 392: Train F1=0.9451 - Val F1=0.6202\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 392: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.615 Recall=0.552\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.632 Recall=0.619\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9914 - loss: 0.4135 - val_accuracy: 0.6250 - val_loss: 1.1289 - train_f1_score: 0.9451 - val_f1_score: 0.6202\n",
      "Epoch 393/700\n",
      "\n",
      "Epoch 393: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 393: Train F1=0.9507 - Val F1=0.5684\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 393: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.588 Recall=0.574\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4100 - val_accuracy: 0.5795 - val_loss: 1.2574 - train_f1_score: 0.9507 - val_f1_score: 0.5684\n",
      "Epoch 394/700\n",
      "\n",
      "Epoch 394: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 394: Train F1=0.9154 - Val F1=0.6066\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 394: Per-class metrics\n",
      "  Class 0: Precision=0.706 Recall=0.444\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.639 Recall=0.605\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9743 - loss: 0.4404 - val_accuracy: 0.6136 - val_loss: 1.0968 - train_f1_score: 0.9154 - val_f1_score: 0.6066\n",
      "Epoch 395/700\n",
      "\n",
      "Epoch 395: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 395: Train F1=0.7875 - Val F1=0.5122\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 395: Per-class metrics\n",
      "  Class 0: Precision=0.405 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.571 Recall=0.500\n",
      "  Macro Avg: Precision=0.548 Recall=0.514\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4168 - val_accuracy: 0.5114 - val_loss: 1.2560 - train_f1_score: 0.7875 - val_f1_score: 0.5122\n",
      "Epoch 396/700\n",
      "\n",
      "Epoch 396: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 396: Train F1=0.7552 - Val F1=0.4966\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 396: Per-class metrics\n",
      "  Class 0: Precision=0.400 Recall=0.741\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.591 Recall=0.406\n",
      "  Macro Avg: Precision=0.559 Recall=0.509\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4196 - val_accuracy: 0.5000 - val_loss: 1.3880 - train_f1_score: 0.7552 - val_f1_score: 0.4966\n",
      "Epoch 397/700\n",
      "\n",
      "Epoch 397: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 397: Train F1=0.8536 - Val F1=0.5743\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 397: Per-class metrics\n",
      "  Class 0: Precision=0.481 Recall=0.481\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.581 Recall=0.574\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4256 - val_accuracy: 0.5795 - val_loss: 1.3032 - train_f1_score: 0.8536 - val_f1_score: 0.5743\n",
      "Epoch 398/700\n",
      "\n",
      "Epoch 398: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 398: Train F1=0.9306 - Val F1=0.5928\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 398: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.444\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.608 Recall=0.594\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9771 - loss: 0.4477 - val_accuracy: 0.6023 - val_loss: 1.2108 - train_f1_score: 0.9306 - val_f1_score: 0.5928\n",
      "Epoch 399/700\n",
      "\n",
      "Epoch 399: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 399: Train F1=0.9018 - Val F1=0.5337\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 399: Per-class metrics\n",
      "  Class 0: Precision=0.433 Recall=0.481\n",
      "  Class 1: Precision=0.607 Recall=0.586\n",
      "  Class 2: Precision=0.567 Recall=0.531\n",
      "  Macro Avg: Precision=0.536 Recall=0.533\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.4355 - val_accuracy: 0.5341 - val_loss: 1.1781 - train_f1_score: 0.9018 - val_f1_score: 0.5337\n",
      "Epoch 400/700\n",
      "\n",
      "Epoch 400: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 400: Train F1=0.9296 - Val F1=0.5439\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 400: Per-class metrics\n",
      "  Class 0: Precision=0.524 Recall=0.407\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.574 Recall=0.844\n",
      "  Macro Avg: Precision=0.566 Recall=0.555\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9914 - loss: 0.4125 - val_accuracy: 0.5682 - val_loss: 1.2448 - train_f1_score: 0.9296 - val_f1_score: 0.5439\n",
      "Epoch 401/700\n",
      "\n",
      "Epoch 401: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 401: Train F1=0.9448 - Val F1=0.5995\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 401: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.556\n",
      "  Class 1: Precision=0.650 Recall=0.448\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.613 Recall=0.605\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4191 - val_accuracy: 0.6136 - val_loss: 1.1741 - train_f1_score: 0.9448 - val_f1_score: 0.5995\n",
      "Epoch 402/700\n",
      "\n",
      "Epoch 402: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 402: Train F1=0.9506 - Val F1=0.6254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 402: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.639 Recall=0.629\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.4141 - val_accuracy: 0.6364 - val_loss: 1.1635 - train_f1_score: 0.9506 - val_f1_score: 0.6254\n",
      "Epoch 403/700\n",
      "\n",
      "Epoch 403: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 403: Train F1=0.9280 - Val F1=0.5676\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 403: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.556\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.580 Recall=0.573\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9829 - loss: 0.4305 - val_accuracy: 0.5795 - val_loss: 1.2366 - train_f1_score: 0.9280 - val_f1_score: 0.5676\n",
      "Epoch 404/700\n",
      "\n",
      "Epoch 404: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 404: Train F1=0.8641 - Val F1=0.5635\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 404: Per-class metrics\n",
      "  Class 0: Precision=0.536 Recall=0.556\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.588 Recall=0.572\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9914 - loss: 0.4131 - val_accuracy: 0.5795 - val_loss: 1.2971 - train_f1_score: 0.8641 - val_f1_score: 0.5635\n",
      "Epoch 405/700\n",
      "\n",
      "Epoch 405: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 405: Train F1=0.9623 - Val F1=0.5912\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 405: Per-class metrics\n",
      "  Class 0: Precision=0.583 Recall=0.519\n",
      "  Class 1: Precision=0.636 Recall=0.483\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.605 Recall=0.594\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4079 - val_accuracy: 0.6023 - val_loss: 1.2097 - train_f1_score: 0.9623 - val_f1_score: 0.5912\n",
      "Epoch 406/700\n",
      "\n",
      "Epoch 406: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 406: Train F1=1.0000 - Val F1=0.6437\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 406: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.655 Recall=0.645\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4161 - val_accuracy: 0.6477 - val_loss: 1.1405 - train_f1_score: 1.0000 - val_f1_score: 0.6437\n",
      "Epoch 407/700\n",
      "\n",
      "Epoch 407: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 407: Train F1=0.9945 - Val F1=0.6639\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 407: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.680 Recall=0.665\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9943 - loss: 0.4169 - val_accuracy: 0.6705 - val_loss: 1.1668 - train_f1_score: 0.9945 - val_f1_score: 0.6639\n",
      "Epoch 408/700\n",
      "\n",
      "Epoch 408: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 408: Train F1=1.0000 - Val F1=0.6427\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 408: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.661 Recall=0.644\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9971 - loss: 0.4038 - val_accuracy: 0.6477 - val_loss: 1.1496 - train_f1_score: 1.0000 - val_f1_score: 0.6427\n",
      "Epoch 409/700\n",
      "\n",
      "Epoch 409: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 409: Train F1=0.9706 - Val F1=0.5434\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 409: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.276\n",
      "  Class 2: Precision=0.532 Recall=0.781\n",
      "  Macro Avg: Precision=0.595 Recall=0.562\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9943 - loss: 0.4054 - val_accuracy: 0.5682 - val_loss: 1.2171 - train_f1_score: 0.9706 - val_f1_score: 0.5434\n",
      "Epoch 410/700\n",
      "\n",
      "Epoch 410: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 410: Train F1=0.9683 - Val F1=0.6203\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 410: Per-class metrics\n",
      "  Class 0: Precision=0.583 Recall=0.519\n",
      "  Class 1: Precision=0.618 Recall=0.724\n",
      "  Class 2: Precision=0.667 Recall=0.625\n",
      "  Macro Avg: Precision=0.623 Recall=0.623\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9657 - loss: 0.4504 - val_accuracy: 0.6250 - val_loss: 1.0528 - train_f1_score: 0.9683 - val_f1_score: 0.6203\n",
      "Epoch 411/700\n",
      "\n",
      "Epoch 411: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 411: Train F1=0.7840 - Val F1=0.4209\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 411: Per-class metrics\n",
      "  Class 0: Precision=0.452 Recall=0.704\n",
      "  Class 1: Precision=0.346 Recall=0.310\n",
      "  Class 2: Precision=0.500 Recall=0.312\n",
      "  Macro Avg: Precision=0.433 Recall=0.442\n",
      "11/11 - 1s - 98ms/step - accuracy: 0.9771 - loss: 0.4404 - val_accuracy: 0.4318 - val_loss: 1.4967 - train_f1_score: 0.7840 - val_f1_score: 0.4209\n",
      "Epoch 412/700\n",
      "\n",
      "Epoch 412: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 412: Train F1=1.0000 - Val F1=0.6382\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 412: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.607 Recall=0.586\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.652 Recall=0.639\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9886 - loss: 0.4261 - val_accuracy: 0.6477 - val_loss: 1.1221 - train_f1_score: 1.0000 - val_f1_score: 0.6382\n",
      "Epoch 413/700\n",
      "\n",
      "Epoch 413: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 413: Train F1=0.9856 - Val F1=0.6460\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 413: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.643 Recall=0.621\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.646 Recall=0.646\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9886 - loss: 0.4229 - val_accuracy: 0.6477 - val_loss: 1.1206 - train_f1_score: 0.9856 - val_f1_score: 0.6460\n",
      "Epoch 414/700\n",
      "\n",
      "Epoch 414: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 414: Train F1=0.9365 - Val F1=0.6035\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 414: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.625 Recall=0.517\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.637 Recall=0.604\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4301 - val_accuracy: 0.6136 - val_loss: 1.2370 - train_f1_score: 0.9365 - val_f1_score: 0.6035\n",
      "Epoch 415/700\n",
      "\n",
      "Epoch 415: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 415: Train F1=0.9889 - Val F1=0.6690\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 415: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.677 Recall=0.667\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9743 - loss: 0.4356 - val_accuracy: 0.6705 - val_loss: 1.0865 - train_f1_score: 0.9889 - val_f1_score: 0.6690\n",
      "Epoch 416/700\n",
      "\n",
      "Epoch 416: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 416: Train F1=0.9445 - Val F1=0.5697\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 416: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.522 Recall=0.750\n",
      "  Macro Avg: Precision=0.603 Recall=0.574\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.9886 - loss: 0.4147 - val_accuracy: 0.5795 - val_loss: 1.2073 - train_f1_score: 0.9445 - val_f1_score: 0.5697\n",
      "Epoch 417/700\n",
      "\n",
      "Epoch 417: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 417: Train F1=0.5787 - Val F1=0.4503\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 417: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.519\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.480 Recall=0.750\n",
      "  Macro Avg: Precision=0.493 Recall=0.480\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9771 - loss: 0.4321 - val_accuracy: 0.4886 - val_loss: 1.4568 - train_f1_score: 0.5787 - val_f1_score: 0.4503\n",
      "Epoch 418/700\n",
      "\n",
      "Epoch 418: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 418: Train F1=0.6219 - Val F1=0.3826\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 418: Per-class metrics\n",
      "  Class 0: Precision=0.429 Recall=0.333\n",
      "  Class 1: Precision=0.455 Recall=0.172\n",
      "  Class 2: Precision=0.411 Recall=0.719\n",
      "  Macro Avg: Precision=0.431 Recall=0.408\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9886 - loss: 0.4186 - val_accuracy: 0.4205 - val_loss: 1.4836 - train_f1_score: 0.6219 - val_f1_score: 0.3826\n",
      "Epoch 419/700\n",
      "\n",
      "Epoch 419: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 419: Train F1=0.8007 - Val F1=0.5147\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 419: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.611 Recall=0.379\n",
      "  Class 2: Precision=0.451 Recall=0.719\n",
      "  Macro Avg: Precision=0.565 Recall=0.514\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4246 - val_accuracy: 0.5227 - val_loss: 1.3436 - train_f1_score: 0.8007 - val_f1_score: 0.5147\n",
      "Epoch 420/700\n",
      "\n",
      "Epoch 420: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 420: Train F1=0.8919 - Val F1=0.5437\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 420: Per-class metrics\n",
      "  Class 0: Precision=0.577 Recall=0.556\n",
      "  Class 1: Precision=0.714 Recall=0.345\n",
      "  Class 2: Precision=0.500 Recall=0.750\n",
      "  Macro Avg: Precision=0.597 Recall=0.550\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9943 - loss: 0.4121 - val_accuracy: 0.5568 - val_loss: 1.2609 - train_f1_score: 0.8919 - val_f1_score: 0.5437\n",
      "Epoch 421/700\n",
      "\n",
      "Epoch 421: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 421: Train F1=0.9365 - Val F1=0.6140\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 421: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.568 Recall=0.656\n",
      "  Macro Avg: Precision=0.621 Recall=0.612\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4259 - val_accuracy: 0.6136 - val_loss: 1.1429 - train_f1_score: 0.9365 - val_f1_score: 0.6140\n",
      "Epoch 422/700\n",
      "\n",
      "Epoch 422: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 422: Train F1=0.9971 - Val F1=0.5753\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 422: Per-class metrics\n",
      "  Class 0: Precision=0.562 Recall=0.667\n",
      "  Class 1: Precision=0.591 Recall=0.448\n",
      "  Class 2: Precision=0.588 Recall=0.625\n",
      "  Macro Avg: Precision=0.581 Recall=0.580\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4197 - val_accuracy: 0.5795 - val_loss: 1.3565 - train_f1_score: 0.9971 - val_f1_score: 0.5753\n",
      "Epoch 423/700\n",
      "\n",
      "Epoch 423: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 423: Train F1=0.9517 - Val F1=0.4930\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 423: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.333\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.439 Recall=0.781\n",
      "  Macro Avg: Precision=0.576 Recall=0.498\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9771 - loss: 0.4406 - val_accuracy: 0.5114 - val_loss: 1.5332 - train_f1_score: 0.9517 - val_f1_score: 0.4930\n",
      "Epoch 424/700\n",
      "\n",
      "Epoch 424: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 424: Train F1=0.9192 - Val F1=0.5405\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 424: Per-class metrics\n",
      "  Class 0: Precision=0.485 Recall=0.593\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.556 Recall=0.625\n",
      "  Macro Avg: Precision=0.557 Recall=0.544\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9714 - loss: 0.4427 - val_accuracy: 0.5455 - val_loss: 1.3380 - train_f1_score: 0.9192 - val_f1_score: 0.5405\n",
      "Epoch 425/700\n",
      "\n",
      "Epoch 425: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 425: Train F1=0.9394 - Val F1=0.5611\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 425: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.414\n",
      "  Class 2: Precision=0.550 Recall=0.688\n",
      "  Macro Avg: Precision=0.583 Recall=0.565\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4374 - val_accuracy: 0.5682 - val_loss: 1.3274 - train_f1_score: 0.9394 - val_f1_score: 0.5611\n",
      "Epoch 426/700\n",
      "\n",
      "Epoch 426: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 426: Train F1=0.9885 - Val F1=0.5710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 426: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.510 Recall=0.781\n",
      "  Macro Avg: Precision=0.614 Recall=0.571\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9857 - loss: 0.4207 - val_accuracy: 0.5795 - val_loss: 1.2948 - train_f1_score: 0.9885 - val_f1_score: 0.5710\n",
      "Epoch 427/700\n",
      "\n",
      "Epoch 427: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 427: Train F1=1.0000 - Val F1=0.5699\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 427: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.548 Recall=0.719\n",
      "  Macro Avg: Precision=0.585 Recall=0.576\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9886 - loss: 0.4100 - val_accuracy: 0.5795 - val_loss: 1.2607 - train_f1_score: 1.0000 - val_f1_score: 0.5699\n",
      "Epoch 428/700\n",
      "\n",
      "Epoch 428: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 428: Train F1=0.9915 - Val F1=0.6274\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 428: Per-class metrics\n",
      "  Class 0: Precision=0.650 Recall=0.481\n",
      "  Class 1: Precision=0.613 Recall=0.655\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.637 Recall=0.629\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9943 - loss: 0.4103 - val_accuracy: 0.6364 - val_loss: 1.1992 - train_f1_score: 0.9915 - val_f1_score: 0.6274\n",
      "Epoch 429/700\n",
      "\n",
      "Epoch 429: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 429: Train F1=0.9710 - Val F1=0.5472\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 429: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.333\n",
      "  Class 1: Precision=0.571 Recall=0.552\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.586 Recall=0.555\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4171 - val_accuracy: 0.5682 - val_loss: 1.4526 - train_f1_score: 0.9710 - val_f1_score: 0.5472\n",
      "Epoch 430/700\n",
      "\n",
      "Epoch 430: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 430: Train F1=0.9944 - Val F1=0.5760\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 430: Per-class metrics\n",
      "  Class 0: Precision=0.647 Recall=0.407\n",
      "  Class 1: Precision=0.571 Recall=0.552\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.600 Recall=0.580\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4259 - val_accuracy: 0.5909 - val_loss: 1.2924 - train_f1_score: 0.9944 - val_f1_score: 0.5760\n",
      "Epoch 431/700\n",
      "\n",
      "Epoch 431: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 431: Train F1=0.9820 - Val F1=0.6645\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 431: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.688 Recall=0.759\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.675 Recall=0.665\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4178 - val_accuracy: 0.6705 - val_loss: 1.0621 - train_f1_score: 0.9820 - val_f1_score: 0.6645\n",
      "Epoch 432/700\n",
      "\n",
      "Epoch 432: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 432: Train F1=0.9141 - Val F1=0.5639\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 432: Per-class metrics\n",
      "  Class 0: Precision=0.519 Recall=0.519\n",
      "  Class 1: Precision=0.600 Recall=0.517\n",
      "  Class 2: Precision=0.583 Recall=0.656\n",
      "  Macro Avg: Precision=0.567 Recall=0.564\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4084 - val_accuracy: 0.5682 - val_loss: 1.1998 - train_f1_score: 0.9141 - val_f1_score: 0.5639\n",
      "Epoch 433/700\n",
      "\n",
      "Epoch 433: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 433: Train F1=0.9567 - Val F1=0.6334\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 433: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.639 Recall=0.633\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9857 - loss: 0.4238 - val_accuracy: 0.6364 - val_loss: 1.1226 - train_f1_score: 0.9567 - val_f1_score: 0.6334\n",
      "Epoch 434/700\n",
      "\n",
      "Epoch 434: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 434: Train F1=0.9882 - Val F1=0.6687\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 434: Per-class metrics\n",
      "  Class 0: Precision=0.769 Recall=0.370\n",
      "  Class 1: Precision=0.735 Recall=0.862\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.713 Recall=0.682\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9857 - loss: 0.4272 - val_accuracy: 0.6932 - val_loss: 1.1565 - train_f1_score: 0.9882 - val_f1_score: 0.6687\n",
      "Epoch 435/700\n",
      "\n",
      "Epoch 435: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 435: Train F1=0.9416 - Val F1=0.6269\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 435: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.370\n",
      "  Class 1: Precision=0.647 Recall=0.759\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.662 Recall=0.637\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9800 - loss: 0.4242 - val_accuracy: 0.6477 - val_loss: 1.2054 - train_f1_score: 0.9416 - val_f1_score: 0.6269\n",
      "Epoch 436/700\n",
      "\n",
      "Epoch 436: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 436: Train F1=0.9732 - Val F1=0.6610\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 436: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.657 Recall=0.793\n",
      "  Class 2: Precision=0.657 Recall=0.719\n",
      "  Macro Avg: Precision=0.679 Recall=0.664\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4127 - val_accuracy: 0.6705 - val_loss: 1.0984 - train_f1_score: 0.9732 - val_f1_score: 0.6610\n",
      "Epoch 437/700\n",
      "\n",
      "Epoch 437: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 437: Train F1=0.9679 - Val F1=0.6134\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 437: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.296\n",
      "  Class 1: Precision=0.605 Recall=0.897\n",
      "  Class 2: Precision=0.676 Recall=0.719\n",
      "  Macro Avg: Precision=0.669 Recall=0.637\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9829 - loss: 0.4229 - val_accuracy: 0.6477 - val_loss: 1.1643 - train_f1_score: 0.9679 - val_f1_score: 0.6134\n",
      "Epoch 438/700\n",
      "\n",
      "Epoch 438: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 438: Train F1=0.8549 - Val F1=0.5112\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 438: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.222\n",
      "  Class 1: Precision=0.538 Recall=0.724\n",
      "  Class 2: Precision=0.538 Recall=0.656\n",
      "  Macro Avg: Precision=0.559 Recall=0.534\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.9857 - loss: 0.4241 - val_accuracy: 0.5455 - val_loss: 1.3597 - train_f1_score: 0.8549 - val_f1_score: 0.5112\n",
      "Epoch 439/700\n",
      "\n",
      "Epoch 439: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 439: Train F1=0.9914 - Val F1=0.6118\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 439: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.576 Recall=0.655\n",
      "  Class 2: Precision=0.600 Recall=0.656\n",
      "  Macro Avg: Precision=0.625 Recall=0.610\n",
      "11/11 - 1s - 110ms/step - accuracy: 0.9914 - loss: 0.4150 - val_accuracy: 0.6136 - val_loss: 1.1694 - train_f1_score: 0.9914 - val_f1_score: 0.6118\n",
      "Epoch 440/700\n",
      "\n",
      "Epoch 440: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 440: Train F1=0.9745 - Val F1=0.5453\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 440: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.591 Recall=0.448\n",
      "  Class 2: Precision=0.490 Recall=0.781\n",
      "  Macro Avg: Precision=0.605 Recall=0.546\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4116 - val_accuracy: 0.5568 - val_loss: 1.3845 - train_f1_score: 0.9745 - val_f1_score: 0.5453\n",
      "Epoch 441/700\n",
      "\n",
      "Epoch 441: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 441: Train F1=0.9940 - Val F1=0.5780\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 441: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.577 Recall=0.517\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.597 Recall=0.581\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4657 - val_accuracy: 0.5909 - val_loss: 1.3088 - train_f1_score: 0.9940 - val_f1_score: 0.5780\n",
      "Epoch 442/700\n",
      "\n",
      "Epoch 442: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 442: Train F1=0.9799 - Val F1=0.6256\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 442: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.722 Recall=0.448\n",
      "  Class 2: Precision=0.574 Recall=0.844\n",
      "  Macro Avg: Precision=0.664 Recall=0.628\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.9829 - loss: 0.4280 - val_accuracy: 0.6364 - val_loss: 1.1151 - train_f1_score: 0.9799 - val_f1_score: 0.6256\n",
      "Epoch 443/700\n",
      "\n",
      "Epoch 443: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 443: Train F1=0.9452 - Val F1=0.6338\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 443: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.556\n",
      "  Class 1: Precision=0.688 Recall=0.759\n",
      "  Class 2: Precision=0.613 Recall=0.594\n",
      "  Macro Avg: Precision=0.633 Recall=0.636\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4339 - val_accuracy: 0.6364 - val_loss: 1.0969 - train_f1_score: 0.9452 - val_f1_score: 0.6338\n",
      "Epoch 444/700\n",
      "\n",
      "Epoch 444: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 444: Train F1=0.9622 - Val F1=0.6706\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 444: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.700 Recall=0.724\n",
      "  Class 2: Precision=0.636 Recall=0.656\n",
      "  Macro Avg: Precision=0.672 Recall=0.670\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4207 - val_accuracy: 0.6705 - val_loss: 1.0527 - train_f1_score: 0.9622 - val_f1_score: 0.6706\n",
      "Epoch 445/700\n",
      "\n",
      "Epoch 445: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 445: Train F1=0.9688 - Val F1=0.6241\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 445: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.625 Recall=0.690\n",
      "  Class 2: Precision=0.633 Recall=0.594\n",
      "  Macro Avg: Precision=0.625 Recall=0.625\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9857 - loss: 0.4328 - val_accuracy: 0.6250 - val_loss: 1.1076 - train_f1_score: 0.9688 - val_f1_score: 0.6241\n",
      "Epoch 446/700\n",
      "\n",
      "Epoch 446: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 446: Train F1=0.9887 - Val F1=0.6334\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 446: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.731 Recall=0.655\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.666 Recall=0.629\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9800 - loss: 0.4266 - val_accuracy: 0.6364 - val_loss: 1.1139 - train_f1_score: 0.9887 - val_f1_score: 0.6334\n",
      "Epoch 447/700\n",
      "\n",
      "Epoch 447: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 447: Train F1=0.9480 - Val F1=0.6330\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 447: Per-class metrics\n",
      "  Class 0: Precision=0.786 Recall=0.407\n",
      "  Class 1: Precision=0.636 Recall=0.724\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.677 Recall=0.638\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4241 - val_accuracy: 0.6477 - val_loss: 1.0531 - train_f1_score: 0.9480 - val_f1_score: 0.6330\n",
      "Epoch 448/700\n",
      "\n",
      "Epoch 448: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 448: Train F1=0.9424 - Val F1=0.6115\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 448: Per-class metrics\n",
      "  Class 0: Precision=0.579 Recall=0.407\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.623 Recall=0.616\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9829 - loss: 0.4267 - val_accuracy: 0.6250 - val_loss: 1.0886 - train_f1_score: 0.9424 - val_f1_score: 0.6115\n",
      "Epoch 449/700\n",
      "\n",
      "Epoch 449: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 449: Train F1=0.9944 - Val F1=0.6448\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 449: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.660 Recall=0.642\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9800 - loss: 0.4317 - val_accuracy: 0.6477 - val_loss: 1.1768 - train_f1_score: 0.9944 - val_f1_score: 0.6448\n",
      "Epoch 450/700\n",
      "\n",
      "Epoch 450: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 450: Train F1=0.9553 - Val F1=0.5258\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 450: Per-class metrics\n",
      "  Class 0: Precision=0.526 Recall=0.370\n",
      "  Class 1: Precision=0.591 Recall=0.448\n",
      "  Class 2: Precision=0.532 Recall=0.781\n",
      "  Macro Avg: Precision=0.550 Recall=0.533\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4241 - val_accuracy: 0.5455 - val_loss: 1.2826 - train_f1_score: 0.9553 - val_f1_score: 0.5258\n",
      "Epoch 451/700\n",
      "\n",
      "Epoch 451: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 451: Train F1=0.9024 - Val F1=0.5556\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 451: Per-class metrics\n",
      "  Class 0: Precision=0.452 Recall=0.519\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.577 Recall=0.469\n",
      "  Macro Avg: Precision=0.558 Recall=0.559\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9857 - loss: 0.4229 - val_accuracy: 0.5568 - val_loss: 1.2189 - train_f1_score: 0.9024 - val_f1_score: 0.5556\n",
      "Epoch 452/700\n",
      "\n",
      "Epoch 452: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 452: Train F1=0.9278 - Val F1=0.6216\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 452: Per-class metrics\n",
      "  Class 0: Precision=0.567 Recall=0.630\n",
      "  Class 1: Precision=0.697 Recall=0.793\n",
      "  Class 2: Precision=0.600 Recall=0.469\n",
      "  Macro Avg: Precision=0.621 Recall=0.630\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9629 - loss: 0.4754 - val_accuracy: 0.6250 - val_loss: 1.0333 - train_f1_score: 0.9278 - val_f1_score: 0.6216\n",
      "Epoch 453/700\n",
      "\n",
      "Epoch 453: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 453: Train F1=0.8684 - Val F1=0.5436\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 453: Per-class metrics\n",
      "  Class 0: Precision=0.486 Recall=0.630\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.562 Recall=0.562\n",
      "  Macro Avg: Precision=0.556 Recall=0.547\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9771 - loss: 0.4418 - val_accuracy: 0.5455 - val_loss: 1.1849 - train_f1_score: 0.8684 - val_f1_score: 0.5436\n",
      "Epoch 454/700\n",
      "\n",
      "Epoch 454: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 454: Train F1=0.7489 - Val F1=0.5490\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 454: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.556 Recall=0.345\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.578 Recall=0.559\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9857 - loss: 0.4147 - val_accuracy: 0.5682 - val_loss: 1.4279 - train_f1_score: 0.7489 - val_f1_score: 0.5490\n",
      "Epoch 455/700\n",
      "\n",
      "Epoch 455: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 455: Train F1=0.9450 - Val F1=0.5746\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 455: Per-class metrics\n",
      "  Class 0: Precision=0.581 Recall=0.667\n",
      "  Class 1: Precision=0.667 Recall=0.345\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.606 Recall=0.587\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9743 - loss: 0.4437 - val_accuracy: 0.5909 - val_loss: 1.2438 - train_f1_score: 0.9450 - val_f1_score: 0.5746\n",
      "Epoch 456/700\n",
      "\n",
      "Epoch 456: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 456: Train F1=0.9381 - Val F1=0.6118\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 456: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.333\n",
      "  Class 1: Precision=0.657 Recall=0.793\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.650 Recall=0.625\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4197 - val_accuracy: 0.6364 - val_loss: 1.0405 - train_f1_score: 0.9381 - val_f1_score: 0.6118\n",
      "Epoch 457/700\n",
      "\n",
      "Epoch 457: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 457: Train F1=0.8952 - Val F1=0.5180\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 457: Per-class metrics\n",
      "  Class 0: Precision=0.567 Recall=0.630\n",
      "  Class 1: Precision=0.636 Recall=0.241\n",
      "  Class 2: Precision=0.511 Recall=0.750\n",
      "  Macro Avg: Precision=0.571 Recall=0.540\n",
      "11/11 - 2s - 139ms/step - accuracy: 0.9943 - loss: 0.4223 - val_accuracy: 0.5455 - val_loss: 1.3316 - train_f1_score: 0.8952 - val_f1_score: 0.5180\n",
      "Epoch 458/700\n",
      "\n",
      "Epoch 458: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 458: Train F1=0.8705 - Val F1=0.5304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 458: Per-class metrics\n",
      "  Class 0: Precision=0.484 Recall=0.556\n",
      "  Class 1: Precision=0.526 Recall=0.345\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.538 Recall=0.540\n",
      "11/11 - 2s - 208ms/step - accuracy: 0.9886 - loss: 0.4170 - val_accuracy: 0.5455 - val_loss: 1.3748 - train_f1_score: 0.8705 - val_f1_score: 0.5304\n",
      "Epoch 459/700\n",
      "\n",
      "Epoch 459: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 459: Train F1=0.9889 - Val F1=0.6422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 459: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.630 Recall=0.586\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.656 Recall=0.641\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9800 - loss: 0.4282 - val_accuracy: 0.6477 - val_loss: 1.1000 - train_f1_score: 0.9889 - val_f1_score: 0.6422\n",
      "Epoch 460/700\n",
      "\n",
      "Epoch 460: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 460: Train F1=0.9971 - Val F1=0.6005\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 460: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.591 Recall=0.812\n",
      "  Macro Avg: Precision=0.619 Recall=0.606\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4160 - val_accuracy: 0.6136 - val_loss: 1.2260 - train_f1_score: 0.9971 - val_f1_score: 0.6005\n",
      "Epoch 461/700\n",
      "\n",
      "Epoch 461: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 461: Train F1=0.9856 - Val F1=0.5416\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 461: Per-class metrics\n",
      "  Class 0: Precision=0.769 Recall=0.370\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.481 Recall=0.812\n",
      "  Macro Avg: Precision=0.623 Recall=0.544\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.4204 - val_accuracy: 0.5568 - val_loss: 1.4794 - train_f1_score: 0.9856 - val_f1_score: 0.5416\n",
      "Epoch 462/700\n",
      "\n",
      "Epoch 462: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 462: Train F1=0.9496 - Val F1=0.5103\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 462: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.474 Recall=0.310\n",
      "  Class 2: Precision=0.520 Recall=0.812\n",
      "  Macro Avg: Precision=0.542 Recall=0.522\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4119 - val_accuracy: 0.5341 - val_loss: 1.5186 - train_f1_score: 0.9496 - val_f1_score: 0.5103\n",
      "Epoch 463/700\n",
      "\n",
      "Epoch 463: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 463: Train F1=0.9098 - Val F1=0.5383\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 463: Per-class metrics\n",
      "  Class 0: Precision=0.577 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.276\n",
      "  Class 2: Precision=0.540 Recall=0.844\n",
      "  Macro Avg: Precision=0.595 Recall=0.558\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9886 - loss: 0.4287 - val_accuracy: 0.5682 - val_loss: 1.4485 - train_f1_score: 0.9098 - val_f1_score: 0.5383\n",
      "Epoch 464/700\n",
      "\n",
      "Epoch 464: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 464: Train F1=0.9630 - Val F1=0.5798\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 464: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.611 Recall=0.379\n",
      "  Class 2: Precision=0.583 Recall=0.875\n",
      "  Macro Avg: Precision=0.610 Recall=0.591\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.4085 - val_accuracy: 0.6023 - val_loss: 1.3355 - train_f1_score: 0.9630 - val_f1_score: 0.5798\n",
      "Epoch 465/700\n",
      "\n",
      "Epoch 465: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 465: Train F1=0.9473 - Val F1=0.6459\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 465: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.677 Recall=0.724\n",
      "  Class 2: Precision=0.667 Recall=0.625\n",
      "  Macro Avg: Precision=0.646 Recall=0.647\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9914 - loss: 0.4220 - val_accuracy: 0.6477 - val_loss: 1.0894 - train_f1_score: 0.9473 - val_f1_score: 0.6459\n",
      "Epoch 466/700\n",
      "\n",
      "Epoch 466: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 466: Train F1=0.9467 - Val F1=0.6202\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 466: Per-class metrics\n",
      "  Class 0: Precision=0.583 Recall=0.519\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.627 Recall=0.619\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9886 - loss: 0.4141 - val_accuracy: 0.6250 - val_loss: 1.1250 - train_f1_score: 0.9467 - val_f1_score: 0.6202\n",
      "Epoch 467/700\n",
      "\n",
      "Epoch 467: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 467: Train F1=0.9941 - Val F1=0.6674\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 467: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.679 Recall=0.655\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.674 Recall=0.666\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9971 - loss: 0.4025 - val_accuracy: 0.6705 - val_loss: 1.1807 - train_f1_score: 0.9941 - val_f1_score: 0.6674\n",
      "Epoch 468/700\n",
      "\n",
      "Epoch 468: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 468: Train F1=0.9945 - Val F1=0.6071\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 468: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.622 Recall=0.608\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4248 - val_accuracy: 0.6136 - val_loss: 1.2423 - train_f1_score: 0.9945 - val_f1_score: 0.6071\n",
      "Epoch 469/700\n",
      "\n",
      "Epoch 469: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 469: Train F1=0.9857 - Val F1=0.5935\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 469: Per-class metrics\n",
      "  Class 0: Precision=0.577 Recall=0.556\n",
      "  Class 1: Precision=0.609 Recall=0.483\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.600 Recall=0.596\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4040 - val_accuracy: 0.6023 - val_loss: 1.2907 - train_f1_score: 0.9857 - val_f1_score: 0.5935\n",
      "Epoch 470/700\n",
      "\n",
      "Epoch 470: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 470: Train F1=0.9914 - Val F1=0.6494\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 470: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.628 Recall=0.844\n",
      "  Macro Avg: Precision=0.668 Recall=0.651\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4055 - val_accuracy: 0.6591 - val_loss: 1.2215 - train_f1_score: 0.9914 - val_f1_score: 0.6494\n",
      "Epoch 471/700\n",
      "\n",
      "Epoch 471: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 471: Train F1=0.9971 - Val F1=0.5733\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 471: Per-class metrics\n",
      "  Class 0: Precision=0.650 Recall=0.481\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.551 Recall=0.844\n",
      "  Macro Avg: Precision=0.611 Recall=0.580\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9971 - loss: 0.4075 - val_accuracy: 0.5909 - val_loss: 1.3329 - train_f1_score: 0.9971 - val_f1_score: 0.5733\n",
      "Epoch 472/700\n",
      "\n",
      "Epoch 472: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 472: Train F1=0.9400 - Val F1=0.5366\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 472: Per-class metrics\n",
      "  Class 0: Precision=0.471 Recall=0.593\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.600 Recall=0.656\n",
      "  Macro Avg: Precision=0.550 Recall=0.543\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9886 - loss: 0.4144 - val_accuracy: 0.5455 - val_loss: 1.3890 - train_f1_score: 0.9400 - val_f1_score: 0.5366\n",
      "Epoch 473/700\n",
      "\n",
      "Epoch 473: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 473: Train F1=0.9801 - Val F1=0.6740\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 473: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.676 Recall=0.781\n",
      "  Macro Avg: Precision=0.690 Recall=0.675\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9686 - loss: 0.4427 - val_accuracy: 0.6818 - val_loss: 1.1602 - train_f1_score: 0.9801 - val_f1_score: 0.6740\n",
      "Epoch 474/700\n",
      "\n",
      "Epoch 474: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Epoch 474: Train F1=0.9884 - Val F1=0.6092\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "Epoch 474: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.630 Recall=0.608\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9657 - loss: 0.4434 - val_accuracy: 0.6136 - val_loss: 1.2808 - train_f1_score: 0.9884 - val_f1_score: 0.6092\n",
      "Epoch 475/700\n",
      "\n",
      "Epoch 475: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 475: Train F1=0.9916 - Val F1=0.6041\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 475: Per-class metrics\n",
      "  Class 0: Precision=0.613 Recall=0.704\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.617 Recall=0.612\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.9857 - loss: 0.4221 - val_accuracy: 0.6136 - val_loss: 1.2120 - train_f1_score: 0.9916 - val_f1_score: 0.6041\n",
      "Epoch 476/700\n",
      "\n",
      "Epoch 476: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 476: Train F1=0.9825 - Val F1=0.6583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 476: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.704 Recall=0.655\n",
      "  Class 2: Precision=0.647 Recall=0.688\n",
      "  Macro Avg: Precision=0.660 Recall=0.657\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9914 - loss: 0.4161 - val_accuracy: 0.6591 - val_loss: 1.1254 - train_f1_score: 0.9825 - val_f1_score: 0.6583\n",
      "Epoch 477/700\n",
      "\n",
      "Epoch 477: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 477: Train F1=0.9827 - Val F1=0.6690\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 477: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.773 Recall=0.586\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.682 Recall=0.668\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4170 - val_accuracy: 0.6705 - val_loss: 1.1148 - train_f1_score: 0.9827 - val_f1_score: 0.6690\n",
      "Epoch 478/700\n",
      "\n",
      "Epoch 478: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 478: Train F1=0.9914 - Val F1=0.6794\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 478: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.760 Recall=0.655\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.694 Recall=0.676\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9943 - loss: 0.4030 - val_accuracy: 0.6818 - val_loss: 1.0797 - train_f1_score: 0.9914 - val_f1_score: 0.6794\n",
      "Epoch 479/700\n",
      "\n",
      "Epoch 479: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 479: Train F1=0.9884 - Val F1=0.7033\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 479: Per-class metrics\n",
      "  Class 0: Precision=0.773 Recall=0.630\n",
      "  Class 1: Precision=0.760 Recall=0.655\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.722 Recall=0.699\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9943 - loss: 0.4020 - val_accuracy: 0.7045 - val_loss: 1.0964 - train_f1_score: 0.9884 - val_f1_score: 0.7033\n",
      "Epoch 480/700\n",
      "\n",
      "Epoch 480: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 480: Train F1=0.9771 - Val F1=0.6437\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 480: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.651 Recall=0.644\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4214 - val_accuracy: 0.6477 - val_loss: 1.1402 - train_f1_score: 0.9771 - val_f1_score: 0.6437\n",
      "Epoch 481/700\n",
      "\n",
      "Epoch 481: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 481: Train F1=0.9943 - Val F1=0.6442\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 481: Per-class metrics\n",
      "  Class 0: Precision=0.739 Recall=0.630\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.662 Recall=0.643\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4112 - val_accuracy: 0.6477 - val_loss: 1.2164 - train_f1_score: 0.9943 - val_f1_score: 0.6442\n",
      "Epoch 482/700\n",
      "\n",
      "Epoch 482: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 482: Train F1=1.0000 - Val F1=0.6560\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 482: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.667 Recall=0.657\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9886 - loss: 0.4093 - val_accuracy: 0.6591 - val_loss: 1.2208 - train_f1_score: 1.0000 - val_f1_score: 0.6560\n",
      "Epoch 483/700\n",
      "\n",
      "Epoch 483: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 483: Train F1=0.9860 - Val F1=0.6141\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 483: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.650 Recall=0.448\n",
      "  Class 2: Precision=0.591 Recall=0.812\n",
      "  Macro Avg: Precision=0.636 Recall=0.618\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9829 - loss: 0.4226 - val_accuracy: 0.6250 - val_loss: 1.2621 - train_f1_score: 0.9860 - val_f1_score: 0.6141\n",
      "Epoch 484/700\n",
      "\n",
      "Epoch 484: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 484: Train F1=0.9798 - Val F1=0.6367\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 484: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.660 Recall=0.638\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9857 - loss: 0.4151 - val_accuracy: 0.6477 - val_loss: 1.2243 - train_f1_score: 0.9798 - val_f1_score: 0.6367\n",
      "Epoch 485/700\n",
      "\n",
      "Epoch 485: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 485: Train F1=0.9388 - Val F1=0.6363\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 485: Per-class metrics\n",
      "  Class 0: Precision=0.630 Recall=0.630\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.644 Recall=0.634\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9886 - loss: 0.4127 - val_accuracy: 0.6364 - val_loss: 1.0351 - train_f1_score: 0.9388 - val_f1_score: 0.6363\n",
      "Epoch 486/700\n",
      "\n",
      "Epoch 486: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 486: Train F1=0.9730 - Val F1=0.6660\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 486: Per-class metrics\n",
      "  Class 0: Precision=0.706 Recall=0.444\n",
      "  Class 1: Precision=0.667 Recall=0.759\n",
      "  Class 2: Precision=0.684 Recall=0.812\n",
      "  Macro Avg: Precision=0.686 Recall=0.672\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9971 - loss: 0.4068 - val_accuracy: 0.6818 - val_loss: 1.1114 - train_f1_score: 0.9730 - val_f1_score: 0.6660\n",
      "Epoch 487/700\n",
      "\n",
      "Epoch 487: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 487: Train F1=0.9850 - Val F1=0.6780\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 487: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.444\n",
      "  Class 1: Precision=0.676 Recall=0.793\n",
      "  Class 2: Precision=0.667 Recall=0.812\n",
      "  Macro Avg: Precision=0.714 Recall=0.683\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4303 - val_accuracy: 0.6932 - val_loss: 1.1290 - train_f1_score: 0.9850 - val_f1_score: 0.6780\n",
      "Epoch 488/700\n",
      "\n",
      "Epoch 488: val_accuracy did not improve from 0.71591\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 488: Train F1=0.9418 - Val F1=0.6655\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 488: Per-class metrics\n",
      "  Class 0: Precision=0.778 Recall=0.519\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.689 Recall=0.664\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9914 - loss: 0.4158 - val_accuracy: 0.6705 - val_loss: 1.0249 - train_f1_score: 0.9418 - val_f1_score: 0.6655\n",
      "Epoch 489/700\n",
      "\n",
      "Epoch 489: val_accuracy improved from 0.71591 to 0.72727, saving model to best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489: Train F1=0.9610 - Val F1=0.7170\n",
      "\n",
      "Saved best model at epoch 489 with val_f1=0.7170\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 489: Per-class metrics\n",
      "  Class 0: Precision=0.824 Recall=0.519\n",
      "  Class 1: Precision=0.686 Recall=0.828\n",
      "  Class 2: Precision=0.722 Recall=0.812\n",
      "  Macro Avg: Precision=0.744 Recall=0.720\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9829 - loss: 0.4193 - val_accuracy: 0.7273 - val_loss: 0.9993 - train_f1_score: 0.9610 - val_f1_score: 0.7170\n",
      "Epoch 490/700\n",
      "\n",
      "Epoch 490: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 490: Train F1=0.9191 - Val F1=0.5361\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 490: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.526 Recall=0.345\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.562 Recall=0.546\n",
      "11/11 - 1s - 95ms/step - accuracy: 1.0000 - loss: 0.3989 - val_accuracy: 0.5568 - val_loss: 1.3030 - train_f1_score: 0.9191 - val_f1_score: 0.5361\n",
      "Epoch 491/700\n",
      "\n",
      "Epoch 491: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 491: Train F1=0.9494 - Val F1=0.5379\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 491: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.529 Recall=0.310\n",
      "  Class 2: Precision=0.510 Recall=0.812\n",
      "  Macro Avg: Precision=0.580 Recall=0.547\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4055 - val_accuracy: 0.5568 - val_loss: 1.4038 - train_f1_score: 0.9494 - val_f1_score: 0.5379\n",
      "Epoch 492/700\n",
      "\n",
      "Epoch 492: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 492: Train F1=0.9510 - Val F1=0.6704\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 492: Per-class metrics\n",
      "  Class 0: Precision=0.762 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.690\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.683 Recall=0.667\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.9829 - loss: 0.4174 - val_accuracy: 0.6705 - val_loss: 1.0633 - train_f1_score: 0.9510 - val_f1_score: 0.6704\n",
      "Epoch 493/700\n",
      "\n",
      "Epoch 493: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 493: Train F1=0.8515 - Val F1=0.6189\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 493: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.628 Recall=0.620\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4216 - val_accuracy: 0.6250 - val_loss: 1.2175 - train_f1_score: 0.8515 - val_f1_score: 0.6189\n",
      "Epoch 494/700\n",
      "\n",
      "Epoch 494: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 494: Train F1=0.9742 - Val F1=0.6190\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 494: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.581 Recall=0.621\n",
      "  Class 2: Precision=0.676 Recall=0.719\n",
      "  Macro Avg: Precision=0.622 Recall=0.619\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9714 - loss: 0.4351 - val_accuracy: 0.6250 - val_loss: 1.2916 - train_f1_score: 0.9742 - val_f1_score: 0.6190\n",
      "Epoch 495/700\n",
      "\n",
      "Epoch 495: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 495: Train F1=0.7652 - Val F1=0.5630\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 495: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.551 Recall=0.844\n",
      "  Macro Avg: Precision=0.607 Recall=0.583\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4172 - val_accuracy: 0.5909 - val_loss: 1.4444 - train_f1_score: 0.7652 - val_f1_score: 0.5630\n",
      "Epoch 496/700\n",
      "\n",
      "Epoch 496: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 496: Train F1=0.9605 - Val F1=0.5632\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 496: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.611 Recall=0.379\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.596 Recall=0.570\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9857 - loss: 0.4273 - val_accuracy: 0.5795 - val_loss: 1.3587 - train_f1_score: 0.9605 - val_f1_score: 0.5632\n",
      "Epoch 497/700\n",
      "\n",
      "Epoch 497: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 497: Train F1=0.9770 - Val F1=0.6258\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 497: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.642 Recall=0.632\n",
      "11/11 - 1s - 117ms/step - accuracy: 1.0000 - loss: 0.3978 - val_accuracy: 0.6364 - val_loss: 1.1801 - train_f1_score: 0.9770 - val_f1_score: 0.6258\n",
      "Epoch 498/700\n",
      "\n",
      "Epoch 498: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 498: Train F1=0.9773 - Val F1=0.5835\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 498: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.571 Recall=0.414\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.598 Recall=0.592\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.3983 - val_accuracy: 0.6023 - val_loss: 1.2307 - train_f1_score: 0.9773 - val_f1_score: 0.5835\n",
      "Epoch 499/700\n",
      "\n",
      "Epoch 499: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 499: Train F1=0.9804 - Val F1=0.6410\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 499: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.519\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.650 Recall=0.641\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9886 - loss: 0.4178 - val_accuracy: 0.6477 - val_loss: 1.1936 - train_f1_score: 0.9804 - val_f1_score: 0.6410\n",
      "Epoch 500/700\n",
      "\n",
      "Epoch 500: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 500: Train F1=0.9791 - Val F1=0.6905\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 500: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.741 Recall=0.690\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.703 Recall=0.688\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.4088 - val_accuracy: 0.6932 - val_loss: 1.0584 - train_f1_score: 0.9791 - val_f1_score: 0.6905\n",
      "Epoch 501/700\n",
      "\n",
      "Epoch 501: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 501: Train F1=0.9219 - Val F1=0.4878\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 501: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.370\n",
      "  Class 1: Precision=0.526 Recall=0.345\n",
      "  Class 2: Precision=0.490 Recall=0.781\n",
      "  Macro Avg: Precision=0.524 Recall=0.499\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9771 - loss: 0.4281 - val_accuracy: 0.5114 - val_loss: 1.5256 - train_f1_score: 0.9219 - val_f1_score: 0.4878\n",
      "Epoch 502/700\n",
      "\n",
      "Epoch 502: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 502: Train F1=0.8645 - Val F1=0.5114\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 502: Per-class metrics\n",
      "  Class 0: Precision=0.520 Recall=0.481\n",
      "  Class 1: Precision=0.478 Recall=0.379\n",
      "  Class 2: Precision=0.550 Recall=0.688\n",
      "  Macro Avg: Precision=0.516 Recall=0.516\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9714 - loss: 0.4290 - val_accuracy: 0.5227 - val_loss: 1.4077 - train_f1_score: 0.8645 - val_f1_score: 0.5114\n",
      "Epoch 503/700\n",
      "\n",
      "Epoch 503: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 503: Train F1=0.9286 - Val F1=0.5388\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 503: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.529 Recall=0.310\n",
      "  Class 2: Precision=0.521 Recall=0.781\n",
      "  Macro Avg: Precision=0.567 Recall=0.549\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4058 - val_accuracy: 0.5568 - val_loss: 1.3980 - train_f1_score: 0.9286 - val_f1_score: 0.5388\n",
      "Epoch 504/700\n",
      "\n",
      "Epoch 504: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 504: Train F1=0.9518 - Val F1=0.5689\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 504: Per-class metrics\n",
      "  Class 0: Precision=0.591 Recall=0.481\n",
      "  Class 1: Precision=0.519 Recall=0.483\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.575 Recall=0.571\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9914 - loss: 0.4120 - val_accuracy: 0.5795 - val_loss: 1.3983 - train_f1_score: 0.9518 - val_f1_score: 0.5689\n",
      "Epoch 505/700\n",
      "\n",
      "Epoch 505: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 505: Train F1=0.9882 - Val F1=0.6087\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 505: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.543 Recall=0.781\n",
      "  Macro Avg: Precision=0.641 Recall=0.607\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4138 - val_accuracy: 0.6136 - val_loss: 1.2500 - train_f1_score: 0.9882 - val_f1_score: 0.6087\n",
      "Epoch 506/700\n",
      "\n",
      "Epoch 506: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 506: Train F1=0.9509 - Val F1=0.5973\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 506: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.556\n",
      "  Class 1: Precision=0.737 Recall=0.483\n",
      "  Class 2: Precision=0.545 Recall=0.750\n",
      "  Macro Avg: Precision=0.627 Recall=0.596\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9829 - loss: 0.4227 - val_accuracy: 0.6023 - val_loss: 1.1659 - train_f1_score: 0.9509 - val_f1_score: 0.5973\n",
      "Epoch 507/700\n",
      "\n",
      "Epoch 507: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 507: Train F1=0.9708 - Val F1=0.6177\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 507: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.444\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.561 Recall=0.719\n",
      "  Macro Avg: Precision=0.639 Recall=0.618\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4136 - val_accuracy: 0.6250 - val_loss: 1.0942 - train_f1_score: 0.9708 - val_f1_score: 0.6177\n",
      "Epoch 508/700\n",
      "\n",
      "Epoch 508: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 508: Train F1=0.9799 - Val F1=0.5921\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 508: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.333\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.624 Recall=0.602\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9943 - loss: 0.4079 - val_accuracy: 0.6136 - val_loss: 1.1227 - train_f1_score: 0.9799 - val_f1_score: 0.5921\n",
      "Epoch 509/700\n",
      "\n",
      "Epoch 509: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 509: Train F1=0.9587 - Val F1=0.6402\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 509: Per-class metrics\n",
      "  Class 0: Precision=0.591 Recall=0.481\n",
      "  Class 1: Precision=0.710 Recall=0.759\n",
      "  Class 2: Precision=0.629 Recall=0.688\n",
      "  Macro Avg: Precision=0.643 Recall=0.643\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9971 - loss: 0.4035 - val_accuracy: 0.6477 - val_loss: 1.0392 - train_f1_score: 0.9587 - val_f1_score: 0.6402\n",
      "Epoch 510/700\n",
      "\n",
      "Epoch 510: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 510: Train F1=0.9253 - Val F1=0.6049\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 510: Per-class metrics\n",
      "  Class 0: Precision=0.545 Recall=0.444\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.618 Recall=0.656\n",
      "  Macro Avg: Precision=0.606 Recall=0.608\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9914 - loss: 0.4106 - val_accuracy: 0.6136 - val_loss: 1.1104 - train_f1_score: 0.9253 - val_f1_score: 0.6049\n",
      "Epoch 511/700\n",
      "\n",
      "Epoch 511: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 511: Train F1=0.9678 - Val F1=0.6203\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 511: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.629 Recall=0.688\n",
      "  Macro Avg: Precision=0.624 Recall=0.620\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4106 - val_accuracy: 0.6250 - val_loss: 1.1534 - train_f1_score: 0.9678 - val_f1_score: 0.6203\n",
      "Epoch 512/700\n",
      "\n",
      "Epoch 512: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 512: Train F1=0.9970 - Val F1=0.6350\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 512: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.444\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.667 Recall=0.637\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9857 - loss: 0.4100 - val_accuracy: 0.6477 - val_loss: 1.1759 - train_f1_score: 0.9970 - val_f1_score: 0.6350\n",
      "Epoch 513/700\n",
      "\n",
      "Epoch 513: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 513: Train F1=0.9619 - Val F1=0.5792\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 513: Per-class metrics\n",
      "  Class 0: Precision=0.889 Recall=0.296\n",
      "  Class 1: Precision=0.679 Recall=0.655\n",
      "  Class 2: Precision=0.510 Recall=0.812\n",
      "  Macro Avg: Precision=0.692 Recall=0.588\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9886 - loss: 0.4160 - val_accuracy: 0.6023 - val_loss: 1.2408 - train_f1_score: 0.9619 - val_f1_score: 0.5792\n",
      "Epoch 514/700\n",
      "\n",
      "Epoch 514: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 514: Train F1=0.7731 - Val F1=0.5467\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 514: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.148\n",
      "  Class 1: Precision=0.615 Recall=0.828\n",
      "  Class 2: Precision=0.591 Recall=0.812\n",
      "  Macro Avg: Precision=0.669 Recall=0.596\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4327 - val_accuracy: 0.6136 - val_loss: 1.3102 - train_f1_score: 0.7731 - val_f1_score: 0.5467\n",
      "Epoch 515/700\n",
      "\n",
      "Epoch 515: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 515: Train F1=0.9014 - Val F1=0.5734\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 515: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.370\n",
      "  Class 1: Precision=0.750 Recall=0.517\n",
      "  Class 2: Precision=0.519 Recall=0.844\n",
      "  Macro Avg: Precision=0.631 Recall=0.577\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9600 - loss: 0.4821 - val_accuracy: 0.5909 - val_loss: 1.2218 - train_f1_score: 0.9014 - val_f1_score: 0.5734\n",
      "Epoch 516/700\n",
      "\n",
      "Epoch 516: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 516: Train F1=0.9264 - Val F1=0.5755\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 516: Per-class metrics\n",
      "  Class 0: Precision=0.524 Recall=0.407\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.586 Recall=0.580\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9486 - loss: 0.4898 - val_accuracy: 0.5909 - val_loss: 1.1121 - train_f1_score: 0.9264 - val_f1_score: 0.5755\n",
      "Epoch 517/700\n",
      "\n",
      "Epoch 517: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 517: Train F1=0.8182 - Val F1=0.6416\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 517: Per-class metrics\n",
      "  Class 0: Precision=0.733 Recall=0.407\n",
      "  Class 1: Precision=0.591 Recall=0.897\n",
      "  Class 2: Precision=0.724 Recall=0.656\n",
      "  Macro Avg: Precision=0.683 Recall=0.653\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9600 - loss: 0.4793 - val_accuracy: 0.6591 - val_loss: 1.1905 - train_f1_score: 0.8182 - val_f1_score: 0.6416\n",
      "Epoch 518/700\n",
      "\n",
      "Epoch 518: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 518: Train F1=0.9972 - Val F1=0.6818\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 518: Per-class metrics\n",
      "  Class 0: Precision=0.773 Recall=0.630\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.701 Recall=0.677\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9514 - loss: 0.4765 - val_accuracy: 0.6818 - val_loss: 1.0026 - train_f1_score: 0.9972 - val_f1_score: 0.6818\n",
      "Epoch 519/700\n",
      "\n",
      "Epoch 519: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 519: Train F1=0.9801 - Val F1=0.6610\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 519: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.625 Recall=0.690\n",
      "  Class 2: Precision=0.645 Recall=0.625\n",
      "  Macro Avg: Precision=0.663 Recall=0.660\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9743 - loss: 0.4447 - val_accuracy: 0.6591 - val_loss: 1.1144 - train_f1_score: 0.9801 - val_f1_score: 0.6610\n",
      "Epoch 520/700\n",
      "\n",
      "Epoch 520: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 520: Train F1=0.9625 - Val F1=0.6103\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 520: Per-class metrics\n",
      "  Class 0: Precision=0.528 Recall=0.704\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.656 Recall=0.656\n",
      "  Macro Avg: Precision=0.628 Recall=0.614\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9800 - loss: 0.4329 - val_accuracy: 0.6136 - val_loss: 1.2725 - train_f1_score: 0.9625 - val_f1_score: 0.6103\n",
      "Epoch 521/700\n",
      "\n",
      "Epoch 521: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 521: Train F1=0.9452 - Val F1=0.6130\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 521: Per-class metrics\n",
      "  Class 0: Precision=0.524 Recall=0.815\n",
      "  Class 1: Precision=0.789 Recall=0.517\n",
      "  Class 2: Precision=0.630 Recall=0.531\n",
      "  Macro Avg: Precision=0.648 Recall=0.621\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9600 - loss: 0.4683 - val_accuracy: 0.6136 - val_loss: 1.1199 - train_f1_score: 0.9452 - val_f1_score: 0.6130\n",
      "Epoch 522/700\n",
      "\n",
      "Epoch 522: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 522: Train F1=0.9823 - Val F1=0.6202\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 522: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.606 Recall=0.690\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.641 Recall=0.620\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.9600 - loss: 0.4787 - val_accuracy: 0.6250 - val_loss: 1.1286 - train_f1_score: 0.9823 - val_f1_score: 0.6202\n",
      "Epoch 523/700\n",
      "\n",
      "Epoch 523: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 523: Train F1=0.7938 - Val F1=0.5457\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 523: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.519\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.509 Recall=0.844\n",
      "  Macro Avg: Precision=0.606 Recall=0.558\n",
      "11/11 - 1s - 123ms/step - accuracy: 0.9800 - loss: 0.4407 - val_accuracy: 0.5682 - val_loss: 1.3425 - train_f1_score: 0.7938 - val_f1_score: 0.5457\n",
      "Epoch 524/700\n",
      "\n",
      "Epoch 524: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 524: Train F1=0.8695 - Val F1=0.5451\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 524: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.625 Recall=0.345\n",
      "  Class 2: Precision=0.481 Recall=0.781\n",
      "  Macro Avg: Precision=0.602 Recall=0.548\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9714 - loss: 0.4415 - val_accuracy: 0.5568 - val_loss: 1.4008 - train_f1_score: 0.8695 - val_f1_score: 0.5451\n",
      "Epoch 525/700\n",
      "\n",
      "Epoch 525: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 525: Train F1=0.9689 - Val F1=0.5385\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 525: Per-class metrics\n",
      "  Class 0: Precision=0.528 Recall=0.704\n",
      "  Class 1: Precision=0.579 Recall=0.379\n",
      "  Class 2: Precision=0.545 Recall=0.562\n",
      "  Macro Avg: Precision=0.551 Recall=0.549\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4233 - val_accuracy: 0.5455 - val_loss: 1.3551 - train_f1_score: 0.9689 - val_f1_score: 0.5385\n",
      "Epoch 526/700\n",
      "\n",
      "Epoch 526: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 526: Train F1=0.9833 - Val F1=0.6394\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 526: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.621 Recall=0.621\n",
      "  Class 2: Precision=0.594 Recall=0.594\n",
      "  Macro Avg: Precision=0.639 Recall=0.639\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9771 - loss: 0.4338 - val_accuracy: 0.6364 - val_loss: 1.1656 - train_f1_score: 0.9833 - val_f1_score: 0.6394\n",
      "Epoch 527/700\n",
      "\n",
      "Epoch 527: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 527: Train F1=1.0000 - Val F1=0.6722\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 527: Per-class metrics\n",
      "  Class 0: Precision=0.810 Recall=0.630\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.700 Recall=0.666\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4207 - val_accuracy: 0.6705 - val_loss: 1.1304 - train_f1_score: 1.0000 - val_f1_score: 0.6722\n",
      "Epoch 528/700\n",
      "\n",
      "Epoch 528: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 528: Train F1=0.9944 - Val F1=0.6355\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 528: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.789 Recall=0.517\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.667 Recall=0.632\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9857 - loss: 0.4235 - val_accuracy: 0.6364 - val_loss: 1.1747 - train_f1_score: 0.9944 - val_f1_score: 0.6355\n",
      "Epoch 529/700\n",
      "\n",
      "Epoch 529: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 529: Train F1=0.9915 - Val F1=0.6958\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 529: Per-class metrics\n",
      "  Class 0: Precision=0.731 Recall=0.704\n",
      "  Class 1: Precision=0.760 Recall=0.655\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.704 Recall=0.693\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4253 - val_accuracy: 0.6932 - val_loss: 1.0606 - train_f1_score: 0.9915 - val_f1_score: 0.6958\n",
      "Epoch 530/700\n",
      "\n",
      "Epoch 530: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 530: Train F1=0.9273 - Val F1=0.6913\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 530: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.719 Recall=0.793\n",
      "  Class 2: Precision=0.647 Recall=0.688\n",
      "  Macro Avg: Precision=0.698 Recall=0.691\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9886 - loss: 0.4243 - val_accuracy: 0.6932 - val_loss: 0.9679 - train_f1_score: 0.9273 - val_f1_score: 0.6913\n",
      "Epoch 531/700\n",
      "\n",
      "Epoch 531: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 531: Train F1=0.9418 - Val F1=0.7050\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 531: Per-class metrics\n",
      "  Class 0: Precision=0.679 Recall=0.704\n",
      "  Class 1: Precision=0.857 Recall=0.621\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.726 Recall=0.702\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4191 - val_accuracy: 0.7045 - val_loss: 0.9389 - train_f1_score: 0.9418 - val_f1_score: 0.7050\n",
      "Epoch 532/700\n",
      "\n",
      "Epoch 532: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 532: Train F1=0.9337 - Val F1=0.6603\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 532: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.741 Recall=0.690\n",
      "  Class 2: Precision=0.645 Recall=0.625\n",
      "  Macro Avg: Precision=0.662 Recall=0.660\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4192 - val_accuracy: 0.6591 - val_loss: 0.9450 - train_f1_score: 0.9337 - val_f1_score: 0.6603\n",
      "Epoch 533/700\n",
      "\n",
      "Epoch 533: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 533: Train F1=0.9679 - Val F1=0.6559\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 533: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.667 Recall=0.656\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9971 - loss: 0.4059 - val_accuracy: 0.6591 - val_loss: 1.0114 - train_f1_score: 0.9679 - val_f1_score: 0.6559\n",
      "Epoch 534/700\n",
      "\n",
      "Epoch 534: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 534: Train F1=0.9774 - Val F1=0.6421\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 534: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.663 Recall=0.644\n",
      "11/11 - 1s - 115ms/step - accuracy: 1.0000 - loss: 0.3996 - val_accuracy: 0.6477 - val_loss: 1.1323 - train_f1_score: 0.9774 - val_f1_score: 0.6421\n",
      "Epoch 535/700\n",
      "\n",
      "Epoch 535: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 535: Train F1=0.9661 - Val F1=0.6416\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 535: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.778 Recall=0.483\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.679 Recall=0.642\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9971 - loss: 0.4078 - val_accuracy: 0.6477 - val_loss: 1.1517 - train_f1_score: 0.9661 - val_f1_score: 0.6416\n",
      "Epoch 536/700\n",
      "\n",
      "Epoch 536: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 536: Train F1=0.9543 - Val F1=0.6477\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 536: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.722 Recall=0.448\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.676 Recall=0.653\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9971 - loss: 0.3993 - val_accuracy: 0.6591 - val_loss: 1.0506 - train_f1_score: 0.9543 - val_f1_score: 0.6477\n",
      "Epoch 537/700\n",
      "\n",
      "Epoch 537: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 537: Train F1=0.9689 - Val F1=0.6784\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 537: Per-class metrics\n",
      "  Class 0: Precision=0.773 Recall=0.630\n",
      "  Class 1: Precision=0.762 Recall=0.552\n",
      "  Class 2: Precision=0.600 Recall=0.844\n",
      "  Macro Avg: Precision=0.712 Recall=0.675\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.4065 - val_accuracy: 0.6818 - val_loss: 1.0619 - train_f1_score: 0.9689 - val_f1_score: 0.6784\n",
      "Epoch 538/700\n",
      "\n",
      "Epoch 538: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538: Train F1=0.9860 - Val F1=0.7176\n",
      "\n",
      "Saved best model at epoch 538 with val_f1=0.7176\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 538: Per-class metrics\n",
      "  Class 0: Precision=0.857 Recall=0.667\n",
      "  Class 1: Precision=0.783 Recall=0.621\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.751 Recall=0.710\n",
      "11/11 - 1s - 116ms/step - accuracy: 1.0000 - loss: 0.4051 - val_accuracy: 0.7159 - val_loss: 1.0270 - train_f1_score: 0.9860 - val_f1_score: 0.7176\n",
      "Epoch 539/700\n",
      "\n",
      "Epoch 539: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 539: Train F1=0.9888 - Val F1=0.6918\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 539: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.667\n",
      "  Class 1: Precision=0.773 Recall=0.586\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.714 Recall=0.688\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9943 - loss: 0.4100 - val_accuracy: 0.6932 - val_loss: 1.0128 - train_f1_score: 0.9888 - val_f1_score: 0.6918\n",
      "Epoch 540/700\n",
      "\n",
      "Epoch 540: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 540: Train F1=0.9856 - Val F1=0.6776\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 540: Per-class metrics\n",
      "  Class 0: Precision=0.708 Recall=0.630\n",
      "  Class 1: Precision=0.739 Recall=0.586\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.694 Recall=0.676\n",
      "11/11 - 1s - 92ms/step - accuracy: 1.0000 - loss: 0.3965 - val_accuracy: 0.6818 - val_loss: 1.0512 - train_f1_score: 0.9856 - val_f1_score: 0.6776\n",
      "Epoch 541/700\n",
      "\n",
      "Epoch 541: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 541: Train F1=0.9917 - Val F1=0.6919\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 541: Per-class metrics\n",
      "  Class 0: Precision=0.773 Recall=0.630\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.714 Recall=0.688\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9943 - loss: 0.4008 - val_accuracy: 0.6932 - val_loss: 1.0641 - train_f1_score: 0.9917 - val_f1_score: 0.6919\n",
      "Epoch 542/700\n",
      "\n",
      "Epoch 542: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 542: Train F1=0.9944 - Val F1=0.6708\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 542: Per-class metrics\n",
      "  Class 0: Precision=0.842 Recall=0.593\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.709 Recall=0.664\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4003 - val_accuracy: 0.6705 - val_loss: 1.0633 - train_f1_score: 0.9944 - val_f1_score: 0.6708\n",
      "Epoch 543/700\n",
      "\n",
      "Epoch 543: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 543: Train F1=0.9971 - Val F1=0.7153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 543: Per-class metrics\n",
      "  Class 0: Precision=0.783 Recall=0.667\n",
      "  Class 1: Precision=0.760 Recall=0.655\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.731 Recall=0.711\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9943 - loss: 0.4092 - val_accuracy: 0.7159 - val_loss: 0.9925 - train_f1_score: 0.9971 - val_f1_score: 0.7153\n",
      "Epoch 544/700\n",
      "\n",
      "Epoch 544: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 544: Train F1=0.9971 - Val F1=0.6929\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 544: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.701 Recall=0.691\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4017 - val_accuracy: 0.6932 - val_loss: 1.0850 - train_f1_score: 0.9971 - val_f1_score: 0.6929\n",
      "Epoch 545/700\n",
      "\n",
      "Epoch 545: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 545: Train F1=0.9889 - Val F1=0.6511\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 545: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.670 Recall=0.654\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9971 - loss: 0.4005 - val_accuracy: 0.6591 - val_loss: 1.1517 - train_f1_score: 0.9889 - val_f1_score: 0.6511\n",
      "Epoch 546/700\n",
      "\n",
      "Epoch 546: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 546: Train F1=0.9717 - Val F1=0.6486\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 546: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.812 Recall=0.448\n",
      "  Class 2: Precision=0.600 Recall=0.844\n",
      "  Macro Avg: Precision=0.693 Recall=0.653\n",
      "11/11 - 1s - 118ms/step - accuracy: 1.0000 - loss: 0.3915 - val_accuracy: 0.6591 - val_loss: 1.1664 - train_f1_score: 0.9717 - val_f1_score: 0.6486\n",
      "Epoch 547/700\n",
      "\n",
      "Epoch 547: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 547: Train F1=0.9856 - Val F1=0.6905\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 547: Per-class metrics\n",
      "  Class 0: Precision=0.643 Recall=0.667\n",
      "  Class 1: Precision=0.783 Recall=0.621\n",
      "  Class 2: Precision=0.676 Recall=0.781\n",
      "  Macro Avg: Precision=0.700 Recall=0.690\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9914 - loss: 0.4047 - val_accuracy: 0.6932 - val_loss: 1.0193 - train_f1_score: 0.9856 - val_f1_score: 0.6905\n",
      "Epoch 548/700\n",
      "\n",
      "Epoch 548: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 548: Train F1=0.9858 - Val F1=0.7146\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 548: Per-class metrics\n",
      "  Class 0: Precision=0.818 Recall=0.667\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.643 Recall=0.844\n",
      "  Macro Avg: Precision=0.737 Recall=0.710\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9971 - loss: 0.3978 - val_accuracy: 0.7159 - val_loss: 1.0496 - train_f1_score: 0.9858 - val_f1_score: 0.7146\n",
      "Epoch 549/700\n",
      "\n",
      "Epoch 549: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 549: Train F1=1.0000 - Val F1=0.6936\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 549: Per-class metrics\n",
      "  Class 0: Precision=0.850 Recall=0.630\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.720 Recall=0.688\n",
      "11/11 - 1s - 94ms/step - accuracy: 1.0000 - loss: 0.3992 - val_accuracy: 0.6932 - val_loss: 1.0738 - train_f1_score: 1.0000 - val_f1_score: 0.6936\n",
      "Epoch 550/700\n",
      "\n",
      "Epoch 550: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 550: Train F1=0.9971 - Val F1=0.6931\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 550: Per-class metrics\n",
      "  Class 0: Precision=0.773 Recall=0.630\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.649 Recall=0.750\n",
      "  Macro Avg: Precision=0.704 Recall=0.690\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4170 - val_accuracy: 0.6932 - val_loss: 1.0195 - train_f1_score: 0.9971 - val_f1_score: 0.6931\n",
      "Epoch 551/700\n",
      "\n",
      "Epoch 551: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 551: Train F1=0.9914 - Val F1=0.6425\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 551: Per-class metrics\n",
      "  Class 0: Precision=0.765 Recall=0.481\n",
      "  Class 1: Precision=0.704 Recall=0.655\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.679 Recall=0.639\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9886 - loss: 0.4178 - val_accuracy: 0.6477 - val_loss: 1.0619 - train_f1_score: 0.9914 - val_f1_score: 0.6425\n",
      "Epoch 552/700\n",
      "\n",
      "Epoch 552: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 552: Train F1=0.9695 - Val F1=0.6229\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 552: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.765 Recall=0.448\n",
      "  Class 2: Precision=0.571 Recall=0.875\n",
      "  Macro Avg: Precision=0.673 Recall=0.626\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4097 - val_accuracy: 0.6364 - val_loss: 1.2066 - train_f1_score: 0.9695 - val_f1_score: 0.6229\n",
      "Epoch 553/700\n",
      "\n",
      "Epoch 553: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 553: Train F1=0.9601 - Val F1=0.6014\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 553: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.551 Recall=0.844\n",
      "  Macro Avg: Precision=0.645 Recall=0.604\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.4030 - val_accuracy: 0.6136 - val_loss: 1.2299 - train_f1_score: 0.9601 - val_f1_score: 0.6014\n",
      "Epoch 554/700\n",
      "\n",
      "Epoch 554: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 554: Train F1=0.9547 - Val F1=0.6168\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 554: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.649 Recall=0.617\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.4017 - val_accuracy: 0.6250 - val_loss: 1.2615 - train_f1_score: 0.9547 - val_f1_score: 0.6168\n",
      "Epoch 555/700\n",
      "\n",
      "Epoch 555: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 555: Train F1=0.9773 - Val F1=0.6544\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 555: Per-class metrics\n",
      "  Class 0: Precision=0.789 Recall=0.556\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.574 Recall=0.844\n",
      "  Macro Avg: Precision=0.697 Recall=0.650\n",
      "11/11 - 1s - 90ms/step - accuracy: 0.9943 - loss: 0.4049 - val_accuracy: 0.6591 - val_loss: 1.2142 - train_f1_score: 0.9773 - val_f1_score: 0.6544\n",
      "Epoch 556/700\n",
      "\n",
      "Epoch 556: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 556: Train F1=0.9470 - Val F1=0.5776\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 556: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.509 Recall=0.844\n",
      "  Macro Avg: Precision=0.645 Recall=0.581\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9914 - loss: 0.4123 - val_accuracy: 0.5909 - val_loss: 1.2558 - train_f1_score: 0.9470 - val_f1_score: 0.5776\n",
      "Epoch 557/700\n",
      "\n",
      "Epoch 557: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 557: Train F1=0.9125 - Val F1=0.5631\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 557: Per-class metrics\n",
      "  Class 0: Precision=0.765 Recall=0.481\n",
      "  Class 1: Precision=0.769 Recall=0.345\n",
      "  Class 2: Precision=0.483 Recall=0.875\n",
      "  Macro Avg: Precision=0.672 Recall=0.567\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9971 - loss: 0.3987 - val_accuracy: 0.5795 - val_loss: 1.3568 - train_f1_score: 0.9125 - val_f1_score: 0.5631\n",
      "Epoch 558/700\n",
      "\n",
      "Epoch 558: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 558: Train F1=0.9738 - Val F1=0.6361\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 558: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.628 Recall=0.844\n",
      "  Macro Avg: Precision=0.656 Recall=0.638\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.4041 - val_accuracy: 0.6477 - val_loss: 1.1327 - train_f1_score: 0.9738 - val_f1_score: 0.6361\n",
      "Epoch 559/700\n",
      "\n",
      "Epoch 559: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 559: Train F1=0.9529 - Val F1=0.6506\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 559: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.622 Recall=0.793\n",
      "  Class 2: Precision=0.667 Recall=0.688\n",
      "  Macro Avg: Precision=0.670 Recall=0.654\n",
      "11/11 - 1s - 116ms/step - accuracy: 1.0000 - loss: 0.3939 - val_accuracy: 0.6591 - val_loss: 1.0721 - train_f1_score: 0.9529 - val_f1_score: 0.6506\n",
      "Epoch 560/700\n",
      "\n",
      "Epoch 560: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 560: Train F1=0.9677 - Val F1=0.6822\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 560: Per-class metrics\n",
      "  Class 0: Precision=0.812 Recall=0.481\n",
      "  Class 1: Precision=0.667 Recall=0.759\n",
      "  Class 2: Precision=0.667 Recall=0.812\n",
      "  Macro Avg: Precision=0.715 Recall=0.684\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9914 - loss: 0.4072 - val_accuracy: 0.6932 - val_loss: 1.0319 - train_f1_score: 0.9677 - val_f1_score: 0.6822\n",
      "Epoch 561/700\n",
      "\n",
      "Epoch 561: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 561: Train F1=0.9567 - Val F1=0.5935\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 561: Per-class metrics\n",
      "  Class 0: Precision=0.684 Recall=0.481\n",
      "  Class 1: Precision=0.625 Recall=0.517\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.622 Recall=0.593\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9829 - loss: 0.4111 - val_accuracy: 0.6023 - val_loss: 1.2717 - train_f1_score: 0.9567 - val_f1_score: 0.5935\n",
      "Epoch 562/700\n",
      "\n",
      "Epoch 562: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 562: Train F1=0.9418 - Val F1=0.5317\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 562: Per-class metrics\n",
      "  Class 0: Precision=0.528 Recall=0.704\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.513 Recall=0.625\n",
      "  Macro Avg: Precision=0.578 Recall=0.546\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9800 - loss: 0.4182 - val_accuracy: 0.5455 - val_loss: 1.3348 - train_f1_score: 0.9418 - val_f1_score: 0.5317\n",
      "Epoch 563/700\n",
      "\n",
      "Epoch 563: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 563: Train F1=0.6805 - Val F1=0.4997\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 563: Per-class metrics\n",
      "  Class 0: Precision=0.458 Recall=0.407\n",
      "  Class 1: Precision=0.500 Recall=0.862\n",
      "  Class 2: Precision=0.714 Recall=0.312\n",
      "  Macro Avg: Precision=0.558 Recall=0.527\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9800 - loss: 0.4292 - val_accuracy: 0.5227 - val_loss: 1.4597 - train_f1_score: 0.6805 - val_f1_score: 0.4997\n",
      "Epoch 564/700\n",
      "\n",
      "Epoch 564: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 564: Train F1=0.9021 - Val F1=0.6781\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 564: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.697 Recall=0.793\n",
      "  Class 2: Precision=0.724 Recall=0.656\n",
      "  Macro Avg: Precision=0.679 Recall=0.681\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9686 - loss: 0.4450 - val_accuracy: 0.6818 - val_loss: 1.0572 - train_f1_score: 0.9021 - val_f1_score: 0.6781\n",
      "Epoch 565/700\n",
      "\n",
      "Epoch 565: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 565: Train F1=0.7577 - Val F1=0.5593\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 565: Per-class metrics\n",
      "  Class 0: Precision=0.513 Recall=0.741\n",
      "  Class 1: Precision=0.658 Recall=0.862\n",
      "  Class 2: Precision=0.636 Recall=0.219\n",
      "  Macro Avg: Precision=0.602 Recall=0.607\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9800 - loss: 0.4248 - val_accuracy: 0.5909 - val_loss: 1.2324 - train_f1_score: 0.7577 - val_f1_score: 0.5593\n",
      "Epoch 566/700\n",
      "\n",
      "Epoch 566: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 566: Train F1=0.9914 - Val F1=0.6187\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 566: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.621 Recall=0.621\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.643 Recall=0.617\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9657 - loss: 0.4615 - val_accuracy: 0.6250 - val_loss: 1.1826 - train_f1_score: 0.9914 - val_f1_score: 0.6187\n",
      "Epoch 567/700\n",
      "\n",
      "Epoch 567: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 567: Train F1=0.9071 - Val F1=0.6253\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 567: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.595 Recall=0.759\n",
      "  Class 2: Precision=0.688 Recall=0.688\n",
      "  Macro Avg: Precision=0.638 Recall=0.630\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4322 - val_accuracy: 0.6364 - val_loss: 1.2111 - train_f1_score: 0.9071 - val_f1_score: 0.6253\n",
      "Epoch 568/700\n",
      "\n",
      "Epoch 568: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 568: Train F1=0.9461 - Val F1=0.5375\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 568: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.444\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.520 Recall=0.812\n",
      "  Macro Avg: Precision=0.579 Recall=0.545\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4170 - val_accuracy: 0.5568 - val_loss: 1.3406 - train_f1_score: 0.9461 - val_f1_score: 0.5375\n",
      "Epoch 569/700\n",
      "\n",
      "Epoch 569: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 569: Train F1=1.0000 - Val F1=0.6461\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 569: Per-class metrics\n",
      "  Class 0: Precision=0.677 Recall=0.778\n",
      "  Class 1: Precision=0.632 Recall=0.414\n",
      "  Class 2: Precision=0.658 Recall=0.781\n",
      "  Macro Avg: Precision=0.656 Recall=0.658\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9800 - loss: 0.4427 - val_accuracy: 0.6591 - val_loss: 1.1464 - train_f1_score: 1.0000 - val_f1_score: 0.6461\n",
      "Epoch 570/700\n",
      "\n",
      "Epoch 570: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 570: Train F1=0.8905 - Val F1=0.5852\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 570: Per-class metrics\n",
      "  Class 0: Precision=0.900 Recall=0.333\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.521 Recall=0.781\n",
      "  Macro Avg: Precision=0.685 Recall=0.590\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9714 - loss: 0.4441 - val_accuracy: 0.6023 - val_loss: 1.2710 - train_f1_score: 0.8905 - val_f1_score: 0.5852\n",
      "Epoch 571/700\n",
      "\n",
      "Epoch 571: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 571: Train F1=1.0000 - Val F1=0.6020\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 571: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.650 Recall=0.448\n",
      "  Class 2: Precision=0.551 Recall=0.844\n",
      "  Macro Avg: Precision=0.646 Recall=0.604\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9943 - loss: 0.4076 - val_accuracy: 0.6136 - val_loss: 1.2705 - train_f1_score: 1.0000 - val_f1_score: 0.6020\n",
      "Epoch 572/700\n",
      "\n",
      "Epoch 572: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 572: Train F1=1.0000 - Val F1=0.6147\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 572: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.591 Recall=0.812\n",
      "  Macro Avg: Precision=0.635 Recall=0.618\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4197 - val_accuracy: 0.6250 - val_loss: 1.1713 - train_f1_score: 1.0000 - val_f1_score: 0.6147\n",
      "Epoch 573/700\n",
      "\n",
      "Epoch 573: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 573: Train F1=0.9972 - Val F1=0.6417\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 573: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.609 Recall=0.483\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.651 Recall=0.644\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4148 - val_accuracy: 0.6477 - val_loss: 1.1240 - train_f1_score: 0.9972 - val_f1_score: 0.6417\n",
      "Epoch 574/700\n",
      "\n",
      "Epoch 574: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 574: Train F1=0.9601 - Val F1=0.5921\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 574: Per-class metrics\n",
      "  Class 0: Precision=0.720 Recall=0.667\n",
      "  Class 1: Precision=0.600 Recall=0.310\n",
      "  Class 2: Precision=0.562 Recall=0.844\n",
      "  Macro Avg: Precision=0.627 Recall=0.607\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9943 - loss: 0.4073 - val_accuracy: 0.6136 - val_loss: 1.2272 - train_f1_score: 0.9601 - val_f1_score: 0.5921\n",
      "Epoch 575/700\n",
      "\n",
      "Epoch 575: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 575: Train F1=0.9524 - Val F1=0.5770\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 575: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.531 Recall=0.812\n",
      "  Macro Avg: Precision=0.623 Recall=0.582\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4114 - val_accuracy: 0.5909 - val_loss: 1.3255 - train_f1_score: 0.9524 - val_f1_score: 0.5770\n",
      "Epoch 576/700\n",
      "\n",
      "Epoch 576: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 576: Train F1=0.9776 - Val F1=0.5985\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 576: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.688 Recall=0.379\n",
      "  Class 2: Precision=0.551 Recall=0.844\n",
      "  Macro Avg: Precision=0.645 Recall=0.605\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9914 - loss: 0.4081 - val_accuracy: 0.6136 - val_loss: 1.2723 - train_f1_score: 0.9776 - val_f1_score: 0.5985\n",
      "Epoch 577/700\n",
      "\n",
      "Epoch 577: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 577: Train F1=0.9861 - Val F1=0.6382\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 577: Per-class metrics\n",
      "  Class 0: Precision=0.655 Recall=0.704\n",
      "  Class 1: Precision=0.684 Recall=0.448\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.655 Recall=0.644\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4099 - val_accuracy: 0.6477 - val_loss: 1.2295 - train_f1_score: 0.9861 - val_f1_score: 0.6382\n",
      "Epoch 578/700\n",
      "\n",
      "Epoch 578: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 578: Train F1=0.9601 - Val F1=0.5989\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 578: Per-class metrics\n",
      "  Class 0: Precision=0.588 Recall=0.741\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.638 Recall=0.621\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9857 - loss: 0.4241 - val_accuracy: 0.6250 - val_loss: 1.3126 - train_f1_score: 0.9601 - val_f1_score: 0.5989\n",
      "Epoch 579/700\n",
      "\n",
      "Epoch 579: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 579: Train F1=0.9916 - Val F1=0.6382\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 579: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.600 Recall=0.844\n",
      "  Macro Avg: Precision=0.665 Recall=0.639\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9914 - loss: 0.4192 - val_accuracy: 0.6477 - val_loss: 1.1815 - train_f1_score: 0.9916 - val_f1_score: 0.6382\n",
      "Epoch 580/700\n",
      "\n",
      "Epoch 580: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 580: Train F1=0.9889 - Val F1=0.6511\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 580: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.661 Recall=0.652\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9971 - loss: 0.4013 - val_accuracy: 0.6591 - val_loss: 1.1088 - train_f1_score: 0.9889 - val_f1_score: 0.6511\n",
      "Epoch 581/700\n",
      "\n",
      "Epoch 581: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 581: Train F1=0.9715 - Val F1=0.6825\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 581: Per-class metrics\n",
      "  Class 0: Precision=0.618 Recall=0.778\n",
      "  Class 1: Precision=0.783 Recall=0.621\n",
      "  Class 2: Precision=0.677 Recall=0.656\n",
      "  Macro Avg: Precision=0.693 Recall=0.685\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9886 - loss: 0.4216 - val_accuracy: 0.6818 - val_loss: 1.0016 - train_f1_score: 0.9715 - val_f1_score: 0.6825\n",
      "Epoch 582/700\n",
      "\n",
      "Epoch 582: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 582: Train F1=0.8703 - Val F1=0.5970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 582: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.576 Recall=0.655\n",
      "  Class 2: Precision=0.618 Recall=0.656\n",
      "  Macro Avg: Precision=0.604 Recall=0.598\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4281 - val_accuracy: 0.6023 - val_loss: 1.0747 - train_f1_score: 0.8703 - val_f1_score: 0.5970\n",
      "Epoch 583/700\n",
      "\n",
      "Epoch 583: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 583: Train F1=0.8695 - Val F1=0.6098\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 583: Per-class metrics\n",
      "  Class 0: Precision=0.591 Recall=0.481\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.614 Recall=0.844\n",
      "  Macro Avg: Precision=0.629 Recall=0.614\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4171 - val_accuracy: 0.6250 - val_loss: 1.1628 - train_f1_score: 0.8695 - val_f1_score: 0.6098\n",
      "Epoch 584/700\n",
      "\n",
      "Epoch 584: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 584: Train F1=0.9361 - Val F1=0.5743\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 584: Per-class metrics\n",
      "  Class 0: Precision=0.462 Recall=0.444\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.579 Recall=0.688\n",
      "  Macro Avg: Precision=0.583 Recall=0.573\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9829 - loss: 0.4190 - val_accuracy: 0.5795 - val_loss: 1.1451 - train_f1_score: 0.9361 - val_f1_score: 0.5743\n",
      "Epoch 585/700\n",
      "\n",
      "Epoch 585: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 585: Train F1=0.8893 - Val F1=0.5900\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 585: Per-class metrics\n",
      "  Class 0: Precision=0.487 Recall=0.704\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.655 Recall=0.594\n",
      "  Macro Avg: Precision=0.614 Recall=0.593\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4180 - val_accuracy: 0.5909 - val_loss: 1.1210 - train_f1_score: 0.8893 - val_f1_score: 0.5900\n",
      "Epoch 586/700\n",
      "\n",
      "Epoch 586: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 586: Train F1=0.9194 - Val F1=0.6367\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 586: Per-class metrics\n",
      "  Class 0: Precision=0.562 Recall=0.667\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.667 Recall=0.562\n",
      "  Macro Avg: Precision=0.640 Recall=0.640\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9971 - loss: 0.4037 - val_accuracy: 0.6364 - val_loss: 1.0600 - train_f1_score: 0.9194 - val_f1_score: 0.6367\n",
      "Epoch 587/700\n",
      "\n",
      "Epoch 587: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 587: Train F1=0.9674 - Val F1=0.6817\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 587: Per-class metrics\n",
      "  Class 0: Precision=0.765 Recall=0.481\n",
      "  Class 1: Precision=0.657 Recall=0.793\n",
      "  Class 2: Precision=0.694 Recall=0.781\n",
      "  Macro Avg: Precision=0.705 Recall=0.685\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9971 - loss: 0.4078 - val_accuracy: 0.6932 - val_loss: 1.0126 - train_f1_score: 0.9674 - val_f1_score: 0.6817\n",
      "Epoch 588/700\n",
      "\n",
      "Epoch 588: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 588: Train F1=0.9794 - Val F1=0.6855\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 588: Per-class metrics\n",
      "  Class 0: Precision=0.778 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.759\n",
      "  Class 2: Precision=0.676 Recall=0.781\n",
      "  Macro Avg: Precision=0.707 Recall=0.686\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9800 - loss: 0.4202 - val_accuracy: 0.6932 - val_loss: 1.0262 - train_f1_score: 0.9794 - val_f1_score: 0.6855\n",
      "Epoch 589/700\n",
      "\n",
      "Epoch 589: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 589: Train F1=0.8803 - Val F1=0.5403\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 589: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.593\n",
      "  Class 1: Precision=0.615 Recall=0.276\n",
      "  Class 2: Precision=0.553 Recall=0.812\n",
      "  Macro Avg: Precision=0.580 Recall=0.560\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9714 - loss: 0.4408 - val_accuracy: 0.5682 - val_loss: 1.3063 - train_f1_score: 0.8803 - val_f1_score: 0.5403\n",
      "Epoch 590/700\n",
      "\n",
      "Epoch 590: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 590: Train F1=0.7182 - Val F1=0.4754\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 590: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.545 Recall=0.207\n",
      "  Class 2: Precision=0.492 Recall=0.906\n",
      "  Macro Avg: Precision=0.549 Recall=0.507\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9743 - loss: 0.4341 - val_accuracy: 0.5227 - val_loss: 1.5264 - train_f1_score: 0.7182 - val_f1_score: 0.4754\n",
      "Epoch 591/700\n",
      "\n",
      "Epoch 591: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 591: Train F1=0.9970 - Val F1=0.5931\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 591: Per-class metrics\n",
      "  Class 0: Precision=0.565 Recall=0.481\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.600 Recall=0.750\n",
      "  Macro Avg: Precision=0.602 Recall=0.594\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9857 - loss: 0.4370 - val_accuracy: 0.6023 - val_loss: 1.1478 - train_f1_score: 0.9970 - val_f1_score: 0.5931\n",
      "Epoch 592/700\n",
      "\n",
      "Epoch 592: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Epoch 592: Train F1=0.9971 - Val F1=0.5620\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 592: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.370\n",
      "  Class 1: Precision=0.593 Recall=0.552\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.591 Recall=0.568\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9829 - loss: 0.4232 - val_accuracy: 0.5795 - val_loss: 1.2486 - train_f1_score: 0.9971 - val_f1_score: 0.5620\n",
      "Epoch 593/700\n",
      "\n",
      "Epoch 593: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 593: Train F1=0.9796 - Val F1=0.6722\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 593: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.692 Recall=0.844\n",
      "  Macro Avg: Precision=0.679 Recall=0.676\n",
      "11/11 - 1s - 97ms/step - accuracy: 0.9971 - loss: 0.4158 - val_accuracy: 0.6818 - val_loss: 1.1613 - train_f1_score: 0.9796 - val_f1_score: 0.6722\n",
      "Epoch 594/700\n",
      "\n",
      "Epoch 594: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 594: Train F1=0.9942 - Val F1=0.6003\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 594: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.571 Recall=0.414\n",
      "  Class 2: Precision=0.605 Recall=0.812\n",
      "  Macro Avg: Precision=0.614 Recall=0.606\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9886 - loss: 0.4115 - val_accuracy: 0.6136 - val_loss: 1.2851 - train_f1_score: 0.9942 - val_f1_score: 0.6003\n",
      "Epoch 595/700\n",
      "\n",
      "Epoch 595: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 595: Train F1=0.9852 - Val F1=0.6063\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 595: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.585 Recall=0.750\n",
      "  Macro Avg: Precision=0.619 Recall=0.609\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4168 - val_accuracy: 0.6136 - val_loss: 1.2885 - train_f1_score: 0.9852 - val_f1_score: 0.6063\n",
      "Epoch 596/700\n",
      "\n",
      "Epoch 596: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 596: Train F1=1.0000 - Val F1=0.6680\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 596: Per-class metrics\n",
      "  Class 0: Precision=0.760 Recall=0.704\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.684 Recall=0.667\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9971 - loss: 0.4081 - val_accuracy: 0.6705 - val_loss: 1.1804 - train_f1_score: 1.0000 - val_f1_score: 0.6680\n",
      "Epoch 597/700\n",
      "\n",
      "Epoch 597: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 597: Train F1=1.0000 - Val F1=0.6360\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 597: Per-class metrics\n",
      "  Class 0: Precision=0.762 Recall=0.593\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.658 Recall=0.631\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9914 - loss: 0.4087 - val_accuracy: 0.6364 - val_loss: 1.2051 - train_f1_score: 1.0000 - val_f1_score: 0.6360\n",
      "Epoch 598/700\n",
      "\n",
      "Epoch 598: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 598: Train F1=1.0000 - Val F1=0.6412\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 598: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.659 Recall=0.640\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9971 - loss: 0.3986 - val_accuracy: 0.6477 - val_loss: 1.1083 - train_f1_score: 1.0000 - val_f1_score: 0.6412\n",
      "Epoch 599/700\n",
      "\n",
      "Epoch 599: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 599: Train F1=0.9911 - Val F1=0.6180\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 599: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.605 Recall=0.719\n",
      "  Macro Avg: Precision=0.626 Recall=0.618\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9971 - loss: 0.4071 - val_accuracy: 0.6250 - val_loss: 1.1526 - train_f1_score: 0.9911 - val_f1_score: 0.6180\n",
      "Epoch 600/700\n",
      "\n",
      "Epoch 600: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 600: Train F1=0.9551 - Val F1=0.5883\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 600: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.611 Recall=0.592\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9943 - loss: 0.4042 - val_accuracy: 0.6023 - val_loss: 1.1810 - train_f1_score: 0.9551 - val_f1_score: 0.5883\n",
      "Epoch 601/700\n",
      "\n",
      "Epoch 601: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 601: Train F1=1.0000 - Val F1=0.5952\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 601: Per-class metrics\n",
      "  Class 0: Precision=0.591 Recall=0.481\n",
      "  Class 1: Precision=0.630 Recall=0.586\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.603 Recall=0.595\n",
      "11/11 - 1s - 92ms/step - accuracy: 1.0000 - loss: 0.4006 - val_accuracy: 0.6023 - val_loss: 1.1893 - train_f1_score: 1.0000 - val_f1_score: 0.5952\n",
      "Epoch 602/700\n",
      "\n",
      "Epoch 602: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 602: Train F1=1.0000 - Val F1=0.6523\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 602: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.633 Recall=0.655\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.670 Recall=0.652\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9943 - loss: 0.4023 - val_accuracy: 0.6591 - val_loss: 1.1629 - train_f1_score: 1.0000 - val_f1_score: 0.6523\n",
      "Epoch 603/700\n",
      "\n",
      "Epoch 603: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 603: Train F1=0.9970 - Val F1=0.6402\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 603: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.519\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.653 Recall=0.640\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9886 - loss: 0.4120 - val_accuracy: 0.6477 - val_loss: 1.1256 - train_f1_score: 0.9970 - val_f1_score: 0.6402\n",
      "Epoch 604/700\n",
      "\n",
      "Epoch 604: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 604: Train F1=0.9854 - Val F1=0.6511\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 604: Per-class metrics\n",
      "  Class 0: Precision=0.615 Recall=0.593\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.664 Recall=0.652\n",
      "11/11 - 1s - 116ms/step - accuracy: 1.0000 - loss: 0.3961 - val_accuracy: 0.6591 - val_loss: 1.1271 - train_f1_score: 0.9854 - val_f1_score: 0.6511\n",
      "Epoch 605/700\n",
      "\n",
      "Epoch 605: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 605: Train F1=0.9882 - Val F1=0.6057\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 605: Per-class metrics\n",
      "  Class 0: Precision=0.552 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.483\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.617 Recall=0.608\n",
      "11/11 - 1s - 96ms/step - accuracy: 1.0000 - loss: 0.3915 - val_accuracy: 0.6136 - val_loss: 1.1677 - train_f1_score: 0.9882 - val_f1_score: 0.6057\n",
      "Epoch 606/700\n",
      "\n",
      "Epoch 606: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 606: Train F1=1.0000 - Val F1=0.6414\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 606: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.652 Recall=0.641\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.3966 - val_accuracy: 0.6477 - val_loss: 1.1224 - train_f1_score: 1.0000 - val_f1_score: 0.6414\n",
      "Epoch 607/700\n",
      "\n",
      "Epoch 607: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 607: Train F1=1.0000 - Val F1=0.6451\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 607: Per-class metrics\n",
      "  Class 0: Precision=0.727 Recall=0.593\n",
      "  Class 1: Precision=0.607 Recall=0.586\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.655 Recall=0.643\n",
      "11/11 - 1s - 93ms/step - accuracy: 1.0000 - loss: 0.3928 - val_accuracy: 0.6477 - val_loss: 1.1498 - train_f1_score: 1.0000 - val_f1_score: 0.6451\n",
      "Epoch 608/700\n",
      "\n",
      "Epoch 608: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 608: Train F1=1.0000 - Val F1=0.6807\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 608: Per-class metrics\n",
      "  Class 0: Precision=0.800 Recall=0.593\n",
      "  Class 1: Precision=0.679 Recall=0.655\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.701 Recall=0.676\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9943 - loss: 0.4007 - val_accuracy: 0.6818 - val_loss: 1.1557 - train_f1_score: 1.0000 - val_f1_score: 0.6807\n",
      "Epoch 609/700\n",
      "\n",
      "Epoch 609: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 609: Train F1=1.0000 - Val F1=0.6536\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 609: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.605 Recall=0.812\n",
      "  Macro Avg: Precision=0.676 Recall=0.652\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9971 - loss: 0.3939 - val_accuracy: 0.6591 - val_loss: 1.1254 - train_f1_score: 1.0000 - val_f1_score: 0.6536\n",
      "Epoch 610/700\n",
      "\n",
      "Epoch 610: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 610: Train F1=0.9504 - Val F1=0.6135\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 610: Per-class metrics\n",
      "  Class 0: Precision=0.543 Recall=0.704\n",
      "  Class 1: Precision=0.706 Recall=0.414\n",
      "  Class 2: Precision=0.667 Recall=0.750\n",
      "  Macro Avg: Precision=0.638 Recall=0.622\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9971 - loss: 0.3953 - val_accuracy: 0.6250 - val_loss: 1.2280 - train_f1_score: 0.9504 - val_f1_score: 0.6135\n",
      "Epoch 611/700\n",
      "\n",
      "Epoch 611: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 611: Train F1=0.9682 - Val F1=0.6730\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 611: Per-class metrics\n",
      "  Class 0: Precision=0.654 Recall=0.630\n",
      "  Class 1: Precision=0.727 Recall=0.552\n",
      "  Class 2: Precision=0.675 Recall=0.844\n",
      "  Macro Avg: Precision=0.685 Recall=0.675\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.3976 - val_accuracy: 0.6818 - val_loss: 1.1018 - train_f1_score: 0.9682 - val_f1_score: 0.6730\n",
      "Epoch 612/700\n",
      "\n",
      "Epoch 612: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 612: Train F1=0.9594 - Val F1=0.6043\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 612: Per-class metrics\n",
      "  Class 0: Precision=0.583 Recall=0.519\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.620 Recall=0.606\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.4004 - val_accuracy: 0.6136 - val_loss: 1.0885 - train_f1_score: 0.9594 - val_f1_score: 0.6043\n",
      "Epoch 613/700\n",
      "\n",
      "Epoch 613: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 613: Train F1=0.8839 - Val F1=0.6228\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 613: Per-class metrics\n",
      "  Class 0: Precision=0.516 Recall=0.593\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.710 Recall=0.688\n",
      "  Macro Avg: Precision=0.627 Recall=0.622\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9829 - loss: 0.4117 - val_accuracy: 0.6250 - val_loss: 1.1642 - train_f1_score: 0.8839 - val_f1_score: 0.6228\n",
      "Epoch 614/700\n",
      "\n",
      "Epoch 614: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 614: Train F1=0.9624 - Val F1=0.6572\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 614: Per-class metrics\n",
      "  Class 0: Precision=0.548 Recall=0.630\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.719 Recall=0.719\n",
      "  Macro Avg: Precision=0.662 Recall=0.656\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4034 - val_accuracy: 0.6591 - val_loss: 1.0625 - train_f1_score: 0.9624 - val_f1_score: 0.6572\n",
      "Epoch 615/700\n",
      "\n",
      "Epoch 615: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 615: Train F1=0.9910 - Val F1=0.6981\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 615: Per-class metrics\n",
      "  Class 0: Precision=0.690 Recall=0.741\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.722 Recall=0.812\n",
      "  Macro Avg: Precision=0.703 Recall=0.702\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9943 - loss: 0.4044 - val_accuracy: 0.7045 - val_loss: 1.0852 - train_f1_score: 0.9910 - val_f1_score: 0.6981\n",
      "Epoch 616/700\n",
      "\n",
      "Epoch 616: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 616: Train F1=0.9798 - Val F1=0.6525\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 616: Per-class metrics\n",
      "  Class 0: Precision=0.593 Recall=0.593\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.694 Recall=0.781\n",
      "  Macro Avg: Precision=0.656 Recall=0.653\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9943 - loss: 0.4014 - val_accuracy: 0.6591 - val_loss: 1.1502 - train_f1_score: 0.9798 - val_f1_score: 0.6525\n",
      "Epoch 617/700\n",
      "\n",
      "Epoch 617: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 617: Train F1=0.9944 - Val F1=0.6633\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 617: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.667 Recall=0.812\n",
      "  Macro Avg: Precision=0.671 Recall=0.665\n",
      "11/11 - 1s - 115ms/step - accuracy: 1.0000 - loss: 0.3943 - val_accuracy: 0.6705 - val_loss: 1.1785 - train_f1_score: 0.9944 - val_f1_score: 0.6633\n",
      "Epoch 618/700\n",
      "\n",
      "Epoch 618: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 618: Train F1=1.0000 - Val F1=0.6383\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 618: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.647 Recall=0.640\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.3948 - val_accuracy: 0.6477 - val_loss: 1.1711 - train_f1_score: 1.0000 - val_f1_score: 0.6383\n",
      "Epoch 619/700\n",
      "\n",
      "Epoch 619: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 619: Train F1=0.9971 - Val F1=0.6510\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 619: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.650 Recall=0.812\n",
      "  Macro Avg: Precision=0.662 Recall=0.652\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9971 - loss: 0.3902 - val_accuracy: 0.6591 - val_loss: 1.1748 - train_f1_score: 0.9971 - val_f1_score: 0.6510\n",
      "Epoch 620/700\n",
      "\n",
      "Epoch 620: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 620: Train F1=0.9797 - Val F1=0.5968\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 620: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.593\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.639 Recall=0.719\n",
      "  Macro Avg: Precision=0.613 Recall=0.598\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9971 - loss: 0.3941 - val_accuracy: 0.6023 - val_loss: 1.1611 - train_f1_score: 0.9797 - val_f1_score: 0.5968\n",
      "Epoch 621/700\n",
      "\n",
      "Epoch 621: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 621: Train F1=0.9858 - Val F1=0.6608\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 621: Per-class metrics\n",
      "  Class 0: Precision=0.655 Recall=0.704\n",
      "  Class 1: Precision=0.700 Recall=0.483\n",
      "  Class 2: Precision=0.667 Recall=0.812\n",
      "  Macro Avg: Precision=0.674 Recall=0.666\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9971 - loss: 0.3961 - val_accuracy: 0.6705 - val_loss: 1.1303 - train_f1_score: 0.9858 - val_f1_score: 0.6608\n",
      "Epoch 622/700\n",
      "\n",
      "Epoch 622: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 622: Train F1=0.9945 - Val F1=0.6540\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 622: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.666 Recall=0.655\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9971 - loss: 0.3939 - val_accuracy: 0.6591 - val_loss: 1.1593 - train_f1_score: 0.9945 - val_f1_score: 0.6540\n",
      "Epoch 623/700\n",
      "\n",
      "Epoch 623: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 623: Train F1=1.0000 - Val F1=0.6540\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 623: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.666 Recall=0.655\n",
      "11/11 - 1s - 113ms/step - accuracy: 1.0000 - loss: 0.3856 - val_accuracy: 0.6591 - val_loss: 1.1425 - train_f1_score: 1.0000 - val_f1_score: 0.6540\n",
      "Epoch 624/700\n",
      "\n",
      "Epoch 624: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 624: Train F1=1.0000 - Val F1=0.7019\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 624: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.720 Recall=0.621\n",
      "  Class 2: Precision=0.694 Recall=0.781\n",
      "  Macro Avg: Precision=0.706 Recall=0.702\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9971 - loss: 0.3919 - val_accuracy: 0.7045 - val_loss: 1.0289 - train_f1_score: 1.0000 - val_f1_score: 0.7019\n",
      "Epoch 625/700\n",
      "\n",
      "Epoch 625: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 625: Train F1=1.0000 - Val F1=0.7139\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 625: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.741\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.694 Recall=0.781\n",
      "  Macro Avg: Precision=0.720 Recall=0.714\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.3934 - val_accuracy: 0.7159 - val_loss: 1.0287 - train_f1_score: 1.0000 - val_f1_score: 0.7139\n",
      "Epoch 626/700\n",
      "\n",
      "Epoch 626: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626: Train F1=0.9972 - Val F1=0.7251\n",
      "\n",
      "Saved best model at epoch 626 with val_f1=0.7251\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 626: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.778\n",
      "  Class 1: Precision=0.783 Recall=0.621\n",
      "  Class 2: Precision=0.714 Recall=0.781\n",
      "  Macro Avg: Precision=0.732 Recall=0.727\n",
      "11/11 - 1s - 120ms/step - accuracy: 1.0000 - loss: 0.3841 - val_accuracy: 0.7273 - val_loss: 1.0369 - train_f1_score: 0.9972 - val_f1_score: 0.7251\n",
      "Epoch 627/700\n",
      "\n",
      "Epoch 627: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 627: Train F1=1.0000 - Val F1=0.6683\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 627: Per-class metrics\n",
      "  Class 0: Precision=0.704 Recall=0.704\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.677 Recall=0.668\n",
      "11/11 - 1s - 107ms/step - accuracy: 0.9943 - loss: 0.3945 - val_accuracy: 0.6705 - val_loss: 1.1485 - train_f1_score: 1.0000 - val_f1_score: 0.6683\n",
      "Epoch 628/700\n",
      "\n",
      "Epoch 628: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 628: Train F1=1.0000 - Val F1=0.6446\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 628: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.654 Recall=0.644\n",
      "11/11 - 1s - 92ms/step - accuracy: 1.0000 - loss: 0.3874 - val_accuracy: 0.6477 - val_loss: 1.1595 - train_f1_score: 1.0000 - val_f1_score: 0.6446\n",
      "Epoch 629/700\n",
      "\n",
      "Epoch 629: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 629: Train F1=0.9914 - Val F1=0.6562\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 629: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.664 Recall=0.656\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.3904 - val_accuracy: 0.6591 - val_loss: 1.1230 - train_f1_score: 0.9914 - val_f1_score: 0.6562\n",
      "Epoch 630/700\n",
      "\n",
      "Epoch 630: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 630: Train F1=0.9827 - Val F1=0.6776\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 630: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.750 Recall=0.621\n",
      "  Class 2: Precision=0.714 Recall=0.781\n",
      "  Macro Avg: Precision=0.683 Recall=0.677\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.3950 - val_accuracy: 0.6818 - val_loss: 1.0249 - train_f1_score: 0.9827 - val_f1_score: 0.6776\n",
      "Epoch 631/700\n",
      "\n",
      "Epoch 631: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 631: Train F1=0.9511 - Val F1=0.6526\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 631: Per-class metrics\n",
      "  Class 0: Precision=0.586 Recall=0.630\n",
      "  Class 1: Precision=0.833 Recall=0.517\n",
      "  Class 2: Precision=0.634 Recall=0.812\n",
      "  Macro Avg: Precision=0.685 Recall=0.653\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9971 - loss: 0.3901 - val_accuracy: 0.6591 - val_loss: 1.0700 - train_f1_score: 0.9511 - val_f1_score: 0.6526\n",
      "Epoch 632/700\n",
      "\n",
      "Epoch 632: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 632: Train F1=0.9569 - Val F1=0.6829\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 632: Per-class metrics\n",
      "  Class 0: Precision=0.550 Recall=0.815\n",
      "  Class 1: Precision=0.810 Recall=0.586\n",
      "  Class 2: Precision=0.778 Recall=0.656\n",
      "  Macro Avg: Precision=0.712 Recall=0.686\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9886 - loss: 0.4035 - val_accuracy: 0.6818 - val_loss: 1.0736 - train_f1_score: 0.9569 - val_f1_score: 0.6829\n",
      "Epoch 633/700\n",
      "\n",
      "Epoch 633: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 633: Train F1=1.0000 - Val F1=0.6782\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 633: Per-class metrics\n",
      "  Class 0: Precision=0.690 Recall=0.741\n",
      "  Class 1: Precision=0.667 Recall=0.552\n",
      "  Class 2: Precision=0.686 Recall=0.750\n",
      "  Macro Avg: Precision=0.681 Recall=0.681\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9857 - loss: 0.4030 - val_accuracy: 0.6818 - val_loss: 1.1203 - train_f1_score: 1.0000 - val_f1_score: 0.6782\n",
      "Epoch 634/700\n",
      "\n",
      "Epoch 634: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 634: Train F1=0.9446 - Val F1=0.5594\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 634: Per-class metrics\n",
      "  Class 0: Precision=0.875 Recall=0.259\n",
      "  Class 1: Precision=0.667 Recall=0.621\n",
      "  Class 2: Precision=0.509 Recall=0.844\n",
      "  Macro Avg: Precision=0.684 Recall=0.575\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9714 - loss: 0.4328 - val_accuracy: 0.5909 - val_loss: 1.2821 - train_f1_score: 0.9446 - val_f1_score: 0.5594\n",
      "Epoch 635/700\n",
      "\n",
      "Epoch 635: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 635: Train F1=0.8224 - Val F1=0.6353\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 635: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.593\n",
      "  Class 1: Precision=0.667 Recall=0.690\n",
      "  Class 2: Precision=0.714 Recall=0.625\n",
      "  Macro Avg: Precision=0.638 Recall=0.636\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9743 - loss: 0.4396 - val_accuracy: 0.6364 - val_loss: 1.1122 - train_f1_score: 0.8224 - val_f1_score: 0.6353\n",
      "Epoch 636/700\n",
      "\n",
      "Epoch 636: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 636: Train F1=0.8890 - Val F1=0.5812\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 636: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.444\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.532 Recall=0.781\n",
      "  Macro Avg: Precision=0.615 Recall=0.581\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9657 - loss: 0.4357 - val_accuracy: 0.5909 - val_loss: 1.1665 - train_f1_score: 0.8890 - val_f1_score: 0.5812\n",
      "Epoch 637/700\n",
      "\n",
      "Epoch 637: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 637: Train F1=0.7825 - Val F1=0.4880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 637: Per-class metrics\n",
      "  Class 0: Precision=0.562 Recall=0.333\n",
      "  Class 1: Precision=0.519 Recall=0.483\n",
      "  Class 2: Precision=0.467 Recall=0.656\n",
      "  Macro Avg: Precision=0.516 Recall=0.491\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9800 - loss: 0.4312 - val_accuracy: 0.5000 - val_loss: 1.2759 - train_f1_score: 0.7825 - val_f1_score: 0.4880\n",
      "Epoch 638/700\n",
      "\n",
      "Epoch 638: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 638: Train F1=0.6154 - Val F1=0.4656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 638: Per-class metrics\n",
      "  Class 0: Precision=0.362 Recall=0.630\n",
      "  Class 1: Precision=0.667 Recall=0.345\n",
      "  Class 2: Precision=0.538 Recall=0.438\n",
      "  Macro Avg: Precision=0.522 Recall=0.471\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9743 - loss: 0.4335 - val_accuracy: 0.4659 - val_loss: 1.3139 - train_f1_score: 0.6154 - val_f1_score: 0.4656\n",
      "Epoch 639/700\n",
      "\n",
      "Epoch 639: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 639: Train F1=0.6073 - Val F1=0.4348\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 639: Per-class metrics\n",
      "  Class 0: Precision=0.432 Recall=0.593\n",
      "  Class 1: Precision=0.500 Recall=0.172\n",
      "  Class 2: Precision=0.488 Recall=0.625\n",
      "  Macro Avg: Precision=0.473 Recall=0.463\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4220 - val_accuracy: 0.4659 - val_loss: 1.4756 - train_f1_score: 0.6073 - val_f1_score: 0.4348\n",
      "Epoch 640/700\n",
      "\n",
      "Epoch 640: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 640: Train F1=0.6458 - Val F1=0.4563\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 640: Per-class metrics\n",
      "  Class 0: Precision=0.500 Recall=0.481\n",
      "  Class 1: Precision=0.394 Recall=0.448\n",
      "  Class 2: Precision=0.483 Recall=0.438\n",
      "  Macro Avg: Precision=0.459 Recall=0.456\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9686 - loss: 0.4582 - val_accuracy: 0.4545 - val_loss: 1.5874 - train_f1_score: 0.6458 - val_f1_score: 0.4563\n",
      "Epoch 641/700\n",
      "\n",
      "Epoch 641: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 641: Train F1=0.8970 - Val F1=0.5340\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 641: Per-class metrics\n",
      "  Class 0: Precision=0.542 Recall=0.481\n",
      "  Class 1: Precision=0.480 Recall=0.414\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.537 Recall=0.538\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4166 - val_accuracy: 0.5455 - val_loss: 1.4345 - train_f1_score: 0.8970 - val_f1_score: 0.5340\n",
      "Epoch 642/700\n",
      "\n",
      "Epoch 642: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 642: Train F1=0.8315 - Val F1=0.5149\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 642: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.444\n",
      "  Class 1: Precision=0.435 Recall=0.345\n",
      "  Class 2: Precision=0.556 Recall=0.781\n",
      "  Macro Avg: Precision=0.530 Recall=0.524\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4290 - val_accuracy: 0.5341 - val_loss: 1.4970 - train_f1_score: 0.8315 - val_f1_score: 0.5149\n",
      "Epoch 643/700\n",
      "\n",
      "Epoch 643: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 643: Train F1=0.9767 - Val F1=0.5406\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 643: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.296\n",
      "  Class 1: Precision=0.571 Recall=0.552\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.593 Recall=0.554\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4218 - val_accuracy: 0.5682 - val_loss: 1.2662 - train_f1_score: 0.9767 - val_f1_score: 0.5406\n",
      "Epoch 644/700\n",
      "\n",
      "Epoch 644: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 644: Train F1=1.0000 - Val F1=0.6307\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 644: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.556\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.637 Recall=0.631\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4125 - val_accuracy: 0.6364 - val_loss: 1.2001 - train_f1_score: 1.0000 - val_f1_score: 0.6307\n",
      "Epoch 645/700\n",
      "\n",
      "Epoch 645: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 645: Train F1=0.9454 - Val F1=0.4534\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 645: Per-class metrics\n",
      "  Class 0: Precision=0.556 Recall=0.370\n",
      "  Class 1: Precision=0.467 Recall=0.241\n",
      "  Class 2: Precision=0.473 Recall=0.812\n",
      "  Macro Avg: Precision=0.498 Recall=0.475\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9771 - loss: 0.4304 - val_accuracy: 0.4886 - val_loss: 1.4854 - train_f1_score: 0.9454 - val_f1_score: 0.4534\n",
      "Epoch 646/700\n",
      "\n",
      "Epoch 646: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 646: Train F1=0.9434 - Val F1=0.6006\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 646: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.552 Recall=0.552\n",
      "  Class 2: Precision=0.595 Recall=0.688\n",
      "  Macro Avg: Precision=0.609 Recall=0.598\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4097 - val_accuracy: 0.6023 - val_loss: 1.2676 - train_f1_score: 0.9434 - val_f1_score: 0.6006\n",
      "Epoch 647/700\n",
      "\n",
      "Epoch 647: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 647: Train F1=0.8338 - Val F1=0.4737\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 647: Per-class metrics\n",
      "  Class 0: Precision=0.632 Recall=0.444\n",
      "  Class 1: Precision=0.438 Recall=0.241\n",
      "  Class 2: Precision=0.472 Recall=0.781\n",
      "  Macro Avg: Precision=0.514 Recall=0.489\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9886 - loss: 0.4074 - val_accuracy: 0.5000 - val_loss: 1.5720 - train_f1_score: 0.8338 - val_f1_score: 0.4737\n",
      "Epoch 648/700\n",
      "\n",
      "Epoch 648: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 648: Train F1=1.0000 - Val F1=0.6347\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 648: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.571 Recall=0.750\n",
      "  Macro Avg: Precision=0.654 Recall=0.631\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9771 - loss: 0.4300 - val_accuracy: 0.6364 - val_loss: 1.1843 - train_f1_score: 1.0000 - val_f1_score: 0.6347\n",
      "Epoch 649/700\n",
      "\n",
      "Epoch 649: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 649: Train F1=0.9316 - Val F1=0.5819\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 649: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.522 Recall=0.750\n",
      "  Macro Avg: Precision=0.614 Recall=0.581\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9886 - loss: 0.4128 - val_accuracy: 0.5909 - val_loss: 1.2752 - train_f1_score: 0.9316 - val_f1_score: 0.5819\n",
      "Epoch 650/700\n",
      "\n",
      "Epoch 650: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 650: Train F1=0.9831 - Val F1=0.6196\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 650: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.542 Recall=0.812\n",
      "  Macro Avg: Precision=0.664 Recall=0.616\n",
      "11/11 - 1s - 111ms/step - accuracy: 0.9914 - loss: 0.4131 - val_accuracy: 0.6250 - val_loss: 1.0541 - train_f1_score: 0.9831 - val_f1_score: 0.6196\n",
      "Epoch 651/700\n",
      "\n",
      "Epoch 651: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 651: Train F1=0.9477 - Val F1=0.5661\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 651: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.296\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.532 Recall=0.781\n",
      "  Macro Avg: Precision=0.618 Recall=0.578\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9886 - loss: 0.4152 - val_accuracy: 0.5909 - val_loss: 1.0955 - train_f1_score: 0.9477 - val_f1_score: 0.5661\n",
      "Epoch 652/700\n",
      "\n",
      "Epoch 652: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 652: Train F1=0.9770 - Val F1=0.6082\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 652: Per-class metrics\n",
      "  Class 0: Precision=0.769 Recall=0.370\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.661 Recall=0.614\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.4055 - val_accuracy: 0.6250 - val_loss: 1.1426 - train_f1_score: 0.9770 - val_f1_score: 0.6082\n",
      "Epoch 653/700\n",
      "\n",
      "Epoch 653: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 653: Train F1=0.9856 - Val F1=0.6197\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 653: Per-class metrics\n",
      "  Class 0: Precision=0.737 Recall=0.519\n",
      "  Class 1: Precision=0.640 Recall=0.552\n",
      "  Class 2: Precision=0.568 Recall=0.781\n",
      "  Macro Avg: Precision=0.648 Recall=0.617\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4027 - val_accuracy: 0.6250 - val_loss: 1.2704 - train_f1_score: 0.9856 - val_f1_score: 0.6197\n",
      "Epoch 654/700\n",
      "\n",
      "Epoch 654: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 654: Train F1=1.0000 - Val F1=0.6307\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 654: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.556\n",
      "  Class 1: Precision=0.654 Recall=0.586\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.637 Recall=0.631\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9914 - loss: 0.4018 - val_accuracy: 0.6364 - val_loss: 1.1957 - train_f1_score: 1.0000 - val_f1_score: 0.6307\n",
      "Epoch 655/700\n",
      "\n",
      "Epoch 655: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 655: Train F1=1.0000 - Val F1=0.6545\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 655: Per-class metrics\n",
      "  Class 0: Precision=0.600 Recall=0.667\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.686 Recall=0.750\n",
      "  Macro Avg: Precision=0.660 Recall=0.656\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9943 - loss: 0.3971 - val_accuracy: 0.6591 - val_loss: 1.2198 - train_f1_score: 1.0000 - val_f1_score: 0.6545\n",
      "Epoch 656/700\n",
      "\n",
      "Epoch 656: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 656: Train F1=0.9941 - Val F1=0.6202\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 656: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.741\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.638 Recall=0.634\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9943 - loss: 0.3948 - val_accuracy: 0.6364 - val_loss: 1.2312 - train_f1_score: 0.9941 - val_f1_score: 0.6202\n",
      "Epoch 657/700\n",
      "\n",
      "Epoch 657: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 657: Train F1=0.9971 - Val F1=0.6820\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 657: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.667\n",
      "  Class 1: Precision=0.692 Recall=0.621\n",
      "  Class 2: Precision=0.632 Recall=0.750\n",
      "  Macro Avg: Precision=0.691 Recall=0.679\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9971 - loss: 0.3950 - val_accuracy: 0.6818 - val_loss: 1.1784 - train_f1_score: 0.9971 - val_f1_score: 0.6820\n",
      "Epoch 658/700\n",
      "\n",
      "Epoch 658: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 658: Train F1=0.9971 - Val F1=0.5945\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 658: Per-class metrics\n",
      "  Class 0: Precision=0.680 Recall=0.630\n",
      "  Class 1: Precision=0.600 Recall=0.414\n",
      "  Class 2: Precision=0.558 Recall=0.750\n",
      "  Macro Avg: Precision=0.613 Recall=0.598\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9971 - loss: 0.4012 - val_accuracy: 0.6023 - val_loss: 1.3013 - train_f1_score: 0.9971 - val_f1_score: 0.5945\n",
      "Epoch 659/700\n",
      "\n",
      "Epoch 659: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 659: Train F1=1.0000 - Val F1=0.6540\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 659: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.666 Recall=0.655\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4028 - val_accuracy: 0.6591 - val_loss: 1.2114 - train_f1_score: 1.0000 - val_f1_score: 0.6540\n",
      "Epoch 660/700\n",
      "\n",
      "Epoch 660: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 660: Train F1=0.9944 - Val F1=0.6434\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 660: Per-class metrics\n",
      "  Class 0: Precision=0.762 Recall=0.593\n",
      "  Class 1: Precision=0.682 Recall=0.517\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.674 Recall=0.641\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9914 - loss: 0.4170 - val_accuracy: 0.6477 - val_loss: 1.1835 - train_f1_score: 0.9944 - val_f1_score: 0.6434\n",
      "Epoch 661/700\n",
      "\n",
      "Epoch 661: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 661: Train F1=0.9735 - Val F1=0.6292\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 661: Per-class metrics\n",
      "  Class 0: Precision=0.682 Recall=0.556\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.658 Recall=0.628\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9943 - loss: 0.4012 - val_accuracy: 0.6364 - val_loss: 1.1340 - train_f1_score: 0.9735 - val_f1_score: 0.6292\n",
      "Epoch 662/700\n",
      "\n",
      "Epoch 662: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 662: Train F1=0.9570 - Val F1=0.6634\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 662: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.667 Recall=0.750\n",
      "  Macro Avg: Precision=0.674 Recall=0.664\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9857 - loss: 0.4058 - val_accuracy: 0.6705 - val_loss: 1.0745 - train_f1_score: 0.9570 - val_f1_score: 0.6634\n",
      "Epoch 663/700\n",
      "\n",
      "Epoch 663: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 663: Train F1=0.9316 - Val F1=0.6012\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 663: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.333\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.658 Recall=0.612\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.3991 - val_accuracy: 0.6250 - val_loss: 1.1795 - train_f1_score: 0.9316 - val_f1_score: 0.6012\n",
      "Epoch 664/700\n",
      "\n",
      "Epoch 664: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 664: Train F1=0.9677 - Val F1=0.6729\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 664: Per-class metrics\n",
      "  Class 0: Precision=0.765 Recall=0.481\n",
      "  Class 1: Precision=0.710 Recall=0.759\n",
      "  Class 2: Precision=0.625 Recall=0.781\n",
      "  Macro Avg: Precision=0.700 Recall=0.674\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4051 - val_accuracy: 0.6818 - val_loss: 1.0853 - train_f1_score: 0.9677 - val_f1_score: 0.6729\n",
      "Epoch 665/700\n",
      "\n",
      "Epoch 665: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 665: Train F1=0.9676 - Val F1=0.6888\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 665: Per-class metrics\n",
      "  Class 0: Precision=0.696 Recall=0.593\n",
      "  Class 1: Precision=0.714 Recall=0.690\n",
      "  Class 2: Precision=0.676 Recall=0.781\n",
      "  Macro Avg: Precision=0.695 Recall=0.688\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9886 - loss: 0.4031 - val_accuracy: 0.6932 - val_loss: 1.0082 - train_f1_score: 0.9676 - val_f1_score: 0.6888\n",
      "Epoch 666/700\n",
      "\n",
      "Epoch 666: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 666: Train F1=0.8954 - Val F1=0.6097\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 666: Per-class metrics\n",
      "  Class 0: Precision=0.611 Recall=0.407\n",
      "  Class 1: Precision=0.655 Recall=0.655\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.625 Recall=0.615\n",
      "11/11 - 1s - 113ms/step - accuracy: 1.0000 - loss: 0.3897 - val_accuracy: 0.6250 - val_loss: 1.0747 - train_f1_score: 0.8954 - val_f1_score: 0.6097\n",
      "Epoch 667/700\n",
      "\n",
      "Epoch 667: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 667: Train F1=0.7809 - Val F1=0.5072\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 667: Per-class metrics\n",
      "  Class 0: Precision=0.429 Recall=0.556\n",
      "  Class 1: Precision=0.550 Recall=0.759\n",
      "  Class 2: Precision=0.692 Recall=0.281\n",
      "  Macro Avg: Precision=0.557 Recall=0.532\n",
      "11/11 - 1s - 91ms/step - accuracy: 0.9857 - loss: 0.4189 - val_accuracy: 0.5227 - val_loss: 1.2808 - train_f1_score: 0.7809 - val_f1_score: 0.5072\n",
      "Epoch 668/700\n",
      "\n",
      "Epoch 668: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 668: Train F1=0.8546 - Val F1=0.5999\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 668: Per-class metrics\n",
      "  Class 0: Precision=0.786 Recall=0.407\n",
      "  Class 1: Precision=0.607 Recall=0.586\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.653 Recall=0.602\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9714 - loss: 0.4511 - val_accuracy: 0.6136 - val_loss: 1.1023 - train_f1_score: 0.8546 - val_f1_score: 0.5999\n",
      "Epoch 669/700\n",
      "\n",
      "Epoch 669: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 669: Train F1=0.9489 - Val F1=0.6219\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 669: Per-class metrics\n",
      "  Class 0: Precision=0.625 Recall=0.556\n",
      "  Class 1: Precision=0.680 Recall=0.586\n",
      "  Class 2: Precision=0.590 Recall=0.719\n",
      "  Macro Avg: Precision=0.632 Recall=0.620\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4082 - val_accuracy: 0.6250 - val_loss: 1.1840 - train_f1_score: 0.9489 - val_f1_score: 0.6219\n",
      "Epoch 670/700\n",
      "\n",
      "Epoch 670: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 670: Train F1=0.8349 - Val F1=0.5144\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 670: Per-class metrics\n",
      "  Class 0: Precision=0.467 Recall=0.519\n",
      "  Class 1: Precision=0.692 Recall=0.310\n",
      "  Class 2: Precision=0.533 Recall=0.750\n",
      "  Macro Avg: Precision=0.564 Recall=0.526\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4144 - val_accuracy: 0.5341 - val_loss: 1.4004 - train_f1_score: 0.8349 - val_f1_score: 0.5144\n",
      "Epoch 671/700\n",
      "\n",
      "Epoch 671: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 671: Train F1=0.8545 - Val F1=0.5084\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 671: Per-class metrics\n",
      "  Class 0: Precision=0.522 Recall=0.444\n",
      "  Class 1: Precision=0.643 Recall=0.310\n",
      "  Class 2: Precision=0.510 Recall=0.812\n",
      "  Macro Avg: Precision=0.558 Recall=0.522\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9857 - loss: 0.4136 - val_accuracy: 0.5341 - val_loss: 1.4502 - train_f1_score: 0.8545 - val_f1_score: 0.5084\n",
      "Epoch 672/700\n",
      "\n",
      "Epoch 672: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 672: Train F1=0.8705 - Val F1=0.5743\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 672: Per-class metrics\n",
      "  Class 0: Precision=0.542 Recall=0.481\n",
      "  Class 1: Precision=0.586 Recall=0.586\n",
      "  Class 2: Precision=0.600 Recall=0.656\n",
      "  Macro Avg: Precision=0.576 Recall=0.575\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9714 - loss: 0.4299 - val_accuracy: 0.5795 - val_loss: 1.2200 - train_f1_score: 0.8705 - val_f1_score: 0.5743\n",
      "Epoch 673/700\n",
      "\n",
      "Epoch 673: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 673: Train F1=0.9661 - Val F1=0.6400\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 673: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.679 Recall=0.655\n",
      "  Class 2: Precision=0.595 Recall=0.781\n",
      "  Macro Avg: Precision=0.665 Recall=0.639\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9657 - loss: 0.4576 - val_accuracy: 0.6477 - val_loss: 1.1023 - train_f1_score: 0.9661 - val_f1_score: 0.6400\n",
      "Epoch 674/700\n",
      "\n",
      "Epoch 674: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 674: Train F1=0.9246 - Val F1=0.6285\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 674: Per-class metrics\n",
      "  Class 0: Precision=0.619 Recall=0.481\n",
      "  Class 1: Precision=0.629 Recall=0.759\n",
      "  Class 2: Precision=0.656 Recall=0.656\n",
      "  Macro Avg: Precision=0.635 Recall=0.632\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4110 - val_accuracy: 0.6364 - val_loss: 1.1198 - train_f1_score: 0.9246 - val_f1_score: 0.6285\n",
      "Epoch 675/700\n",
      "\n",
      "Epoch 675: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 675: Train F1=0.6416 - Val F1=0.4070\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 675: Per-class metrics\n",
      "  Class 0: Precision=0.340 Recall=0.593\n",
      "  Class 1: Precision=0.550 Recall=0.379\n",
      "  Class 2: Precision=0.429 Recall=0.281\n",
      "  Macro Avg: Precision=0.440 Recall=0.418\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9800 - loss: 0.4190 - val_accuracy: 0.4091 - val_loss: 1.3547 - train_f1_score: 0.6416 - val_f1_score: 0.4070\n",
      "Epoch 676/700\n",
      "\n",
      "Epoch 676: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 676: Train F1=0.9082 - Val F1=0.6126\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 676: Per-class metrics\n",
      "  Class 0: Precision=0.750 Recall=0.333\n",
      "  Class 1: Precision=0.667 Recall=0.759\n",
      "  Class 2: Precision=0.581 Recall=0.781\n",
      "  Macro Avg: Precision=0.666 Recall=0.624\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9886 - loss: 0.4123 - val_accuracy: 0.6364 - val_loss: 1.2053 - train_f1_score: 0.9082 - val_f1_score: 0.6126\n",
      "Epoch 677/700\n",
      "\n",
      "Epoch 677: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 677: Train F1=0.9886 - Val F1=0.6353\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 677: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.444\n",
      "  Class 1: Precision=0.600 Recall=0.724\n",
      "  Class 2: Precision=0.686 Recall=0.750\n",
      "  Macro Avg: Precision=0.651 Recall=0.640\n",
      "11/11 - 1s - 92ms/step - accuracy: 0.9886 - loss: 0.4113 - val_accuracy: 0.6477 - val_loss: 1.1584 - train_f1_score: 0.9886 - val_f1_score: 0.6353\n",
      "Epoch 678/700\n",
      "\n",
      "Epoch 678: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 678: Train F1=1.0000 - Val F1=0.6658\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 678: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.667 Recall=0.750\n",
      "  Macro Avg: Precision=0.675 Recall=0.665\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4186 - val_accuracy: 0.6705 - val_loss: 1.1408 - train_f1_score: 1.0000 - val_f1_score: 0.6658\n",
      "Epoch 679/700\n",
      "\n",
      "Epoch 679: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 679: Train F1=0.8087 - Val F1=0.5325\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 679: Per-class metrics\n",
      "  Class 0: Precision=0.429 Recall=0.556\n",
      "  Class 1: Precision=0.619 Recall=0.448\n",
      "  Class 2: Precision=0.594 Recall=0.594\n",
      "  Macro Avg: Precision=0.547 Recall=0.533\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9857 - loss: 0.4227 - val_accuracy: 0.5341 - val_loss: 1.2643 - train_f1_score: 0.8087 - val_f1_score: 0.5325\n",
      "Epoch 680/700\n",
      "\n",
      "Epoch 680: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 680: Train F1=0.3946 - Val F1=0.3441\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 680: Per-class metrics\n",
      "  Class 0: Precision=0.344 Recall=0.815\n",
      "  Class 1: Precision=0.571 Recall=0.138\n",
      "  Class 2: Precision=0.471 Recall=0.250\n",
      "  Macro Avg: Precision=0.462 Recall=0.401\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9914 - loss: 0.4093 - val_accuracy: 0.3864 - val_loss: 1.5386 - train_f1_score: 0.3946 - val_f1_score: 0.3441\n",
      "Epoch 681/700\n",
      "\n",
      "Epoch 681: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 681: Train F1=0.8841 - Val F1=0.4941\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 681: Per-class metrics\n",
      "  Class 0: Precision=0.406 Recall=0.481\n",
      "  Class 1: Precision=0.647 Recall=0.379\n",
      "  Class 2: Precision=0.513 Recall=0.625\n",
      "  Macro Avg: Precision=0.522 Recall=0.495\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9800 - loss: 0.4158 - val_accuracy: 0.5000 - val_loss: 1.3469 - train_f1_score: 0.8841 - val_f1_score: 0.4941\n",
      "Epoch 682/700\n",
      "\n",
      "Epoch 682: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 682: Train F1=0.9913 - Val F1=0.6314\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 682: Per-class metrics\n",
      "  Class 0: Precision=0.607 Recall=0.630\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.615 Recall=0.750\n",
      "  Macro Avg: Precision=0.646 Recall=0.632\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9943 - loss: 0.4002 - val_accuracy: 0.6364 - val_loss: 1.1966 - train_f1_score: 0.9913 - val_f1_score: 0.6314\n",
      "Epoch 683/700\n",
      "\n",
      "Epoch 683: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 683: Train F1=0.9880 - Val F1=0.6425\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 683: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.606 Recall=0.690\n",
      "  Class 2: Precision=0.657 Recall=0.719\n",
      "  Macro Avg: Precision=0.654 Recall=0.642\n",
      "11/11 - 1s - 120ms/step - accuracy: 0.9943 - loss: 0.4065 - val_accuracy: 0.6477 - val_loss: 1.2675 - train_f1_score: 0.9880 - val_f1_score: 0.6425\n",
      "Epoch 684/700\n",
      "\n",
      "Epoch 684: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 684: Train F1=0.9940 - Val F1=0.6470\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 684: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.571 Recall=0.690\n",
      "  Class 2: Precision=0.724 Recall=0.656\n",
      "  Macro Avg: Precision=0.654 Recall=0.646\n",
      "11/11 - 1s - 115ms/step - accuracy: 0.9886 - loss: 0.4056 - val_accuracy: 0.6477 - val_loss: 1.2350 - train_f1_score: 0.9940 - val_f1_score: 0.6470\n",
      "Epoch 685/700\n",
      "\n",
      "Epoch 685: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 685: Train F1=0.9970 - Val F1=0.6519\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 685: Per-class metrics\n",
      "  Class 0: Precision=0.571 Recall=0.741\n",
      "  Class 1: Precision=0.737 Recall=0.483\n",
      "  Class 2: Precision=0.706 Recall=0.750\n",
      "  Macro Avg: Precision=0.671 Recall=0.658\n",
      "11/11 - 1s - 94ms/step - accuracy: 0.9914 - loss: 0.4083 - val_accuracy: 0.6591 - val_loss: 1.2372 - train_f1_score: 0.9970 - val_f1_score: 0.6519\n",
      "Epoch 686/700\n",
      "\n",
      "Epoch 686: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 686: Train F1=0.9679 - Val F1=0.6508\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 686: Per-class metrics\n",
      "  Class 0: Precision=0.722 Recall=0.481\n",
      "  Class 1: Precision=0.690 Recall=0.690\n",
      "  Class 2: Precision=0.610 Recall=0.781\n",
      "  Macro Avg: Precision=0.674 Recall=0.651\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9800 - loss: 0.4434 - val_accuracy: 0.6591 - val_loss: 1.1284 - train_f1_score: 0.9679 - val_f1_score: 0.6508\n",
      "Epoch 687/700\n",
      "\n",
      "Epoch 687: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 687: Train F1=0.9273 - Val F1=0.5454\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 687: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.593\n",
      "  Class 1: Precision=0.636 Recall=0.241\n",
      "  Class 2: Precision=0.528 Recall=0.875\n",
      "  Macro Avg: Precision=0.610 Recall=0.570\n",
      "11/11 - 1s - 119ms/step - accuracy: 0.9743 - loss: 0.4403 - val_accuracy: 0.5795 - val_loss: 1.3895 - train_f1_score: 0.9273 - val_f1_score: 0.5454\n",
      "Epoch 688/700\n",
      "\n",
      "Epoch 688: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 688: Train F1=0.9372 - Val F1=0.6810\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 688: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.647 Recall=0.759\n",
      "  Class 2: Precision=0.741 Recall=0.625\n",
      "  Macro Avg: Precision=0.685 Recall=0.683\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9800 - loss: 0.4304 - val_accuracy: 0.6818 - val_loss: 1.1144 - train_f1_score: 0.9372 - val_f1_score: 0.6810\n",
      "Epoch 689/700\n",
      "\n",
      "Epoch 689: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 689: Train F1=0.9656 - Val F1=0.6288\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 689: Per-class metrics\n",
      "  Class 0: Precision=0.700 Recall=0.519\n",
      "  Class 1: Precision=0.696 Recall=0.552\n",
      "  Class 2: Precision=0.578 Recall=0.812\n",
      "  Macro Avg: Precision=0.658 Recall=0.628\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9714 - loss: 0.4299 - val_accuracy: 0.6364 - val_loss: 1.1952 - train_f1_score: 0.9656 - val_f1_score: 0.6288\n",
      "Epoch 690/700\n",
      "\n",
      "Epoch 690: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 690: Train F1=0.9334 - Val F1=0.6099\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 690: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.706 Recall=0.414\n",
      "  Class 2: Precision=0.560 Recall=0.875\n",
      "  Macro Avg: Precision=0.660 Recall=0.615\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9914 - loss: 0.4143 - val_accuracy: 0.6250 - val_loss: 1.2896 - train_f1_score: 0.9334 - val_f1_score: 0.6099\n",
      "Epoch 691/700\n",
      "\n",
      "Epoch 691: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 691: Train F1=0.9943 - Val F1=0.6694\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 691: Per-class metrics\n",
      "  Class 0: Precision=0.692 Recall=0.667\n",
      "  Class 1: Precision=0.600 Recall=0.621\n",
      "  Class 2: Precision=0.719 Recall=0.719\n",
      "  Macro Avg: Precision=0.670 Recall=0.669\n",
      "11/11 - 1s - 113ms/step - accuracy: 0.9800 - loss: 0.4136 - val_accuracy: 0.6705 - val_loss: 1.2117 - train_f1_score: 0.9943 - val_f1_score: 0.6694\n",
      "Epoch 692/700\n",
      "\n",
      "Epoch 692: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 692: Train F1=0.9802 - Val F1=0.6306\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 692: Per-class metrics\n",
      "  Class 0: Precision=0.714 Recall=0.556\n",
      "  Class 1: Precision=0.714 Recall=0.517\n",
      "  Class 2: Precision=0.565 Recall=0.812\n",
      "  Macro Avg: Precision=0.665 Recall=0.628\n",
      "11/11 - 1s - 96ms/step - accuracy: 0.9886 - loss: 0.4147 - val_accuracy: 0.6364 - val_loss: 1.2069 - train_f1_score: 0.9802 - val_f1_score: 0.6306\n",
      "Epoch 693/700\n",
      "\n",
      "Epoch 693: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 693: Train F1=0.9858 - Val F1=0.6583\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 693: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.667\n",
      "  Class 1: Precision=0.708 Recall=0.586\n",
      "  Class 2: Precision=0.622 Recall=0.719\n",
      "  Macro Avg: Precision=0.666 Recall=0.657\n",
      "11/11 - 1s - 116ms/step - accuracy: 0.9886 - loss: 0.4120 - val_accuracy: 0.6591 - val_loss: 1.1722 - train_f1_score: 0.9858 - val_f1_score: 0.6583\n",
      "Epoch 694/700\n",
      "\n",
      "Epoch 694: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 694: Train F1=0.9684 - Val F1=0.6360\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 694: Per-class metrics\n",
      "  Class 0: Precision=0.640 Recall=0.593\n",
      "  Class 1: Precision=0.688 Recall=0.759\n",
      "  Class 2: Precision=0.581 Recall=0.562\n",
      "  Macro Avg: Precision=0.636 Recall=0.638\n",
      "11/11 - 1s - 95ms/step - accuracy: 0.9829 - loss: 0.4199 - val_accuracy: 0.6364 - val_loss: 1.1558 - train_f1_score: 0.9684 - val_f1_score: 0.6360\n",
      "Epoch 695/700\n",
      "\n",
      "Epoch 695: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 695: Train F1=0.9768 - Val F1=0.6221\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 695: Per-class metrics\n",
      "  Class 0: Precision=0.667 Recall=0.519\n",
      "  Class 1: Precision=0.647 Recall=0.759\n",
      "  Class 2: Precision=0.576 Recall=0.594\n",
      "  Macro Avg: Precision=0.630 Recall=0.624\n",
      "11/11 - 1s - 118ms/step - accuracy: 0.9914 - loss: 0.4059 - val_accuracy: 0.6250 - val_loss: 1.2102 - train_f1_score: 0.9768 - val_f1_score: 0.6221\n",
      "Epoch 696/700\n",
      "\n",
      "Epoch 696: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 696: Train F1=0.9305 - Val F1=0.6057\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 696: Per-class metrics\n",
      "  Class 0: Precision=0.609 Recall=0.519\n",
      "  Class 1: Precision=0.600 Recall=0.828\n",
      "  Class 2: Precision=0.640 Recall=0.500\n",
      "  Macro Avg: Precision=0.616 Recall=0.615\n",
      "11/11 - 1s - 93ms/step - accuracy: 0.9914 - loss: 0.4019 - val_accuracy: 0.6136 - val_loss: 1.2371 - train_f1_score: 0.9305 - val_f1_score: 0.6057\n",
      "Epoch 697/700\n",
      "\n",
      "Epoch 697: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 697: Train F1=0.9190 - Val F1=0.6012\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 697: Per-class metrics\n",
      "  Class 0: Precision=0.533 Recall=0.593\n",
      "  Class 1: Precision=0.588 Recall=0.690\n",
      "  Class 2: Precision=0.708 Recall=0.531\n",
      "  Macro Avg: Precision=0.610 Recall=0.604\n",
      "11/11 - 1s - 115ms/step - accuracy: 1.0000 - loss: 0.3981 - val_accuracy: 0.6023 - val_loss: 1.2173 - train_f1_score: 0.9190 - val_f1_score: 0.6012\n",
      "Epoch 698/700\n",
      "\n",
      "Epoch 698: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 698: Train F1=0.9701 - Val F1=0.6523\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 698: Per-class metrics\n",
      "  Class 0: Precision=0.636 Recall=0.519\n",
      "  Class 1: Precision=0.656 Recall=0.724\n",
      "  Class 2: Precision=0.676 Recall=0.719\n",
      "  Macro Avg: Precision=0.656 Recall=0.654\n",
      "11/11 - 1s - 117ms/step - accuracy: 0.9886 - loss: 0.4037 - val_accuracy: 0.6591 - val_loss: 1.1610 - train_f1_score: 0.9701 - val_f1_score: 0.6523\n",
      "Epoch 699/700\n",
      "\n",
      "Epoch 699: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 699: Train F1=0.9764 - Val F1=0.6644\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 699: Per-class metrics\n",
      "  Class 0: Precision=0.778 Recall=0.519\n",
      "  Class 1: Precision=0.645 Recall=0.690\n",
      "  Class 2: Precision=0.641 Recall=0.781\n",
      "  Macro Avg: Precision=0.688 Recall=0.663\n",
      "11/11 - 1s - 114ms/step - accuracy: 0.9943 - loss: 0.3953 - val_accuracy: 0.6705 - val_loss: 1.2150 - train_f1_score: 0.9764 - val_f1_score: 0.6644\n",
      "Epoch 700/700\n",
      "\n",
      "Epoch 700: val_accuracy did not improve from 0.72727\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 700: Train F1=0.9885 - Val F1=0.6265\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "Epoch 700: Per-class metrics\n",
      "  Class 0: Precision=0.652 Recall=0.556\n",
      "  Class 1: Precision=0.652 Recall=0.517\n",
      "  Class 2: Precision=0.619 Recall=0.812\n",
      "  Macro Avg: Precision=0.641 Recall=0.628\n",
      "11/11 - 1s - 112ms/step - accuracy: 0.9914 - loss: 0.4114 - val_accuracy: 0.6364 - val_loss: 1.3084 - train_f1_score: 0.9885 - val_f1_score: 0.6265\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "==============================\n",
      "  CONFIDENCE INTERVALS (95%)\n",
      "==============================\n",
      "\n",
      "Macro AUC = 0.7823  (95% CI: 0.7000 – 0.8515)\n",
      "\n",
      "Per-class ROC AUC with 95% CI:\n",
      "  1: 0.7892  (95% CI: 0.6708 – 0.8880)\n",
      "  4: 0.7414  (95% CI: 0.6303 – 0.8382)\n",
      "  5: 0.8150  (95% CI: 0.7114 – 0.9104)\n",
      "\n",
      "Per-class Precision–Recall AUC with 95% CI:\n",
      "  1 PR-AUC: 0.6305  (95% CI: 0.4302 – 0.8200)\n",
      "  4 PR-AUC: 0.5502  (95% CI: 0.3648 – 0.7276)\n",
      "  5 PR-AUC: 0.7744  (95% CI: 0.6208 – 0.8881)\n",
      "\n",
      "Done computing bootstrap confidence intervals.\n",
      "\n",
      "\n",
      "✅ Validation النتائج:\n",
      "  Accuracy : 0.6364\n",
      "  F1       : 0.6297\n",
      "  MCC      : 0.4560\n",
      "  Precision: 0.6401\n",
      "  Recall   : 0.6364\n",
      "\n",
      "Per-class report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6522    0.5556    0.6000        27\n",
      "           1     0.6522    0.5172    0.5769        29\n",
      "           2     0.6190    0.8125    0.7027        32\n",
      "\n",
      "    accuracy                         0.6364        88\n",
      "   macro avg     0.6411    0.6284    0.6265        88\n",
      "weighted avg     0.6401    0.6364    0.6297        88\n",
      "\n",
      "✅ Saved history to: history_Chinese_diaper_sleepy_uncomfortable.pkl\n",
      "✅ checkpoint_path: best_Chinese_diaper_sleepy_uncomfortable_batch32.keras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef, precision_score, recall_score,\n",
    "    classification_report\n",
    ")\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Ensure shapes are Conv2D-compatible: (N,H,W,1)\n",
    "# ============================================================\n",
    "def ensure_4d(X, name=\"X\"):\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 3:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        print(f\"✅ Added channel dim to {name}: now {X.shape}\")\n",
    "    elif X.ndim == 4:\n",
    "        print(f\"✅ {name} already 4D: {X.shape}\")\n",
    "    else:\n",
    "        raise ValueError(f\"{name} must be 3D or 4D. Got shape {X.shape}\")\n",
    "    return X\n",
    "\n",
    "X_train_split = ensure_4d(X_train_split, \"X_train_split\")\n",
    "X_val_split   = ensure_4d(X_val_split,   \"X_val_split\")\n",
    "\n",
    "# Optional: only if you actually use X_test/y_test later\n",
    "if \"X_test\" in globals():\n",
    "    X_test = ensure_4d(X_test, \"X_test\")\n",
    "\n",
    "print(\"X_train_split shape:\", X_train_split.shape)\n",
    "print(\"X_val_split shape  :\", X_val_split.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 1) 🔴 REMAP LABELS from old IDs {1,4,5} -> new IDs {0,1,2}\n",
    "# ============================================================\n",
    "y_train_split = np.asarray(y_train_split).astype(int)\n",
    "y_val_split   = np.asarray(y_val_split).astype(int)\n",
    "\n",
    "old_ids = [1, 4, 5]\n",
    "old_to_new = {1: 0, 4: 1, 5: 2}\n",
    "new_to_name = {0: \"Diaper\", 1: \"Sleepy\", 2: \"Uncomfortable\"}  # optional\n",
    "\n",
    "# Safety checks\n",
    "if not set(np.unique(y_train_split)).issubset(set(old_ids)):\n",
    "    raise ValueError(f\"y_train_split has labels outside {old_ids}: {np.unique(y_train_split)}\")\n",
    "\n",
    "if not set(np.unique(y_val_split)).issubset(set(old_ids)):\n",
    "    raise ValueError(f\"y_val_split has labels outside {old_ids}: {np.unique(y_val_split)}\")\n",
    "\n",
    "# Actual remapping\n",
    "y_train_split = np.array([old_to_new[v] for v in y_train_split], dtype=np.int64)\n",
    "y_val_split   = np.array([old_to_new[v] for v in y_val_split], dtype=np.int64)\n",
    "\n",
    "print(\"✅ Remapped labels:\")\n",
    "print(\"  unique y_train_split:\", np.unique(y_train_split))\n",
    "print(\"  unique y_val_split  :\", np.unique(y_val_split))\n",
    "print(\"  mapping:\", new_to_name)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) num_classes (NOW SAFE)\n",
    "# ============================================================\n",
    "num_classes = int(len(np.unique(y_train_split)))\n",
    "print(\"✅ num_classes:\", num_classes)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Correct num_classes based on the labels YOU TRAIN ON\n",
    "# ============================================================\n",
    "y_train_split = np.asarray(y_train_split).astype(int)\n",
    "y_val_split   = np.asarray(y_val_split).astype(int)\n",
    "\n",
    "num_classes = int(len(np.unique(y_train_split)))\n",
    "print(\"✅ num_classes:\", num_classes, \"| unique y_train_split:\", np.unique(y_train_split))\n",
    "\n",
    "# Safety: ensure labels are in [0..num_classes-1]\n",
    "if np.min(y_train_split) < 0 or np.max(y_train_split) >= num_classes:\n",
    "    raise ValueError(\n",
    "        f\"y_train_split labels must be in [0..{num_classes-1}]. \"\n",
    "        f\"Got min={np.min(y_train_split)}, max={np.max(y_train_split)}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 2) Compute class weights from y_train_split (NOT y_train)\n",
    "# ============================================================\n",
    "classes = np.unique(y_train_split)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train_split\n",
    ")\n",
    "class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights)}\n",
    "print(\"✅ Class weights:\", class_weight_dict)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Input shape and model creation\n",
    "# ============================================================\n",
    "input_shape = X_train_split.shape[1:]  # (H,W,1)\n",
    "print(\"✅ input_shape:\", input_shape)\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "print(\"✅ Model built\")\n",
    "\n",
    "# ============================================================\n",
    "# 4) Callbacks\n",
    "# ============================================================\n",
    "save_best_callback = SaveBestModelOnF1(monitor='val_f1_score', save_dir='saved_models')\n",
    "\n",
    "# If you want checkpoint by val_accuracy (your old behavior)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# optional callbacks (enable if you want)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_f1_score',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5) One-hot encode labels (since you use CategoricalCrossentropy)\n",
    "# ============================================================\n",
    "y_train_onehot = to_categorical(y_train_split, num_classes=num_classes)\n",
    "y_val_onehot   = to_categorical(y_val_split,   num_classes=num_classes)\n",
    "\n",
    "# ============================================================\n",
    "# 6) Your custom callbacks (make sure they expect int labels)\n",
    "# ============================================================\n",
    "f1_callback = F1ScoreCallback(X_train_split, y_train_split, X_val_split, y_val_split)\n",
    "metrics_logger = MetricsLogger(X_val_split, y_val_split)\n",
    "\n",
    "# If you have this callback defined; otherwise comment it out\n",
    "if \"AUCPlotsCallback\" in globals():\n",
    "    auc_callback = AUCPlotsCallback(\n",
    "        X_val_split,\n",
    "        y_val_onehot,\n",
    "        class_names=list(class_names) if \"class_names\" in globals() else None\n",
    "    )\n",
    "    extra_callbacks = [auc_callback]\n",
    "else:\n",
    "    extra_callbacks = []\n",
    "\n",
    "# ============================================================\n",
    "# 7) Train\n",
    "# ============================================================\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_onehot,\n",
    "    validation_data=(X_val_split, y_val_onehot),\n",
    "    epochs=700,\n",
    "    batch_size=32,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        model_checkpoint,\n",
    "        f1_callback,\n",
    "        save_best_callback,\n",
    "        metrics_logger,\n",
    "        # reduce_lr,        # ✅ uncomment if you want\n",
    "        # early_stopping,   # ✅ uncomment if you want\n",
    "        *extra_callbacks\n",
    "    ],\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8) Evaluate on validation (after training)\n",
    "# ============================================================\n",
    "val_probs = model.predict(X_val_split, verbose=0)\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "val_f1 = f1_score(y_val_split, val_preds, average='weighted')\n",
    "val_mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "val_precision = precision_score(y_val_split, val_preds, average='weighted', zero_division=0)\n",
    "val_recall = recall_score(y_val_split, val_preds, average='weighted', zero_division=0)\n",
    "val_accuracy = float(np.mean(val_preds == y_val_split))\n",
    "\n",
    "print(f\"\\n✅ Validation النتائج:\")\n",
    "print(f\"  Accuracy : {val_accuracy:.4f}\")\n",
    "print(f\"  F1       : {val_f1:.4f}\")\n",
    "print(f\"  MCC      : {val_mcc:.4f}\")\n",
    "print(f\"  Precision: {val_precision:.4f}\")\n",
    "print(f\"  Recall   : {val_recall:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class report:\")\n",
    "print(classification_report(y_val_split, val_preds, digits=4))\n",
    "\n",
    "# ============================================================\n",
    "# 9) Save history\n",
    "# ============================================================\n",
    "with open(history_name, \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(f\"✅ Saved history to: {history_name}\")\n",
    "print(f\"✅ checkpoint_path: {checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216b8df-55ef-4792-acfc-1c2dc8b7c329",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a55a3731-5b1c-4c3f-a115-019fc5f93efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "#  LOSS PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history.get('loss', []), label='Train Loss')\n",
    "plt.plot(history.history.get('val_loss', []), label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "#  ACCURACY PLOT\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(history.history.get('accuracy', []), label='Train Accuracy')\n",
    "plt.plot(history.history.get('val_accuracy', []), label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "#  F1-SCORE PLOT  (From your callback)\n",
    "# ================================\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(f1_callback.train_f1s, label='Train F1 (macro)')\n",
    "plt.plot(f1_callback.val_f1s, label='Val F1 (macro)')\n",
    "plt.title(\"F1 Score Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1 Score (macro)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2f06280-7e04-4c1b-92fd-d79e9887f372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_chinese[i] for i in labels]   # adjust mapping if not Chinese set\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=tick_labels, yticklabels=tick_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – Validation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b47476c-eada-4e99-9d21-a1c426bfdb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curves(y_true_onehot, y_pred_prob, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    n_classes = y_true_onehot.shape[1]\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_onehot[:, c], y_pred_prob[:, c])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr, tpr, lw=2,\n",
    "                 label=f\"{class_names[c]} (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "    # Diagonal line\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves (One-vs-Rest)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    plt.show()\n",
    "\n",
    "y_pred_prob = model.predict(X_val_split)\n",
    "y_true_onehot = y_val_onehot\n",
    "\n",
    "class_names = list(le.classes_)   # <-- FIXED\n",
    "\n",
    "plot_roc_curves(y_true_onehot, y_pred_prob, class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d90e0b0e-3f81-4108-bd4e-5c39ee7cb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Validation Metrics =====\n",
      "Accuracy   : 0.6364\n",
      "F1-micro   : 0.6364\n",
      "F1-macro   : 0.6265\n",
      "MCC        : 0.4560\n",
      "ROC-AUC    : 0.7846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef, roc_auc_score,\n",
    "    accuracy_score, precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "acc = accuracy_score(y_val_split, val_preds)\n",
    "\n",
    "# ---- ROC-AUC (One-vs-Rest) ----\n",
    "y_val_bin = label_binarize(y_val_split, classes=labels)\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_val_bin, val_probs, multi_class=\"ovr\", average=\"macro\"\n",
    "    )\n",
    "except:\n",
    "    roc_auc = None\n",
    "\n",
    "print(\"\\n===== Validation Metrics =====\")\n",
    "print(f\"Accuracy   : {acc:.4f}\")\n",
    "print(f\"F1-micro   : {f1_micro:.4f}\")\n",
    "print(f\"F1-macro   : {f1_macro:.4f}\")\n",
    "print(f\"MCC        : {mcc:.4f}\")\n",
    "print(f\"ROC-AUC    : {roc_auc:.4f}\" if roc_auc is not None else \"ROC-AUC: unavailable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1dc42-a6d4-4c10-b8f4-bce30b3e80dd",
   "metadata": {},
   "source": [
    "## Plot and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aba2fc81-3d2d-4b34-8bdc-dfcabf0a0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/1451947756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Keep only probs for classes of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mval_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_probs_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_classes\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape (N, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Recompute predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, matthews_corrcoef, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# -------------------- Setup --------------------\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Classes of interest in original encoding\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# Map to new encoded ids {0,1,2}\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# -------------------- Predictions --------------------\n",
    "val_probs_full = model.predict(X_val_split)\n",
    "\n",
    "# Keep only probs for classes of interest\n",
    "val_probs = val_probs_full[:, unique_classes]  # shape (N, 3)\n",
    "\n",
    "# Recompute predictions\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# -------------------- Confusion Matrix --------------------\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_merge_3mood[i] for i in labels]\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=tick_labels,\n",
    "    yticklabels=tick_labels,\n",
    "    annot_kws={\"size\": 16}\n",
    ")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "cm_path = os.path.join(output_dir, f\"confusion_matrix_{timestamp}.png\")\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "\n",
    "# Binarize labels for ROC AUC\n",
    "y_val_bin = label_binarize(y_val_split, classes=np.unique(y_val_split))\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_val_bin, val_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "except ValueError:\n",
    "    roc_auc = None\n",
    "\n",
    "report = classification_report(\n",
    "    y_val_split,\n",
    "    val_preds,\n",
    "    target_names=[id2cls_merge_3mood[i] for i in np.unique(y_val_split)],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "stats_path = os.path.join(output_dir, f\"validation_stats_{timestamp}.txt\")\n",
    "with open(stats_path, \"w\") as f:\n",
    "    f.write(\"Validation Metrics:\\n\")\n",
    "    f.write(f\"F1 (micro): {f1_micro:.4f}\\n\")\n",
    "    f.write(f\"F1 (macro): {f1_macro:.4f}\\n\")\n",
    "    f.write(f\"MCC       : {mcc:.4f}\\n\")\n",
    "    f.write(f\"ROC AUC   : {roc_auc:.4f}\\n\" if roc_auc is not None else \"ROC AUC not available\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"✅ Saved confusion matrix to {cm_path}\")\n",
    "print(f\"✅ Saved metrics to {stats_path}\")\n",
    "\n",
    "# -------------------- Training Curves --------------------\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "curve_path = os.path.join(output_dir, f\"training_curves_{timestamp}.png\")\n",
    "plt.savefig(curve_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved training curves to {curve_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fa5c24f-c8af-44b9-8011-95892c6fb5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_360842/2052889078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Keep only columns for the 3 moods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mval_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_probs_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_classes\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# shape (N, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Recompute predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# -------------------- Setup --------------------\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Classes of interest in original encoding\n",
    "keep_classes = [1, 4, 5]   # diaper=1, sleepy=4, uncomfortable=5\n",
    "class_names = {1: \"diaper\", 4: \"sleepy\", 5: \"uncomfortable\"}\n",
    "\n",
    "# Map old IDs -> new {0,1,2}\n",
    "unique_classes = sorted(keep_classes)  # [1,4,5]\n",
    "class2newid = {old: new for new, old in enumerate(unique_classes)}\n",
    "id2cls_merge_3mood = {new: class_names[old] for old, new in class2newid.items()}\n",
    "\n",
    "# -------------------- Predictions --------------------\n",
    "val_probs_full = model.predict(X_val_split)     # shape (N, all_classes)\n",
    "\n",
    "# Keep only columns for the 3 moods\n",
    "val_probs = val_probs_full[:, unique_classes]   # shape (N, 3)\n",
    "\n",
    "# Recompute predictions\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# -------------------- Confusion Matrix --------------------\n",
    "cm = confusion_matrix(y_val_split, val_preds)\n",
    "labels = np.unique(y_val_split)\n",
    "tick_labels = [id2cls_merge_3mood[i] for i in labels]\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=tick_labels,\n",
    "    yticklabels=tick_labels,\n",
    "    annot_kws={\"size\": 16}\n",
    ")\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "cm_path = os.path.join(output_dir, f\"confusion_matrix_{timestamp}.png\")\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# -------------------- Metrics --------------------\n",
    "f1_micro = f1_score(y_val_split, val_preds, average='micro')\n",
    "f1_macro = f1_score(y_val_split, val_preds, average='macro')\n",
    "mcc = matthews_corrcoef(y_val_split, val_preds)\n",
    "\n",
    "# Binarize labels for ROC AUC (3 classes only)\n",
    "y_val_bin = label_binarize(y_val_split, classes=np.arange(len(unique_classes)))\n",
    "\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_val_bin, val_probs, average=\"macro\", multi_class=\"ovr\")\n",
    "except ValueError:\n",
    "    roc_auc = None\n",
    "\n",
    "report = classification_report(\n",
    "    y_val_split,\n",
    "    val_preds,\n",
    "    target_names=[id2cls_merge_3mood[i] for i in np.unique(y_val_split)],\n",
    "    digits=4\n",
    ")\n",
    "\n",
    "stats_path = os.path.join(output_dir, f\"validation_stats_{timestamp}.txt\")\n",
    "with open(stats_path, \"w\") as f:\n",
    "    f.write(\"Validation Metrics:\\n\")\n",
    "    f.write(f\"F1 (micro): {f1_micro:.4f}\\n\")\n",
    "    f.write(f\"F1 (macro): {f1_macro:.4f}\\n\")\n",
    "    f.write(f\"MCC       : {mcc:.4f}\\n\")\n",
    "    f.write(f\"ROC AUC   : {roc_auc:.4f}\\n\" if roc_auc is not None else \"ROC AUC not available\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\nClass mapping:\\n\")\n",
    "    f.write(str(id2cls_merge_3mood))\n",
    "\n",
    "print(f\"✅ Saved confusion matrix to {cm_path}\")\n",
    "print(f\"✅ Saved metrics to {stats_path}\")\n",
    "\n",
    "# -------------------- Training Curves --------------------\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "curve_path = os.path.join(output_dir, f\"training_curves_{timestamp}.png\")\n",
    "plt.savefig(curve_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"✅ Saved training curves to {curve_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eab58be3-a19e-4ff9-a732-eef212800b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Total samples        : 88\n",
      "Top-1 correct        : 65\n",
      "Top-2 correct        : 79\n",
      "Wrong top-1 but fixed by 2nd : 14\n",
      "Top-1 Accuracy       : 0.7386\n",
      "Top-2 Accuracy       : 0.8977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get full probability predictions (shape: [n_samples, n_classes])\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)   # top-1 predictions\n",
    "\n",
    "# Sort predictions to get top-2 indices\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]  # last two = top-2\n",
    "\n",
    "# Boolean: was the correct label in top-2 predictions?\n",
    "correct_top2 = [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    "\n",
    "# Count stats\n",
    "top1_correct = np.sum(val_preds == y_val_split)\n",
    "top2_correct = np.sum(correct_top2)\n",
    "only_second_correct = np.sum((val_preds != y_val_split) & np.array(correct_top2))\n",
    "\n",
    "print(f\"Total samples        : {len(y_val_split)}\")\n",
    "print(f\"Top-1 correct        : {top1_correct}\")\n",
    "print(f\"Top-2 correct        : {top2_correct}\")\n",
    "print(f\"Wrong top-1 but fixed by 2nd : {only_second_correct}\")\n",
    "print(f\"Top-1 Accuracy       : {top1_correct/len(y_val_split):.4f}\")\n",
    "print(f\"Top-2 Accuracy       : {top2_correct/len(y_val_split):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67b63184-4420-4b2a-ac51-b493599647b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Wrong top-1 but correct at 2nd prediction (per class):\n",
      "awake          : 11\n",
      "diaper         : 6\n",
      "hug            : 4\n",
      "hungry         : 0\n",
      "sleepy         : 0\n",
      "uncomfortable  : 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get probability predictions\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# Top-2 indices per sample\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]\n",
    "\n",
    "# Identify \"wrong top-1 but fixed by top-2\"\n",
    "wrong_fixed = (val_preds != y_val_split) & np.array(\n",
    "    [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    ")\n",
    "\n",
    "# # Class mapping (example, update to match your dataset)\n",
    "# id2cls = {\n",
    "#     0: \"hungry\",\n",
    "#     1: \"awake\",\n",
    "#     2: \"sleepy\",\n",
    "#     3: \"diaper\",\n",
    "#     4: \"uncomfortable\"\n",
    "# }\n",
    "\n",
    "# Count per-class\n",
    "counts = {cls: 0 for cls in id2cls_chinese.values()}\n",
    "for i, flag in enumerate(wrong_fixed):\n",
    "    if flag:  # case where top-2 fixed it\n",
    "        cls_name = id2cls_chinese[y_val_split[i]]\n",
    "        counts[cls_name] += 1\n",
    "\n",
    "print(\"Wrong top-1 but correct at 2nd prediction (per class):\")\n",
    "for cls, c in counts.items():\n",
    "    print(f\"{cls:15s}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35bf1b1b-d9f3-4011-9a22-cd1e5860ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Wrong top-1 but correct at 2nd prediction (per class):\n",
      "awake          : 11 cases\n",
      "   → misclassified as hug: 8\n",
      "   → misclassified as diaper: 3\n",
      "diaper         : 6 cases\n",
      "   → misclassified as hug: 2\n",
      "   → misclassified as awake: 4\n",
      "hug            : 4 cases\n",
      "   → misclassified as diaper: 2\n",
      "   → misclassified as awake: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get probability predictions\n",
    "val_probs = model.predict(X_val_split)\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "# Top-2 indices per sample\n",
    "top2_preds = np.argsort(val_probs, axis=1)[:, -2:]\n",
    "\n",
    "# Identify \"wrong top-1 but fixed by top-2\"\n",
    "wrong_fixed = (val_preds != y_val_split) & np.array(\n",
    "    [y_val_split[i] in top2_preds[i] for i in range(len(y_val_split))]\n",
    ")\n",
    "\n",
    "\n",
    "# Count per true class and record wrong top-1s\n",
    "counts = {cls: 0 for cls in id2cls_chinese.values()}\n",
    "confusions = {cls: [] for cls in id2cls_chinese.values()}\n",
    "\n",
    "for i, flag in enumerate(wrong_fixed):\n",
    "    if flag:\n",
    "        true_cls = id2cls_chinese[y_val_split[i]]\n",
    "        wrong_cls = id2cls_chinese[val_preds[i]]\n",
    "        counts[true_cls] += 1\n",
    "        confusions[true_cls].append(wrong_cls)\n",
    "\n",
    "# Print summary\n",
    "print(\"Wrong top-1 but correct at 2nd prediction (per class):\")\n",
    "for cls, c in counts.items():\n",
    "    if c > 0:\n",
    "        wrong_breakdown = {w: confusions[cls].count(w) for w in set(confusions[cls])}\n",
    "        print(f\"{cls:15s}: {c} cases\")\n",
    "        for wrong, wc in wrong_breakdown.items():\n",
    "            print(f\"   → misclassified as {wrong}: {wc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c5ab8-32f2-4bb9-90e6-fcaf48a9ae63",
   "metadata": {},
   "source": [
    "# Avg smooth Ensemble Chinese baby cry and reverb chinese baby cry and Baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de653c66-ea12-4eaf-a36e-604d73cd7138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5225bdb-cb76-41f7-a63c-5d098c85fb93",
   "metadata": {},
   "source": [
    "# Agree vote Ensemble Chinese baby cry and reverb chinese baby cry and Baby2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732a77c-eaf6-4c33-be89-03c202e37834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e209a6-74dc-4f1f-807f-ffbfd54e0d2b",
   "metadata": {},
   "source": [
    "# Statistical test analysis of ensemble merged and single trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de640d-d76d-4385-8afb-1d47a545d5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "/usr/bin/python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
